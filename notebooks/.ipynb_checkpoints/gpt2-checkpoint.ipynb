{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "device = \"cuda:1\"\n",
    "model_id = \"gpt2-large\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_perplexity(dialog, prmt, mod_idx=None):\n",
    "    # Tokenize both utterances\n",
    "    perpl = []\n",
    "    \n",
    "    for idx, (cntx, tkn) in enumerate(zip(dialog[:-1], dialog[1:])):\n",
    "        if mod_idx is None:\n",
    "            add_ = \"\"\n",
    "        else:\n",
    "            # if it is not [MOD]'s turn and we are not trying to predict [MOD]'s utterance, we want to add its utterance as context!\n",
    "            if (\"[MOD]\" not in cntx and \"[MOD]\" not in tkn) and idx!=0:\n",
    "                add_ = np.asarray(dialog)[mod_idx[idx] + 1]\n",
    "            else:\n",
    "                add_ = \"\"\n",
    "        \n",
    "        prompt = tokenizer.encode(prmt, return_tensors=\"pt\") \n",
    "        context = tokenizer.encode(add_ + \" \" + cntx, return_tensors=\"pt\")\n",
    "        tokens = tokenizer.encode(tkn, return_tensors=\"pt\")\n",
    "        encodings = torch.cat((prompt, context,tokens), dim=1)\n",
    "        max_length = model.config.n_positions\n",
    "\n",
    "        stride = 2024\n",
    "        seq_len = encodings.size(1)\n",
    "\n",
    "        nlls = []\n",
    "        prev_end_loc = prompt.size(1) + context.size(1)\n",
    "\n",
    "        for begin_loc in range(0, seq_len, stride):\n",
    "            end_loc = min(begin_loc + max_length, seq_len)\n",
    "            trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "            input_ids = encodings[:, begin_loc:end_loc].to(device)\n",
    "            target_ids = input_ids.clone()\n",
    "            target_ids[:, :-trg_len] = -100\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, labels=target_ids)\n",
    "\n",
    "                # loss is calculated using CrossEntropyLoss which averages over valid labels\n",
    "                # N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\n",
    "                # to the left by 1.\n",
    "                neg_log_likelihood = outputs.loss\n",
    "\n",
    "            nlls.append(neg_log_likelihood)\n",
    "\n",
    "            prev_end_loc = end_loc\n",
    "            if end_loc == seq_len:\n",
    "                break\n",
    "        perpl.append(torch.exp(torch.stack(nlls).mean()).item())\n",
    "        print(torch.exp(torch.stack(nlls).mean()).item())\n",
    "    return perpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_perplexity(dialog, prmt, mod_idx=None):\n",
    "    # Tokenize both utterances\n",
    "    perpl = []\n",
    "    \n",
    "    for idx, cntx in enumerate(dialog[1:]):\n",
    "        \n",
    "        prompt = tokenizer.encode(prmt, return_tensors=\"pt\") \n",
    "        context += tokenizer.encode(cntx, return_tensors=\"pt\")\n",
    "        tokens = tokenizer.encode(tkn, return_tensors=\"pt\")\n",
    "\n",
    "        encodings = torch.cat((prompt, context,tokens), dim=1)\n",
    "        max_length = model.config.n_positions\n",
    "\n",
    "        stride = 2024\n",
    "        seq_len = encodings.size(1)\n",
    "\n",
    "        nlls = []\n",
    "        prev_end_loc = prompt.size(1) + context.size(1)\n",
    "        \n",
    "        for begin_loc in range(0, seq_len, stride):\n",
    "            end_loc = min(begin_loc + max_length, seq_len)\n",
    "            trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "            input_ids = encodings[:, begin_loc:end_loc].to(device)\n",
    "            target_ids = input_ids.clone()\n",
    "            target_ids[:, :-trg_len] = -100\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, labels=target_ids)\n",
    "                neg_log_likelihood = outputs.loss\n",
    "\n",
    "            nlls.append(neg_log_likelihood)\n",
    "\n",
    "            prev_end_loc = end_loc\n",
    "            if end_loc == seq_len:\n",
    "                break\n",
    "        perpl.append(torch.exp(torch.stack(nlls).mean()).item())\n",
    "        print(torch.exp(torch.stack(nlls).mean()).item())\n",
    "    return perpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [0] doesn't match the broadcast shape [1, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[([^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]]+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m matches \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(pattern, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(dialog))\n\u001b[0;32m---> 13\u001b[0m perpl \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdialog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprmt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patt \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(matches):\n\u001b[1;32m     16\u001b[0m     idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([index \u001b[38;5;28;01mfor\u001b[39;00m index, element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(matches) \u001b[38;5;28;01mif\u001b[39;00m element \u001b[38;5;241m==\u001b[39m patt])\n",
      "Cell \u001b[0;32mIn[40], line 11\u001b[0m, in \u001b[0;36mcompute_perplexity\u001b[0;34m(dialog, prmt, mod_idx)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (cntx, tkn) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(dialog[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dialog[\u001b[38;5;241m1\u001b[39m:])):\n\u001b[1;32m     10\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(prmt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m---> 11\u001b[0m     context \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(cntx, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(tkn, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((prompt, context,tokens), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [0] doesn't match the broadcast shape [1, 0]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "# Example usage\n",
    "dialog = [\"\",\n",
    "          \"[Mark]: How are you doing today?\",\n",
    "          \"[Lisa]: I'm good, thanks for asking.\",\n",
    "          \"[Mark]: Did you complete the report?\",\n",
    "          \"[Lisa]: Not yet, but I'll have it ready by tomorrow.\"]\n",
    "prmt = \"This is a conversation between Mark and Lisa.\\nPredict the next most probable utterance:\"\n",
    "\n",
    "pattern = r'\\[([^\\]]+)\\]'\n",
    "matches = re.findall(pattern, \"\".join(dialog))\n",
    "perpl = compute_perplexity(dialog, prmt)\n",
    "\n",
    "for patt in np.unique(matches):\n",
    "    idx = np.asarray([index for index, element in enumerate(matches) if element == patt])\n",
    "    print(f\"{patt} :\", np.mean(np.asarray(perpl)[idx]))\n",
    "\n",
    "for d, p in zip(dialog[1:], perpl):\n",
    "    print(f\"{d}, {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:  This is a conversation between D and S.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [D]: Hey, I've been thinking about our upcoming project. I believe we should take a more assertive approach to meet our deadlines.\n",
      "25.97359848022461\n",
      "prompt:  This is a conversation between D and S.\n",
      "Predict the next most probable utterance:\n",
      "context:  [D]: Hey, I've been thinking about our upcoming project. I believe we should take a more assertive approach to meet our deadlines.\n",
      "token:  [S]: Oh, absolutely. I completely agree. What specific tasks do you think I should focus on to support our goals?\n",
      "13.740754127502441\n",
      "prompt:  This is a conversation between D and S.\n",
      "Predict the next most probable utterance:\n",
      "context:  [S]: Oh, absolutely. I completely agree. What specific tasks do you think I should focus on to support our goals?\n",
      "token:  [D]: Great. I need you to take charge of the research phase. Make sure to gather all the relevant information and compile a detailed report by the end of the week.\n",
      "10.73189640045166\n",
      "prompt:  This is a conversation between D and S.\n",
      "Predict the next most probable utterance:\n",
      "context:  [D]: Great. I need you to take charge of the research phase. Make sure to gather all the relevant information and compile a detailed report by the end of the week.\n",
      "token:  [S]: Of course, I'll get started right away. Should I consider any specific sources or themes?\n",
      "23.564462661743164\n",
      "prompt:  This is a conversation between D and S.\n",
      "Predict the next most probable utterance:\n",
      "context:  [S]: Of course, I'll get started right away. Should I consider any specific sources or themes?\n",
      "token:  [D]: I trust your judgment, but prioritize industry reports and recent studies. We need solid data to make our case.\n",
      "30.773483276367188\n",
      "prompt:  This is a conversation between D and S.\n",
      "Predict the next most probable utterance:\n",
      "context:  [D]: I trust your judgment, but prioritize industry reports and recent studies. We need solid data to make our case.\n",
      "token:  [S]: Got it. I'll make sure to provide a comprehensive overview in the report.\n",
      "13.806295394897461\n",
      "prompt:  This is a conversation between D and S.\n",
      "Predict the next most probable utterance:\n",
      "context:  [S]: Got it. I'll make sure to provide a comprehensive overview in the report.\n",
      "token:  [D]: Perfect. Additionally, I'd like you to prepare a brief presentation summarizing the key findings. We have a meeting next Monday, and your insights will be crucial.\n",
      "16.1573543548584\n",
      "prompt:  This is a conversation between D and S.\n",
      "Predict the next most probable utterance:\n",
      "context:  [D]: Perfect. Additionally, I'd like you to prepare a brief presentation summarizing the key findings. We have a meeting next Monday, and your insights will be crucial.\n",
      "token:  [S]: No problem. I'll ensure the presentation is concise and highlights the most important points.\n",
      "10.54537296295166\n",
      "prompt:  This is a conversation between D and S.\n",
      "Predict the next most probable utterance:\n",
      "context:  [S]: No problem. I'll ensure the presentation is concise and highlights the most important points.\n",
      "token:  [D]: Good. Let me know if you need any assistance, but I expect you to handle this with minimal supervision.\n",
      "11.710285186767578\n",
      "prompt:  This is a conversation between D and S.\n",
      "Predict the next most probable utterance:\n",
      "context:  [D]: Good. Let me know if you need any assistance, but I expect you to handle this with minimal supervision.\n",
      "token:  [S]: Thank you for entrusting me with this responsibility. I'll do my best to meet your expectations.\n",
      "5.891037940979004\n",
      "[25.97359848022461, 13.740754127502441, 10.73189640045166, 23.564462661743164, 30.773483276367188, 13.806295394897461, 16.1573543548584, 10.54537296295166, 11.710285186767578, 5.891037940979004]\n",
      "D : 19.069323539733887\n",
      "S : 13.509584617614745\n",
      "[D]: Hey, I've been thinking about our upcoming project. I believe we should take a more assertive approach to meet our deadlines., 25.97359848022461\n",
      "[S]: Oh, absolutely. I completely agree. What specific tasks do you think I should focus on to support our goals?, 13.740754127502441\n",
      "[D]: Great. I need you to take charge of the research phase. Make sure to gather all the relevant information and compile a detailed report by the end of the week., 10.73189640045166\n",
      "[S]: Of course, I'll get started right away. Should I consider any specific sources or themes?, 23.564462661743164\n",
      "[D]: I trust your judgment, but prioritize industry reports and recent studies. We need solid data to make our case., 30.773483276367188\n",
      "[S]: Got it. I'll make sure to provide a comprehensive overview in the report., 13.806295394897461\n",
      "[D]: Perfect. Additionally, I'd like you to prepare a brief presentation summarizing the key findings. We have a meeting next Monday, and your insights will be crucial., 16.1573543548584\n",
      "[S]: No problem. I'll ensure the presentation is concise and highlights the most important points., 10.54537296295166\n",
      "[D]: Good. Let me know if you need any assistance, but I expect you to handle this with minimal supervision., 11.710285186767578\n",
      "[S]: Thank you for entrusting me with this responsibility. I'll do my best to meet your expectations., 5.891037940979004\n"
     ]
    }
   ],
   "source": [
    "gpt1 = [\"\",\n",
    "        \"[D]: Hey, I've been thinking about our upcoming project. I believe we should take a more assertive approach to meet our deadlines.\",\n",
    "        \"[S]: Oh, absolutely. I completely agree. What specific tasks do you think I should focus on to support our goals?\",\n",
    "        \"[D]: Great. I need you to take charge of the research phase. Make sure to gather all the relevant information and compile a detailed report by the end of the week.\",\n",
    "        \"[S]: Of course, I'll get started right away. Should I consider any specific sources or themes?\",\n",
    "        \"[D]: I trust your judgment, but prioritize industry reports and recent studies. We need solid data to make our case.\",\n",
    "        \"[S]: Got it. I'll make sure to provide a comprehensive overview in the report.\",\n",
    "        \"[D]: Perfect. Additionally, I'd like you to prepare a brief presentation summarizing the key findings. We have a meeting next Monday, and your insights will be crucial.\",\n",
    "        \"[S]: No problem. I'll ensure the presentation is concise and highlights the most important points.\",\n",
    "        \"[D]: Good. Let me know if you need any assistance, but I expect you to handle this with minimal supervision.\",\n",
    "        \"[S]: Thank you for entrusting me with this responsibility. I'll do my best to meet your expectations.\"]\n",
    "\n",
    "prmt = \"This is a conversation between D and S.\\nPredict the next most probable utterance:\"\n",
    "\n",
    "pattern = r'\\[([^\\]]+)\\]'\n",
    "matches = re.findall(pattern, \"\".join(gpt1))\n",
    "perpl = compute_perplexity(gpt1, prmt)\n",
    "print(perpl)\n",
    "for patt in np.unique(matches):\n",
    "    idx = np.asarray([index for index, element in enumerate(matches) if element == patt])\n",
    "    print(f\"{patt} :\", np.mean(np.asarray(perpl)[idx]))\n",
    "for d, p in zip(gpt1[1:], perpl):\n",
    "    print(f\"{d}, {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[Teacher]: \"Good morning, John. Did you complete your homework?\"', '[Student]: \"Yes, I did.\"', '[Teacher]: \"Great! Can you show it to me?\"', '[Student]: \"Sure, here it is.\"', '[Teacher]: \"Well done, John. Keep up the good work.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Good morning, John. Did you complete your homework?\"\n",
      "23.159488677978516\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Good morning, John. Did you complete your homework?\"\n",
      "token:  [Student]: \"Yes, I did.\"\n",
      "3.780818462371826\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I did.\"\n",
      "token:  [Teacher]: \"Great! Can you show it to me?\"\n",
      "9.264633178710938\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great! Can you show it to me?\"\n",
      "token:  [Student]: \"Sure, here it is.\"\n",
      "5.8555803298950195\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure, here it is.\"\n",
      "token:  [Teacher]: \"Well done, John. Keep up the good work.\"\n",
      "7.177946090698242\n",
      "Student : 4.818199396133423\n",
      "Teacher : 13.200689315795898\n",
      "['', '[Student]: \"I have a question about the assignment.\"', '[Teacher]: \"Sure, what\\'s your question?\"', '[Student]: \"I don\\'t understand this part.\"', '[Teacher]: \"Let me explain it to you.\"', '[Student]: \"Okay, I understand now. Thank you.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"I have a question about the assignment.\"\n",
      "35.830318450927734\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I have a question about the assignment.\"\n",
      "token:  [Teacher]: \"Sure, what's your question?\"\n",
      "4.273094177246094\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, what's your question?\"\n",
      "token:  [Student]: \"I don't understand this part.\"\n",
      "7.95077657699585\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I don't understand this part.\"\n",
      "token:  [Teacher]: \"Let me explain it to you.\"\n",
      "4.102541446685791\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let me explain it to you.\"\n",
      "token:  [Student]: \"Okay, I understand now. Thank you.\"\n",
      "6.714158058166504\n",
      "Student : 16.831751028696697\n",
      "Teacher : 4.187817811965942\n",
      "['', '[Teacher]: \"Let\\'s start the class. Open your books to page 34.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Today, we will learn about the solar system.\"', '[Student]: \"Sounds interesting.\"', '[Teacher]: \"Let\\'s start with the sun.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Let's start the class. Open your books to page 34.\"\n",
      "37.95305252075195\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start the class. Open your books to page 34.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "6.7796807289123535\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Today, we will learn about the solar system.\"\n",
      "10.47153091430664\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today, we will learn about the solar system.\"\n",
      "token:  [Student]: \"Sounds interesting.\"\n",
      "10.29538345336914\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sounds interesting.\"\n",
      "token:  [Teacher]: \"Let's start with the sun.\"\n",
      "12.045586585998535\n",
      "Student : 8.537532091140747\n",
      "Teacher : 20.156723340352375\n",
      "['', '[Student]: \"I\\'m having trouble with this problem.\"', '[Teacher]: \"Let\\'s go through it together.\"', '[Student]: \"I\\'m still not getting it.\"', '[Teacher]: \"Don\\'t worry. Let\\'s try a different approach.\"', '[Student]: \"That makes sense. Thanks for your help.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"I'm having trouble with this problem.\"\n",
      "35.128997802734375\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with this problem.\"\n",
      "token:  [Teacher]: \"Let's go through it together.\"\n",
      "6.444061756134033\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's go through it together.\"\n",
      "token:  [Student]: \"I'm still not getting it.\"\n",
      "8.242572784423828\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm still not getting it.\"\n",
      "token:  [Teacher]: \"Don't worry. Let's try a different approach.\"\n",
      "6.445180892944336\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Don't worry. Let's try a different approach.\"\n",
      "token:  [Student]: \"That makes sense. Thanks for your help.\"\n",
      "9.316442489624023\n",
      "Student : 17.562671025594074\n",
      "Teacher : 6.444621324539185\n",
      "['', '[Teacher]: \"Today, we will have a quiz. Are you ready?\"', '[Student]: \"Yes, I am.\"', '[Teacher]: \"Good. Let\\'s start.\"', '[Student]: \"Okay.\"', '[Teacher]: \"First question, what is the capital of France?\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today, we will have a quiz. Are you ready?\"\n",
      "21.46384620666504\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today, we will have a quiz. Are you ready?\"\n",
      "token:  [Student]: \"Yes, I am.\"\n",
      "4.195226192474365\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I am.\"\n",
      "token:  [Teacher]: \"Good. Let's start.\"\n",
      "6.542447566986084\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Good. Let's start.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "5.821906089782715\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"First question, what is the capital of France?\"\n",
      "12.693042755126953\n",
      "Student : 5.00856614112854\n",
      "Teacher : 13.566445509592691\n",
      "['', '[Teacher]: \"We will be starting a new chapter today. Are you ready?\"', '[Student]: \"Yes, I am.\"', '[Teacher]: \"Good. Let\\'s start with the basics.\"', '[Student]: \"Okay.\"', '[Teacher]: \"The chapter is about photosynthesis.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"We will be starting a new chapter today. Are you ready?\"\n",
      "22.279876708984375\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"We will be starting a new chapter today. Are you ready?\"\n",
      "token:  [Student]: \"Yes, I am.\"\n",
      "3.90583872795105\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I am.\"\n",
      "token:  [Teacher]: \"Good. Let's start with the basics.\"\n",
      "5.90444803237915\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Good. Let's start with the basics.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "5.937046051025391\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"The chapter is about photosynthesis.\"\n",
      "28.114416122436523\n",
      "Student : 4.92144238948822\n",
      "Teacher : 18.766246954600017\n",
      "['', '[Student]: \"I didn\\'t understand the homework.\"', '[Teacher]: \"Let\\'s go over it together.\"', '[Student]: \"That would be helpful.\"', '[Teacher]: \"First, let\\'s look at the instructions.\"', '[Student]: \"Oh, I see where I went wrong.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"I didn't understand the homework.\"\n",
      "55.6278190612793\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I didn't understand the homework.\"\n",
      "token:  [Teacher]: \"Let's go over it together.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.033215045928955\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's go over it together.\"\n",
      "token:  [Student]: \"That would be helpful.\"\n",
      "10.414844512939453\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That would be helpful.\"\n",
      "token:  [Teacher]: \"First, let's look at the instructions.\"\n",
      "11.24404525756836\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"First, let's look at the instructions.\"\n",
      "token:  [Student]: \"Oh, I see where I went wrong.\"\n",
      "10.238276481628418\n",
      "Student : 25.426980018615723\n",
      "Teacher : 9.138630151748657\n",
      "['', '[Teacher]: \"Today we will be discussing the civil war. Any questions before we start?\"', '[Student]: \"No, I\\'m ready.\"', '[Teacher]: \"Great, let\\'s begin.\"', '[Student]: \"Okay.\"', '[Teacher]: \"The civil war was a pivotal moment in our history.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the civil war. Any questions before we start?\"\n",
      "31.022897720336914\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the civil war. Any questions before we start?\"\n",
      "token:  [Student]: \"No, I'm ready.\"\n",
      "4.966426849365234\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"No, I'm ready.\"\n",
      "token:  [Teacher]: \"Great, let's begin.\"\n",
      "7.205973148345947\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's begin.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "6.835707664489746\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"The civil war was a pivotal moment in our history.\"\n",
      "16.794466018676758\n",
      "Student : 5.90106725692749\n",
      "Teacher : 18.34111229578654\n",
      "['', '[Student]: \"Can we go over the last chapter again? I\\'m a bit confused.\"', '[Teacher]: \"Of course, let\\'s review it together.\"', '[Student]: \"Thank you.\"', '[Teacher]: \"Let\\'s start from the beginning.\"', '[Student]: \"That makes it clearer.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "27.45329475402832\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "token:  [Teacher]: \"Of course, let's review it together.\"\n",
      "6.415534973144531\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, let's review it together.\"\n",
      "token:  [Student]: \"Thank you.\"\n",
      "7.232381820678711\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you.\"\n",
      "token:  [Teacher]: \"Let's start from the beginning.\"\n",
      "6.786656379699707\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start from the beginning.\"\n",
      "token:  [Student]: \"That makes it clearer.\"\n",
      "19.93571662902832\n",
      "Student : 18.207131067911785\n",
      "Teacher : 6.601095676422119\n",
      "['', '[Teacher]: \"Let\\'s start the class with a quick recap of yesterday\\'s lesson.\"', '[Student]: \"Sure.\"', '[Teacher]: \"We discussed the water cycle. Can you tell me what you remember?\"', '[Student]: \"The water cycle involves evaporation, condensation, and precipitation.\"', '[Teacher]: \"Excellent! Let\\'s move on to today\\'s lesson.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "20.01887321472168\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "token:  [Student]: \"Sure.\"\n",
      "8.22253131866455\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure.\"\n",
      "token:  [Teacher]: \"We discussed the water cycle. Can you tell me what you remember?\"\n",
      "19.18282699584961\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"We discussed the water cycle. Can you tell me what you remember?\"\n",
      "token:  [Student]: \"The water cycle involves evaporation, condensation, and precipitation.\"\n",
      "4.998530387878418\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"The water cycle involves evaporation, condensation, and precipitation.\"\n",
      "token:  [Teacher]: \"Excellent! Let's move on to today's lesson.\"\n",
      "7.995016098022461\n",
      "Student : 6.610530853271484\n",
      "Teacher : 15.73223876953125\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of gravity. Are you ready?\"', '[Student]: \"Yes, I am.\"', '[Teacher]: \"Great, let\\'s start with the definition.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Gravity is a force that attracts two objects towards each other.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of gravity. Are you ready?\"\n",
      "21.47015380859375\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of gravity. Are you ready?\"\n",
      "token:  [Student]: \"Yes, I am.\"\n",
      "3.889904022216797\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I am.\"\n",
      "token:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "9.019451141357422\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "7.042109489440918\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Gravity is a force that attracts two objects towards each other.\"\n",
      "10.007889747619629\n",
      "Student : 5.466006755828857\n",
      "Teacher : 13.499164899190268\n",
      "['', '[Student]: \"I\\'m having trouble with this math problem.\"', '[Teacher]: \"Let\\'s break it down together.\"', '[Student]: \"That would be helpful.\"', '[Teacher]: \"First, let\\'s simplify the equation.\"', '[Student]: \"Oh, I see where I went wrong.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"I'm having trouble with this math problem.\"\n",
      "25.94668197631836\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with this math problem.\"\n",
      "token:  [Teacher]: \"Let's break it down together.\"\n",
      "8.118480682373047\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's break it down together.\"\n",
      "token:  [Student]: \"That would be helpful.\"\n",
      "10.194622039794922\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That would be helpful.\"\n",
      "token:  [Teacher]: \"First, let's simplify the equation.\"\n",
      "15.530435562133789\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"First, let's simplify the equation.\"\n",
      "token:  [Student]: \"Oh, I see where I went wrong.\"\n",
      "10.563639640808105\n",
      "Student : 15.568314552307129\n",
      "Teacher : 11.824458122253418\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of democracy. Any questions before we start?\"', '[Student]: \"No, I\\'m ready.\"', '[Teacher]: \"Great, let\\'s begin.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Democracy is a form of government where the people have the power to choose their leaders.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of democracy. Any questions before we start?\"\n",
      "26.168325424194336\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of democracy. Any questions before we start?\"\n",
      "token:  [Student]: \"No, I'm ready.\"\n",
      "5.107711315155029\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"No, I'm ready.\"\n",
      "token:  [Teacher]: \"Great, let's begin.\"\n",
      "7.205973148345947\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's begin.\"\n",
      "token:  [Student]: \"Okay.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.835707664489746\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Democracy is a form of government where the people have the power to choose their leaders.\"\n",
      "6.414319038391113\n",
      "Student : 5.971709489822388\n",
      "Teacher : 13.262872536977133\n",
      "['', '[Student]: \"Can we go over the last chapter again? I\\'m a bit confused.\"', '[Teacher]: \"Of course, let\\'s review it together.\"', '[Student]: \"Thank you.\"', '[Teacher]: \"Let\\'s start from the beginning.\"', '[Student]: \"That makes it clearer.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "27.45329475402832\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "token:  [Teacher]: \"Of course, let's review it together.\"\n",
      "6.415534973144531\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, let's review it together.\"\n",
      "token:  [Student]: \"Thank you.\"\n",
      "7.232381820678711\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you.\"\n",
      "token:  [Teacher]: \"Let's start from the beginning.\"\n",
      "6.786656379699707\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start from the beginning.\"\n",
      "token:  [Student]: \"That makes it clearer.\"\n",
      "19.93571662902832\n",
      "Student : 18.207131067911785\n",
      "Teacher : 6.601095676422119\n",
      "['', '[Teacher]: \"Let\\'s start the class with a quick recap of yesterday\\'s lesson.\"', '[Student]: \"Sure.\"', '[Teacher]: \"We discussed the concept of photosynthesis. Can you tell me what you remember?\"', '[Student]: \"Photosynthesis is the process by which green plants make their own food using sunlight.\"', '[Teacher]: \"Excellent! Let\\'s move on to today\\'s lesson.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "20.01887321472168\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "token:  [Student]: \"Sure.\"\n",
      "8.22253131866455\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure.\"\n",
      "token:  [Teacher]: \"We discussed the concept of photosynthesis. Can you tell me what you remember?\"\n",
      "15.887619018554688\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"We discussed the concept of photosynthesis. Can you tell me what you remember?\"\n",
      "token:  [Student]: \"Photosynthesis is the process by which green plants make their own food using sunlight.\"\n",
      "6.857820510864258\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Photosynthesis is the process by which green plants make their own food using sunlight.\"\n",
      "token:  [Teacher]: \"Excellent! Let's move on to today's lesson.\"\n",
      "8.547346115112305\n",
      "Student : 7.540175914764404\n",
      "Teacher : 14.817946116129557\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of evolution. Are you ready?\"', '[Student]: \"Yes, I am.\"', '[Teacher]: \"Great, let\\'s start with the definition.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Evolution is the process by which species of organisms undergo change over time.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of evolution. Are you ready?\"\n",
      "20.682636260986328\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of evolution. Are you ready?\"\n",
      "token:  [Student]: \"Yes, I am.\"\n",
      "3.9001502990722656\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I am.\"\n",
      "token:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "9.019451141357422\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "7.042109489440918\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Evolution is the process by which species of organisms undergo change over time.\"\n",
      "10.740785598754883\n",
      "Student : 5.471129894256592\n",
      "Teacher : 13.480957667032877\n",
      "['', '[Student]: \"I\\'m having trouble with this history question.\"', '[Teacher]: \"Let\\'s break it down together.\"', '[Student]: \"That would be helpful.\"', '[Teacher]: \"First, let\\'s look at the context of the question.\"', '[Student]: \"Oh, I see where I went wrong.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"I'm having trouble with this history question.\"\n",
      "54.891746520996094\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with this history question.\"\n",
      "token:  [Teacher]: \"Let's break it down together.\"\n",
      "8.594027519226074\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's break it down together.\"\n",
      "token:  [Student]: \"That would be helpful.\"\n",
      "10.194622039794922\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That would be helpful.\"\n",
      "token:  [Teacher]: \"First, let's look at the context of the question.\"\n",
      "7.416992664337158\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"First, let's look at the context of the question.\"\n",
      "token:  [Student]: \"Oh, I see where I went wrong.\"\n",
      "11.010393142700195\n",
      "Student : 25.36558723449707\n",
      "Teacher : 8.005510091781616\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of climate change. Any questions before we start?\"', '[Student]: \"No, I\\'m ready.\"', '[Teacher]: \"Great, let\\'s begin.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Climate change refers to long-term changes in temperature and typical weather patterns in a place.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of climate change. Any questions before we start?\"\n",
      "22.213180541992188\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of climate change. Any questions before we start?\"\n",
      "token:  [Student]: \"No, I'm ready.\"\n",
      "4.937024116516113\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"No, I'm ready.\"\n",
      "token:  [Teacher]: \"Great, let's begin.\"\n",
      "7.205973148345947\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's begin.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "6.835707664489746\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Climate change refers to long-term changes in temperature and typical weather patterns in a place.\"\n",
      "22.09263801574707\n",
      "Student : 5.88636589050293\n",
      "Teacher : 17.170597235361736\n",
      "['', '[Student]: \"Can we go over the last chapter again? I\\'m a bit confused.\"', '[Teacher]: \"Of course, let\\'s review it together.\"', '[Student]: \"Thank you.\"', '[Teacher]: \"Let\\'s start from the beginning.\"', '[Student]: \"That makes it clearer.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "27.45329475402832\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "token:  [Teacher]: \"Of course, let's review it together.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.415534973144531\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, let's review it together.\"\n",
      "token:  [Student]: \"Thank you.\"\n",
      "7.232381820678711\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you.\"\n",
      "token:  [Teacher]: \"Let's start from the beginning.\"\n",
      "6.786656379699707\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start from the beginning.\"\n",
      "token:  [Student]: \"That makes it clearer.\"\n",
      "19.93571662902832\n",
      "Student : 18.207131067911785\n",
      "Teacher : 6.601095676422119\n",
      "['', '[Teacher]: \"Let\\'s start the class with a quick recap of yesterday\\'s lesson.\"', '[Student]: \"Sure.\"', '[Teacher]: \"We discussed the concept of democracy. Can you tell me what you remember?\"', '[Student]: \"Democracy is a form of government where the people have the power to choose their leaders.\"', '[Teacher]: \"Excellent! Let\\'s move on to today\\'s lesson.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "20.01887321472168\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "token:  [Student]: \"Sure.\"\n",
      "8.22253131866455\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure.\"\n",
      "token:  [Teacher]: \"We discussed the concept of democracy. Can you tell me what you remember?\"\n",
      "17.180742263793945\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"We discussed the concept of democracy. Can you tell me what you remember?\"\n",
      "token:  [Student]: \"Democracy is a form of government where the people have the power to choose their leaders.\"\n",
      "4.0122857093811035\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Democracy is a form of government where the people have the power to choose their leaders.\"\n",
      "token:  [Teacher]: \"Excellent! Let's move on to today's lesson.\"\n",
      "8.350569725036621\n",
      "Student : 6.117408514022827\n",
      "Teacher : 15.183395067850748\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of ecosystems. Are you ready?\"', '[Student]: \"Yes, I am.\"', '[Teacher]: \"Great, let\\'s start with the definition.\"', '[Student]: \"Okay.\"', '[Teacher]: \"An ecosystem is a community of living organisms in conjunction with the nonliving components of their environment.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of ecosystems. Are you ready?\"\n",
      "29.691329956054688\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of ecosystems. Are you ready?\"\n",
      "token:  [Student]: \"Yes, I am.\"\n",
      "3.8817079067230225\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I am.\"\n",
      "token:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "9.019451141357422\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "7.042109489440918\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"An ecosystem is a community of living organisms in conjunction with the nonliving components of their environment.\"\n",
      "20.18858528137207\n",
      "Student : 5.46190869808197\n",
      "Teacher : 19.633122126261394\n",
      "['', '[Student]: \"I\\'m having trouble with this geography question.\"', '[Teacher]: \"Let\\'s break it down together.\"', '[Student]: \"That would be helpful.\"', '[Teacher]: \"First, let\\'s look at the context of the question.\"', '[Student]: \"Oh, I see where I went wrong.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"I'm having trouble with this geography question.\"\n",
      "54.69964599609375\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with this geography question.\"\n",
      "token:  [Teacher]: \"Let's break it down together.\"\n",
      "8.584705352783203\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's break it down together.\"\n",
      "token:  [Student]: \"That would be helpful.\"\n",
      "10.194622039794922\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That would be helpful.\"\n",
      "token:  [Teacher]: \"First, let's look at the context of the question.\"\n",
      "7.416992664337158\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"First, let's look at the context of the question.\"\n",
      "token:  [Student]: \"Oh, I see where I went wrong.\"\n",
      "11.010393142700195\n",
      "Student : 25.30155372619629\n",
      "Teacher : 8.00084900856018\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of human rights. Any questions before we start?\"', '[Student]: \"No, I\\'m ready.\"', '[Teacher]: \"Great, let\\'s begin.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Human rights are the basic rights and freedoms to which all individuals are entitled.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of human rights. Any questions before we start?\"\n",
      "22.15908432006836\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of human rights. Any questions before we start?\"\n",
      "token:  [Student]: \"No, I'm ready.\"\n",
      "4.873213291168213\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"No, I'm ready.\"\n",
      "token:  [Teacher]: \"Great, let's begin.\"\n",
      "7.205973148345947\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's begin.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "6.835707664489746\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Human rights are the basic rights and freedoms to which all individuals are entitled.\"\n",
      "12.48218059539795\n",
      "Student : 5.8544604778289795\n",
      "Teacher : 13.949079354604086\n",
      "['', '[Student]: \"Can we go over the last chapter again? I\\'m a bit confused.\"', '[Teacher]: \"Of course, let\\'s review it together.\"', '[Student]: \"Thank you.\"', '[Teacher]: \"Let\\'s start from the beginning.\"', '[Student]: \"That makes it clearer.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "27.45329475402832\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "token:  [Teacher]: \"Of course, let's review it together.\"\n",
      "6.415534973144531\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, let's review it together.\"\n",
      "token:  [Student]: \"Thank you.\"\n",
      "7.232381820678711\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you.\"\n",
      "token:  [Teacher]: \"Let's start from the beginning.\"\n",
      "6.786656379699707\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start from the beginning.\"\n",
      "token:  [Student]: \"That makes it clearer.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.93571662902832\n",
      "Student : 18.207131067911785\n",
      "Teacher : 6.601095676422119\n",
      "['', '[Teacher]: \"Let\\'s start the class with a quick recap of yesterday\\'s lesson.\"', '[Student]: \"Sure.\"', '[Teacher]: \"We discussed the concept of evolution. Can you tell me what you remember?\"', '[Student]: \"Evolution is the process by which species of organisms undergo change over time.\"', '[Teacher]: \"Excellent! Let\\'s move on to today\\'s lesson.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "20.01887321472168\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "token:  [Student]: \"Sure.\"\n",
      "8.22253131866455\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure.\"\n",
      "token:  [Teacher]: \"We discussed the concept of evolution. Can you tell me what you remember?\"\n",
      "14.243362426757812\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"We discussed the concept of evolution. Can you tell me what you remember?\"\n",
      "token:  [Student]: \"Evolution is the process by which species of organisms undergo change over time.\"\n",
      "6.0686798095703125\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Evolution is the process by which species of organisms undergo change over time.\"\n",
      "token:  [Teacher]: \"Excellent! Let's move on to today's lesson.\"\n",
      "8.636809349060059\n",
      "Student : 7.145605564117432\n",
      "Teacher : 14.299681663513184\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of biodiversity. Are you ready?\"', '[Student]: \"Yes, I am.\"', '[Teacher]: \"Great, let\\'s start with the definition.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Biodiversity refers to the variety of life on Earth, including the variety within and between species and within and between ecosystems.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of biodiversity. Are you ready?\"\n",
      "26.157546997070312\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of biodiversity. Are you ready?\"\n",
      "token:  [Student]: \"Yes, I am.\"\n",
      "3.9157066345214844\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I am.\"\n",
      "token:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "9.019451141357422\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "7.042109489440918\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Biodiversity refers to the variety of life on Earth, including the variety within and between species and within and between ecosystems.\"\n",
      "11.478790283203125\n",
      "Student : 5.478908061981201\n",
      "Teacher : 15.551929473876953\n",
      "['', '[Student]: \"I\\'m having trouble with this science question.\"', '[Teacher]: \"Let\\'s break it down together.\"', '[Student]: \"That would be helpful.\"', '[Teacher]: \"First, let\\'s look at the context of the question.\"', '[Student]: \"Oh, I see where I went wrong.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"I'm having trouble with this science question.\"\n",
      "44.91377258300781\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with this science question.\"\n",
      "token:  [Teacher]: \"Let's break it down together.\"\n",
      "8.40229606628418\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's break it down together.\"\n",
      "token:  [Student]: \"That would be helpful.\"\n",
      "10.194622039794922\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That would be helpful.\"\n",
      "token:  [Teacher]: \"First, let's look at the context of the question.\"\n",
      "7.416992664337158\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"First, let's look at the context of the question.\"\n",
      "token:  [Student]: \"Oh, I see where I went wrong.\"\n",
      "11.010393142700195\n",
      "Student : 22.03959592183431\n",
      "Teacher : 7.909644365310669\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of globalization. Any questions before we start?\"', '[Student]: \"No, I\\'m ready.\"', '[Teacher]: \"Great, let\\'s begin.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Globalization is the process by which businesses or other organizations develop international influence or start operating on an international scale.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of globalization. Any questions before we start?\"\n",
      "28.33898162841797\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of globalization. Any questions before we start?\"\n",
      "token:  [Student]: \"No, I'm ready.\"\n",
      "4.978328704833984\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"No, I'm ready.\"\n",
      "token:  [Teacher]: \"Great, let's begin.\"\n",
      "7.205973148345947\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's begin.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "6.835707664489746\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Globalization is the process by which businesses or other organizations develop international influence or start operating on an international scale.\"\n",
      "35.86179733276367\n",
      "Student : 5.907018184661865\n",
      "Teacher : 23.80225070317586\n",
      "['', '[Student]: \"Can we go over the last chapter again? I\\'m a bit confused.\"', '[Teacher]: \"Of course, let\\'s review it together.\"', '[Student]: \"Thank you.\"', '[Teacher]: \"Let\\'s start from the beginning.\"', '[Student]: \"That makes it clearer.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "27.45329475402832\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "token:  [Teacher]: \"Of course, let's review it together.\"\n",
      "6.415534973144531\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, let's review it together.\"\n",
      "token:  [Student]: \"Thank you.\"\n",
      "7.232381820678711\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you.\"\n",
      "token:  [Teacher]: \"Let's start from the beginning.\"\n",
      "6.786656379699707\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start from the beginning.\"\n",
      "token:  [Student]: \"That makes it clearer.\"\n",
      "19.93571662902832\n",
      "Student : 18.207131067911785\n",
      "Teacher : 6.601095676422119\n",
      "['', '[Teacher]: \"Let\\'s start the class with a quick recap of yesterday\\'s lesson.\"', '[Student]: \"Sure.\"', '[Teacher]: \"We discussed the concept of human rights. Can you tell me what you remember?\"', '[Student]: \"Human rights are the basic rights and freedoms to which all individuals are entitled.\"', '[Teacher]: \"Excellent! Let\\'s move on to today\\'s lesson.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "20.01887321472168\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "token:  [Student]: \"Sure.\"\n",
      "8.22253131866455\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure.\"\n",
      "token:  [Teacher]: \"We discussed the concept of human rights. Can you tell me what you remember?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.846953392028809\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"We discussed the concept of human rights. Can you tell me what you remember?\"\n",
      "token:  [Student]: \"Human rights are the basic rights and freedoms to which all individuals are entitled.\"\n",
      "6.3163323402404785\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Human rights are the basic rights and freedoms to which all individuals are entitled.\"\n",
      "token:  [Teacher]: \"Excellent! Let's move on to today's lesson.\"\n",
      "8.33304214477539\n",
      "Student : 7.269431829452515\n",
      "Teacher : 14.399622917175293\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of renewable energy. Are you ready?\"', '[Student]: \"Yes, I am.\"', '[Teacher]: \"Great, let\\'s start with the definition.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Renewable energy is energy that is collected from renewable resources, which are naturally replenished on a human timescale.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of renewable energy. Are you ready?\"\n",
      "24.09650230407715\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of renewable energy. Are you ready?\"\n",
      "token:  [Student]: \"Yes, I am.\"\n",
      "3.915684938430786\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I am.\"\n",
      "token:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "9.019451141357422\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "7.042109489440918\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Renewable energy is energy that is collected from renewable resources, which are naturally replenished on a human timescale.\"\n",
      "17.344432830810547\n",
      "Student : 5.478897213935852\n",
      "Teacher : 16.82012875874837\n",
      "['', '[Student]: \"I\\'m having trouble with this physics problem.\"', '[Teacher]: \"Let\\'s break it down together.\"', '[Student]: \"That would be helpful.\"', '[Teacher]: \"First, let\\'s look at the formula.\"', '[Student]: \"Oh, I see where I went wrong.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"I'm having trouble with this physics problem.\"\n",
      "37.27592468261719\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with this physics problem.\"\n",
      "token:  [Teacher]: \"Let's break it down together.\"\n",
      "8.233928680419922\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's break it down together.\"\n",
      "token:  [Student]: \"That would be helpful.\"\n",
      "10.194622039794922\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That would be helpful.\"\n",
      "token:  [Teacher]: \"First, let's look at the formula.\"\n",
      "12.047861099243164\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"First, let's look at the formula.\"\n",
      "token:  [Student]: \"Oh, I see where I went wrong.\"\n",
      "10.725020408630371\n",
      "Student : 19.39852237701416\n",
      "Teacher : 10.140894889831543\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of sustainability. Any questions before we start?\"', '[Student]: \"No, I\\'m ready.\"', '[Teacher]: \"Great, let\\'s begin.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Sustainability is the ability to exist constantly.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of sustainability. Any questions before we start?\"\n",
      "25.964942932128906\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of sustainability. Any questions before we start?\"\n",
      "token:  [Student]: \"No, I'm ready.\"\n",
      "5.0776519775390625\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"No, I'm ready.\"\n",
      "token:  [Teacher]: \"Great, let's begin.\"\n",
      "7.205973148345947\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's begin.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "6.835707664489746\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Sustainability is the ability to exist constantly.\"\n",
      "33.12621307373047\n",
      "Student : 5.956679821014404\n",
      "Teacher : 22.099043051401775\n",
      "['', '[Student]: \"Can we go over the last chapter again? I\\'m a bit confused.\"', '[Teacher]: \"Of course, let\\'s review it together.\"', '[Student]: \"Thank you.\"', '[Teacher]: \"Let\\'s start from the beginning.\"', '[Student]: \"That makes it clearer.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "27.45329475402832\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "token:  [Teacher]: \"Of course, let's review it together.\"\n",
      "6.415534973144531\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, let's review it together.\"\n",
      "token:  [Student]: \"Thank you.\"\n",
      "7.232381820678711\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you.\"\n",
      "token:  [Teacher]: \"Let's start from the beginning.\"\n",
      "6.786656379699707\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start from the beginning.\"\n",
      "token:  [Student]: \"That makes it clearer.\"\n",
      "19.93571662902832\n",
      "Student : 18.207131067911785\n",
      "Teacher : 6.601095676422119\n",
      "['', '[Teacher]: \"Let\\'s start the class with a quick recap of yesterday\\'s lesson.\"', '[Student]: \"Sure.\"', '[Teacher]: \"We discussed the concept of biodiversity. Can you tell me what you remember?\"', '[Student]: \"Biodiversity refers to the variety of life on Earth, including the variety within and between species and within and between ecosystems.\"', '[Teacher]: \"Excellent! Let\\'s move on to today\\'s lesson.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "20.01887321472168\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "token:  [Student]: \"Sure.\"\n",
      "8.22253131866455\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure.\"\n",
      "token:  [Teacher]: \"We discussed the concept of biodiversity. Can you tell me what you remember?\"\n",
      "17.947681427001953\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"We discussed the concept of biodiversity. Can you tell me what you remember?\"\n",
      "token:  [Student]: \"Biodiversity refers to the variety of life on Earth, including the variety within and between species and within and between ecosystems.\"\n",
      "7.2474365234375\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Biodiversity refers to the variety of life on Earth, including the variety within and between species and within and between ecosystems.\"\n",
      "token:  [Teacher]: \"Excellent! Let's move on to today's lesson.\"\n",
      "8.124567031860352\n",
      "Student : 7.734983921051025\n",
      "Teacher : 15.363707224527994\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of algebra. Are you ready?\"', '[Student]: \"Yes, I am.\"', '[Teacher]: \"Great, let\\'s start with the definition.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Algebra is a branch of mathematics dealing with symbols and the rules for manipulating those symbols.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of algebra. Are you ready?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.141788482666016\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of algebra. Are you ready?\"\n",
      "token:  [Student]: \"Yes, I am.\"\n",
      "3.8100030422210693\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I am.\"\n",
      "token:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "9.019451141357422\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "7.042109489440918\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Algebra is a branch of mathematics dealing with symbols and the rules for manipulating those symbols.\"\n",
      "12.009552001953125\n",
      "Student : 5.426056265830994\n",
      "Teacher : 15.056930541992188\n",
      "['', '[Student]: \"I\\'m having trouble with this chemistry question.\"', '[Teacher]: \"Let\\'s break it down together.\"', '[Student]: \"That would be helpful.\"', '[Teacher]: \"First, let\\'s look at the periodic table.\"', '[Student]: \"Oh, I see where I went wrong.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"I'm having trouble with this chemistry question.\"\n",
      "53.4105339050293\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with this chemistry question.\"\n",
      "token:  [Teacher]: \"Let's break it down together.\"\n",
      "8.220457077026367\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's break it down together.\"\n",
      "token:  [Student]: \"That would be helpful.\"\n",
      "10.194622039794922\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That would be helpful.\"\n",
      "token:  [Teacher]: \"First, let's look at the periodic table.\"\n",
      "11.355133056640625\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"First, let's look at the periodic table.\"\n",
      "token:  [Student]: \"Oh, I see where I went wrong.\"\n",
      "10.537679672241211\n",
      "Student : 24.71427853902181\n",
      "Teacher : 9.787795066833496\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of democracy. Any questions before we start?\"', '[Student]: \"No, I\\'m ready.\"', '[Teacher]: \"Great, let\\'s begin.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Democracy is a form of government where the people have the power to choose their leaders.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of democracy. Any questions before we start?\"\n",
      "26.168325424194336\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of democracy. Any questions before we start?\"\n",
      "token:  [Student]: \"No, I'm ready.\"\n",
      "5.107711315155029\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"No, I'm ready.\"\n",
      "token:  [Teacher]: \"Great, let's begin.\"\n",
      "7.205973148345947\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's begin.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "6.835707664489746\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Democracy is a form of government where the people have the power to choose their leaders.\"\n",
      "6.414319038391113\n",
      "Student : 5.971709489822388\n",
      "Teacher : 13.262872536977133\n",
      "['', '[Student]: \"Can we go over the last chapter again? I\\'m a bit confused.\"', '[Teacher]: \"Of course, let\\'s review it together.\"', '[Student]: \"Thank you.\"', '[Teacher]: \"Let\\'s start from the beginning.\"', '[Student]: \"That makes it clearer.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "27.45329475402832\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "token:  [Teacher]: \"Of course, let's review it together.\"\n",
      "6.415534973144531\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, let's review it together.\"\n",
      "token:  [Student]: \"Thank you.\"\n",
      "7.232381820678711\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you.\"\n",
      "token:  [Teacher]: \"Let's start from the beginning.\"\n",
      "6.786656379699707\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start from the beginning.\"\n",
      "token:  [Student]: \"That makes it clearer.\"\n",
      "19.93571662902832\n",
      "Student : 18.207131067911785\n",
      "Teacher : 6.601095676422119\n",
      "['', '[Teacher]: \"Let\\'s start the class with a quick recap of yesterday\\'s lesson.\"', '[Student]: \"Sure.\"', '[Teacher]: \"We discussed the concept of globalization. Can you tell me what you remember?\"', '[Student]: \"Globalization is the process by which businesses or other organizations develop international influence or start operating on an international scale.\"', '[Teacher]: \"Excellent! Let\\'s move on to today\\'s lesson.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "20.01887321472168\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "token:  [Student]: \"Sure.\"\n",
      "8.22253131866455\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure.\"\n",
      "token:  [Teacher]: \"We discussed the concept of globalization. Can you tell me what you remember?\"\n",
      "17.72733497619629\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"We discussed the concept of globalization. Can you tell me what you remember?\"\n",
      "token:  [Student]: \"Globalization is the process by which businesses or other organizations develop international influence or start operating on an international scale.\"\n",
      "18.618694305419922\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Globalization is the process by which businesses or other organizations develop international influence or start operating on an international scale.\"\n",
      "token:  [Teacher]: \"Excellent! Let's move on to today's lesson.\"\n",
      "8.059064865112305\n",
      "Student : 13.420612812042236\n",
      "Teacher : 15.268424352010092\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of geometry. Are you ready?\"', '[Student]: \"Yes, I am.\"', '[Teacher]: \"Great, let\\'s start with the definition.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Geometry is a branch of mathematics concerned with questions of shape, size, relative position of figures, and the properties of space.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of geometry. Are you ready?\"\n",
      "23.76353645324707\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of geometry. Are you ready?\"\n",
      "token:  [Student]: \"Yes, I am.\"\n",
      "3.860732078552246\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I am.\"\n",
      "token:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "9.019451141357422\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "token:  [Student]: \"Okay.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.042109489440918\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Geometry is a branch of mathematics concerned with questions of shape, size, relative position of figures, and the properties of space.\"\n",
      "13.482544898986816\n",
      "Student : 5.451420783996582\n",
      "Teacher : 15.421844164530436\n",
      "['', '[Student]: \"I\\'m having trouble with this biology question.\"', '[Teacher]: \"Let\\'s break it down together.\"', '[Student]: \"That would be helpful.\"', '[Teacher]: \"First, let\\'s look at the cell structure.\"', '[Student]: \"Oh, I see where I went wrong.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"I'm having trouble with this biology question.\"\n",
      "54.13230895996094\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with this biology question.\"\n",
      "token:  [Teacher]: \"Let's break it down together.\"\n",
      "8.462857246398926\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's break it down together.\"\n",
      "token:  [Student]: \"That would be helpful.\"\n",
      "10.194622039794922\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That would be helpful.\"\n",
      "token:  [Teacher]: \"First, let's look at the cell structure.\"\n",
      "13.959721565246582\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"First, let's look at the cell structure.\"\n",
      "token:  [Student]: \"Oh, I see where I went wrong.\"\n",
      "10.683619499206543\n",
      "Student : 25.00351683298747\n",
      "Teacher : 11.211289405822754\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of literature. Any questions before we start?\"', '[Student]: \"No, I\\'m ready.\"', '[Teacher]: \"Great, let\\'s begin.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Literature is a term used to describe written and sometimes spoken material.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of literature. Any questions before we start?\"\n",
      "27.65281867980957\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of literature. Any questions before we start?\"\n",
      "token:  [Student]: \"No, I'm ready.\"\n",
      "5.047021389007568\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"No, I'm ready.\"\n",
      "token:  [Teacher]: \"Great, let's begin.\"\n",
      "7.205973148345947\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's begin.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "6.835707664489746\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Literature is a term used to describe written and sometimes spoken material.\"\n",
      "20.809864044189453\n",
      "Student : 5.941364526748657\n",
      "Teacher : 18.55621862411499\n",
      "['', '[Student]: \"Can we go over the last chapter again? I\\'m a bit confused.\"', '[Teacher]: \"Of course, let\\'s review it together.\"', '[Student]: \"Thank you.\"', '[Teacher]: \"Let\\'s start from the beginning.\"', '[Student]: \"That makes it clearer.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "27.45329475402832\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "token:  [Teacher]: \"Of course, let's review it together.\"\n",
      "6.415534973144531\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, let's review it together.\"\n",
      "token:  [Student]: \"Thank you.\"\n",
      "7.232381820678711\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you.\"\n",
      "token:  [Teacher]: \"Let's start from the beginning.\"\n",
      "6.786656379699707\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start from the beginning.\"\n",
      "token:  [Student]: \"That makes it clearer.\"\n",
      "19.93571662902832\n",
      "Student : 18.207131067911785\n",
      "Teacher : 6.601095676422119\n",
      "['', '[Teacher]: \"Let\\'s start the class with a quick recap of yesterday\\'s lesson.\"', '[Student]: \"Sure.\"', '[Teacher]: \"We discussed the concept of algebra. Can you tell me what you remember?\"', '[Student]: \"Algebra is a branch of mathematics dealing with symbols and the rules for manipulating those symbols.\"', '[Teacher]: \"Excellent! Let\\'s move on to today\\'s lesson.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "20.01887321472168\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "token:  [Student]: \"Sure.\"\n",
      "8.22253131866455\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure.\"\n",
      "token:  [Teacher]: \"We discussed the concept of algebra. Can you tell me what you remember?\"\n",
      "16.042842864990234\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"We discussed the concept of algebra. Can you tell me what you remember?\"\n",
      "token:  [Student]: \"Algebra is a branch of mathematics dealing with symbols and the rules for manipulating those symbols.\"\n",
      "7.345389366149902\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Algebra is a branch of mathematics dealing with symbols and the rules for manipulating those symbols.\"\n",
      "token:  [Teacher]: \"Excellent! Let's move on to today's lesson.\"\n",
      "9.028668403625488\n",
      "Student : 7.783960342407227\n",
      "Teacher : 15.030128161112467\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of trigonometry. Are you ready?\"', '[Student]: \"Yes, I am.\"', '[Teacher]: \"Great, let\\'s start with the definition.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Trigonometry is a branch of mathematics that studies relationships involving lengths and angles of triangles.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of trigonometry. Are you ready?\"\n",
      "18.540210723876953\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of trigonometry. Are you ready?\"\n",
      "token:  [Student]: \"Yes, I am.\"\n",
      "3.869365692138672\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I am.\"\n",
      "token:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "9.019451141357422\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's start with the definition.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "7.042109489440918\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Trigonometry is a branch of mathematics that studies relationships involving lengths and angles of triangles.\"\n",
      "15.322212219238281\n",
      "Student : 5.455737590789795\n",
      "Teacher : 14.293958028157553\n",
      "['', '[Student]: \"I\\'m having trouble with this English question.\"', '[Teacher]: \"Let\\'s break it down together.\"', '[Student]: \"That would be helpful.\"', '[Teacher]: \"First, let\\'s look at the grammar rules.\"', '[Student]: \"Oh, I see where I went wrong.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"I'm having trouble with this English question.\"\n",
      "46.244163513183594\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with this English question.\"\n",
      "token:  [Teacher]: \"Let's break it down together.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.528223991394043\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's break it down together.\"\n",
      "token:  [Student]: \"That would be helpful.\"\n",
      "10.194622039794922\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That would be helpful.\"\n",
      "token:  [Teacher]: \"First, let's look at the grammar rules.\"\n",
      "9.624067306518555\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"First, let's look at the grammar rules.\"\n",
      "token:  [Student]: \"Oh, I see where I went wrong.\"\n",
      "11.429396629333496\n",
      "Student : 22.622727394104004\n",
      "Teacher : 9.076145648956299\n",
      "['', '[Teacher]: \"Today we will be discussing the concept of economics. Any questions before we start?\"', '[Student]: \"No, I\\'m ready.\"', '[Teacher]: \"Great, let\\'s begin.\"', '[Student]: \"Okay.\"', '[Teacher]: \"Economics is a social science concerned with the production, distribution, and consumption of goods and services.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today we will be discussing the concept of economics. Any questions before we start?\"\n",
      "25.777122497558594\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today we will be discussing the concept of economics. Any questions before we start?\"\n",
      "token:  [Student]: \"No, I'm ready.\"\n",
      "4.9998393058776855\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"No, I'm ready.\"\n",
      "token:  [Teacher]: \"Great, let's begin.\"\n",
      "7.205973148345947\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great, let's begin.\"\n",
      "token:  [Student]: \"Okay.\"\n",
      "6.835707664489746\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Okay.\"\n",
      "token:  [Teacher]: \"Economics is a social science concerned with the production, distribution, and consumption of goods and services.\"\n",
      "6.722501754760742\n",
      "Student : 5.917773485183716\n",
      "Teacher : 13.235199133555094\n",
      "['', '[Student]: \"Can we go over the last chapter again? I\\'m a bit confused.\"', '[Teacher]: \"Of course, let\\'s review it together.\"', '[Student]: \"Thank you.\"', '[Teacher]: \"Let\\'s start from the beginning.\"', '[Student]: \"That makes it clearer.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "27.45329475402832\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Can we go over the last chapter again? I'm a bit confused.\"\n",
      "token:  [Teacher]: \"Of course, let's review it together.\"\n",
      "6.415534973144531\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, let's review it together.\"\n",
      "token:  [Student]: \"Thank you.\"\n",
      "7.232381820678711\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you.\"\n",
      "token:  [Teacher]: \"Let's start from the beginning.\"\n",
      "6.786656379699707\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start from the beginning.\"\n",
      "token:  [Student]: \"That makes it clearer.\"\n",
      "19.93571662902832\n",
      "Student : 18.207131067911785\n",
      "Teacher : 6.601095676422119\n",
      "['', '[Teacher]: \"Let\\'s start the class with a quick recap of yesterday\\'s lesson.\"', '[Student]: \"Sure.\"', '[Teacher]: \"We discussed the concept of geometry. Can you tell me what you remember?\"', '[Student]: \"Geometry is a branch of mathematics concerned with questions of shape, size, relative position of figures, and the properties of space.\"', '[Teacher]: \"Excellent! Let\\'s move on to today\\'s lesson.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "20.01887321472168\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's start the class with a quick recap of yesterday's lesson.\"\n",
      "token:  [Student]: \"Sure.\"\n",
      "8.22253131866455\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure.\"\n",
      "token:  [Teacher]: \"We discussed the concept of geometry. Can you tell me what you remember?\"\n",
      "17.58807945251465\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"We discussed the concept of geometry. Can you tell me what you remember?\"\n",
      "token:  [Student]: \"Geometry is a branch of mathematics concerned with questions of shape, size, relative position of figures, and the properties of space.\"\n",
      "8.811572074890137\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Geometry is a branch of mathematics concerned with questions of shape, size, relative position of figures, and the properties of space.\"\n",
      "token:  [Teacher]: \"Excellent! Let's move on to today's lesson.\"\n",
      "8.593695640563965\n",
      "Student : 8.517051696777344\n",
      "Teacher : 15.400216102600098\n",
      "['', '[Student]: \"Sir, I didn\\'t understand the concept of gravitational force that we discussed in the last class. Can you explain it again?\"', '[Teacher]: \"Sure. Gravitational force is the force that attracts two bodies towards each other. Every object in the universe experiences this force due to its mass.\"', '[Student]: \"So, does it mean that the heavier the object, the stronger the gravitational force?\"', '[Teacher]: \"Yes, that\\'s correct. The gravitational force is directly proportional to the mass of the objects and inversely proportional to the square of the distance between them.\"', '[Student]: \"I see. That makes sense. Thank you, sir.\"', '[Teacher]: \"You\\'re welcome. Any other doubts?\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Sir, I didn't understand the concept of gravitational force that we discussed in the last class. Can you explain it again?\"\n",
      "19.889366149902344\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I didn't understand the concept of gravitational force that we discussed in the last class. Can you explain it again?\"\n",
      "token:  [Teacher]: \"Sure. Gravitational force is the force that attracts two bodies towards each other. Every object in the universe experiences this force due to its mass.\"\n",
      "5.343615531921387\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure. Gravitational force is the force that attracts two bodies towards each other. Every object in the universe experiences this force due to its mass.\"\n",
      "token:  [Student]: \"So, does it mean that the heavier the object, the stronger the gravitational force?\"\n",
      "6.252507209777832\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"So, does it mean that the heavier the object, the stronger the gravitational force?\"\n",
      "token:  [Teacher]: \"Yes, that's correct. The gravitational force is directly proportional to the mass of the objects and inversely proportional to the square of the distance between them.\"\n",
      "3.363757848739624\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Yes, that's correct. The gravitational force is directly proportional to the mass of the objects and inversely proportional to the square of the distance between them.\"\n",
      "token:  [Student]: \"I see. That makes sense. Thank you, sir.\"\n",
      "5.482138156890869\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I see. That makes sense. Thank you, sir.\"\n",
      "token:  [Teacher]: \"You're welcome. Any other doubts?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.185187339782715\n",
      "Student : 10.541337172190348\n",
      "Teacher : 6.964186906814575\n",
      "['', '[Teacher]: \"I\\'ve reviewed your assignment, and I have some feedback. You\\'ve done a good job overall, but there are a few areas where you could improve.\"', '[Student]: \"I appreciate your feedback, sir. Could you please elaborate on the areas I need to improve?\"', '[Teacher]: \"Sure. In the second question, you didn\\'t provide enough evidence to support your argument. Also, your conclusion could be more concise.\"', '[Student]: \"I understand. I\\'ll work on these areas. Thank you for your feedback.\"', '[Teacher]: \"You\\'re welcome. Keep up the good work.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"I've reviewed your assignment, and I have some feedback. You've done a good job overall, but there are a few areas where you could improve.\"\n",
      "10.789400100708008\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I've reviewed your assignment, and I have some feedback. You've done a good job overall, but there are a few areas where you could improve.\"\n",
      "token:  [Student]: \"I appreciate your feedback, sir. Could you please elaborate on the areas I need to improve?\"\n",
      "8.033063888549805\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I appreciate your feedback, sir. Could you please elaborate on the areas I need to improve?\"\n",
      "token:  [Teacher]: \"Sure. In the second question, you didn't provide enough evidence to support your argument. Also, your conclusion could be more concise.\"\n",
      "12.939950942993164\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure. In the second question, you didn't provide enough evidence to support your argument. Also, your conclusion could be more concise.\"\n",
      "token:  [Student]: \"I understand. I'll work on these areas. Thank you for your feedback.\"\n",
      "10.631823539733887\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I understand. I'll work on these areas. Thank you for your feedback.\"\n",
      "token:  [Teacher]: \"You're welcome. Keep up the good work.\"\n",
      "4.098956108093262\n",
      "Student : 9.332443714141846\n",
      "Teacher : 9.276102383931478\n",
      "['', '[Student]: \"Miss, I\\'m having trouble solving this math problem. Can you help me?\"', '[Teacher]: \"Of course. Let\\'s go through it together. What part are you struggling with?\"', '[Student]: \"I\\'m not sure how to start the problem. I understand the concept, but I\\'m having trouble applying it.\"', '[Teacher]: \"Alright. Let\\'s break it down step by step. First, let\\'s identify what the problem is asking for.\"', '[Student]: \"That makes sense. I think I understand now. Thank you, Miss.\"', '[Teacher]: \"You\\'re welcome. Don\\'t hesitate to ask if you have more doubts.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Miss, I'm having trouble solving this math problem. Can you help me?\"\n",
      "17.98426628112793\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I'm having trouble solving this math problem. Can you help me?\"\n",
      "token:  [Teacher]: \"Of course. Let's go through it together. What part are you struggling with?\"\n",
      "7.018128395080566\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course. Let's go through it together. What part are you struggling with?\"\n",
      "token:  [Student]: \"I'm not sure how to start the problem. I understand the concept, but I'm having trouble applying it.\"\n",
      "6.806484222412109\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm not sure how to start the problem. I understand the concept, but I'm having trouble applying it.\"\n",
      "token:  [Teacher]: \"Alright. Let's break it down step by step. First, let's identify what the problem is asking for.\"\n",
      "6.25126314163208\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Alright. Let's break it down step by step. First, let's identify what the problem is asking for.\"\n",
      "token:  [Student]: \"That makes sense. I think I understand now. Thank you, Miss.\"\n",
      "12.894097328186035\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That makes sense. I think I understand now. Thank you, Miss.\"\n",
      "token:  [Teacher]: \"You're welcome. Don't hesitate to ask if you have more doubts.\"\n",
      "8.31394100189209\n",
      "Student : 12.561615943908691\n",
      "Teacher : 7.194444179534912\n",
      "['', '[Student]: \"Sir, I\\'m interested in pursuing a career in computer science. Can you provide some guidance?\"', '[Teacher]: \"Sure. Computer science is a vast field with numerous opportunities. You could consider areas like software development, data science, artificial intelligence, and cybersecurity.\"', '[Student]: \"I\\'m particularly interested in artificial intelligence. What courses should I take to pursue a career in this field?\"', '[Teacher]: \"You should focus on courses related to machine learning, neural networks, and natural language processing. Also, having a strong foundation in mathematics and programming is crucial.\"', '[Student]: \"Thank you, sir. That was helpful.\"', '[Teacher]: \"You\\'re welcome. Feel free to ask if you have more questions.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Sir, I'm interested in pursuing a career in computer science. Can you provide some guidance?\"\n",
      "18.02363395690918\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I'm interested in pursuing a career in computer science. Can you provide some guidance?\"\n",
      "token:  [Teacher]: \"Sure. Computer science is a vast field with numerous opportunities. You could consider areas like software development, data science, artificial intelligence, and cybersecurity.\"\n",
      "8.496359825134277\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure. Computer science is a vast field with numerous opportunities. You could consider areas like software development, data science, artificial intelligence, and cybersecurity.\"\n",
      "token:  [Student]: \"I'm particularly interested in artificial intelligence. What courses should I take to pursue a career in this field?\"\n",
      "6.8138747215271\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm particularly interested in artificial intelligence. What courses should I take to pursue a career in this field?\"\n",
      "token:  [Teacher]: \"You should focus on courses related to machine learning, neural networks, and natural language processing. Also, having a strong foundation in mathematics and programming is crucial.\"\n",
      "6.610109806060791\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"You should focus on courses related to machine learning, neural networks, and natural language processing. Also, having a strong foundation in mathematics and programming is crucial.\"\n",
      "token:  [Student]: \"Thank you, sir. That was helpful.\"\n",
      "10.088915824890137\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you, sir. That was helpful.\"\n",
      "token:  [Teacher]: \"You're welcome. Feel free to ask if you have more questions.\"\n",
      "5.82420015335083\n",
      "Student : 11.642141501108805\n",
      "Teacher : 6.976889928181966\n",
      "['', '[Teacher]: \"With exams approaching, it\\'s important to have a good study plan. Any thoughts on how you plan to prepare?\"', '[Student]: \"I plan to revise all the chapters thoroughly and solve previous year question papers. I\\'ll also focus on my weak areas.\"', '[Teacher]: \"That\\'s a good strategy. Remember to take breaks and not to cram all the information at once. Consistent study is more effective.\"', '[Student]: \"Thank you for the advice, sir. I\\'ll keep that in mind.\"', '[Teacher]: \"You\\'re welcome. All the best for your exams.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"With exams approaching, it's important to have a good study plan. Any thoughts on how you plan to prepare?\"\n",
      "22.781192779541016\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"With exams approaching, it's important to have a good study plan. Any thoughts on how you plan to prepare?\"\n",
      "token:  [Student]: \"I plan to revise all the chapters thoroughly and solve previous year question papers. I'll also focus on my weak areas.\"\n",
      "38.98551559448242\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I plan to revise all the chapters thoroughly and solve previous year question papers. I'll also focus on my weak areas.\"\n",
      "token:  [Teacher]: \"That's a good strategy. Remember to take breaks and not to cram all the information at once. Consistent study is more effective.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.313230514526367\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a good strategy. Remember to take breaks and not to cram all the information at once. Consistent study is more effective.\"\n",
      "token:  [Student]: \"Thank you for the advice, sir. I'll keep that in mind.\"\n",
      "5.5925374031066895\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you for the advice, sir. I'll keep that in mind.\"\n",
      "token:  [Teacher]: \"You're welcome. All the best for your exams.\"\n",
      "6.720533847808838\n",
      "Student : 22.289026498794556\n",
      "Teacher : 14.60498571395874\n",
      "['', '[Teacher]: \"Effective time management is crucial for academic success. Have you thought about how you plan your study time?\"', '[Student]: \"I try to study for a few hours every day after school. But sometimes, I find it hard to stick to my schedule.\"', '[Teacher]: \"It\\'s important to have a realistic schedule. Also, remember to allocate time for relaxation and hobbies. This will help you avoid burnout.\"', '[Student]: \"That makes sense. I\\'ll try to balance my study and leisure time better. Thank you, Miss.\"', '[Teacher]: \"You\\'re welcome. Remember, it\\'s about working smarter, not harder.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Effective time management is crucial for academic success. Have you thought about how you plan your study time?\"\n",
      "25.64529037475586\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Effective time management is crucial for academic success. Have you thought about how you plan your study time?\"\n",
      "token:  [Student]: \"I try to study for a few hours every day after school. But sometimes, I find it hard to stick to my schedule.\"\n",
      "5.921313285827637\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I try to study for a few hours every day after school. But sometimes, I find it hard to stick to my schedule.\"\n",
      "token:  [Teacher]: \"It's important to have a realistic schedule. Also, remember to allocate time for relaxation and hobbies. This will help you avoid burnout.\"\n",
      "9.934228897094727\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"It's important to have a realistic schedule. Also, remember to allocate time for relaxation and hobbies. This will help you avoid burnout.\"\n",
      "token:  [Student]: \"That makes sense. I'll try to balance my study and leisure time better. Thank you, Miss.\"\n",
      "15.154918670654297\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That makes sense. I'll try to balance my study and leisure time better. Thank you, Miss.\"\n",
      "token:  [Teacher]: \"You're welcome. Remember, it's about working smarter, not harder.\"\n",
      "6.109696388244629\n",
      "Student : 10.538115978240967\n",
      "Teacher : 13.896405220031738\n",
      "['', '[Teacher]: \"Today, we\\'re going to explore the topic of climate change. Instead of a lecture, I want you to ask questions and explore the topic in-depth.\"', '[Student]: \"That sounds interesting. I\\'ve always wondered why the polar ice caps are melting at such a fast rate.\"', '[Teacher]: \"Great question. It\\'s mainly due to the increase in global temperatures. Can you think of why the temperatures are rising?\"', '[Student]: \"Is it because of the increase in greenhouse gases like carbon dioxide in the atmosphere?\"', '[Teacher]: \"Exactly. Now, let\\'s delve deeper into this issue.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Today, we're going to explore the topic of climate change. Instead of a lecture, I want you to ask questions and explore the topic in-depth.\"\n",
      "13.886837005615234\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Today, we're going to explore the topic of climate change. Instead of a lecture, I want you to ask questions and explore the topic in-depth.\"\n",
      "token:  [Student]: \"That sounds interesting. I've always wondered why the polar ice caps are melting at such a fast rate.\"\n",
      "6.357748031616211\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That sounds interesting. I've always wondered why the polar ice caps are melting at such a fast rate.\"\n",
      "token:  [Teacher]: \"Great question. It's mainly due to the increase in global temperatures. Can you think of why the temperatures are rising?\"\n",
      "10.010469436645508\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Great question. It's mainly due to the increase in global temperatures. Can you think of why the temperatures are rising?\"\n",
      "token:  [Student]: \"Is it because of the increase in greenhouse gases like carbon dioxide in the atmosphere?\"\n",
      "4.4781646728515625\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Is it because of the increase in greenhouse gases like carbon dioxide in the atmosphere?\"\n",
      "token:  [Teacher]: \"Exactly. Now, let's delve deeper into this issue.\"\n",
      "10.624652862548828\n",
      "Student : 5.417956352233887\n",
      "Teacher : 11.507319768269857\n",
      "['', '[Teacher]: \"I\\'ve noticed that you\\'ve been disrupting the class quite often. It\\'s important to respect the learning environment.\"', '[Student]: \"I apologize, sir. I didn\\'t realize I was causing a disturbance.\"', '[Teacher]: \"It\\'s important to be aware of our actions and how they affect others. Let\\'s try to maintain a conducive environment for learning.\"', '[Student]: \"I understand, sir. I\\'ll make sure to behave appropriately in the future.\"', '[Teacher]: \"Thank you. I appreciate your understanding.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"I've noticed that you've been disrupting the class quite often. It's important to respect the learning environment.\"\n",
      "20.72861671447754\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I've noticed that you've been disrupting the class quite often. It's important to respect the learning environment.\"\n",
      "token:  [Student]: \"I apologize, sir. I didn't realize I was causing a disturbance.\"\n",
      "6.604611873626709\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I apologize, sir. I didn't realize I was causing a disturbance.\"\n",
      "token:  [Teacher]: \"It's important to be aware of our actions and how they affect others. Let's try to maintain a conducive environment for learning.\"\n",
      "8.74595832824707\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"It's important to be aware of our actions and how they affect others. Let's try to maintain a conducive environment for learning.\"\n",
      "token:  [Student]: \"I understand, sir. I'll make sure to behave appropriately in the future.\"\n",
      "7.101824760437012\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I understand, sir. I'll make sure to behave appropriately in the future.\"\n",
      "token:  [Teacher]: \"Thank you. I appreciate your understanding.\"\n",
      "5.0875163078308105\n",
      "Student : 6.85321831703186\n",
      "Teacher : 11.520697116851807\n",
      "['', '[Student]: \"Sir, I\\'ve been facing some personal challenges recently and it\\'s affecting my academic performance.\"', '[Teacher]: \"I\\'m sorry to hear that. It\\'s important to remember that it\\'s okay to seek help. Have you considered speaking to a counselor?\"', '[Student]: \"I haven\\'t, but I\\'ll consider it. Thank you for your understanding, sir.\"', '[Teacher]: \"You\\'re welcome. Remember, we\\'re here to support you.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Sir, I've been facing some personal challenges recently and it's affecting my academic performance.\"\n",
      "26.562868118286133\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I've been facing some personal challenges recently and it's affecting my academic performance.\"\n",
      "token:  [Teacher]: \"I'm sorry to hear that. It's important to remember that it's okay to seek help. Have you considered speaking to a counselor?\"\n",
      "6.2161359786987305\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I'm sorry to hear that. It's important to remember that it's okay to seek help. Have you considered speaking to a counselor?\"\n",
      "token:  [Student]: \"I haven't, but I'll consider it. Thank you for your understanding, sir.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.416811943054199\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I haven't, but I'll consider it. Thank you for your understanding, sir.\"\n",
      "token:  [Teacher]: \"You're welcome. Remember, we're here to support you.\"\n",
      "5.70031213760376\n",
      "Student : 16.489840030670166\n",
      "Teacher : 5.958224058151245\n",
      "['', '[Teacher]: \"I\\'ve noticed you have a keen interest in literature. Have you thought about exploring this interest further?\"', '[Student]: \"I love reading, but I\\'m not sure how to explore it further.\"', '[Teacher]: \"You could consider joining a book club or even starting a blog to review books. It could be a great way to nurture your interest.\"', '[Student]: \"That sounds interesting. I\\'ll definitely consider it. Thank you, Miss.\"', '[Teacher]: \"You\\'re welcome. I\\'m sure you\\'ll do great.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"I've noticed you have a keen interest in literature. Have you thought about exploring this interest further?\"\n",
      "19.356245040893555\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I've noticed you have a keen interest in literature. Have you thought about exploring this interest further?\"\n",
      "token:  [Student]: \"I love reading, but I'm not sure how to explore it further.\"\n",
      "4.784702301025391\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I love reading, but I'm not sure how to explore it further.\"\n",
      "token:  [Teacher]: \"You could consider joining a book club or even starting a blog to review books. It could be a great way to nurture your interest.\"\n",
      "11.318190574645996\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"You could consider joining a book club or even starting a blog to review books. It could be a great way to nurture your interest.\"\n",
      "token:  [Student]: \"That sounds interesting. I'll definitely consider it. Thank you, Miss.\"\n",
      "10.55018138885498\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That sounds interesting. I'll definitely consider it. Thank you, Miss.\"\n",
      "token:  [Teacher]: \"You're welcome. I'm sure you'll do great.\"\n",
      "4.585800647735596\n",
      "Student : 7.6674418449401855\n",
      "Teacher : 11.753412087758383\n",
      "['', '[Teacher]: \"Working in a group can be challenging but it\\'s a great opportunity to learn from each other. How\\'s your group project going?\"', '[Student]: \"We\\'re making progress, but sometimes it\\'s hard to coordinate with everyone.\"', '[Teacher]: \"It\\'s important to have clear communication and assign roles based on each member\\'s strengths. This can help improve your group dynamics.\"', '[Student]: \"That\\'s a good idea. We\\'ll try that. Thank you, sir.\"', '[Teacher]: \"You\\'re welcome. Good luck with your project.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Working in a group can be challenging but it's a great opportunity to learn from each other. How's your group project going?\"\n",
      "18.4094181060791\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Working in a group can be challenging but it's a great opportunity to learn from each other. How's your group project going?\"\n",
      "token:  [Student]: \"We're making progress, but sometimes it's hard to coordinate with everyone.\"\n",
      "9.433369636535645\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"We're making progress, but sometimes it's hard to coordinate with everyone.\"\n",
      "token:  [Teacher]: \"It's important to have clear communication and assign roles based on each member's strengths. This can help improve your group dynamics.\"\n",
      "13.108036994934082\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"It's important to have clear communication and assign roles based on each member's strengths. This can help improve your group dynamics.\"\n",
      "token:  [Student]: \"That's a good idea. We'll try that. Thank you, sir.\"\n",
      "8.756158828735352\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That's a good idea. We'll try that. Thank you, sir.\"\n",
      "token:  [Teacher]: \"You're welcome. Good luck with your project.\"\n",
      "5.015806674957275\n",
      "Student : 9.094764232635498\n",
      "Teacher : 12.177753925323486\n",
      "['', '[Student]: \"Sir, I\\'m not happy with my exam results. I was expecting to do better.\"', '[Teacher]: \"I understand your disappointment. Let\\'s go through your paper and see where you can improve.\"', '[Student]: \"That would be helpful. Thank you, sir.\"', '[Teacher]: \"You\\'re welcome. Remember, it\\'s not about the marks, but about understanding the concepts.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Sir, I'm not happy with my exam results. I was expecting to do better.\"\n",
      "17.721708297729492\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I'm not happy with my exam results. I was expecting to do better.\"\n",
      "token:  [Teacher]: \"I understand your disappointment. Let's go through your paper and see where you can improve.\"\n",
      "7.589410305023193\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I understand your disappointment. Let's go through your paper and see where you can improve.\"\n",
      "token:  [Student]: \"That would be helpful. Thank you, sir.\"\n",
      "8.603410720825195\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That would be helpful. Thank you, sir.\"\n",
      "token:  [Teacher]: \"You're welcome. Remember, it's not about the marks, but about understanding the concepts.\"\n",
      "9.007391929626465\n",
      "Student : 13.162559509277344\n",
      "Teacher : 8.298401117324829\n",
      "['', '[Teacher]: \"Everyone has a unique learning style. Some people learn better by listening, while others learn better by doing. Have you thought about what works best for you?\"', '[Student]: \"I think I learn better by doing. Practical assignments and experiments help me understand concepts better.\"', '[Teacher]: \"That\\'s great. It\\'s important to understand your learning style to make the most of your study time.\"', '[Student]: \"I agree. Thank you for your guidance, sir.\"', '[Teacher]: \"You\\'re welcome. Happy learning!\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Everyone has a unique learning style. Some people learn better by listening, while others learn better by doing. Have you thought about what works best for you?\"\n",
      "12.252431869506836\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Everyone has a unique learning style. Some people learn better by listening, while others learn better by doing. Have you thought about what works best for you?\"\n",
      "token:  [Student]: \"I think I learn better by doing. Practical assignments and experiments help me understand concepts better.\"\n",
      "13.498613357543945\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I think I learn better by doing. Practical assignments and experiments help me understand concepts better.\"\n",
      "token:  [Teacher]: \"That's great. It's important to understand your learning style to make the most of your study time.\"\n",
      "7.126224040985107\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's great. It's important to understand your learning style to make the most of your study time.\"\n",
      "token:  [Student]: \"I agree. Thank you for your guidance, sir.\"\n",
      "10.009052276611328\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I agree. Thank you for your guidance, sir.\"\n",
      "token:  [Teacher]: \"You're welcome. Happy learning!\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.188695907592773\n",
      "Student : 11.753832817077637\n",
      "Teacher : 9.189117272694906\n",
      "['', '[Teacher]: \"Understanding the real-world application of a subject can enhance its relevance. Can anyone give an example of how we use algebra in our daily lives?\"', '[Student]: \"We use algebra when we calculate distances or when we manage our finances.\"', '[Teacher]: \"Exactly. Understanding the practical application of a subject can make it more interesting.\"', '[Student]: \"I agree, sir. It makes the subject more relatable.\"', '[Teacher]: \"Absolutely. Let\\'s try to relate our subjects to real-world scenarios whenever we can.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Understanding the real-world application of a subject can enhance its relevance. Can anyone give an example of how we use algebra in our daily lives?\"\n",
      "39.850704193115234\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Understanding the real-world application of a subject can enhance its relevance. Can anyone give an example of how we use algebra in our daily lives?\"\n",
      "token:  [Student]: \"We use algebra when we calculate distances or when we manage our finances.\"\n",
      "13.660603523254395\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"We use algebra when we calculate distances or when we manage our finances.\"\n",
      "token:  [Teacher]: \"Exactly. Understanding the practical application of a subject can make it more interesting.\"\n",
      "13.90531063079834\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Exactly. Understanding the practical application of a subject can make it more interesting.\"\n",
      "token:  [Student]: \"I agree, sir. It makes the subject more relatable.\"\n",
      "9.569477081298828\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I agree, sir. It makes the subject more relatable.\"\n",
      "token:  [Teacher]: \"Absolutely. Let's try to relate our subjects to real-world scenarios whenever we can.\"\n",
      "15.906683921813965\n",
      "Student : 11.615040302276611\n",
      "Teacher : 23.22089958190918\n",
      "['', '[Teacher]: \"To revise effectively, you need to understand your learning style. Some people learn better by reading, others by listening or doing.\"', '[Student]: \"I think I learn better by doing. How can I revise this way?\"', '[Teacher]: \"You can use active learning techniques. For example, you can solve problems, create flashcards, or teach the material to someone else.\"', '[Student]: \"That sounds helpful. I\\'ll try these techniques. Thank you, sir.\"', ' ', '[Teacher]: \"I\\'ve noticed that you\\'re not participating much in class. Is there a reason for this?\"', '[Student]: \"I\\'m not confident in my answers. I\\'m afraid I might say something wrong.\"', '[Teacher]: \"Remember, it\\'s okay to make mistakes. That\\'s how we learn. I encourage you to participate more. It will help you understand the material better.\"', '[Student]: \"I\\'ll try to participate more. Thank you for your advice, Miss.\"', ' ', '[Student]: \"Sir, we\\'re having some conflicts in our group project. We can\\'t agree on the direction of the project.\"', '[Teacher]: \"Conflicts are common in group projects. The key is to communicate effectively. Listen to each other\\'s ideas and try to find a compromise.\"', '[Student]: \"We\\'ll try that. Thank you, sir.\"', ' ', '[Teacher]: \"Let\\'s reflect on our field trip. What did you learn from it?\"', '[Student]: \"I learned a lot about the local ecosystem. It was interesting to see the concepts we learned in class applied in real life.\"', '[Teacher]: \"That\\'s great. Field trips are a valuable learning experience. They provide a practical perspective on the material we cover in class.\"', ' ', '[Teacher]: \"Let\\'s create an individualized learning plan for you. What areas do you feel you need to improve in?\"', '[Student]: \"I\\'m struggling with math. I find it difficult to understand the concepts.\"', '[Teacher]: \"We can focus on math in your learning plan. We\\'ll start with the basics and gradually move to more complex concepts. We\\'ll also include regular assessments to track your progress.\"', '[Student]: \"That sounds helpful. Thank you, Miss.\"', ' ', '[Teacher]: \"In our diverse classroom, it\\'s important to be culturally sensitive. Can anyone tell me what that means?\"', '[Student]: \"It means respecting and appreciating differences in cultures.\"', '[Teacher]: \"That\\'s correct. It\\'s about understanding and accepting that people have different cultural backgrounds and experiences.\"', ' ', '[Teacher]: \"I encourage you to get involved in community projects. It\\'s a great way to apply what you learn in class and make a positive impact.\"', '[Student]: \"I\\'m interested in environmental projects. Are there any opportunities in our community?\"', '[Teacher]: \"Yes, there are several environmental projects. I\\'ll provide you with more information.\"', ' ', '[Student]: \"Sir, I\\'m looking for internships but I\\'m not sure where to start.\"', '[Teacher]: \"Firstly, identify your areas of interest. Then, research companies that align with those interests.\"', '[Student]: \"I\\'m interested in software development. But I\\'m not sure how to approach these companies.\"', '[Teacher]: \"Start by tailoring your resume to highlight your skills in software development. Then, write a compelling cover letter explaining why you\\'re interested in the company and how you can contribute.\"', '[Student]: \"That sounds helpful. What about the interview process?\"', '[Teacher]: \"Prepare by researching common interview questions. Practice your answers but remember to be yourself during the interview.\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"To revise effectively, you need to understand your learning style. Some people learn better by reading, others by listening or doing.\"\n",
      "26.982492446899414\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"To revise effectively, you need to understand your learning style. Some people learn better by reading, others by listening or doing.\"\n",
      "token:  [Student]: \"I think I learn better by doing. How can I revise this way?\"\n",
      "9.365704536437988\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I think I learn better by doing. How can I revise this way?\"\n",
      "token:  [Teacher]: \"You can use active learning techniques. For example, you can solve problems, create flashcards, or teach the material to someone else.\"\n",
      "11.052462577819824\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"You can use active learning techniques. For example, you can solve problems, create flashcards, or teach the material to someone else.\"\n",
      "token:  [Student]: \"That sounds helpful. I'll try these techniques. Thank you, sir.\"\n",
      "11.530975341796875\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That sounds helpful. I'll try these techniques. Thank you, sir.\"\n",
      "token:   \n",
      "1741.0880126953125\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:   \n",
      "token:  [Teacher]: \"I've noticed that you're not participating much in class. Is there a reason for this?\"\n",
      "11.481382369995117\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I've noticed that you're not participating much in class. Is there a reason for this?\"\n",
      "token:  [Student]: \"I'm not confident in my answers. I'm afraid I might say something wrong.\"\n",
      "7.949779510498047\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm not confident in my answers. I'm afraid I might say something wrong.\"\n",
      "token:  [Teacher]: \"Remember, it's okay to make mistakes. That's how we learn. I encourage you to participate more. It will help you understand the material better.\"\n",
      "7.911651134490967\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Remember, it's okay to make mistakes. That's how we learn. I encourage you to participate more. It will help you understand the material better.\"\n",
      "token:  [Student]: \"I'll try to participate more. Thank you for your advice, Miss.\"\n",
      "9.790708541870117\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'll try to participate more. Thank you for your advice, Miss.\"\n",
      "token:   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2106.2685546875\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:   \n",
      "token:  [Student]: \"Sir, we're having some conflicts in our group project. We can't agree on the direction of the project.\"\n",
      "19.74815559387207\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, we're having some conflicts in our group project. We can't agree on the direction of the project.\"\n",
      "token:  [Teacher]: \"Conflicts are common in group projects. The key is to communicate effectively. Listen to each other's ideas and try to find a compromise.\"\n",
      "8.028877258300781\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Conflicts are common in group projects. The key is to communicate effectively. Listen to each other's ideas and try to find a compromise.\"\n",
      "token:  [Student]: \"We'll try that. Thank you, sir.\"\n",
      "12.49010181427002\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"We'll try that. Thank you, sir.\"\n",
      "token:   \n",
      "1977.0689697265625\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:   \n",
      "token:  [Teacher]: \"Let's reflect on our field trip. What did you learn from it?\"\n",
      "21.993267059326172\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's reflect on our field trip. What did you learn from it?\"\n",
      "token:  [Student]: \"I learned a lot about the local ecosystem. It was interesting to see the concepts we learned in class applied in real life.\"\n",
      "9.693585395812988\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I learned a lot about the local ecosystem. It was interesting to see the concepts we learned in class applied in real life.\"\n",
      "token:  [Teacher]: \"That's great. Field trips are a valuable learning experience. They provide a practical perspective on the material we cover in class.\"\n",
      "12.215595245361328\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's great. Field trips are a valuable learning experience. They provide a practical perspective on the material we cover in class.\"\n",
      "token:   \n",
      "763.94140625\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:   \n",
      "token:  [Teacher]: \"Let's create an individualized learning plan for you. What areas do you feel you need to improve in?\"\n",
      "16.66908073425293\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's create an individualized learning plan for you. What areas do you feel you need to improve in?\"\n",
      "token:  [Student]: \"I'm struggling with math. I find it difficult to understand the concepts.\"\n",
      "6.188260078430176\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm struggling with math. I find it difficult to understand the concepts.\"\n",
      "token:  [Teacher]: \"We can focus on math in your learning plan. We'll start with the basics and gradually move to more complex concepts. We'll also include regular assessments to track your progress.\"\n",
      "11.03979206085205\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"We can focus on math in your learning plan. We'll start with the basics and gradually move to more complex concepts. We'll also include regular assessments to track your progress.\"\n",
      "token:  [Student]: \"That sounds helpful. Thank you, Miss.\"\n",
      "13.540326118469238\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That sounds helpful. Thank you, Miss.\"\n",
      "token:   \n",
      "2140.521240234375\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:   \n",
      "token:  [Teacher]: \"In our diverse classroom, it's important to be culturally sensitive. Can anyone tell me what that means?\"\n",
      "21.90986442565918\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"In our diverse classroom, it's important to be culturally sensitive. Can anyone tell me what that means?\"\n",
      "token:  [Student]: \"It means respecting and appreciating differences in cultures.\"\n",
      "9.437115669250488\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"It means respecting and appreciating differences in cultures.\"\n",
      "token:  [Teacher]: \"That's correct. It's about understanding and accepting that people have different cultural backgrounds and experiences.\"\n",
      "7.510466575622559\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct. It's about understanding and accepting that people have different cultural backgrounds and experiences.\"\n",
      "token:   \n",
      "637.8539428710938\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:   \n",
      "token:  [Teacher]: \"I encourage you to get involved in community projects. It's a great way to apply what you learn in class and make a positive impact.\"\n",
      "11.867573738098145\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I encourage you to get involved in community projects. It's a great way to apply what you learn in class and make a positive impact.\"\n",
      "token:  [Student]: \"I'm interested in environmental projects. Are there any opportunities in our community?\"\n",
      "9.30688190460205\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm interested in environmental projects. Are there any opportunities in our community?\"\n",
      "token:  [Teacher]: \"Yes, there are several environmental projects. I'll provide you with more information.\"\n",
      "5.922089576721191\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Yes, there are several environmental projects. I'll provide you with more information.\"\n",
      "token:   \n",
      "914.3792724609375\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:   \n",
      "token:  [Student]: \"Sir, I'm looking for internships but I'm not sure where to start.\"\n",
      "17.60552215576172\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I'm looking for internships but I'm not sure where to start.\"\n",
      "token:  [Teacher]: \"Firstly, identify your areas of interest. Then, research companies that align with those interests.\"\n",
      "16.94683074951172\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Firstly, identify your areas of interest. Then, research companies that align with those interests.\"\n",
      "token:  [Student]: \"I'm interested in software development. But I'm not sure how to approach these companies.\"\n",
      "9.771502494812012\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm interested in software development. But I'm not sure how to approach these companies.\"\n",
      "token:  [Teacher]: \"Start by tailoring your resume to highlight your skills in software development. Then, write a compelling cover letter explaining why you're interested in the company and how you can contribute.\"\n",
      "7.239817142486572\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Start by tailoring your resume to highlight your skills in software development. Then, write a compelling cover letter explaining why you're interested in the company and how you can contribute.\"\n",
      "token:  [Student]: \"That sounds helpful. What about the interview process?\"\n",
      "11.84841251373291\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"That sounds helpful. What about the interview process?\"\n",
      "token:  [Teacher]: \"Prepare by researching common interview questions. Practice your answers but remember to be yourself during the interview.\"\n",
      "17.98647117614746\n",
      "Student : 261.37579369544983\n",
      "Teacher : 375.0692002773285\n",
      "['', '[Teacher]: \"Let\\'s discuss some ethical dilemmas related to our course. For instance, consider the use of AI in decision-making. What are your thoughts?\"', '[Student]: \"While AI can make decisions faster and more accurately, it might not consider ethical implications.\"', '[Teacher]: \"That\\'s a valid point. AI might not consider fairness, privacy, and other ethical issues. What can be done to address this?\"', '[Student]: \"We could incorporate ethical guidelines into the AI\\'s decision-making process.\"', '[Teacher]: \"Excellent. That\\'s one possible solution. Any other thoughts?\"']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Teacher]: \"Let's discuss some ethical dilemmas related to our course. For instance, consider the use of AI in decision-making. What are your thoughts?\"\n",
      "20.847633361816406\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Let's discuss some ethical dilemmas related to our course. For instance, consider the use of AI in decision-making. What are your thoughts?\"\n",
      "token:  [Student]: \"While AI can make decisions faster and more accurately, it might not consider ethical implications.\"\n",
      "16.558231353759766\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"While AI can make decisions faster and more accurately, it might not consider ethical implications.\"\n",
      "token:  [Teacher]: \"That's a valid point. AI might not consider fairness, privacy, and other ethical issues. What can be done to address this?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.331642150878906\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a valid point. AI might not consider fairness, privacy, and other ethical issues. What can be done to address this?\"\n",
      "token:  [Student]: \"We could incorporate ethical guidelines into the AI's decision-making process.\"\n",
      "8.555794715881348\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"We could incorporate ethical guidelines into the AI's decision-making process.\"\n",
      "token:  [Teacher]: \"Excellent. That's one possible solution. Any other thoughts?\"\n",
      "13.542702674865723\n",
      "Student : 12.557013034820557\n",
      "Teacher : 14.573992729187012\n",
      "['', '[Student]: \"Miss, I\\'m feeling stressed about the upcoming exams. I\\'m not sure how to manage it.\"', '[Teacher]: \"It\\'s normal to feel stressed before exams. But there are ways to manage it. Firstly, create a study schedule. This will help you stay organized and reduce anxiety.\"', '[Student]: \"I have a schedule but I still feel overwhelmed.\"', '[Teacher]: \"In that case, try some relaxation techniques like deep breathing or meditation. Also, make sure to take breaks and get enough sleep.\"', '[Student]: \"I\\'ll try that. Thank you, Miss.\"', '']\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [Student]: \"Miss, I'm feeling stressed about the upcoming exams. I'm not sure how to manage it.\"\n",
      "20.593446731567383\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I'm feeling stressed about the upcoming exams. I'm not sure how to manage it.\"\n",
      "token:  [Teacher]: \"It's normal to feel stressed before exams. But there are ways to manage it. Firstly, create a study schedule. This will help you stay organized and reduce anxiety.\"\n",
      "8.6890230178833\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"It's normal to feel stressed before exams. But there are ways to manage it. Firstly, create a study schedule. This will help you stay organized and reduce anxiety.\"\n",
      "token:  [Student]: \"I have a schedule but I still feel overwhelmed.\"\n",
      "9.439287185668945\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I have a schedule but I still feel overwhelmed.\"\n",
      "token:  [Teacher]: \"In that case, try some relaxation techniques like deep breathing or meditation. Also, make sure to take breaks and get enough sleep.\"\n",
      "8.97716999053955\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"In that case, try some relaxation techniques like deep breathing or meditation. Also, make sure to take breaks and get enough sleep.\"\n",
      "token:  [Student]: \"I'll try that. Thank you, Miss.\"\n",
      "9.97081470489502\n",
      "prompt:  This is a conversation between Teacher and Student.\n",
      "Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'll try that. Thank you, Miss.\"\n",
      "token:  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[([^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]]+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m matches \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(pattern, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(dataset))\n\u001b[0;32m---> 14\u001b[0m perpl \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprmt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patt \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(matches):\n\u001b[1;32m     16\u001b[0m     idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([index \u001b[38;5;28;01mfor\u001b[39;00m index, element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(matches) \u001b[38;5;28;01mif\u001b[39;00m element \u001b[38;5;241m==\u001b[39m patt])\n",
      "Cell \u001b[0;32mIn[25], line 41\u001b[0m, in \u001b[0;36mcompute_perplexity\u001b[0;34m(dialog, prmt, mod_idx)\u001b[0m\n\u001b[1;32m     38\u001b[0m target_ids[:, :\u001b[38;5;241m-\u001b[39mtrg_len] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 41\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# loss is calculated using CrossEntropyLoss which averages over valid labels\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# to the left by 1.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     neg_log_likelihood \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/.py31env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/.py31env/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1074\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1074\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/.py31env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/.py31env/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:837\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    834\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mn_layer)\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 837\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwte\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwpe(position_ids)\n\u001b[1;32m    839\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\n",
      "File \u001b[0;32m~/miniconda3/envs/.py31env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/.py31env/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/.py31env/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/gpt4/teacher_dominated.txt\"\n",
    "with open(file_path, 'r') as file:\n",
    "    datasets = file.read().split('\\n\\n')\n",
    "\n",
    "# Now 'dataset' is a list where each element is a chunk from the file\n",
    "for dataset in datasets:\n",
    "    firstliner = \"\"\n",
    "    dataset = [firstliner] + dataset.split(\"\\n\")\n",
    "    print(dataset)\n",
    "    prmt = \"This is a conversation between Teacher and Student.\\nPredict the next most probable utterance:\"\n",
    "\n",
    "    pattern = r'\\[([^\\]]+)\\]'\n",
    "    matches = re.findall(pattern, \"\".join(dataset))\n",
    "    perpl = compute_perplexity(dataset, prmt)\n",
    "    for patt in np.unique(matches):\n",
    "        idx = np.asarray([index for index, element in enumerate(matches) if element == patt])\n",
    "        print(f\"{patt} :\", np.mean(np.asarray(perpl)[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I have prepared a presentation on the solar system. Can I present it to the class?\"', '[Teacher]: \"Sure, go ahead.\"', '[Student]: \"Thank you. So, the solar system consists of the Sun and everything that orbits around it.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"There are eight planets in the solar system. They are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.\"', '[Teacher]: \"Very good. Continue.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I have prepared a presentation on the solar system. Can I present it to the class?\"\n",
      "20.73455238342285\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I have prepared a presentation on the solar system. Can I present it to the class?\"\n",
      "token:  [Teacher]: \"Sure, go ahead.\"\n",
      "5.137509346008301\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, go ahead.\"\n",
      "token:  [Student]: \"Thank you. So, the solar system consists of the Sun and everything that orbits around it.\"\n",
      "15.1744966506958\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you. So, the solar system consists of the Sun and everything that orbits around it.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "6.724918365478516\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"There are eight planets in the solar system. They are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.\"\n",
      "3.396245241165161\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"There are eight planets in the solar system. They are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "18.098182678222656\n",
      "Student : 13.101764758427938\n",
      "Teacher : 9.986870129903158\n",
      "['This is a conversation between Teacher and Student. ', '[Teacher]: \"Can anyone explain the Pythagorean theorem?\"', '[Student]: \"Yes, I can. The Pythagorean theorem states that in a right-angled triangle, the square of the hypotenuse is equal to the sum of the squares of the other two sides.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It\\'s a fundamental relation in Euclidean geometry and it\\'s used in many areas of mathematics and physics.\"', '[Teacher]: \"Excellent explanation.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Teacher]: \"Can anyone explain the Pythagorean theorem?\"\n",
      "24.16722869873047\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Can anyone explain the Pythagorean theorem?\"\n",
      "token:  [Student]: \"Yes, I can. The Pythagorean theorem states that in a right-angled triangle, the square of the hypotenuse is equal to the sum of the squares of the other two sides.\"\n",
      "2.8331680297851562\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I can. The Pythagorean theorem states that in a right-angled triangle, the square of the hypotenuse is equal to the sum of the squares of the other two sides.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "9.074944496154785\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It's a fundamental relation in Euclidean geometry and it's used in many areas of mathematics and physics.\"\n",
      "14.712676048278809\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It's a fundamental relation in Euclidean geometry and it's used in many areas of mathematics and physics.\"\n",
      "token:  [Teacher]: \"Excellent explanation.\"\n",
      "30.813444137573242\n",
      "Student : 8.772922039031982\n",
      "Teacher : 21.351872444152832\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I have done some extra research on the topic of World War II. Can I share it with the class?\"', '[Teacher]: \"Of course, please go ahead.\"', '[Student]: \"World War II was the deadliest conflict in human history, resulting in 70 to 85 million fatalities.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It involved more than 30 countries and resulted in significant changes in the world.\"', '[Teacher]: \"Very good. Continue.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I have done some extra research on the topic of World War II. Can I share it with the class?\"\n",
      "18.169588088989258\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I have done some extra research on the topic of World War II. Can I share it with the class?\"\n",
      "token:  [Teacher]: \"Of course, please go ahead.\"\n",
      "6.743897914886475\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, please go ahead.\"\n",
      "token:  [Student]: \"World War II was the deadliest conflict in human history, resulting in 70 to 85 million fatalities.\"\n",
      "16.001415252685547\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"World War II was the deadliest conflict in human history, resulting in 70 to 85 million fatalities.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "8.786882400512695\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It involved more than 30 countries and resulted in significant changes in the world.\"\n",
      "42.58078384399414\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It involved more than 30 countries and resulted in significant changes in the world.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "17.114910125732422\n",
      "Student : 25.58392906188965\n",
      "Teacher : 10.881896813710531\n",
      "['This is a conversation between Teacher and Student. ', '[Teacher]: \"Can anyone explain the process of photosynthesis?\"', '[Student]: \"Yes, I can. Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll pigments.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It involves the conversion of carbon dioxide and water into glucose and oxygen. The glucose is used by the plants for energy and growth.\"', '[Teacher]: \"Excellent explanation.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Teacher]: \"Can anyone explain the process of photosynthesis?\"\n",
      "39.7297248840332\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Can anyone explain the process of photosynthesis?\"\n",
      "token:  [Student]: \"Yes, I can. Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll pigments.\"\n",
      "8.1707181930542\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I can. Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll pigments.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "9.120829582214355\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It involves the conversion of carbon dioxide and water into glucose and oxygen. The glucose is used by the plants for energy and growth.\"\n",
      "21.180173873901367\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It involves the conversion of carbon dioxide and water into glucose and oxygen. The glucose is used by the plants for energy and growth.\"\n",
      "token:  [Teacher]: \"Excellent explanation.\"\n",
      "35.7459831237793\n",
      "Student : 14.675446033477783\n",
      "Teacher : 28.198845863342285\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I have prepared a book report on \\'To Kill a Mockingbird\\'. Can I present it to the class?\"', '[Teacher]: \"Sure, go ahead.\"', '[Student]: \"Thank you. \\'To Kill a Mockingbird\\' is a novel by Harper Lee published in 1960. It was immediately successful, winning the Pulitzer Prize, and has become a classic of modern American literature.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"The plot and characters are loosely based on Lee\\'s observations of her family, her neighbors and an event that occurred near her hometown of Monroeville, Alabama, in 1936, when she was 10 years old.\"', '[Teacher]: \"Very good. Continue.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I have prepared a book report on 'To Kill a Mockingbird'. Can I present it to the class?\"\n",
      "18.72336769104004\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I have prepared a book report on 'To Kill a Mockingbird'. Can I present it to the class?\"\n",
      "token:  [Teacher]: \"Sure, go ahead.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.735140800476074\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, go ahead.\"\n",
      "token:  [Student]: \"Thank you. 'To Kill a Mockingbird' is a novel by Harper Lee published in 1960. It was immediately successful, winning the Pulitzer Prize, and has become a classic of modern American literature.\"\n",
      "8.99692153930664\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you. 'To Kill a Mockingbird' is a novel by Harper Lee published in 1960. It was immediately successful, winning the Pulitzer Prize, and has become a classic of modern American literature.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "12.32402515411377\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"The plot and characters are loosely based on Lee's observations of her family, her neighbors and an event that occurred near her hometown of Monroeville, Alabama, in 1936, when she was 10 years old.\"\n",
      "20.284957885742188\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The plot and characters are loosely based on Lee's observations of her family, her neighbors and an event that occurred near her hometown of Monroeville, Alabama, in 1936, when she was 10 years old.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "20.84039306640625\n",
      "Student : 16.00174903869629\n",
      "Teacher : 12.966519673665365\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I have been studying the French Revolution and I would like to share some insights.\"', '[Teacher]: \"Please, go ahead.\"', '[Student]: \"The French Revolution was a period of radical political and societal change in France that lasted from 1789 until 1799.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It led to the end of monarchy and the rise of Napoleon Bonaparte.\"', '[Teacher]: \"Very good. Continue.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I have been studying the French Revolution and I would like to share some insights.\"\n",
      "21.28262710571289\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I have been studying the French Revolution and I would like to share some insights.\"\n",
      "token:  [Teacher]: \"Please, go ahead.\"\n",
      "10.34494400024414\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Please, go ahead.\"\n",
      "token:  [Student]: \"The French Revolution was a period of radical political and societal change in France that lasted from 1789 until 1799.\"\n",
      "11.91677474975586\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The French Revolution was a period of radical political and societal change in France that lasted from 1789 until 1799.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "10.712827682495117\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It led to the end of monarchy and the rise of Napoleon Bonaparte.\"\n",
      "21.139759063720703\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It led to the end of monarchy and the rise of Napoleon Bonaparte.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "18.84342384338379\n",
      "Student : 18.113053639729817\n",
      "Teacher : 13.300398508707682\n",
      "['This is a conversation between Teacher and Student. ', '[Teacher]: \"Can anyone explain the concept of evolution?\"', '[Student]: \"Yes, I can. Evolution is the process by which different kinds of living organisms are thought to have developed and diversified from earlier forms during the history of the earth.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"The theory of evolution is widely accepted among the scientific community, providing a broad explanation of the range of life forms on Earth.\"', '[Teacher]: \"Excellent explanation.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Teacher]: \"Can anyone explain the concept of evolution?\"\n",
      "32.930824279785156\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Can anyone explain the concept of evolution?\"\n",
      "token:  [Student]: \"Yes, I can. Evolution is the process by which different kinds of living organisms are thought to have developed and diversified from earlier forms during the history of the earth.\"\n",
      "7.518041133880615\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I can. Evolution is the process by which different kinds of living organisms are thought to have developed and diversified from earlier forms during the history of the earth.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "12.324257850646973\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"The theory of evolution is widely accepted among the scientific community, providing a broad explanation of the range of life forms on Earth.\"\n",
      "16.738048553466797\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The theory of evolution is widely accepted among the scientific community, providing a broad explanation of the range of life forms on Earth.\"\n",
      "token:  [Teacher]: \"Excellent explanation.\"\n",
      "36.076473236083984\n",
      "Student : 12.128044843673706\n",
      "Teacher : 27.11051845550537\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I have done some extra research on the topic of the Civil Rights Movement. Can I share it with the class?\"', '[Teacher]: \"Of course, please go ahead.\"', '[Student]: \"The Civil Rights Movement was a struggle for social justice that took place mainly during the 1950s and 1960s for Black Americans to gain equal rights under the law in the United States.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It was a major influence on social justice movements worldwide.\"', '[Teacher]: \"Very good. Continue.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I have done some extra research on the topic of the Civil Rights Movement. Can I share it with the class?\"\n",
      "22.16506576538086\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I have done some extra research on the topic of the Civil Rights Movement. Can I share it with the class?\"\n",
      "token:  [Teacher]: \"Of course, please go ahead.\"\n",
      "7.209322929382324\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, please go ahead.\"\n",
      "token:  [Student]: \"The Civil Rights Movement was a struggle for social justice that took place mainly during the 1950s and 1960s for Black Americans to gain equal rights under the law in the United States.\"\n",
      "11.19007396697998\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The Civil Rights Movement was a struggle for social justice that took place mainly during the 1950s and 1960s for Black Americans to gain equal rights under the law in the United States.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "10.231995582580566\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It was a major influence on social justice movements worldwide.\"\n",
      "42.73496627807617\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It was a major influence on social justice movements worldwide.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "20.626300811767578\n",
      "Student : 25.36336867014567\n",
      "Teacher : 12.68920644124349\n",
      "['This is a conversation between Teacher and Student. ', '[Teacher]: \"Can anyone explain the concept of gravity?\"', '[Student]: \"Yes, I can. Gravity is a force by which a planet or other body draws objects toward its center.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It\\'s the force that keeps us on the ground and the planets orbiting the sun.\"', '[Teacher]: \"Excellent explanation.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Teacher]: \"Can anyone explain the concept of gravity?\"\n",
      "31.704809188842773\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Can anyone explain the concept of gravity?\"\n",
      "token:  [Student]: \"Yes, I can. Gravity is a force by which a planet or other body draws objects toward its center.\"\n",
      "8.449865341186523\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I can. Gravity is a force by which a planet or other body draws objects toward its center.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.917330741882324\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It's the force that keeps us on the ground and the planets orbiting the sun.\"\n",
      "21.184602737426758\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It's the force that keeps us on the ground and the planets orbiting the sun.\"\n",
      "token:  [Teacher]: \"Excellent explanation.\"\n",
      "34.6729621887207\n",
      "Student : 14.81723403930664\n",
      "Teacher : 24.765034039815266\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I have prepared a presentation on the human body. Can I present it to the class?\"', '[Teacher]: \"Sure, go ahead.\"', '[Student]: \"Thank you. The human body is made up of several organ systems that work together as one unit.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"These systems include the circulatory system, respiratory system, immune system, skeletal system, digestive system, nervous system, and more.\"', '[Teacher]: \"Very good. Continue.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I have prepared a presentation on the human body. Can I present it to the class?\"\n",
      "16.313222885131836\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I have prepared a presentation on the human body. Can I present it to the class?\"\n",
      "token:  [Teacher]: \"Sure, go ahead.\"\n",
      "4.792267799377441\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, go ahead.\"\n",
      "token:  [Student]: \"Thank you. The human body is made up of several organ systems that work together as one unit.\"\n",
      "13.951931953430176\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you. The human body is made up of several organ systems that work together as one unit.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "7.52622652053833\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"These systems include the circulatory system, respiratory system, immune system, skeletal system, digestive system, nervous system, and more.\"\n",
      "13.832047462463379\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"These systems include the circulatory system, respiratory system, immune system, skeletal system, digestive system, nervous system, and more.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "17.305397033691406\n",
      "Student : 14.69906743367513\n",
      "Teacher : 9.874630451202393\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I have been studying the Industrial Revolution and I would like to share some insights.\"', '[Teacher]: \"Please, go ahead.\"', '[Student]: \"The Industrial Revolution was a period of major industrialization and innovation that took place during the late 1700s and early 1800s.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It began in Great Britain and quickly spread throughout the world.\"', '[Teacher]: \"Very good. Continue.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I have been studying the Industrial Revolution and I would like to share some insights.\"\n",
      "26.939340591430664\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I have been studying the Industrial Revolution and I would like to share some insights.\"\n",
      "token:  [Teacher]: \"Please, go ahead.\"\n",
      "9.370902061462402\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Please, go ahead.\"\n",
      "token:  [Student]: \"The Industrial Revolution was a period of major industrialization and innovation that took place during the late 1700s and early 1800s.\"\n",
      "10.648289680480957\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The Industrial Revolution was a period of major industrialization and innovation that took place during the late 1700s and early 1800s.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "9.90530776977539\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It began in Great Britain and quickly spread throughout the world.\"\n",
      "24.773374557495117\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It began in Great Britain and quickly spread throughout the world.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "15.16612434387207\n",
      "Student : 20.787001609802246\n",
      "Teacher : 11.480778058369955\n",
      "['This is a conversation between Teacher and Student. ', '[Teacher]: \"Can anyone explain the concept of democracy?\"', '[Student]: \"Yes, I can. Democracy is a system of government where the citizens exercise power by voting.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"In a direct democracy, the citizens as a whole form a governing body and vote directly on each issue.\"', '[Teacher]: \"Excellent explanation.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Teacher]: \"Can anyone explain the concept of democracy?\"\n",
      "39.069740295410156\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Can anyone explain the concept of democracy?\"\n",
      "token:  [Student]: \"Yes, I can. Democracy is a system of government where the citizens exercise power by voting.\"\n",
      "6.490097999572754\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I can. Democracy is a system of government where the citizens exercise power by voting.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "9.40844440460205\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"In a direct democracy, the citizens as a whole form a governing body and vote directly on each issue.\"\n",
      "25.795726776123047\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"In a direct democracy, the citizens as a whole form a governing body and vote directly on each issue.\"\n",
      "token:  [Teacher]: \"Excellent explanation.\"\n",
      "45.627113342285156\n",
      "Student : 16.1429123878479\n",
      "Teacher : 31.36843268076579\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I have done some extra research on the topic of the Cold War. Can I share it with the class?\"', '[Teacher]: \"Of course, please go ahead.\"', '[Student]: \"The Cold War was a period of geopolitical tension between the Soviet Union and the United States and their respective allies, the Eastern Bloc and the Western Bloc, after World War II.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It lasted from 1947 to 1991, and it was characterized by political and military tension, but there was no large-scale fighting directly between the two superpowers.\"', '[Teacher]: \"Very good. Continue.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I have done some extra research on the topic of the Cold War. Can I share it with the class?\"\n",
      "19.674392700195312\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I have done some extra research on the topic of the Cold War. Can I share it with the class?\"\n",
      "token:  [Teacher]: \"Of course, please go ahead.\"\n",
      "6.781813621520996\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, please go ahead.\"\n",
      "token:  [Student]: \"The Cold War was a period of geopolitical tension between the Soviet Union and the United States and their respective allies, the Eastern Bloc and the Western Bloc, after World War II.\"\n",
      "6.574210166931152\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The Cold War was a period of geopolitical tension between the Soviet Union and the United States and their respective allies, the Eastern Bloc and the Western Bloc, after World War II.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "10.602840423583984\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It lasted from 1947 to 1991, and it was characterized by political and military tension, but there was no large-scale fighting directly between the two superpowers.\"\n",
      "27.624326705932617\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It lasted from 1947 to 1991, and it was characterized by political and military tension, but there was no large-scale fighting directly between the two superpowers.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "22.158720016479492\n",
      "Student : 17.957643191019695\n",
      "Teacher : 13.181124687194824\n",
      "['This is a conversation between Teacher and Student. ', '[Teacher]: \"Can anyone explain the concept of climate change?\"', '[Student]: \"Yes, I can. Climate change refers to significant changes in global temperatures and weather patterns over time.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It\\'s a major issue that\\'s largely caused by human activities, such as burning fossil fuels, deforestation, and industrial processes.\"', '[Teacher]: \"Excellent explanation.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Teacher]: \"Can anyone explain the concept of climate change?\"\n",
      "30.114797592163086\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Can anyone explain the concept of climate change?\"\n",
      "token:  [Student]: \"Yes, I can. Climate change refers to significant changes in global temperatures and weather patterns over time.\"\n",
      "8.455347061157227\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I can. Climate change refers to significant changes in global temperatures and weather patterns over time.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.733360290527344\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It's a major issue that's largely caused by human activities, such as burning fossil fuels, deforestation, and industrial processes.\"\n",
      "17.133880615234375\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It's a major issue that's largely caused by human activities, such as burning fossil fuels, deforestation, and industrial processes.\"\n",
      "token:  [Teacher]: \"Excellent explanation.\"\n",
      "33.373477935791016\n",
      "Student : 12.7946138381958\n",
      "Teacher : 24.07387860616048\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I have prepared a presentation on the Roman Empire. Can I present it to the class?\"', '[Teacher]: \"Sure, go ahead.\"', '[Student]: \"Thank you. The Roman Empire was the post-Republican period of ancient Rome.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It had a government headed by emperors and large territorial holdings around the Mediterranean Sea in Europe, North Africa, and West Asia.\"', '[Teacher]: \"Very good. Continue.\"', '... (Continue in this format for 25 more interactions)', '[Student]: \"Sir, I have been studying the Renaissance period and I would like to share some insights.\"', '[Teacher]: \"Please, go ahead.\"', '[Student]: \"The Renaissance was a period in European history marking the transition from the Middle Ages to Modernity and covering the 15th and 16th centuries.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It was characterized by a renewed interest in the classical knowledge and values of ancient Greece and Rome.\"', '[Teacher]: \"Very good. Continue.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I have prepared a presentation on the Roman Empire. Can I present it to the class?\"\n",
      "22.09537696838379\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I have prepared a presentation on the Roman Empire. Can I present it to the class?\"\n",
      "token:  [Teacher]: \"Sure, go ahead.\"\n",
      "5.123293399810791\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, go ahead.\"\n",
      "token:  [Student]: \"Thank you. The Roman Empire was the post-Republican period of ancient Rome.\"\n",
      "40.43203353881836\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you. The Roman Empire was the post-Republican period of ancient Rome.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "8.525516510009766\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It had a government headed by emperors and large territorial holdings around the Mediterranean Sea in Europe, North Africa, and West Asia.\"\n",
      "36.35743713378906\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It had a government headed by emperors and large territorial holdings around the Mediterranean Sea in Europe, North Africa, and West Asia.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "20.804534912109375\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Very good. Continue.\"\n",
      "token:  ... (Continue in this format for 25 more interactions)\n",
      "110.17108154296875\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  ... (Continue in this format for 25 more interactions)\n",
      "token:  [Student]: \"Sir, I have been studying the Renaissance period and I would like to share some insights.\"\n",
      "40.258888244628906\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I have been studying the Renaissance period and I would like to share some insights.\"\n",
      "token:  [Teacher]: \"Please, go ahead.\"\n",
      "9.320154190063477\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Please, go ahead.\"\n",
      "token:  [Student]: \"The Renaissance was a period in European history marking the transition from the Middle Ages to Modernity and covering the 15th and 16th centuries.\"\n",
      "13.114015579223633\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The Renaissance was a period in European history marking the transition from the Middle Ages to Modernity and covering the 15th and 16th centuries.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "10.464210510253906\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It was characterized by a renewed interest in the classical knowledge and values of ancient Greece and Rome.\"\n",
      "26.153736114501953\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It was characterized by a renewed interest in the classical knowledge and values of ancient Greece and Rome.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "17.142484664916992\n",
      "Student : 38.14004898071289\n",
      "Teacher : 18.99666412671407\n",
      "['This is a conversation between Teacher and Student. ', '[Teacher]: \"Can anyone explain the concept of quantum physics?\"', '[Student]: \"Yes, I can. Quantum physics is a branch of physics that deals with phenomena on a very small scale, such as atoms and subatomic particles.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"It\\'s known for its \\'weird\\' phenomena, such as superposition and entanglement.\"', '[Teacher]: \"Excellent explanation.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Teacher]: \"Can anyone explain the concept of quantum physics?\"\n",
      "30.664772033691406\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Can anyone explain the concept of quantum physics?\"\n",
      "token:  [Student]: \"Yes, I can. Quantum physics is a branch of physics that deals with phenomena on a very small scale, such as atoms and subatomic particles.\"\n",
      "4.39962100982666\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I can. Quantum physics is a branch of physics that deals with phenomena on a very small scale, such as atoms and subatomic particles.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "8.8993558883667\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"It's known for its 'weird' phenomena, such as superposition and entanglement.\"\n",
      "23.22559356689453\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It's known for its 'weird' phenomena, such as superposition and entanglement.\"\n",
      "token:  [Teacher]: \"Excellent explanation.\"\n",
      "30.72965431213379\n",
      "Student : 13.812607288360596\n",
      "Teacher : 23.431260744730633\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I have done some extra research on the topic of the Enlightenment. Can I share it with the class?\"', '[Teacher]: \"Of course, please go ahead.\"', '[Student]: \"The Enlightenment was an intellectual and philosophical movement that dominated the world of ideas in Europe during the 17th and 18th centuries.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"Enlightenment thinkers sought to reform society and advance knowledge using reason and the scientific method.\"', '[Teacher]: \"Very good. Continue.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I have done some extra research on the topic of the Enlightenment. Can I share it with the class?\"\n",
      "26.932764053344727\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I have done some extra research on the topic of the Enlightenment. Can I share it with the class?\"\n",
      "token:  [Teacher]: \"Of course, please go ahead.\"\n",
      "6.4282546043396\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, please go ahead.\"\n",
      "token:  [Student]: \"The Enlightenment was an intellectual and philosophical movement that dominated the world of ideas in Europe during the 17th and 18th centuries.\"\n",
      "13.60811710357666\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The Enlightenment was an intellectual and philosophical movement that dominated the world of ideas in Europe during the 17th and 18th centuries.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "10.271377563476562\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"Enlightenment thinkers sought to reform society and advance knowledge using reason and the scientific method.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.34337615966797\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Enlightenment thinkers sought to reform society and advance knowledge using reason and the scientific method.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "24.090097427368164\n",
      "Student : 25.961419105529785\n",
      "Teacher : 13.59657653172811\n",
      "['This is a conversation between Teacher and Student. ', '[Teacher]: \"Can anyone explain the concept of artificial intelligence?\"', '[Student]: \"Yes, I can. Artificial intelligence refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\"', '[Teacher]: \"Excellent explanation.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Teacher]: \"Can anyone explain the concept of artificial intelligence?\"\n",
      "31.535409927368164\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Can anyone explain the concept of artificial intelligence?\"\n",
      "token:  [Student]: \"Yes, I can. Artificial intelligence refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.\"\n",
      "9.111425399780273\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I can. Artificial intelligence refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "9.028778076171875\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\"\n",
      "20.468538284301758\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\"\n",
      "token:  [Teacher]: \"Excellent explanation.\"\n",
      "38.60307693481445\n",
      "Student : 14.789981842041016\n",
      "Teacher : 26.389088312784832\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I have prepared a presentation on the Greek mythology. Can I present it to the class?\"', '[Teacher]: \"Sure, go ahead.\"', '[Student]: \"Thank you. Greek mythology is the body of myths originally told by the ancient Greeks.\"', '[Teacher]: \"That\\'s correct.\"', '[Student]: \"These stories concern the origin and nature of the world, the lives and activities of deities, heroes, and mythological creatures, and the origins and significance of the ancient Greeks\\' own cult and ritual practices.\"', '[Teacher]: \"Very good. Continue.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I have prepared a presentation on the Greek mythology. Can I present it to the class?\"\n",
      "19.031158447265625\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I have prepared a presentation on the Greek mythology. Can I present it to the class?\"\n",
      "token:  [Teacher]: \"Sure, go ahead.\"\n",
      "5.349465370178223\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, go ahead.\"\n",
      "token:  [Student]: \"Thank you. Greek mythology is the body of myths originally told by the ancient Greeks.\"\n",
      "27.856529235839844\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you. Greek mythology is the body of myths originally told by the ancient Greeks.\"\n",
      "token:  [Teacher]: \"That's correct.\"\n",
      "9.048223495483398\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct.\"\n",
      "token:  [Student]: \"These stories concern the origin and nature of the world, the lives and activities of deities, heroes, and mythological creatures, and the origins and significance of the ancient Greeks' own cult and ritual practices.\"\n",
      "24.82522201538086\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"These stories concern the origin and nature of the world, the lives and activities of deities, heroes, and mythological creatures, and the origins and significance of the ancient Greeks' own cult and ritual practices.\"\n",
      "token:  [Teacher]: \"Very good. Continue.\"\n",
      "18.803403854370117\n",
      "Student : 23.904303232828777\n",
      "Teacher : 11.067030906677246\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'ve been researching the topic of climate change and its impact on global biodiversity. May I share my findings?\"', '[Teacher]: \"Absolutely, we\\'d love to hear your insights.\"', '[Student]: \"Climate change is leading to shifts in species distribution, population declines, and in some cases, extinction. For example, polar bears are losing their habitats due to melting ice caps.\"', '[Teacher]: \"That\\'s a great point. How does this impact the food chain?\"', '[Student]: \"When one species is affected, it can disrupt the entire food chain. For instance, if polar bears decline, it could lead to an overpopulation of seals, their primary food source.\"', '[Teacher]: \"Excellent. You\\'ve clearly done your research.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I've been researching the topic of climate change and its impact on global biodiversity. May I share my findings?\"\n",
      "24.55370330810547\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I've been researching the topic of climate change and its impact on global biodiversity. May I share my findings?\"\n",
      "token:  [Teacher]: \"Absolutely, we'd love to hear your insights.\"\n",
      "8.261944770812988\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Absolutely, we'd love to hear your insights.\"\n",
      "token:  [Student]: \"Climate change is leading to shifts in species distribution, population declines, and in some cases, extinction. For example, polar bears are losing their habitats due to melting ice caps.\"\n",
      "12.295498847961426\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Climate change is leading to shifts in species distribution, population declines, and in some cases, extinction. For example, polar bears are losing their habitats due to melting ice caps.\"\n",
      "token:  [Teacher]: \"That's a great point. How does this impact the food chain?\"\n",
      "10.584056854248047\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a great point. How does this impact the food chain?\"\n",
      "token:  [Student]: \"When one species is affected, it can disrupt the entire food chain. For instance, if polar bears decline, it could lead to an overpopulation of seals, their primary food source.\"\n",
      "11.328289985656738\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"When one species is affected, it can disrupt the entire food chain. For instance, if polar bears decline, it could lead to an overpopulation of seals, their primary food source.\"\n",
      "token:  [Teacher]: \"Excellent. You've clearly done your research.\"\n",
      "17.606409072875977\n",
      "Student : 16.05916404724121\n",
      "Teacher : 12.150803565979004\n",
      "['This is a conversation between Teacher and Student. ', '[Teacher]: \"Can anyone explain the concept of genetic engineering?\"', '[Student]: \"Yes, I can. Genetic engineering is the direct manipulation of an organism\\'s genes using biotechnology. It\\'s a set of technologies used to change the genetic makeup of cells, including the transfer of genes within and across species boundaries to produce improved or novel organisms.\"', '[Teacher]: \"That\\'s a comprehensive definition. Can you give us an example of its application?\"', '[Student]: \"Sure, one of the most common examples is the creation of genetically modified crops, like corn and soybeans, that are resistant to pests or drought.\"', '[Teacher]: \"Well done. You\\'ve explained that very well.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Teacher]: \"Can anyone explain the concept of genetic engineering?\"\n",
      "36.05207824707031\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Can anyone explain the concept of genetic engineering?\"\n",
      "token:  [Student]: \"Yes, I can. Genetic engineering is the direct manipulation of an organism's genes using biotechnology. It's a set of technologies used to change the genetic makeup of cells, including the transfer of genes within and across species boundaries to produce improved or novel organisms.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.351787567138672\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I can. Genetic engineering is the direct manipulation of an organism's genes using biotechnology. It's a set of technologies used to change the genetic makeup of cells, including the transfer of genes within and across species boundaries to produce improved or novel organisms.\"\n",
      "token:  [Teacher]: \"That's a comprehensive definition. Can you give us an example of its application?\"\n",
      "9.51156234741211\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a comprehensive definition. Can you give us an example of its application?\"\n",
      "token:  [Student]: \"Sure, one of the most common examples is the creation of genetically modified crops, like corn and soybeans, that are resistant to pests or drought.\"\n",
      "8.279818534851074\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure, one of the most common examples is the creation of genetically modified crops, like corn and soybeans, that are resistant to pests or drought.\"\n",
      "token:  [Teacher]: \"Well done. You've explained that very well.\"\n",
      "19.73518943786621\n",
      "Student : 9.815803050994873\n",
      "Teacher : 21.766276677449543\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'ve been studying the concept of supply and demand in economics. Can I share my understanding?\"', '[Teacher]: \"Of course, please go ahead.\"', '[Student]: \"Supply and demand is a model of price determination in a market. It postulates that in a competitive market, the unit price for a particular good or service will vary until it settles at a point where the quantity demanded by consumers will equal the quantity supplied by producers, resulting in an economic equilibrium for price and quantity.\"', '[Teacher]: \"That\\'s correct. Can you explain how changes in supply or demand can affect this equilibrium?\"', '[Student]: \"Yes, if demand increases and supply remains unchanged, a shortage occurs, leading to a higher equilibrium price. If supply increases and demand remains unchanged, a surplus occurs, leading to a lower equilibrium price.\"', '[Teacher]: \"Excellent. You\\'ve clearly understood the concept.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I've been studying the concept of supply and demand in economics. Can I share my understanding?\"\n",
      "21.506616592407227\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I've been studying the concept of supply and demand in economics. Can I share my understanding?\"\n",
      "token:  [Teacher]: \"Of course, please go ahead.\"\n",
      "6.443088054656982\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, please go ahead.\"\n",
      "token:  [Student]: \"Supply and demand is a model of price determination in a market. It postulates that in a competitive market, the unit price for a particular good or service will vary until it settles at a point where the quantity demanded by consumers will equal the quantity supplied by producers, resulting in an economic equilibrium for price and quantity.\"\n",
      "12.564468383789062\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Supply and demand is a model of price determination in a market. It postulates that in a competitive market, the unit price for a particular good or service will vary until it settles at a point where the quantity demanded by consumers will equal the quantity supplied by producers, resulting in an economic equilibrium for price and quantity.\"\n",
      "token:  [Teacher]: \"That's correct. Can you explain how changes in supply or demand can affect this equilibrium?\"\n",
      "13.395526885986328\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct. Can you explain how changes in supply or demand can affect this equilibrium?\"\n",
      "token:  [Student]: \"Yes, if demand increases and supply remains unchanged, a shortage occurs, leading to a higher equilibrium price. If supply increases and demand remains unchanged, a surplus occurs, leading to a lower equilibrium price.\"\n",
      "4.945467948913574\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, if demand increases and supply remains unchanged, a shortage occurs, leading to a higher equilibrium price. If supply increases and demand remains unchanged, a surplus occurs, leading to a lower equilibrium price.\"\n",
      "token:  [Teacher]: \"Excellent. You've clearly understood the concept.\"\n",
      "18.67413330078125\n",
      "Student : 13.005517641703287\n",
      "Teacher : 12.83758274714152\n",
      "['This is a conversation between Teacher and Student. ', '[Teacher]: \"Can anyone explain the concept of the water cycle?\"', '[Student]: \"Yes, I can. The water cycle, also known as the hydrologic cycle, describes the continuous movement of water on, above, and below the surface of the Earth. The water changes from liquid to gas in a process called evaporation, or transpiration in plants. Then it condenses, forming clouds, and falls back to the surface as precipitation.\"', '[Teacher]: \"That\\'s a good explanation. Can you tell us what role the sun plays in this cycle?\"', '[Student]: \"Sure, the sun provides the energy that drives the water cycle. It causes the evaporation of water from the oceans, lakes, and other water bodies, as well as from plants.\"', '[Teacher]: \"Well done. You\\'ve explained that very well.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Teacher]: \"Can anyone explain the concept of the water cycle?\"\n",
      "33.506526947021484\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Can anyone explain the concept of the water cycle?\"\n",
      "token:  [Student]: \"Yes, I can. The water cycle, also known as the hydrologic cycle, describes the continuous movement of water on, above, and below the surface of the Earth. The water changes from liquid to gas in a process called evaporation, or transpiration in plants. Then it condenses, forming clouds, and falls back to the surface as precipitation.\"\n",
      "6.440448760986328\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I can. The water cycle, also known as the hydrologic cycle, describes the continuous movement of water on, above, and below the surface of the Earth. The water changes from liquid to gas in a process called evaporation, or transpiration in plants. Then it condenses, forming clouds, and falls back to the surface as precipitation.\"\n",
      "token:  [Teacher]: \"That's a good explanation. Can you tell us what role the sun plays in this cycle?\"\n",
      "7.351921558380127\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a good explanation. Can you tell us what role the sun plays in this cycle?\"\n",
      "token:  [Student]: \"Sure, the sun provides the energy that drives the water cycle. It causes the evaporation of water from the oceans, lakes, and other water bodies, as well as from plants.\"\n",
      "9.063566207885742\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sure, the sun provides the energy that drives the water cycle. It causes the evaporation of water from the oceans, lakes, and other water bodies, as well as from plants.\"\n",
      "token:  [Teacher]: \"Well done. You've explained that very well.\"\n",
      "15.252208709716797\n",
      "Student : 7.752007484436035\n",
      "Teacher : 18.70355240503947\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'ve been researching the topic of the American Civil Rights Movement. May I share my findings?\"', '[Teacher]: \"Absolutely, we\\'d love to hear your insights.\"', '[Student]: \"The American Civil Rights Movement was a decades-long struggle by African Americans and their like-minded allies to end institutionalized racial discrimination, disenfranchisement, and racial segregation in the United States. The movement has its roots in the Reconstruction era during the late 19th century, although it made its largest legislative gains in the mid-1960s after years of direct actions and grassroots protests.\"', '[Teacher]: \"That\\'s a great summary. Can you tell us about some of the key figures in the movement?\"', '[Student]: \"Certainly. Some of the key figures include Martin Luther King Jr., Rosa Parks, Malcolm X, and many others. Each played a significant role in fighting for and securing civil rights for African Americans.\"', '[Teacher]: \"Excellent. You\\'ve clearly done your research.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I've been researching the topic of the American Civil Rights Movement. May I share my findings?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.855445861816406\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I've been researching the topic of the American Civil Rights Movement. May I share my findings?\"\n",
      "token:  [Teacher]: \"Absolutely, we'd love to hear your insights.\"\n",
      "7.725945949554443\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Absolutely, we'd love to hear your insights.\"\n",
      "token:  [Student]: \"The American Civil Rights Movement was a decades-long struggle by African Americans and their like-minded allies to end institutionalized racial discrimination, disenfranchisement, and racial segregation in the United States. The movement has its roots in the Reconstruction era during the late 19th century, although it made its largest legislative gains in the mid-1960s after years of direct actions and grassroots protests.\"\n",
      "11.205387115478516\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The American Civil Rights Movement was a decades-long struggle by African Americans and their like-minded allies to end institutionalized racial discrimination, disenfranchisement, and racial segregation in the United States. The movement has its roots in the Reconstruction era during the late 19th century, although it made its largest legislative gains in the mid-1960s after years of direct actions and grassroots protests.\"\n",
      "token:  [Teacher]: \"That's a great summary. Can you tell us about some of the key figures in the movement?\"\n",
      "7.339485168457031\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a great summary. Can you tell us about some of the key figures in the movement?\"\n",
      "token:  [Student]: \"Certainly. Some of the key figures include Martin Luther King Jr., Rosa Parks, Malcolm X, and many others. Each played a significant role in fighting for and securing civil rights for African Americans.\"\n",
      "6.918761730194092\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Certainly. Some of the key figures include Martin Luther King Jr., Rosa Parks, Malcolm X, and many others. Each played a significant role in fighting for and securing civil rights for African Americans.\"\n",
      "token:  [Teacher]: \"Excellent. You've clearly done your research.\"\n",
      "17.99216651916504\n",
      "Student : 14.659864902496338\n",
      "Teacher : 11.019199212392172\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'ve been studying for the upcoming exam and I have a few questions about the material. Can we discuss them?\"', '[Teacher]: \"Of course, go ahead.\"', '[Student]: \"Firstly, I\\'m having trouble understanding the concept of mitosis. Could you explain it again?\"', '[Teacher]: \"Sure, mitosis is the process where a single cell divides into two identical daughter cells.\"', '[Student]: \"I see, so it\\'s a type of cell division. And what about meiosis? How is it different?\"', '[Teacher]: \"Meiosis is a type of cell division that reduces the number of chromosomes in the parent cell by half and produces four gamete cells.\"', '[Student]: \"Got it, so mitosis results in identical cells, while meiosis results in different cells. Thanks for clarifying.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I've been studying for the upcoming exam and I have a few questions about the material. Can we discuss them?\"\n",
      "11.863381385803223\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I've been studying for the upcoming exam and I have a few questions about the material. Can we discuss them?\"\n",
      "token:  [Teacher]: \"Of course, go ahead.\"\n",
      "4.943239688873291\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, go ahead.\"\n",
      "token:  [Student]: \"Firstly, I'm having trouble understanding the concept of mitosis. Could you explain it again?\"\n",
      "18.4114933013916\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Firstly, I'm having trouble understanding the concept of mitosis. Could you explain it again?\"\n",
      "token:  [Teacher]: \"Sure, mitosis is the process where a single cell divides into two identical daughter cells.\"\n",
      "6.782830238342285\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, mitosis is the process where a single cell divides into two identical daughter cells.\"\n",
      "token:  [Student]: \"I see, so it's a type of cell division. And what about meiosis? How is it different?\"\n",
      "12.647587776184082\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I see, so it's a type of cell division. And what about meiosis? How is it different?\"\n",
      "token:  [Teacher]: \"Meiosis is a type of cell division that reduces the number of chromosomes in the parent cell by half and produces four gamete cells.\"\n",
      "9.679157257080078\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Meiosis is a type of cell division that reduces the number of chromosomes in the parent cell by half and produces four gamete cells.\"\n",
      "token:  [Student]: \"Got it, so mitosis results in identical cells, while meiosis results in different cells. Thanks for clarifying.\"\n",
      "15.886906623840332\n",
      "Student : 14.70234227180481\n",
      "Teacher : 7.135075728098552\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'ve been reviewing the material for the exam and I\\'ve noticed a pattern in the types of questions that are asked. Can I share my observations?\"', '[Teacher]: \"Absolutely, please go ahead.\"', '[Student]: \"It seems like the exam questions often focus on applying concepts rather than just recalling facts. For example, instead of asking us to define a term, the questions often ask us to use that term to solve a problem or explain a phenomenon.\"', '[Teacher]: \"That\\'s a very astute observation. You\\'re correct that the exams are designed to test your understanding and application of the material, not just memorization.\"', '[Student]: \"That\\'s helpful to know. I\\'ll make sure to focus on understanding the concepts deeply rather than just memorizing facts.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I've been reviewing the material for the exam and I've noticed a pattern in the types of questions that are asked. Can I share my observations?\"\n",
      "16.068735122680664\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I've been reviewing the material for the exam and I've noticed a pattern in the types of questions that are asked. Can I share my observations?\"\n",
      "token:  [Teacher]: \"Absolutely, please go ahead.\"\n",
      "8.309208869934082\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Absolutely, please go ahead.\"\n",
      "token:  [Student]: \"It seems like the exam questions often focus on applying concepts rather than just recalling facts. For example, instead of asking us to define a term, the questions often ask us to use that term to solve a problem or explain a phenomenon.\"\n",
      "14.922969818115234\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It seems like the exam questions often focus on applying concepts rather than just recalling facts. For example, instead of asking us to define a term, the questions often ask us to use that term to solve a problem or explain a phenomenon.\"\n",
      "token:  [Teacher]: \"That's a very astute observation. You're correct that the exams are designed to test your understanding and application of the material, not just memorization.\"\n",
      "8.347981452941895\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a very astute observation. You're correct that the exams are designed to test your understanding and application of the material, not just memorization.\"\n",
      "token:  [Student]: \"That's helpful to know. I'll make sure to focus on understanding the concepts deeply rather than just memorizing facts.\"\n",
      "13.283536911010742\n",
      "Student : 14.758413950602213\n",
      "Teacher : 8.328595161437988\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'ve been studying the material for the exam and I\\'ve come up with a study strategy. Can I share it with you and get your feedback?\"', '[Teacher]: \"Of course, I\\'d be happy to hear it.\"', '[Student]: \"I plan to review the lecture notes and textbook chapters first, then do the practice problems. After that, I\\'ll review the solutions to the problems and make sure I understand them. Finally, I\\'ll review the material again and do more practice problems.\"', '[Teacher]: \"That sounds like a solid strategy. Just make sure to take breaks and not to cram all your studying into one session.\"', '[Student]: \"I\\'ll keep that in mind. Thanks for the feedback.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I've been studying the material for the exam and I've come up with a study strategy. Can I share it with you and get your feedback?\"\n",
      "12.782629013061523\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I've been studying the material for the exam and I've come up with a study strategy. Can I share it with you and get your feedback?\"\n",
      "token:  [Teacher]: \"Of course, I'd be happy to hear it.\"\n",
      "5.596861362457275\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, I'd be happy to hear it.\"\n",
      "token:  [Student]: \"I plan to review the lecture notes and textbook chapters first, then do the practice problems. After that, I'll review the solutions to the problems and make sure I understand them. Finally, I'll review the material again and do more practice problems.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.22217845916748\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I plan to review the lecture notes and textbook chapters first, then do the practice problems. After that, I'll review the solutions to the problems and make sure I understand them. Finally, I'll review the material again and do more practice problems.\"\n",
      "token:  [Teacher]: \"That sounds like a solid strategy. Just make sure to take breaks and not to cram all your studying into one session.\"\n",
      "12.196406364440918\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That sounds like a solid strategy. Just make sure to take breaks and not to cram all your studying into one session.\"\n",
      "token:  [Student]: \"I'll keep that in mind. Thanks for the feedback.\"\n",
      "6.843672275543213\n",
      "Student : 10.282826582590738\n",
      "Teacher : 8.896633863449097\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'ve been reviewing the material for the exam and I\\'ve noticed that I\\'m having trouble with a few topics. Can we go over them during office hours?\"', '[Teacher]: \"Absolutely, I\\'d be happy to help. What topics are you struggling with?\"', '[Student]: \"I\\'m having trouble with the concepts of supply and demand and market equilibrium. I understand the basic definitions, but I\\'m having trouble applying them to real-world scenarios.\"', '[Teacher]: \"I see. We can definitely go over those topics during office hours. In the meantime, try to do some practice problems and see if that helps.\"', '[Student]: \"I\\'ll do that. Thanks for your help.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I've been reviewing the material for the exam and I've noticed that I'm having trouble with a few topics. Can we go over them during office hours?\"\n",
      "15.151165008544922\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I've been reviewing the material for the exam and I've noticed that I'm having trouble with a few topics. Can we go over them during office hours?\"\n",
      "token:  [Teacher]: \"Absolutely, I'd be happy to help. What topics are you struggling with?\"\n",
      "5.7645978927612305\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Absolutely, I'd be happy to help. What topics are you struggling with?\"\n",
      "token:  [Student]: \"I'm having trouble with the concepts of supply and demand and market equilibrium. I understand the basic definitions, but I'm having trouble applying them to real-world scenarios.\"\n",
      "7.968273162841797\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with the concepts of supply and demand and market equilibrium. I understand the basic definitions, but I'm having trouble applying them to real-world scenarios.\"\n",
      "token:  [Teacher]: \"I see. We can definitely go over those topics during office hours. In the meantime, try to do some practice problems and see if that helps.\"\n",
      "15.01409912109375\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I see. We can definitely go over those topics during office hours. In the meantime, try to do some practice problems and see if that helps.\"\n",
      "token:  [Student]: \"I'll do that. Thanks for your help.\"\n",
      "7.010005950927734\n",
      "Student : 10.043148040771484\n",
      "Teacher : 10.38934850692749\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'ve been studying for the upcoming exam and I have a few questions about the format. Can we discuss them?\"', '[Teacher]: \"Of course, go ahead.\"', '[Student]: \"Will the exam be multiple choice, short answer, or a mix of both? And will there be any essay questions?\"', '[Teacher]: \"The exam will be a mix of multiple choice and short answer questions. There won\\'t be any essay questions.\"', '[Student]: \"That\\'s helpful to know. I\\'ll make sure to prepare accordingly. Thanks for the information.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I've been studying for the upcoming exam and I have a few questions about the format. Can we discuss them?\"\n",
      "13.589041709899902\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I've been studying for the upcoming exam and I have a few questions about the format. Can we discuss them?\"\n",
      "token:  [Teacher]: \"Of course, go ahead.\"\n",
      "4.980967044830322\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, go ahead.\"\n",
      "token:  [Student]: \"Will the exam be multiple choice, short answer, or a mix of both? And will there be any essay questions?\"\n",
      "11.607858657836914\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Will the exam be multiple choice, short answer, or a mix of both? And will there be any essay questions?\"\n",
      "token:  [Teacher]: \"The exam will be a mix of multiple choice and short answer questions. There won't be any essay questions.\"\n",
      "3.141927480697632\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"The exam will be a mix of multiple choice and short answer questions. There won't be any essay questions.\"\n",
      "token:  [Student]: \"That's helpful to know. I'll make sure to prepare accordingly. Thanks for the information.\"\n",
      "11.3480224609375\n",
      "Student : 12.18164094289144\n",
      "Teacher : 4.061447262763977\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'ve been reviewing the material for the exam and I\\'ve noticed that some topics are more difficult for me than others. Can we go over them during office hours?\"', '[Teacher]: \"Absolutely, I\\'d be happy to help. What topics are you struggling with?\"', '[Student]: \"I\\'m having trouble with the concepts of photosynthesis and cellular respiration. I understand the basic processes, but I\\'m having trouble understanding the details and how they relate to each other.\"', '[Teacher]: \"I see. We can definitely go over those topics during office hours. In the meantime, try to review the material and see if that helps.\"', '[Student]: \"I\\'ll do that. Thanks for your help.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I've been reviewing the material for the exam and I've noticed that some topics are more difficult for me than others. Can we go over them during office hours?\"\n",
      "16.01295280456543\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I've been reviewing the material for the exam and I've noticed that some topics are more difficult for me than others. Can we go over them during office hours?\"\n",
      "token:  [Teacher]: \"Absolutely, I'd be happy to help. What topics are you struggling with?\"\n",
      "6.309754848480225\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Absolutely, I'd be happy to help. What topics are you struggling with?\"\n",
      "token:  [Student]: \"I'm having trouble with the concepts of photosynthesis and cellular respiration. I understand the basic processes, but I'm having trouble understanding the details and how they relate to each other.\"\n",
      "6.476131439208984\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with the concepts of photosynthesis and cellular respiration. I understand the basic processes, but I'm having trouble understanding the details and how they relate to each other.\"\n",
      "token:  [Teacher]: \"I see. We can definitely go over those topics during office hours. In the meantime, try to review the material and see if that helps.\"\n",
      "15.981764793395996\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I see. We can definitely go over those topics during office hours. In the meantime, try to review the material and see if that helps.\"\n",
      "token:  [Student]: \"I'll do that. Thanks for your help.\"\n",
      "6.591127395629883\n",
      "Student : 9.693403879801432\n",
      "Teacher : 11.14575982093811\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'ve been studying for the upcoming exam and I have a few questions about the material. Can we discuss them?\"', '[Teacher]: \"Of course, go ahead.\"', '[Student]: \"Firstly, I\\'m having trouble understanding the concept of the water cycle. Could you explain it again?\"', '[Teacher]: \"Sure, the water cycle describes the continuous movement of water on, above, and below the surface of the Earth.\"', '[Student]: \"I see, so it\\'s a cycle of evaporation, condensation, and precipitation. And what role does the sun play in this cycle?\"', '[Teacher]: \"The sun provides the energy that drives the water cycle. It causes the evaporation of water from the oceans, lakes, and other water bodies.\"', '[Student]: \"Got it, so the sun drives the water cycle. Thanks for clarifying.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I've been studying for the upcoming exam and I have a few questions about the material. Can we discuss them?\"\n",
      "11.863381385803223\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I've been studying for the upcoming exam and I have a few questions about the material. Can we discuss them?\"\n",
      "token:  [Teacher]: \"Of course, go ahead.\"\n",
      "4.943239688873291\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, go ahead.\"\n",
      "token:  [Student]: \"Firstly, I'm having trouble understanding the concept of the water cycle. Could you explain it again?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.2763671875\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Firstly, I'm having trouble understanding the concept of the water cycle. Could you explain it again?\"\n",
      "token:  [Teacher]: \"Sure, the water cycle describes the continuous movement of water on, above, and below the surface of the Earth.\"\n",
      "7.956638336181641\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, the water cycle describes the continuous movement of water on, above, and below the surface of the Earth.\"\n",
      "token:  [Student]: \"I see, so it's a cycle of evaporation, condensation, and precipitation. And what role does the sun play in this cycle?\"\n",
      "6.188226699829102\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I see, so it's a cycle of evaporation, condensation, and precipitation. And what role does the sun play in this cycle?\"\n",
      "token:  [Teacher]: \"The sun provides the energy that drives the water cycle. It causes the evaporation of water from the oceans, lakes, and other water bodies.\"\n",
      "6.301586151123047\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"The sun provides the energy that drives the water cycle. It causes the evaporation of water from the oceans, lakes, and other water bodies.\"\n",
      "token:  [Student]: \"Got it, so the sun drives the water cycle. Thanks for clarifying.\"\n",
      "10.70944595336914\n",
      "Student : 11.509355306625366\n",
      "Teacher : 6.400488058725993\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'ve been reviewing the material for the exam and I\\'ve noticed a pattern in the types of questions that are asked. Can I share my observations?\"', '[Teacher]: \"Absolutely, please go ahead.\"', '[Student]: \"It seems like the exam questions often focus on understanding and interpreting graphs and data, rather than just recalling facts. For example, instead of asking us to define a term, the questions often ask us to interpret a graph or data set using that term.\"', '[Teacher]: \"That\\'s a very astute observation. You\\'re correct that the exams are designed to test your understanding and interpretation of the material, not just memorization.\"', '[Student]: \"That\\'s helpful to know. I\\'ll make sure to focus on understanding and interpreting graphs and data.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I've been reviewing the material for the exam and I've noticed a pattern in the types of questions that are asked. Can I share my observations?\"\n",
      "16.068735122680664\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I've been reviewing the material for the exam and I've noticed a pattern in the types of questions that are asked. Can I share my observations?\"\n",
      "token:  [Teacher]: \"Absolutely, please go ahead.\"\n",
      "8.309208869934082\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Absolutely, please go ahead.\"\n",
      "token:  [Student]: \"It seems like the exam questions often focus on understanding and interpreting graphs and data, rather than just recalling facts. For example, instead of asking us to define a term, the questions often ask us to interpret a graph or data set using that term.\"\n",
      "15.712873458862305\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"It seems like the exam questions often focus on understanding and interpreting graphs and data, rather than just recalling facts. For example, instead of asking us to define a term, the questions often ask us to interpret a graph or data set using that term.\"\n",
      "token:  [Teacher]: \"That's a very astute observation. You're correct that the exams are designed to test your understanding and interpretation of the material, not just memorization.\"\n",
      "7.82269811630249\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a very astute observation. You're correct that the exams are designed to test your understanding and interpretation of the material, not just memorization.\"\n",
      "token:  [Student]: \"That's helpful to know. I'll make sure to focus on understanding and interpreting graphs and data.\"\n",
      "16.791847229003906\n",
      "Student : 16.191151936848957\n",
      "Teacher : 8.065953493118286\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'ve been studying the material for the exam and I\\'ve come up with a study strategy. Can I share it with you and get your feedback?\"', '[Teacher]: \"Of course, I\\'d be happy to hear it.\"', '[Student]: \"I plan to review the lecture notes and textbook chapters first, then do the practice problems. After that, I\\'ll review the solutions to the problems and make sure I understand them. Finally, I\\'ll review the material again and do more practice problems.\"', '[Teacher]: \"That sounds like a solid strategy. Just make sure to take breaks and not to cram all your studying into one session.\"', '[Student]: \"I\\'ll keep that in mind. Thanks for the feedback.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I've been studying the material for the exam and I've come up with a study strategy. Can I share it with you and get your feedback?\"\n",
      "12.782629013061523\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I've been studying the material for the exam and I've come up with a study strategy. Can I share it with you and get your feedback?\"\n",
      "token:  [Teacher]: \"Of course, I'd be happy to hear it.\"\n",
      "5.596861362457275\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course, I'd be happy to hear it.\"\n",
      "token:  [Student]: \"I plan to review the lecture notes and textbook chapters first, then do the practice problems. After that, I'll review the solutions to the problems and make sure I understand them. Finally, I'll review the material again and do more practice problems.\"\n",
      "11.22217845916748\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I plan to review the lecture notes and textbook chapters first, then do the practice problems. After that, I'll review the solutions to the problems and make sure I understand them. Finally, I'll review the material again and do more practice problems.\"\n",
      "token:  [Teacher]: \"That sounds like a solid strategy. Just make sure to take breaks and not to cram all your studying into one session.\"\n",
      "12.196406364440918\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That sounds like a solid strategy. Just make sure to take breaks and not to cram all your studying into one session.\"\n",
      "token:  [Student]: \"I'll keep that in mind. Thanks for the feedback.\"\n",
      "6.843672275543213\n",
      "Student : 10.282826582590738\n",
      "Teacher : 8.896633863449097\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'ve been reviewing the material for the exam and I\\'ve noticed that I\\'m having trouble with a few topics. Can we go over them during office hours?\"', '[Teacher]: \"Absolutely, I\\'d be happy to help. What topics are you struggling with?\"', '[Student]: \"I\\'m having trouble with the concepts of evolution and natural selection. I understand the basic definitions, but I\\'m having trouble understanding the details and how they relate to each other.\"', '[Teacher]: \"I see. We can definitely go over those topics during office hours. In the meantime, try to review the material and see if that helps.\"', '[Student]: \"I\\'ll do that. Thanks for your help.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I've been reviewing the material for the exam and I've noticed that I'm having trouble with a few topics. Can we go over them during office hours?\"\n",
      "15.151165008544922\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I've been reviewing the material for the exam and I've noticed that I'm having trouble with a few topics. Can we go over them during office hours?\"\n",
      "token:  [Teacher]: \"Absolutely, I'd be happy to help. What topics are you struggling with?\"\n",
      "5.7645978927612305\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Absolutely, I'd be happy to help. What topics are you struggling with?\"\n",
      "token:  [Student]: \"I'm having trouble with the concepts of evolution and natural selection. I understand the basic definitions, but I'm having trouble understanding the details and how they relate to each other.\"\n",
      "5.997125625610352\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm having trouble with the concepts of evolution and natural selection. I understand the basic definitions, but I'm having trouble understanding the details and how they relate to each other.\"\n",
      "token:  [Teacher]: \"I see. We can definitely go over those topics during office hours. In the meantime, try to review the material and see if that helps.\"\n",
      "16.03556251525879\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I see. We can definitely go over those topics during office hours. In the meantime, try to review the material and see if that helps.\"\n",
      "token:  [Student]: \"I'll do that. Thanks for your help.\"\n",
      "6.591127395629883\n",
      "Student : 9.246472676595053\n",
      "Teacher : 10.90008020401001\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I want to discuss my academic goals for this semester. I aim to improve my grades in Mathematics and Science.\"', '[Teacher]: \"That\\'s a good goal. How do you plan to achieve it?\"', '[Student]: \"I plan to devote more time to these subjects and solve more practice problems. I also plan to attend extra classes if necessary.\"', '[Teacher]: \"That sounds like a good plan. Remember, consistency is key. Keep me updated on your progress.\"', '[Student]: \"Sure, sir. Thank you for your guidance.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I want to discuss my academic goals for this semester. I aim to improve my grades in Mathematics and Science.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.664369583129883\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I want to discuss my academic goals for this semester. I aim to improve my grades in Mathematics and Science.\"\n",
      "token:  [Teacher]: \"That's a good goal. How do you plan to achieve it?\"\n",
      "5.0992045402526855\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a good goal. How do you plan to achieve it?\"\n",
      "token:  [Student]: \"I plan to devote more time to these subjects and solve more practice problems. I also plan to attend extra classes if necessary.\"\n",
      "18.05356216430664\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I plan to devote more time to these subjects and solve more practice problems. I also plan to attend extra classes if necessary.\"\n",
      "token:  [Teacher]: \"That sounds like a good plan. Remember, consistency is key. Keep me updated on your progress.\"\n",
      "9.688471794128418\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That sounds like a good plan. Remember, consistency is key. Keep me updated on your progress.\"\n",
      "token:  [Student]: \"Sure, sir. Thank you for your guidance.\"\n",
      "8.733519554138184\n",
      "Student : 17.15048376719157\n",
      "Teacher : 7.393838167190552\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, we\\'ve been working on our group project and we have some ideas we\\'d like to discuss.\"', '[Teacher]: \"Sure, I\\'d love to hear them.\"', '[Student]: \"We\\'re thinking of creating an interactive website for our history project. It will have timelines, maps, and quizzes.\"', '[Teacher]: \"That sounds like a great idea. It\\'s important to ensure the information is accurate and well-researched.\"', '[Student]: \"Absolutely, we\\'ve divided the research work among ourselves. We\\'ll also have a peer-review process to double-check the information.\"', '[Teacher]: \"Excellent. I look forward to seeing your project.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, we've been working on our group project and we have some ideas we'd like to discuss.\"\n",
      "18.42441177368164\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, we've been working on our group project and we have some ideas we'd like to discuss.\"\n",
      "token:  [Teacher]: \"Sure, I'd love to hear them.\"\n",
      "5.9525465965271\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, I'd love to hear them.\"\n",
      "token:  [Student]: \"We're thinking of creating an interactive website for our history project. It will have timelines, maps, and quizzes.\"\n",
      "20.76660919189453\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"We're thinking of creating an interactive website for our history project. It will have timelines, maps, and quizzes.\"\n",
      "token:  [Teacher]: \"That sounds like a great idea. It's important to ensure the information is accurate and well-researched.\"\n",
      "6.452295303344727\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That sounds like a great idea. It's important to ensure the information is accurate and well-researched.\"\n",
      "token:  [Student]: \"Absolutely, we've divided the research work among ourselves. We'll also have a peer-review process to double-check the information.\"\n",
      "24.749210357666016\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Absolutely, we've divided the research work among ourselves. We'll also have a peer-review process to double-check the information.\"\n",
      "token:  [Teacher]: \"Excellent. I look forward to seeing your project.\"\n",
      "8.853611946105957\n",
      "Student : 21.31341044108073\n",
      "Teacher : 7.086151281992595\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'m really interested in the topic we discussed today. Could you recommend some additional resources or readings?\"', '[Teacher]: \"Absolutely, I\\'m glad you\\'re interested. You can start with \\'A Brief History of Time\\' by Stephen Hawking. It\\'s a great book for understanding the basics of cosmology.\"', '[Student]: \"Thank you, Miss. I\\'ll definitely check it out.\"', '[Teacher]: \"You\\'re welcome. Happy reading!\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I'm really interested in the topic we discussed today. Could you recommend some additional resources or readings?\"\n",
      "28.532865524291992\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I'm really interested in the topic we discussed today. Could you recommend some additional resources or readings?\"\n",
      "token:  [Teacher]: \"Absolutely, I'm glad you're interested. You can start with 'A Brief History of Time' by Stephen Hawking. It's a great book for understanding the basics of cosmology.\"\n",
      "7.58330774307251\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Absolutely, I'm glad you're interested. You can start with 'A Brief History of Time' by Stephen Hawking. It's a great book for understanding the basics of cosmology.\"\n",
      "token:  [Student]: \"Thank you, Miss. I'll definitely check it out.\"\n",
      "8.720965385437012\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you, Miss. I'll definitely check it out.\"\n",
      "token:  [Teacher]: \"You're welcome. Happy reading!\"\n",
      "13.510268211364746\n",
      "Student : 18.626915454864502\n",
      "Teacher : 10.546787977218628\n",
      "['This is a conversation between Teacher and Student. ', '[Teacher]: \"In today\\'s digital age, integrating technology in education is crucial. Any thoughts on how we can do this?\"', '[Student]: \"We could use online platforms for discussions and assignments. It would also be helpful to have online resources for self-study.\"', '[Teacher]: \"Those are great suggestions. We\\'ll definitely consider them.\"', '[Student]: \"Thank you, Miss. I believe it would enhance our learning experience.\"', '[Teacher]: \"I agree. Thank you for your input.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Teacher]: \"In today's digital age, integrating technology in education is crucial. Any thoughts on how we can do this?\"\n",
      "28.0567569732666\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"In today's digital age, integrating technology in education is crucial. Any thoughts on how we can do this?\"\n",
      "token:  [Student]: \"We could use online platforms for discussions and assignments. It would also be helpful to have online resources for self-study.\"\n",
      "12.802023887634277\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"We could use online platforms for discussions and assignments. It would also be helpful to have online resources for self-study.\"\n",
      "token:  [Teacher]: \"Those are great suggestions. We'll definitely consider them.\"\n",
      "9.571187973022461\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Those are great suggestions. We'll definitely consider them.\"\n",
      "token:  [Student]: \"Thank you, Miss. I believe it would enhance our learning experience.\"\n",
      "12.936859130859375\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you, Miss. I believe it would enhance our learning experience.\"\n",
      "token:  [Teacher]: \"I agree. Thank you for your input.\"\n",
      "7.170957565307617\n",
      "Student : 12.869441509246826\n",
      "Teacher : 14.93296750386556\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, for our art project, we\\'re thinking of creating a mural that represents our school\\'s values. What do you think?\"', '[Teacher]: \"That sounds like a wonderful idea. It\\'s important to plan it well and ensure everyone in the group contributes.\"', '[Student]: \"Absolutely, we\\'ve already started planning. We\\'re excited to start working on it.\"', '[Teacher]: \"I\\'m excited to see the final result. Good luck!\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, for our art project, we're thinking of creating a mural that represents our school's values. What do you think?\"\n",
      "20.088895797729492\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, for our art project, we're thinking of creating a mural that represents our school's values. What do you think?\"\n",
      "token:  [Teacher]: \"That sounds like a wonderful idea. It's important to plan it well and ensure everyone in the group contributes.\"\n",
      "15.428825378417969\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That sounds like a wonderful idea. It's important to plan it well and ensure everyone in the group contributes.\"\n",
      "token:  [Student]: \"Absolutely, we've already started planning. We're excited to start working on it.\"\n",
      "13.285694122314453\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Absolutely, we've already started planning. We're excited to start working on it.\"\n",
      "token:  [Teacher]: \"I'm excited to see the final result. Good luck!\"\n",
      "9.183043479919434\n",
      "Student : 16.687294960021973\n",
      "Teacher : 12.305934429168701\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"The guest speaker session was really insightful. I learned a lot about entrepreneurship.\"', '[Teacher]: \"I\\'m glad you found it useful. What were your key takeaways?\"', '[Student]: \"The speaker emphasized the importance of resilience and innovation in entrepreneurship. He also shared his own experiences which were very inspiring.\"', '[Teacher]: \"Those are great takeaways. Remember, learning is not confined to the classroom. There\\'s a lot we can learn from people\\'s experiences.\"', '[Student]: \"Absolutely, sir. I look forward to more such sessions.\"', '[Teacher]: \"I\\'m glad to hear that. We\\'ll definitely plan more such sessions.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"The guest speaker session was really insightful. I learned a lot about entrepreneurship.\"\n",
      "72.29911041259766\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The guest speaker session was really insightful. I learned a lot about entrepreneurship.\"\n",
      "token:  [Teacher]: \"I'm glad you found it useful. What were your key takeaways?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.666356086730957\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I'm glad you found it useful. What were your key takeaways?\"\n",
      "token:  [Student]: \"The speaker emphasized the importance of resilience and innovation in entrepreneurship. He also shared his own experiences which were very inspiring.\"\n",
      "21.74724578857422\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The speaker emphasized the importance of resilience and innovation in entrepreneurship. He also shared his own experiences which were very inspiring.\"\n",
      "token:  [Teacher]: \"Those are great takeaways. Remember, learning is not confined to the classroom. There's a lot we can learn from people's experiences.\"\n",
      "13.245261192321777\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Those are great takeaways. Remember, learning is not confined to the classroom. There's a lot we can learn from people's experiences.\"\n",
      "token:  [Student]: \"Absolutely, sir. I look forward to more such sessions.\"\n",
      "19.102371215820312\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Absolutely, sir. I look forward to more such sessions.\"\n",
      "token:  [Teacher]: \"I'm glad to hear that. We'll definitely plan more such sessions.\"\n",
      "8.195088386535645\n",
      "Student : 37.71624247233073\n",
      "Teacher : 9.702235221862793\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'ve been thinking about how to revise for the upcoming exams. I have a few strategies in mind.\"', '[Teacher]: \"That\\'s great. What are your strategies?\"', '[Student]: \"Firstly, I plan to review the lecture notes and highlight the key points. Then, I\\'ll create flashcards for important concepts and use them for active recall.\"', '[Teacher]: \"That sounds like a good plan.\"', '[Student]: \"I also plan to do practice problems to apply what I\\'ve learned. And finally, I\\'ll review past exam papers to understand the format and types of questions.\"', '[Teacher]: \"Excellent. That\\'s a comprehensive revision strategy.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I've been thinking about how to revise for the upcoming exams. I have a few strategies in mind.\"\n",
      "18.37331771850586\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I've been thinking about how to revise for the upcoming exams. I have a few strategies in mind.\"\n",
      "token:  [Teacher]: \"That's great. What are your strategies?\"\n",
      "6.026179790496826\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's great. What are your strategies?\"\n",
      "token:  [Student]: \"Firstly, I plan to review the lecture notes and highlight the key points. Then, I'll create flashcards for important concepts and use them for active recall.\"\n",
      "17.094768524169922\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Firstly, I plan to review the lecture notes and highlight the key points. Then, I'll create flashcards for important concepts and use them for active recall.\"\n",
      "token:  [Teacher]: \"That sounds like a good plan.\"\n",
      "6.511009693145752\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That sounds like a good plan.\"\n",
      "token:  [Student]: \"I also plan to do practice problems to apply what I've learned. And finally, I'll review past exam papers to understand the format and types of questions.\"\n",
      "23.568012237548828\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I also plan to do practice problems to apply what I've learned. And finally, I'll review past exam papers to understand the format and types of questions.\"\n",
      "token:  [Teacher]: \"Excellent. That's a comprehensive revision strategy.\"\n",
      "25.357913970947266\n",
      "Student : 19.678699493408203\n",
      "Teacher : 12.631701151529947\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'ve been trying to participate more in class. I\\'ve been asking questions and contributing to discussions.\"', '[Teacher]: \"Yes, I\\'ve noticed that. You\\'re doing well.\"', '[Student]: \"I\\'ve also been trying to help my classmates when they have doubts. And I\\'ve been sharing relevant articles and resources in our class group.\"', '[Teacher]: \"That\\'s excellent. Keep it up.\"', '[Student]: \"I\\'ll also try to present more in class. I think it will help me improve my public speaking skills.\"', '[Teacher]: \"That\\'s a great idea. I look forward to your presentations.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I've been trying to participate more in class. I've been asking questions and contributing to discussions.\"\n",
      "16.624263763427734\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I've been trying to participate more in class. I've been asking questions and contributing to discussions.\"\n",
      "token:  [Teacher]: \"Yes, I've noticed that. You're doing well.\"\n",
      "6.9075727462768555\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Yes, I've noticed that. You're doing well.\"\n",
      "token:  [Student]: \"I've also been trying to help my classmates when they have doubts. And I've been sharing relevant articles and resources in our class group.\"\n",
      "24.57606315612793\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I've also been trying to help my classmates when they have doubts. And I've been sharing relevant articles and resources in our class group.\"\n",
      "token:  [Teacher]: \"That's excellent. Keep it up.\"\n",
      "8.12832260131836\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's excellent. Keep it up.\"\n",
      "token:  [Student]: \"I'll also try to present more in class. I think it will help me improve my public speaking skills.\"\n",
      "14.77125358581543\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'll also try to present more in class. I think it will help me improve my public speaking skills.\"\n",
      "token:  [Teacher]: \"That's a great idea. I look forward to your presentations.\"\n",
      "6.721011638641357\n",
      "Student : 18.657193501790363\n",
      "Teacher : 7.252302328745524\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, we\\'re having some conflicts in our group project. We\\'ve been trying to resolve them but we could use some guidance.\"', '[Teacher]: \"What are the conflicts about?\"', '[Student]: \"We have different ideas about how to approach the project. Some of us want to focus on the theoretical aspects while others want to focus on the practical aspects.\"', '[Teacher]: \"I see. What have you tried so far?\"', '[Student]: \"We\\'ve tried discussing our ideas and finding a middle ground. But we haven\\'t been able to reach a consensus.\"', '[Teacher]: \"Have you considered dividing the project into parts and assigning each part based on the members\\' interests?\"', '[Student]: \"That\\'s a good idea. We\\'ll try that. Thank you, sir.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, we're having some conflicts in our group project. We've been trying to resolve them but we could use some guidance.\"\n",
      "22.2957763671875\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, we're having some conflicts in our group project. We've been trying to resolve them but we could use some guidance.\"\n",
      "token:  [Teacher]: \"What are the conflicts about?\"\n",
      "9.447883605957031\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"What are the conflicts about?\"\n",
      "token:  [Student]: \"We have different ideas about how to approach the project. Some of us want to focus on the theoretical aspects while others want to focus on the practical aspects.\"\n",
      "6.056057929992676\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"We have different ideas about how to approach the project. Some of us want to focus on the theoretical aspects while others want to focus on the practical aspects.\"\n",
      "token:  [Teacher]: \"I see. What have you tried so far?\"\n",
      "11.144954681396484\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I see. What have you tried so far?\"\n",
      "token:  [Student]: \"We've tried discussing our ideas and finding a middle ground. But we haven't been able to reach a consensus.\"\n",
      "9.472081184387207\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"We've tried discussing our ideas and finding a middle ground. But we haven't been able to reach a consensus.\"\n",
      "token:  [Teacher]: \"Have you considered dividing the project into parts and assigning each part based on the members' interests?\"\n",
      "16.72260284423828\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Have you considered dividing the project into parts and assigning each part based on the members' interests?\"\n",
      "token:  [Student]: \"That's a good idea. We'll try that. Thank you, sir.\"\n",
      "8.63349723815918\n",
      "Student : 11.61435317993164\n",
      "Teacher : 12.438480377197266\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, the field trip to the museum was really informative. I learned a lot about ancient civilizations.\"', '[Teacher]: \"I\\'m glad you found it useful. What was your favorite part?\"', '[Student]: \"I particularly enjoyed the exhibit on Egyptian civilization. The artifacts were fascinating and the information provided was very detailed.\"', '[Teacher]: \"That\\'s great. Did you learn anything new?\"', '[Student]: \"Yes, I learned about their writing system, hieroglyphics, and their religious beliefs. It was interesting to see how advanced their civilization was.\"', '[Teacher]: \"That\\'s excellent. I\\'m glad you learned so much.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, the field trip to the museum was really informative. I learned a lot about ancient civilizations.\"\n",
      "20.520401000976562\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, the field trip to the museum was really informative. I learned a lot about ancient civilizations.\"\n",
      "token:  [Teacher]: \"I'm glad you found it useful. What was your favorite part?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.389886379241943\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I'm glad you found it useful. What was your favorite part?\"\n",
      "token:  [Student]: \"I particularly enjoyed the exhibit on Egyptian civilization. The artifacts were fascinating and the information provided was very detailed.\"\n",
      "23.96896743774414\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I particularly enjoyed the exhibit on Egyptian civilization. The artifacts were fascinating and the information provided was very detailed.\"\n",
      "token:  [Teacher]: \"That's great. Did you learn anything new?\"\n",
      "7.723758220672607\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's great. Did you learn anything new?\"\n",
      "token:  [Student]: \"Yes, I learned about their writing system, hieroglyphics, and their religious beliefs. It was interesting to see how advanced their civilization was.\"\n",
      "9.910542488098145\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I learned about their writing system, hieroglyphics, and their religious beliefs. It was interesting to see how advanced their civilization was.\"\n",
      "token:  [Teacher]: \"That's excellent. I'm glad you learned so much.\"\n",
      "7.568056583404541\n",
      "Student : 18.13330364227295\n",
      "Teacher : 7.22723372777303\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'ve been thinking about my learning plan. I believe I need to focus more on practical applications.\"', '[Teacher]: \"That\\'s a good observation. How do you plan to do that?\"', '[Student]: \"I plan to do more projects and hands-on activities. I believe it will help me understand the concepts better.\"', '[Teacher]: \"That sounds like a good plan.\"', '[Student]: \"I also plan to participate in coding competitions. It will give me a chance to apply what I\\'ve learned and also learn from others.\"', '[Teacher]: \"Excellent. That\\'s a comprehensive learning plan.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I've been thinking about my learning plan. I believe I need to focus more on practical applications.\"\n",
      "19.557514190673828\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I've been thinking about my learning plan. I believe I need to focus more on practical applications.\"\n",
      "token:  [Teacher]: \"That's a good observation. How do you plan to do that?\"\n",
      "6.573947906494141\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a good observation. How do you plan to do that?\"\n",
      "token:  [Student]: \"I plan to do more projects and hands-on activities. I believe it will help me understand the concepts better.\"\n",
      "13.651561737060547\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I plan to do more projects and hands-on activities. I believe it will help me understand the concepts better.\"\n",
      "token:  [Teacher]: \"That sounds like a good plan.\"\n",
      "6.703334331512451\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That sounds like a good plan.\"\n",
      "token:  [Student]: \"I also plan to participate in coding competitions. It will give me a chance to apply what I've learned and also learn from others.\"\n",
      "14.923517227172852\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I also plan to participate in coding competitions. It will give me a chance to apply what I've learned and also learn from others.\"\n",
      "token:  [Teacher]: \"Excellent. That's a comprehensive learning plan.\"\n",
      "16.894126892089844\n",
      "Student : 16.04419771830241\n",
      "Teacher : 10.057136376698812\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'ve been reading about cultural sensitivity. I think it\\'s important to respect and understand different cultures.\"', '[Teacher]: \"That\\'s very true. How do you plan to practice it?\"', '[Student]: \"I plan to read more about different cultures and their customs. I also plan to interact with people from different cultures to understand their perspectives.\"', '[Teacher]: \"That\\'s a great initiative.\"', '[Student]: \"I also think we should have more discussions about cultural sensitivity in class. It will help us understand and respect each other\\'s cultures.\"', '[Teacher]: \"That\\'s a great idea. We\\'ll definitely do that.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I've been reading about cultural sensitivity. I think it's important to respect and understand different cultures.\"\n",
      "19.486087799072266\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I've been reading about cultural sensitivity. I think it's important to respect and understand different cultures.\"\n",
      "token:  [Teacher]: \"That's very true. How do you plan to practice it?\"\n",
      "10.69122314453125\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's very true. How do you plan to practice it?\"\n",
      "token:  [Student]: \"I plan to read more about different cultures and their customs. I also plan to interact with people from different cultures to understand their perspectives.\"\n",
      "9.657294273376465\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I plan to read more about different cultures and their customs. I also plan to interact with people from different cultures to understand their perspectives.\"\n",
      "token:  [Teacher]: \"That's a great initiative.\"\n",
      "14.292537689208984\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a great initiative.\"\n",
      "token:  [Student]: \"I also think we should have more discussions about cultural sensitivity in class. It will help us understand and respect each other's cultures.\"\n",
      "11.368999481201172\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I also think we should have more discussions about cultural sensitivity in class. It will help us understand and respect each other's cultures.\"\n",
      "token:  [Teacher]: \"That's a great idea. We'll definitely do that.\"\n",
      "6.039168834686279\n",
      "Student : 13.504127184549967\n",
      "Teacher : 10.340976556142172\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'ve been thinking about getting involved in community projects. I believe it will help me develop my skills and also contribute to the community.\"', '[Teacher]: \"That\\'s a great idea. What kind of projects are you interested in?\"', '[Student]: \"I\\'m interested in environmental projects. I would like to contribute to initiatives that aim to protect and preserve the environment.\"', '[Teacher]: \"That\\'s commendable. How do you plan to get involved?\"', '[Student]: \"I plan to join a local environmental group. They organize clean-up drives and tree planting activities. I believe it will be a good learning experience.\"', '[Teacher]: \"That\\'s excellent. I\\'m sure you\\'ll learn a lot and also make a positive impact.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I've been thinking about getting involved in community projects. I believe it will help me develop my skills and also contribute to the community.\"\n",
      "16.09351921081543\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I've been thinking about getting involved in community projects. I believe it will help me develop my skills and also contribute to the community.\"\n",
      "token:  [Teacher]: \"That's a great idea. What kind of projects are you interested in?\"\n",
      "4.079502105712891\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a great idea. What kind of projects are you interested in?\"\n",
      "token:  [Student]: \"I'm interested in environmental projects. I would like to contribute to initiatives that aim to protect and preserve the environment.\"\n",
      "8.34656047821045\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm interested in environmental projects. I would like to contribute to initiatives that aim to protect and preserve the environment.\"\n",
      "token:  [Teacher]: \"That's commendable. How do you plan to get involved?\"\n",
      "8.19172191619873\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's commendable. How do you plan to get involved?\"\n",
      "token:  [Student]: \"I plan to join a local environmental group. They organize clean-up drives and tree planting activities. I believe it will be a good learning experience.\"\n",
      "12.798504829406738\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I plan to join a local environmental group. They organize clean-up drives and tree planting activities. I believe it will be a good learning experience.\"\n",
      "token:  [Teacher]: \"That's excellent. I'm sure you'll learn a lot and also make a positive impact.\"\n",
      "8.289834976196289\n",
      "Student : 12.412861506144205\n",
      "Teacher : 6.853686332702637\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I would like to discuss my performance in the last test. I feel I could have done better.\"', '[Teacher]: \"Sure, let\\'s discuss. Where do you think you went wrong?\"', '[Student]: \"I think I didn\\'t manage my time well. I spent too much time on a few questions and didn\\'t have enough time for the rest.\"', '[Teacher]: \"That\\'s a common issue. You need to practice more to improve your time management skills.\"', '[Student]: \"Yes, I will do that. Also, I found some questions confusing. Can we go over them?\"', '[Teacher]: \"Of course. Let\\'s go through them.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I would like to discuss my performance in the last test. I feel I could have done better.\"\n",
      "13.12595272064209\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I would like to discuss my performance in the last test. I feel I could have done better.\"\n",
      "token:  [Teacher]: \"Sure, let's discuss. Where do you think you went wrong?\"\n",
      "7.20792293548584\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, let's discuss. Where do you think you went wrong?\"\n",
      "token:  [Student]: \"I think I didn't manage my time well. I spent too much time on a few questions and didn't have enough time for the rest.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.356403827667236\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I think I didn't manage my time well. I spent too much time on a few questions and didn't have enough time for the rest.\"\n",
      "token:  [Teacher]: \"That's a common issue. You need to practice more to improve your time management skills.\"\n",
      "8.719470977783203\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a common issue. You need to practice more to improve your time management skills.\"\n",
      "token:  [Student]: \"Yes, I will do that. Also, I found some questions confusing. Can we go over them?\"\n",
      "15.029474258422852\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I will do that. Also, I found some questions confusing. Can we go over them?\"\n",
      "token:  [Teacher]: \"Of course. Let's go through them.\"\n",
      "5.871679782867432\n",
      "Student : 11.503943602244059\n",
      "Teacher : 7.266357898712158\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I need some advice on selecting my courses for the next semester.\"', '[Teacher]: \"Sure, what are your interests?\"', '[Student]: \"I\\'m interested in computer science and mathematics. I\\'m considering taking advanced courses in these subjects.\"', '[Teacher]: \"That sounds like a good plan. Do you have any specific courses in mind?\"', '[Student]: \"I\\'m thinking about \\'Data Structures and Algorithms\\' and \\'Calculus III\\'. What do you think?\"', '[Teacher]: \"Those are excellent choices. They will certainly help you in your future studies.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I need some advice on selecting my courses for the next semester.\"\n",
      "32.75187683105469\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I need some advice on selecting my courses for the next semester.\"\n",
      "token:  [Teacher]: \"Sure, what are your interests?\"\n",
      "9.439140319824219\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, what are your interests?\"\n",
      "token:  [Student]: \"I'm interested in computer science and mathematics. I'm considering taking advanced courses in these subjects.\"\n",
      "8.965825080871582\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm interested in computer science and mathematics. I'm considering taking advanced courses in these subjects.\"\n",
      "token:  [Teacher]: \"That sounds like a good plan. Do you have any specific courses in mind?\"\n",
      "6.036373138427734\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That sounds like a good plan. Do you have any specific courses in mind?\"\n",
      "token:  [Student]: \"I'm thinking about 'Data Structures and Algorithms' and 'Calculus III'. What do you think?\"\n",
      "7.014746189117432\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm thinking about 'Data Structures and Algorithms' and 'Calculus III'. What do you think?\"\n",
      "token:  [Teacher]: \"Those are excellent choices. They will certainly help you in your future studies.\"\n",
      "10.73054027557373\n",
      "Student : 16.24414936701457\n",
      "Teacher : 8.73535124460856\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'m having some issues with the online learning platform. I can\\'t access the course materials.\"', '[Teacher]: \"I see. Have you tried logging out and logging back in?\"', '[Student]: \"Yes, I have. But the problem persists. I also tried using a different browser, but that didn\\'t help either.\"', '[Teacher]: \"Alright. Let\\'s try to troubleshoot the issue together.\"', '[Student]: \"Thank you, sir. I appreciate your help.\"', '[Teacher]: \"You\\'re welcome. Let\\'s start by checking your internet connection.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I'm having some issues with the online learning platform. I can't access the course materials.\"\n",
      "17.505481719970703\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I'm having some issues with the online learning platform. I can't access the course materials.\"\n",
      "token:  [Teacher]: \"I see. Have you tried logging out and logging back in?\"\n",
      "5.441082000732422\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I see. Have you tried logging out and logging back in?\"\n",
      "token:  [Student]: \"Yes, I have. But the problem persists. I also tried using a different browser, but that didn't help either.\"\n",
      "7.762615203857422\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I have. But the problem persists. I also tried using a different browser, but that didn't help either.\"\n",
      "token:  [Teacher]: \"Alright. Let's try to troubleshoot the issue together.\"\n",
      "11.890213012695312\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Alright. Let's try to troubleshoot the issue together.\"\n",
      "token:  [Student]: \"Thank you, sir. I appreciate your help.\"\n",
      "6.830158710479736\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you, sir. I appreciate your help.\"\n",
      "token:  [Teacher]: \"You're welcome. Let's start by checking your internet connection.\"\n",
      "13.037419319152832\n",
      "Student : 10.699418544769287\n",
      "Teacher : 10.122904777526855\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I found the guest lecture on climate change very enlightening.\"', '[Teacher]: \"I\\'m glad to hear that. What were your key takeaways?\"', '[Student]: \"The lecturer emphasized the urgency of the situation and the need for immediate action. He also discussed various ways in which we can contribute to mitigating climate change.\"', '[Teacher]: \"That\\'s correct. It\\'s important for everyone to do their part.\"', '[Student]: \"Yes, I agree. I\\'m thinking about starting a climate action club in our school. What do you think?\"', '[Teacher]: \"That\\'s a wonderful idea. I fully support it.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I found the guest lecture on climate change very enlightening.\"\n",
      "68.55421447753906\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I found the guest lecture on climate change very enlightening.\"\n",
      "token:  [Teacher]: \"I'm glad to hear that. What were your key takeaways?\"\n",
      "9.004770278930664\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I'm glad to hear that. What were your key takeaways?\"\n",
      "token:  [Student]: \"The lecturer emphasized the urgency of the situation and the need for immediate action. He also discussed various ways in which we can contribute to mitigating climate change.\"\n",
      "12.213282585144043\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"The lecturer emphasized the urgency of the situation and the need for immediate action. He also discussed various ways in which we can contribute to mitigating climate change.\"\n",
      "token:  [Teacher]: \"That's correct. It's important for everyone to do their part.\"\n",
      "9.119366645812988\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's correct. It's important for everyone to do their part.\"\n",
      "token:  [Student]: \"Yes, I agree. I'm thinking about starting a climate action club in our school. What do you think?\"\n",
      "11.705414772033691\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, I agree. I'm thinking about starting a climate action club in our school. What do you think?\"\n",
      "token:  [Teacher]: \"That's a wonderful idea. I fully support it.\"\n",
      "7.033813953399658\n",
      "Student : 30.824303944905598\n",
      "Teacher : 8.38598362604777\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'m considering forming a study group for our math class. I believe it would be beneficial for collaborative learning.\"', '[Teacher]: \"That\\'s a great idea. Study groups can be very effective.\"', '[Student]: \"I\\'m glad you think so. I was thinking about inviting 4-5 classmates who are serious about their studies. We can meet twice a week to discuss the topics covered in class.\"', '[Teacher]: \"That sounds like a good plan. Make sure everyone gets a chance to contribute.\"', '[Student]: \"Yes, sir. I will ensure that. Thank you for your support.\"', '[Teacher]: \"You\\'re welcome. Good luck with your study group.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I'm considering forming a study group for our math class. I believe it would be beneficial for collaborative learning.\"\n",
      "24.692811965942383\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I'm considering forming a study group for our math class. I believe it would be beneficial for collaborative learning.\"\n",
      "token:  [Teacher]: \"That's a great idea. Study groups can be very effective.\"\n",
      "7.153210639953613\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a great idea. Study groups can be very effective.\"\n",
      "token:  [Student]: \"I'm glad you think so. I was thinking about inviting 4-5 classmates who are serious about their studies. We can meet twice a week to discuss the topics covered in class.\"\n",
      "12.375251770019531\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm glad you think so. I was thinking about inviting 4-5 classmates who are serious about their studies. We can meet twice a week to discuss the topics covered in class.\"\n",
      "token:  [Teacher]: \"That sounds like a good plan. Make sure everyone gets a chance to contribute.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.869128227233887\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That sounds like a good plan. Make sure everyone gets a chance to contribute.\"\n",
      "token:  [Student]: \"Yes, sir. I will ensure that. Thank you for your support.\"\n",
      "10.803418159484863\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, sir. I will ensure that. Thank you for your support.\"\n",
      "token:  [Teacher]: \"You're welcome. Good luck with your study group.\"\n",
      "8.914324760437012\n",
      "Student : 15.957160631815592\n",
      "Teacher : 7.978887875874837\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'m interested in getting involved in extracurricular activities. Can you suggest some opportunities?\"', '[Teacher]: \"Sure. What are your interests?\"', '[Student]: \"I\\'m interested in sports, music, and community service. I believe these activities can help me develop my skills and broaden my horizons.\"', '[Teacher]: \"That\\'s true. You can join the school\\'s sports teams, music clubs, or volunteer for community service.\"', '[Student]: \"Thank you, Miss. I will explore these options.\"', '[Teacher]: \"You\\'re welcome. I\\'m sure you\\'ll find something you enjoy.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I'm interested in getting involved in extracurricular activities. Can you suggest some opportunities?\"\n",
      "18.228496551513672\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I'm interested in getting involved in extracurricular activities. Can you suggest some opportunities?\"\n",
      "token:  [Teacher]: \"Sure. What are your interests?\"\n",
      "7.842408657073975\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure. What are your interests?\"\n",
      "token:  [Student]: \"I'm interested in sports, music, and community service. I believe these activities can help me develop my skills and broaden my horizons.\"\n",
      "7.752158164978027\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm interested in sports, music, and community service. I believe these activities can help me develop my skills and broaden my horizons.\"\n",
      "token:  [Teacher]: \"That's true. You can join the school's sports teams, music clubs, or volunteer for community service.\"\n",
      "9.651714324951172\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's true. You can join the school's sports teams, music clubs, or volunteer for community service.\"\n",
      "token:  [Student]: \"Thank you, Miss. I will explore these options.\"\n",
      "13.342918395996094\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you, Miss. I will explore these options.\"\n",
      "token:  [Teacher]: \"You're welcome. I'm sure you'll find something you enjoy.\"\n",
      "5.712501049041748\n",
      "Student : 13.107857704162598\n",
      "Teacher : 7.735541343688965\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I\\'m planning to do a research project on artificial intelligence. Can you provide some guidance?\"', '[Teacher]: \"Of course. What\\'s your research question?\"', '[Student]: \"I want to explore the impact of artificial intelligence on job displacement. I believe it\\'s a relevant and important topic.\"', '[Teacher]: \"That\\'s a very interesting topic. You can start by reviewing the existing literature on the subject.\"', '[Student]: \"Yes, sir. I will do that. Thank you for your guidance.\"', '[Teacher]: \"You\\'re welcome. Good luck with your research.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I'm planning to do a research project on artificial intelligence. Can you provide some guidance?\"\n",
      "16.505247116088867\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I'm planning to do a research project on artificial intelligence. Can you provide some guidance?\"\n",
      "token:  [Teacher]: \"Of course. What's your research question?\"\n",
      "8.058490753173828\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Of course. What's your research question?\"\n",
      "token:  [Student]: \"I want to explore the impact of artificial intelligence on job displacement. I believe it's a relevant and important topic.\"\n",
      "13.884549140930176\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I want to explore the impact of artificial intelligence on job displacement. I believe it's a relevant and important topic.\"\n",
      "token:  [Teacher]: \"That's a very interesting topic. You can start by reviewing the existing literature on the subject.\"\n",
      "7.621234893798828\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a very interesting topic. You can start by reviewing the existing literature on the subject.\"\n",
      "token:  [Student]: \"Yes, sir. I will do that. Thank you for your guidance.\"\n",
      "6.819431304931641\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Yes, sir. I will do that. Thank you for your guidance.\"\n",
      "token:  [Teacher]: \"You're welcome. Good luck with your research.\"\n",
      "7.729541301727295\n",
      "Student : 12.40307585398356\n",
      "Teacher : 7.803088982899983\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I\\'m feeling a bit overwhelmed with all the assignments and tests. I could use some motivation.\"', '[Teacher]: \"I understand. It\\'s normal to feel overwhelmed at times. Remember, it\\'s okay to take breaks and ask for help when you need it.\"', '[Student]: \"Thank you, Miss. I will keep that in mind. I will also try to manage my time better and prioritize my tasks.\"', '[Teacher]: \"That\\'s a good strategy. You can do this. I believe in you.\"', '[Student]: \"Thank you, Miss. Your words are very encouraging.\"', '[Teacher]: \"You\\'re welcome. Don\\'t hesitate to reach out if you need any help.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I'm feeling a bit overwhelmed with all the assignments and tests. I could use some motivation.\"\n",
      "18.798580169677734\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I'm feeling a bit overwhelmed with all the assignments and tests. I could use some motivation.\"\n",
      "token:  [Teacher]: \"I understand. It's normal to feel overwhelmed at times. Remember, it's okay to take breaks and ask for help when you need it.\"\n",
      "6.16779899597168\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"I understand. It's normal to feel overwhelmed at times. Remember, it's okay to take breaks and ask for help when you need it.\"\n",
      "token:  [Student]: \"Thank you, Miss. I will keep that in mind. I will also try to manage my time better and prioritize my tasks.\"\n",
      "8.45852279663086\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you, Miss. I will keep that in mind. I will also try to manage my time better and prioritize my tasks.\"\n",
      "token:  [Teacher]: \"That's a good strategy. You can do this. I believe in you.\"\n",
      "8.03597354888916\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a good strategy. You can do this. I believe in you.\"\n",
      "token:  [Student]: \"Thank you, Miss. Your words are very encouraging.\"\n",
      "11.141351699829102\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you, Miss. Your words are very encouraging.\"\n",
      "token:  [Teacher]: \"You're welcome. Don't hesitate to reach out if you need any help.\"\n",
      "6.469203472137451\n",
      "Student : 12.799484888712565\n",
      "Teacher : 6.890992005666097\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Sir, I believe peer collaboration can enhance our learning experience. Can we incorporate it in our assignments or projects?\"', '[Teacher]: \"That\\'s a good suggestion. Collaborative learning can be very beneficial.\"', '[Student]: \"I\\'m glad you think so. We can form small groups and work together on assignments or projects. This will allow us to learn from each other and develop our teamwork skills.\"', '[Teacher]: \"That sounds like a good plan. I will consider it.\"', '[Student]: \"Thank you, sir. I believe it will be a positive change.\"', '[Teacher]: \"You\\'re welcome. I appreciate your initiative.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Sir, I believe peer collaboration can enhance our learning experience. Can we incorporate it in our assignments or projects?\"\n",
      "49.243804931640625\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Sir, I believe peer collaboration can enhance our learning experience. Can we incorporate it in our assignments or projects?\"\n",
      "token:  [Teacher]: \"That's a good suggestion. Collaborative learning can be very beneficial.\"\n",
      "8.682011604309082\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That's a good suggestion. Collaborative learning can be very beneficial.\"\n",
      "token:  [Student]: \"I'm glad you think so. We can form small groups and work together on assignments or projects. This will allow us to learn from each other and develop our teamwork skills.\"\n",
      "8.485635757446289\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"I'm glad you think so. We can form small groups and work together on assignments or projects. This will allow us to learn from each other and develop our teamwork skills.\"\n",
      "token:  [Teacher]: \"That sounds like a good plan. I will consider it.\"\n",
      "6.295729637145996\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"That sounds like a good plan. I will consider it.\"\n",
      "token:  [Student]: \"Thank you, sir. I believe it will be a positive change.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.101644515991211\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you, sir. I believe it will be a positive change.\"\n",
      "token:  [Teacher]: \"You're welcome. I appreciate your initiative.\"\n",
      "9.555538177490234\n",
      "Student : 22.277028401692707\n",
      "Teacher : 8.177759806315104\n",
      "['This is a conversation between Teacher and Student. ', '[Student]: \"Miss, I found the career development workshop very informative. I have some questions, though.\"', '[Teacher]: \"Sure, go ahead.\"', '[Student]: \"You mentioned the importance of internships. How can we find internships that align with our career goals?\"', '[Teacher]: \"You can start by researching companies in your field of interest. Look for internship opportunities on their websites or on job portals.\"', '[Student]: \"Thank you, Miss. I will do that. Also, can you provide some tips on writing a good resume?\"', '[Teacher]: \"Of course. A good resume should be concise, well-organized, and tailored to the job you\\'re applying for.\"']\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  This is a conversation between Teacher and Student. \n",
      "token:  [Student]: \"Miss, I found the career development workshop very informative. I have some questions, though.\"\n",
      "45.81081008911133\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Miss, I found the career development workshop very informative. I have some questions, though.\"\n",
      "token:  [Teacher]: \"Sure, go ahead.\"\n",
      "6.056887626647949\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"Sure, go ahead.\"\n",
      "token:  [Student]: \"You mentioned the importance of internships. How can we find internships that align with our career goals?\"\n",
      "17.139684677124023\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"You mentioned the importance of internships. How can we find internships that align with our career goals?\"\n",
      "token:  [Teacher]: \"You can start by researching companies in your field of interest. Look for internship opportunities on their websites or on job portals.\"\n",
      "9.84775161743164\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Teacher]: \"You can start by researching companies in your field of interest. Look for internship opportunities on their websites or on job portals.\"\n",
      "token:  [Student]: \"Thank you, Miss. I will do that. Also, can you provide some tips on writing a good resume?\"\n",
      "10.267093658447266\n",
      "prompt:  Predict the next most probable utterance:\n",
      "context:  [Student]: \"Thank you, Miss. I will do that. Also, can you provide some tips on writing a good resume?\"\n",
      "token:  [Teacher]: \"Of course. A good resume should be concise, well-organized, and tailored to the job you're applying for.\"\n",
      "5.24454927444458\n",
      "Student : 24.40586280822754\n",
      "Teacher : 7.049729506174724\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/gpt4/student_dominated.txt\"\n",
    "with open(file_path, 'r') as file:\n",
    "    datasets = file.read().split('\\n\\n')\n",
    "\n",
    "# Now 'dataset' is a list where each element is a chunk from the file\n",
    "for dataset in datasets:\n",
    "    firstliner = \"This is a conversation between Teacher and Student. \"\n",
    "    dataset = [firstliner] + dataset.split(\"\\n\")\n",
    "    print(dataset)\n",
    "    prmt = \"Predict the next most probable utterance:\"\n",
    "\n",
    "    pattern = r'\\[([^\\]]+)\\]'\n",
    "    matches = re.findall(pattern, \"\".join(dataset))\n",
    "    perpl = compute_perplexity(dataset, prmt)\n",
    "    for patt in np.unique(matches):\n",
    "        idx = np.asarray([index for index, element in enumerate(matches) if element == patt])\n",
    "        print(f\"{patt} :\", np.mean(np.asarray(perpl)[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speech transcription_Transcriber/S05.trs</td>\n",
       "      <td>[MOD] Ok hi welcome, thank you for coming toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speech transcription_Transcriber/S17.trs</td>\n",
       "      <td>[MOD] Hello guys, thanks very much for being h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>speech transcription_Transcriber/S10.trs</td>\n",
       "      <td>[MOD] Ok. So I would like us to play a quiz. O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speech transcription_Transcriber/S21.trs</td>\n",
       "      <td>[MOD] Ok so hello guys. Thanks very [S1] Hi. [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speech transcription_Transcriber/S18.trs</td>\n",
       "      <td>[MOD] Ok hi guys Thanks very much for coming [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>speech transcription_Transcriber/S14.trs</td>\n",
       "      <td>[MOD] Hello guys thanks very much for coming h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>speech transcription_Transcriber/S19.trs</td>\n",
       "      <td>[MOD] Perfect. Well hi guys. Welcome. [S1] Hi....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>speech transcription_Transcriber/S22.trs</td>\n",
       "      <td>[MOD] Ah it's fine. Hello guys. Thanks very mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>speech transcription_Transcriber/S11.trs</td>\n",
       "      <td>[MOD] Right. So, I would like us to play a qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>speech transcription_Transcriber/S20.trs</td>\n",
       "      <td>[MOD] So hello. Thanks very [S1] Hi. [MOD] muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>speech transcription_Transcriber/S13.trs</td>\n",
       "      <td>[MOD]: Well hello, thanks very much for coming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>speech transcription_Transcriber/S04.trs</td>\n",
       "      <td>[MOD] ok Hello, thank you for coming today, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>speech transcription_Transcriber/S07.trs</td>\n",
       "      <td>[MOD] Ok. So welcome, thank you very much for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>speech transcription_Transcriber/S08.trs</td>\n",
       "      <td>[MOD] So good evening [S2] Good evening. [MOD]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>speech transcription_Transcriber/S23.trs</td>\n",
       "      <td>[MOD] So hi guys thanks [S1] hi [MOD] very muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>speech transcription_Transcriber/S09.trs</td>\n",
       "      <td>[MOD] Ok [S2] Yeah so [MOD] So I would like us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>speech transcription_Transcriber/S02.trs</td>\n",
       "      <td>[MOD] Ok so thanks for coming today. we're goi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        path  \\\n",
       "0   speech transcription_Transcriber/S05.trs   \n",
       "1   speech transcription_Transcriber/S17.trs   \n",
       "2   speech transcription_Transcriber/S10.trs   \n",
       "3   speech transcription_Transcriber/S21.trs   \n",
       "4   speech transcription_Transcriber/S18.trs   \n",
       "5   speech transcription_Transcriber/S14.trs   \n",
       "6   speech transcription_Transcriber/S19.trs   \n",
       "7   speech transcription_Transcriber/S22.trs   \n",
       "8   speech transcription_Transcriber/S11.trs   \n",
       "9   speech transcription_Transcriber/S20.trs   \n",
       "10  speech transcription_Transcriber/S13.trs   \n",
       "11  speech transcription_Transcriber/S04.trs   \n",
       "12  speech transcription_Transcriber/S07.trs   \n",
       "13  speech transcription_Transcriber/S08.trs   \n",
       "14  speech transcription_Transcriber/S23.trs   \n",
       "15  speech transcription_Transcriber/S09.trs   \n",
       "16  speech transcription_Transcriber/S02.trs   \n",
       "\n",
       "                                                 text  \n",
       "0   [MOD] Ok hi welcome, thank you for coming toda...  \n",
       "1   [MOD] Hello guys, thanks very much for being h...  \n",
       "2   [MOD] Ok. So I would like us to play a quiz. O...  \n",
       "3   [MOD] Ok so hello guys. Thanks very [S1] Hi. [...  \n",
       "4   [MOD] Ok hi guys Thanks very much for coming [...  \n",
       "5   [MOD] Hello guys thanks very much for coming h...  \n",
       "6   [MOD] Perfect. Well hi guys. Welcome. [S1] Hi....  \n",
       "7   [MOD] Ah it's fine. Hello guys. Thanks very mu...  \n",
       "8   [MOD] Right. So, I would like us to play a qui...  \n",
       "9   [MOD] So hello. Thanks very [S1] Hi. [MOD] muc...  \n",
       "10  [MOD]: Well hello, thanks very much for coming...  \n",
       "11  [MOD] ok Hello, thank you for coming today, we...  \n",
       "12  [MOD] Ok. So welcome, thank you very much for ...  \n",
       "13  [MOD] So good evening [S2] Good evening. [MOD]...  \n",
       "14  [MOD] So hi guys thanks [S1] hi [MOD] very muc...  \n",
       "15  [MOD] Ok [S2] Yeah so [MOD] So I would like us...  \n",
       "16  [MOD] Ok so thanks for coming today. we're goi...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "multisimo_df = pd.read_csv(\"../data/processed/multisimo_text.csv\")\n",
    "multisimo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech transcription_Transcriber/S05.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Ok hi welcome, thank you for coming today. We're going to play a quiz. I would like to ask you three questions which were posed to a group of one hundred people and I would like you to guess the three most popular answers to these questions. \n",
      "17.746978759765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok hi welcome, thank you for coming today. We're going to play a quiz. I would like to ask you three questions which were posed to a group of one hundred people and I would like you to guess the three most popular answers to these questions. \n",
      "token:  [S2] Ok. \n",
      "21.13665008544922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] Ok? \n",
      "39.825374603271484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok? \n",
      "token:  [S1] Ok. \n",
      "12.21041202545166\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] And then I will ask you to talk to each other and guess the ranking of the answers in terms of popularity. So for example if I say what are some ways in which you can pe carry patients to the hospital you would say things like an ambulance, wheelchair, patient's bed ok? And then you would \n",
      "39.214412689208984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And then I will ask you to talk to each other and guess the ranking of the answers in terms of popularity. So for example if I say what are some ways in which you can pe carry patients to the hospital you would say things like an ambulance, wheelchair, patient's bed ok? And then you would \n",
      "token:  [S1] mhmm \n",
      "55.02379608154297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] try to see to find which one of these were you know was the most popular answer and so on \n",
      "92.25167846679688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] try to see to find which one of these were you know was the most popular answer and so on \n",
      "token:  [S2] Is it \n",
      "87.59037017822266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Is it \n",
      "token:  [S1] mhmm \n",
      "24.855215072631836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [S2] are they gonna be general questions or it's something where it depends on the audience what would be the \n",
      "36.41114044189453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] are they gonna be general questions or it's something where it depends on the audience what would be the \n",
      "token:  [MOD] uhuh \n",
      "374.0685119628906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] uhuh \n",
      "token:  [S2] most likely \n",
      "35.22932052612305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] most likely \n",
      "token:  [MOD] hm \n",
      "113.38117218017578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S2] answer \n",
      "74.80731201171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] answer \n",
      "token:  [MOD] hm It was just a group of one hundred participants and they \n",
      "127.79290008544922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm It was just a group of one hundred participants and they \n",
      "token:  [S2] mixed \n",
      "158.92091369628906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mixed \n",
      "token:  [MOD] yes \n",
      "130.7139892578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes \n",
      "token:  [S1] yeah su \n",
      "139.19017028808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah su \n",
      "token:  [S2] ok \n",
      "10.896517753601074\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] So \n",
      "131.90846252441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So \n",
      "token:  [S1] pposed to be a random sample. \n",
      "63.49544143676758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] pposed to be a random sample. \n",
      "token:  [MOD] Exactly so we don't ha ve a specific profile of these participants \n",
      "210.28997802734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly so we don't ha ve a specific profile of these participants \n",
      "token:  [S1] ok \n",
      "71.6756820678711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] is that ok? \n",
      "35.06930160522461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] is that ok? \n",
      "token:  [S2] Yeah. \n",
      "34.82334518432617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Do you have any other \n",
      "29.627470016479492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Do you have any other \n",
      "token:  [S1] Yeah. \n",
      "127.30815124511719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] questions? \n",
      "131.9075164794922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] questions? \n",
      "token:  [S1] hmm I mean they there won't be any I mean \n",
      "60.300933837890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm I mean they there won't be any I mean \n",
      "token:  [MOD] no \n",
      "65.89268493652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no \n",
      "token:  [S1] we won't have the question written or a \n",
      "89.98168182373047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] we won't have the question written or a \n",
      "token:  [MOD] No I will just give \n",
      "147.998046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No I will just give \n",
      "token:  [S1] nything ah \n",
      "193.10861206054688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] nything ah \n",
      "token:  [MOD] them to you orally and then you will have the opportunity to discuss I would really like you to work together. \n",
      "65.47159576416016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] them to you orally and then you will have the opportunity to discuss I would really like you to work together. \n",
      "token:  [S2] Ok. \n",
      "27.940059661865234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] And have a discussion before you're able to give y me your final decisions. Is that ok? \n",
      "74.08707427978516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And have a discussion before you're able to give y me your final decisions. Is that ok? \n",
      "token:  [S2] Yeah. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.186880111694336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Ok. \n",
      "4.780437469482422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Right. So, the first think I would like you to name is a public place where you would be more likely to catch f the flu or a cold. \n",
      "39.64106750488281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Right. So, the first think I would like you to name is a public place where you would be more likely to catch f the flu or a cold. \n",
      "token:  [S1] hmm The the bus? \n",
      "113.41551208496094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm The the bus? \n",
      "token:  [S2] Yeah \n",
      "18.91577911376953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [S1] s some \n",
      "66.87352752685547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] s some \n",
      "token:  [S2] yeah \n",
      "36.45164489746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] thing like yeah? \n",
      "42.354591369628906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] thing like yeah? \n",
      "token:  [MOD] I mean it's eh that was not one of the ah that's a good idea \n",
      "68.98470306396484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I mean it's eh that was not one of the ah that's a good idea \n",
      "token:  [S1] hmm \n",
      "26.866802215576172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] it's it wasn't one of the most popular answers but think about other means of transport. \n",
      "80.96930694580078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it's it wasn't one of the most popular answers but think about other means of transport. \n",
      "token:  [S1] hm \n",
      "41.45466995239258\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hm \n",
      "token:  [S2] Airplane I think \n",
      "27.429866790771484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Airplane I think \n",
      "token:  [MOD] Excellent \n",
      "145.5230255126953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent \n",
      "token:  [S2] airplane. \n",
      "217.22430419921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] airplane. \n",
      "token:  [MOD] very good \n",
      "127.40447235107422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very good \n",
      "token:  [S2] yeah \n",
      "53.987449645996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] yeah. \n",
      "57.81612014770508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah. \n",
      "token:  [S1] hmm \n",
      "36.15639877319336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] So you have one, you need two more now. \n",
      "43.45020294189453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have one, you need two more now. \n",
      "token:  [S2] So \n",
      "78.16331481933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So \n",
      "token:  [S1] hmm The t there is a train as well but \n",
      "81.75653076171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm The t there is a train as well but \n",
      "token:  [MOD] Well the other two answers are not really means of transport. \n",
      "79.0919189453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well the other two answers are not really means of transport. \n",
      "token:  [S1] oh ok ok \n",
      "52.202308654785156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh ok ok \n",
      "token:  [MOD] So think about other public places. \n",
      "134.26443481445312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So think about other public places. \n",
      "token:  [S2] Well like schools and \n",
      "144.2264404296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Well like schools and \n",
      "token:  [MOD] hmm \n",
      "172.27691650390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] hmm \n",
      "9.166403770446777\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] You know like daycare kind of sort of \n",
      "65.02735137939453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You know like daycare kind of sort of \n",
      "token:  [MOD] Excellent, very good. So school is an the other one, yeah? \n",
      "84.71190643310547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent, very good. So school is an the other one, yeah? \n",
      "token:  [S1] Well eh I don't know you you can get it also like in a hospital but I'm not sure \n",
      "42.85966873168945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Well eh I don't know you you can get it also like in a hospital but I'm not sure \n",
      "token:  [MOD] Excellent \n",
      "103.59584045410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent \n",
      "token:  [S1] yeah well \n",
      "94.37754821777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah well \n",
      "token:  [MOD] yes indeed yeah. \n",
      "155.16526794433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes indeed yeah. \n",
      "token:  [S1] ok \n",
      "55.56554412841797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] So that was the other answer. So you have the three, would you like us to would you like to have a quick chat about the popularity of these answers so what's \n",
      "47.97270584106445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So that was the other answer. So you have the three, would you like us to would you like to have a quick chat about the popularity of these answers so what's \n",
      "token:  [S2] the \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.72734069824219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the \n",
      "token:  [MOD] what's the most popular answer? \n",
      "52.939998626708984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] what's the most popular answer? \n",
      "token:  [S1] So it's eh So it's hospital, school and airplane. \n",
      "142.50291442871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So it's eh So it's hospital, school and airplane. \n",
      "token:  [S2] mhmm \n",
      "19.463489532470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [S1] So Maybe school? \n",
      "83.89259338378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So Maybe school? \n",
      "token:  [S2] Yeah be \n",
      "68.43695831298828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah be \n",
      "token:  [S1] but \n",
      "17.755874633789062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but \n",
      "token:  [S2] cause y y young \n",
      "125.9139175415039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cause y y young \n",
      "token:  [S1] because \n",
      "15.604344367980957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] because \n",
      "token:  [S2] like a \n",
      "21.530241012573242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] like a \n",
      "token:  [S1] it's yeah young child \n",
      "77.2635498046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it's yeah young child \n",
      "token:  [S2] children yeah \n",
      "32.36991882324219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] children yeah \n",
      "token:  [S1] dren but but hospital you have more mixed but I don't know \n",
      "129.46652221679688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] dren but but hospital you have more mixed but I don't know \n",
      "token:  [S2] \n",
      "9.346830368041992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] hm \n",
      "16.812664031982422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hm \n",
      "token:  [S2] Yeah but you can I d I don't know I'm not sure whether you you you know you catch more sickness when you're already sick you know sort of eh \n",
      "61.26175308227539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah but you can I d I don't know I'm not sure whether you you you know you catch more sickness when you're already sick you know sort of eh \n",
      "token:  [S1] hmm \n",
      "13.7742919921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] Cause it feels li I don't know for me it feels like that you know in schools because especially parents they tend to send their children to school when they're sick \n",
      "51.67647171020508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cause it feels li I don't know for me it feels like that you know in schools because especially parents they tend to send their children to school when they're sick \n",
      "token:  [S1] yeah \n",
      "16.413888931274414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] and then it's just kind of you know y you know it was sort of kind of and stuff \n",
      "34.145755767822266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and then it's just kind of you know y you know it was sort of kind of and stuff \n",
      "token:  [S1] yeah when one is sick yeah \n",
      "80.88021087646484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah when one is sick yeah \n",
      "token:  [S2] I don't know like I don't I don't have the impression I mean cause I know a few people working hospitals and that they got sick that often so you you I mean you have people coming to visit but I mean you have people already sick \n",
      "36.39900207519531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know like I don't I don't have the impression I mean cause I know a few people working hospitals and that they got sick that often so you you I mean you have people coming to visit but I mean you have people already sick \n",
      "token:  [S1] hmm \n",
      "13.888747215270996\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] so you can't \n",
      "17.229671478271484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so you can't \n",
      "token:  [S1] yeah \n",
      "10.711849212646484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] count them in and then you know you have people that \n",
      "47.57948684692383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] count them in and then you know you have people that \n",
      "token:  [S1] yeah I think I would go with \n",
      "15.432082176208496\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah I think I would go with \n",
      "token:  [S2] that sort of \n",
      "22.209577560424805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] that sort of \n",
      "token:  [S1] with school as well as the the f the most popular \n",
      "59.58976745605469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] with school as well as the the f the most popular \n",
      "token:  [S2] yeah \n",
      "22.82998275756836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] yeah \n",
      "7.421728134155273\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] \n",
      "9.88302993774414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] god hm \n",
      "50.0379753112793\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] god hm \n",
      "token:  [S2] I think well the airplane is also I just heard that you you are I don't know maybe it's because you're kind of in a closed space maybe the sanitary kind of conditions are not great I don't know. \n",
      "40.71764373779297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think well the airplane is also I just heard that you you are I don't know maybe it's because you're kind of in a closed space maybe the sanitary kind of conditions are not great I don't know. \n",
      "token:  [S1] mhmm \n",
      "15.04654312133789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [S2] I just heard that you know so and then I think it's how to say it like I once traveled with a cold and it really aggravates your cold I think, so d you know you tend to feel like I think it tends to be more painful than say train travel I think but I'm not sure whether that actually affects you know be more infectious. \n",
      "56.21059036254883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I just heard that you know so and then I think it's how to say it like I once traveled with a cold and it really aggravates your cold I think, so d you know you tend to feel like I think it tends to be more painful than say train travel I think but I'm not sure whether that actually affects you know be more infectious. \n",
      "token:  [S1] Yeah but because in airplane most likely to be you know adults. They might not you know try to you know cover the their mouth or having baby that might not be as not dangerous but give a risk of infection as children who will just you know touch everything and every \n",
      "81.29660034179688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah but because in airplane most likely to be you know adults. They might not you know try to you know cover the their mouth or having baby that might not be as not dangerous but give a risk of infection as children who will just you know touch everything and every \n",
      "token:  [S2] yeah \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.541047096252441\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] one. \n",
      "17.82081413269043\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] one. \n",
      "token:  [S2] But at the same time like I think you you're more likely to travel when you're sick. I mean by by airplane because you know you already booked a plane and you know unless you've got insurance and you you're gonna cancel the flight \n",
      "39.83600997924805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] But at the same time like I think you you're more likely to travel when you're sick. I mean by by airplane because you know you already booked a plane and you know unless you've got insurance and you you're gonna cancel the flight \n",
      "token:  [S1] hmm \n",
      "15.761977195739746\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] I think. So I I at least I would be more likely to travel by by plane when I'm sick I don't know I don't know by bus or by train or something because it's something you can avoid sort of. \n",
      "28.582275390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think. So I I at least I would be more likely to travel by by plane when I'm sick I don't know I don't know by bus or by train or something because it's something you can avoid sort of. \n",
      "token:  [S1] hmm \n",
      "16.480989456176758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] I don't know I'm not sure whether it it \n",
      "15.346982955932617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know I'm not sure whether it it \n",
      "token:  [MOD] But are you talking about the \n",
      "39.69417190551758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But are you talking about the \n",
      "token:  [S1] Eh no \n",
      "323.22784423828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Eh no \n",
      "token:  [MOD] probability where eh you would have more chances I mean are you trying to think about the ho you know probability of getting sick or are you looking at the popularity of the answers? \n",
      "107.99701690673828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] probability where eh you would have more chances I mean are you trying to think about the ho you know probability of getting sick or are you looking at the popularity of the answers? \n",
      "token:  [S2] \n",
      "34.707237243652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] So \n",
      "242.73191833496094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So \n",
      "token:  [S2] Well ob viously there's a reasoning about I think it's more likely that \n",
      "68.3689193725586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Well ob viously there's a reasoning about I think it's more likely that \n",
      "token:  [MOD] hmm \n",
      "209.47372436523438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] you know get sick \n",
      "113.45348358154297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] you know get sick \n",
      "token:  [MOD] hmm \n",
      "51.28488540649414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] of then it's maybe some \n",
      "135.00355529785156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] of then it's maybe some \n",
      "token:  [MOD] right \n",
      "244.73394775390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] right \n",
      "token:  [S2] ing that'll be you know \n",
      "159.6068878173828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ing that'll be you know \n",
      "token:  [MOD] ok \n",
      "127.28441619873047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok \n",
      "token:  [S2] \n",
      "38.66764831542969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] hmm \n",
      "106.61027526855469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] hmm \n",
      "9.166403770446777\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] I don't know maybe maybe \n",
      "14.706006050109863\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know maybe maybe \n",
      "token:  [S1] I don't know \n",
      "3.9714064598083496\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't know \n",
      "token:  [S2] hospitals yeah maybe that 'll be more int intuitive I don't know eh \n",
      "164.71066284179688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hospitals yeah maybe that 'll be more int intuitive I don't know eh \n",
      "token:  [S1] Yeah I I honestly I don't think airplane would pro necessa \n",
      "142.94139099121094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah I I honestly I don't think airplane would pro necessa \n",
      "token:  [S2] rily be a popular answer I think in that I think it's logic I don't think \n",
      "44.2783088684082\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] rily be a popular answer I think in that I think it's logic I don't think \n",
      "token:  [S1] yes so \n",
      "24.56634521484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yes so \n",
      "token:  [S2] it's necessarily very b gonna be very popular \n",
      "89.08768463134766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] it's necessarily very b gonna be very popular \n",
      "token:  [S1] So \n",
      "21.871660232543945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So \n",
      "token:  [MOD] So what would be your final ranking then? \n",
      "70.85093688964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So what would be your final ranking then? \n",
      "token:  [S2] I'd say hos pitals befo \n",
      "220.90447998046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'd say hos pitals befo \n",
      "token:  [S1] hmm \n",
      "26.609464645385742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] re airplanes I don't know \n",
      "35.38130569458008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] re airplanes I don't know \n",
      "token:  [MOD] And would the top \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269.0171813964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And would the top \n",
      "token:  [S1] hm I I then I would you know hospital before \n",
      "271.1746826171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hm I I then I would you know hospital before \n",
      "token:  [S2] top would be \n",
      "28.301973342895508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] top would be \n",
      "token:  [S1] airplane would in first would be schools yeah \n",
      "309.9883117675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] airplane would in first would be schools yeah \n",
      "token:  [S2] bef and school yeah yeah \n",
      "43.23312759399414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] bef and school yeah yeah \n",
      "token:  [MOD] So, is it schools, hospitals and airplanes? \n",
      "101.03409576416016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So, is it schools, hospitals and airplanes? \n",
      "token:  [S2] Yeah. \n",
      "26.9349422454834\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Yeah. \n",
      "4.336958408355713\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Excellent, you got it. That was the right ranking very good. \n",
      "50.018646240234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent, you got it. That was the right ranking very good. \n",
      "token:  [S1] Ok. \n",
      "20.68689727783203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] Ok. \n",
      "4.238768577575684\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] Now let's move on to the second question. I would like you to name an instrument in a symphony orchestra. \n",
      "19.03602409362793\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Now let's move on to the second question. I would like you to name an instrument in a symphony orchestra. \n",
      "token:  [S2] \n",
      "24.321338653564453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] oh \n",
      "36.7059326171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh \n",
      "token:  [S2] Violin. \n",
      "11.211668014526367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violin. \n",
      "token:  [S1] eh \n",
      "71.22147369384766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] eh \n",
      "token:  [MOD] Very good that's one yeah. \n",
      "155.8448486328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good that's one yeah. \n",
      "token:  [S2] Cello. \n",
      "64.91569519042969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cello. \n",
      "token:  [MOD] Excellent, yes. \n",
      "73.42015075683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent, yes. \n",
      "token:  [S1] and eh \n",
      "176.84454345703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and eh \n",
      "token:  [MOD] One more? \n",
      "146.2838592529297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] One more? \n",
      "token:  [S1] eh Bass? but \n",
      "601.175048828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] eh Bass? but \n",
      "token:  [MOD] hmm no I've a \n",
      "108.58149719238281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm no I've a \n",
      "token:  [S1] not a very yeah here again my English is lacking sligh tly \n",
      "212.26759338378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] not a very yeah here again my English is lacking sligh tly \n",
      "token:  [MOD] Well this is a the flute? simple I would like you to think about instruments that are commonly used in even in live concert concerts or you know different types of music \n",
      "83.12898254394531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well this is a the flute? simple I would like you to think about instruments that are commonly used in even in live concert concerts or you know different types of music \n",
      "token:  [S1] maybe a flu te? \n",
      "144.70651245117188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] maybe a flu te? \n",
      "token:  [MOD] hmm \n",
      "72.3692626953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] hm No? \n",
      "38.65341567993164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hm No? \n",
      "token:  [MOD] No but try again. \n",
      "53.86936950683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No but try again. \n",
      "token:  [S1] hmm \n",
      "41.44881820678711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] But it wouldn't be kind of extravagant like an ha a harp or \n",
      "119.8161849975586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] But it wouldn't be kind of extravagant like an ha a harp or \n",
      "token:  [MOD] No \n",
      "209.10118103027344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No \n",
      "token:  [S2] something \n",
      "121.59500885009766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] something \n",
      "token:  [MOD] I mean it's a common English word cause you v because you mentioned your limited vocabulary about instruments the I mean this musical instrument is \n",
      "181.92747497558594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I mean it's a common English word cause you v because you mentioned your limited vocabulary about instruments the I mean this musical instrument is \n",
      "token:  [S1] hmm \n",
      "43.23798370361328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] very commonly used in English, it's a common simple word. \n",
      "57.31910705566406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very commonly used in English, it's a common simple word. \n",
      "token:  [S1] ok so \n",
      "77.30699920654297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok so \n",
      "token:  [S2] Like a \n",
      "28.963762283325195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Like a \n",
      "token:  [S1] \n",
      "14.802789688110352\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] trumpet? \n",
      "50.976890563964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] trumpet? \n",
      "token:  [MOD] Nope. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.173561096191406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Nope. \n",
      "token:  [S2] No. \n",
      "20.83803367614746\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No. \n",
      "token:  [MOD] It allows you to give the rhythm the melody as well. \n",
      "116.17231750488281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It allows you to give the rhythm the melody as well. \n",
      "token:  [S2] ok \n",
      "109.47976684570312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] hmm I guess so eh a drum? \n",
      "54.1176872253418\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm I guess so eh a drum? \n",
      "token:  [MOD] Yes that's it \n",
      "39.04883575439453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes that's it \n",
      "token:  [S1] yeah \n",
      "49.122650146484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] very good. So \n",
      "122.84736633300781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very good. So \n",
      "token:  [S1] ok \n",
      "71.90074920654297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] you now have the three ok? Would you like \n",
      "142.0653839111328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you now have the three ok? Would you like \n",
      "token:  [S2] hmm \n",
      "76.79139709472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] us would you like to talk about their ranking? \n",
      "85.43853759765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] us would you like to talk about their ranking? \n",
      "token:  [S1] Oh ok so you said So \n",
      "118.64490509033203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh ok so you said So \n",
      "token:  [S2] So we ah in terms popularity then \n",
      "104.11820983886719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So we ah in terms popularity then \n",
      "token:  [MOD] mhmm \n",
      "92.79906463623047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] Maybe violin would be \n",
      "254.5176239013672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Maybe violin would be \n",
      "token:  [S2] yeah \n",
      "19.398317337036133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] the first ye \n",
      "55.25551223754883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the first ye \n",
      "token:  [MOD] hmm \n",
      "171.04476928710938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] ah \n",
      "48.126487731933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah \n",
      "token:  [S2] yeah I think so \n",
      "13.085286140441895\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah I think so \n",
      "token:  [S1] yeah \n",
      "8.592577934265137\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] I think that's very \n",
      "15.986372947692871\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think that's very \n",
      "token:  [S1] Yeah violin and then cello and then drum? Because it's it's I thought of violin, just couldn't catch the word in English so and yeah I don't know if you agree. \n",
      "65.90119934082031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah violin and then cello and then drum? Because it's it's I thought of violin, just couldn't catch the word in English so and yeah I don't know if you agree. \n",
      "token:  [S2] \n",
      "10.463809967041016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] I I'm not sure the \n",
      "32.42339324951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I I'm not sure the \n",
      "token:  [S2] yeah \n",
      "22.254409790039062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] last two but \n",
      "65.80376434326172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] last two but \n",
      "token:  [S2] Yeah I think it's probably what people would think of cause I don't really think of like drums I mean they're kind of they're more on the background I think like \n",
      "35.409996032714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah I think it's probably what people would think of cause I don't really think of like drums I mean they're kind of they're more on the background I think like \n",
      "token:  [S1] hmm \n",
      "11.762985229492188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] I think everything that gives rhythm is not I mean i it's obviously very necessary but at the same time it's it's not very \n",
      "54.08837127685547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think everything that gives rhythm is not I mean i it's obviously very necessary but at the same time it's it's not very \n",
      "token:  [MOD] hm \n",
      "100.61773681640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S1] hm \n",
      "10.109627723693848\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hm \n",
      "token:  [MOD] prominent \n",
      "425.7162170410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] prominent \n",
      "token:  [S2] yeah and I think it's better because you know cellos tend to be quite big as well I th and also and \n",
      "120.26362609863281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah and I think it's better because you know cellos tend to be quite big as well I th and also and \n",
      "token:  [S1] yeah \n",
      "12.579943656921387\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] usually I think they're placed in front of the you know from the stage you know so \n",
      "56.92033386230469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] usually I think they're placed in front of the you know from the stage you know so \n",
      "token:  [S1] yeah in front yeah yeah \n",
      "29.992233276367188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah in front yeah yeah \n",
      "token:  [S2] drums they tend to be at the side or at the back I think \n",
      "35.230220794677734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] drums they tend to be at the side or at the back I think \n",
      "token:  [S1] hmm \n",
      "17.836076736450195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] sort of so it wouldn't be as visible I'd say. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.973188400268555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] sort of so it wouldn't be as visible I'd say. \n",
      "token:  [MOD] So what would be your final decision? \n",
      "29.93851661682129\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So what would be your final decision? \n",
      "token:  [S1] yeah \n",
      "76.59479522705078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] yeah vi \n",
      "41.78853988647461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah vi \n",
      "token:  [S1] like ah violin \n",
      "125.1852798461914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like ah violin \n",
      "token:  [S2] violin, cello and then \n",
      "25.053773880004883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] violin, cello and then \n",
      "token:  [S1] yeah \n",
      "15.207379341125488\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] You're very good. \n",
      "45.74477767944336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You're very good. \n",
      "token:  [S1] and then drum. yeah \n",
      "306.4475402832031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and then drum. yeah \n",
      "token:  [MOD] Well done you got it \n",
      "59.84798812866211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well done you got it \n",
      "token:  [S1] hmm \n",
      "33.762245178222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] very good. So now the third and the final question, I would like you to name something that people cut. \n",
      "66.86083221435547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very good. So now the third and the final question, I would like you to name something that people cut. \n",
      "token:  [S2] cut \n",
      "64.14350128173828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cut \n",
      "token:  [MOD] Things that people cut. \n",
      "130.2364044189453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Things that people cut. \n",
      "token:  [S1] Cut? \n",
      "32.41590881347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cut? \n",
      "token:  [MOD] Yeah. \n",
      "50.69011688232422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] That's very broad. \n",
      "25.404176712036133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] That's very broad. \n",
      "token:  [S1] Yes. \n",
      "5.744475364685059\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yes. \n",
      "token:  [S2] \n",
      "10.539885520935059\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] \n",
      "5.087191581726074\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] Carrots? \n",
      "18.454166412353516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Carrots? \n",
      "token:  [S1] I I I I \n",
      "14.337267875671387\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I I I I \n",
      "token:  [MOD] ok \n",
      "215.8413543701172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok \n",
      "token:  [S1] came with apple but eh ah \n",
      "297.6951904296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] came with apple but eh ah \n",
      "token:  [MOD] Well think about food but l think about a different category of food not foo fruit or vegetables. \n",
      "179.63980102539062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well think about food but l think about a different category of food not foo fruit or vegetables. \n",
      "token:  [S2] Eh meat? \n",
      "118.97444152832031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Eh meat? \n",
      "token:  [MOD] Very good yeah. That that \n",
      "217.68260192871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good yeah. That that \n",
      "token:  [S1] So \n",
      "34.98153305053711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So \n",
      "token:  [MOD] was one. \n",
      "125.14995574951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] was one. \n",
      "token:  [S2] ok \n",
      "167.6079864501953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] yeah \n",
      "90.82000732421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] ok so \n",
      "39.66788101196289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok so \n",
      "token:  [S2] Bread? \n",
      "51.925140380859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Bread? \n",
      "token:  [MOD] I mean ok meat is one answer but the n forget about the food now move to other things \n",
      "258.8260192871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I mean ok meat is one answer but the n forget about the food now move to other things \n",
      "token:  [S2] ok ok \n",
      "38.62192153930664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok ok \n",
      "token:  [S1] ok \n",
      "8.20450496673584\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] that was just a food item \n",
      "19.54400634765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] that was just a food item \n",
      "token:  [S1] ok \n",
      "11.21165943145752\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] yeah \n",
      "85.48063659667969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S2] Wood? \n",
      "171.5278778076172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Wood? \n",
      "token:  [MOD] y \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195.0156707763672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] y \n",
      "token:  [S2] no \n",
      "80.55239868164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no \n",
      "token:  [MOD] yeah good idea but it wasn't one of the popu lar answers ok \n",
      "142.7668914794922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah good idea but it wasn't one of the popu lar answers ok \n",
      "token:  [S1] a juat \n",
      "152.2194061279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] a juat \n",
      "token:  [S2] Hair? \n",
      "66.04971313476562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair? \n",
      "token:  [MOD] Yes very good. Very good. And one more? \n",
      "40.8641242980957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes very good. Very good. And one more? \n",
      "token:  [S1] Go ahead. I I \n",
      "51.61331558227539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Go ahead. I I \n",
      "token:  [S2] no no no I'm \n",
      "21.648588180541992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no no no I'm \n",
      "token:  [S1] I feel \n",
      "18.8624267578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I feel \n",
      "token:  [S2] I don't know \n",
      "5.75354528427124\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know \n",
      "token:  [S1] like ah \n",
      "54.362396240234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like ah \n",
      "token:  [S2] cut ok so we have we have meat we have \n",
      "68.5645751953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cut ok so we have we have meat we have \n",
      "token:  [S1] hair \n",
      "26.34431266784668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hair \n",
      "token:  [S2] hair \n",
      "5.5123724937438965\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair \n",
      "token:  [S1] meat and hair \n",
      "34.81619644165039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat and hair \n",
      "token:  [S2] So we have we have food and we have something on the \n",
      "26.21448516845703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So we have we have food and we have something on the \n",
      "token:  [S1] nai \n",
      "79.0674819946289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] nai \n",
      "token:  [S2] person \n",
      "36.914527893066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] person \n",
      "token:  [S1] ls? \n",
      "36.322296142578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ls? \n",
      "token:  [S2] so \n",
      "15.868361473083496\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so \n",
      "token:  [S1] yeah but that's already yeah \n",
      "51.53728485107422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah but that's already yeah \n",
      "token:  [S2] yeah maybe that it has to be something else \n",
      "17.572490692138672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah maybe that it has to be something else \n",
      "token:  [S1] yeah \n",
      "10.981325149536133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] So maybe that's something that is not animate not food \n",
      "95.5492935180664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So maybe that's something that is not animate not food \n",
      "token:  [S1] maybe with like scissors, paper? No? \n",
      "69.1755599975586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] maybe with like scissors, paper? No? \n",
      "token:  [MOD] Paper \n",
      "246.9299774169922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Paper \n",
      "token:  [S1] yeah \n",
      "92.28339385986328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] well done \n",
      "80.06182098388672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] well done \n",
      "token:  [S1] yeah \n",
      "32.98690414428711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] yeah \n",
      "36.475040435791016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] ok \n",
      "29.147520065307617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] that was the other one. \n",
      "44.85909652709961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] that was the other one. \n",
      "token:  [S1] ok \n",
      "89.01924133300781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] So in terms of popularity how would you rank these answers? \n",
      "44.783782958984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So in terms of popularity how would you rank these answers? \n",
      "token:  [S2] I don't think that meat is very popular. \n",
      "22.030649185180664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't think that meat is very popular. \n",
      "token:  [MOD] hm \n",
      "102.373046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S1] nah \n",
      "32.80409622192383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] nah \n",
      "token:  [S2] I think I think paper would \n",
      "79.79210662841797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think I think paper would \n",
      "token:  [S1] hmm \n",
      "12.974160194396973\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] probably be very that very popoular answer. \n",
      "133.2228240966797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] probably be very that very popoular answer. \n",
      "token:  [S1] Yeah but I think hair as well is I don't know eh i it's both with scissors so I don't know yeah many paper \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.54261779785156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah but I think hair as well is I don't know eh i it's both with scissors so I don't know yeah many paper \n",
      "token:  [S2] cut hair \n",
      "19.84585952758789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cut hair \n",
      "token:  [S1] ah I don't know eh sorry \n",
      "35.16575241088867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah I don't know eh sorry \n",
      "token:  [S2] paper I think I don't know you made me unsure again yeah I think I think you're right I think meat should probably be very close \n",
      "48.516273498535156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] paper I think I don't know you made me unsure again yeah I think I think you're right I think meat should probably be very close \n",
      "token:  [S1] hmm hmm \n",
      "16.627605438232422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm hmm \n",
      "token:  [S2] I don't know it's not something that I think you that I just I just \n",
      "24.890439987182617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know it's not something that I think you that I just I just \n",
      "token:  [S1] yeah but \n",
      "20.433490753173828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah but \n",
      "token:  [S2] tend to think of food and I think that's why I came you know \n",
      "35.206783294677734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] tend to think of food and I think that's why I came you know \n",
      "token:  [S1] yeah we we ask me something of cutting eh instantly for food in first not not meat but food so it's ah \n",
      "309.346435546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah we we ask me something of cutting eh instantly for food in first not not meat but food so it's ah \n",
      "token:  [S2] yeah yeah yeah yeah So I think well I don't think it's a popular answer like \n",
      "25.176912307739258\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah yeah yeah yeah So I think well I don't think it's a popular answer like \n",
      "token:  [S1] hm yeah maybe not \n",
      "24.601037979125977\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hm yeah maybe not \n",
      "token:  [MOD] What would be the first thing that would come to most people's minds? \n",
      "11.848998069763184\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] What would be the first thing that would come to most people's minds? \n",
      "token:  [S1] Maybe I would say hair but I don't know I I didn't follow it now it seems logical now that now that you said it so \n",
      "63.60980224609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Maybe I would say hair but I don't know I I didn't follow it now it seems logical now that now that you said it so \n",
      "token:  [S2] Well i don't know I think it's paper actually \n",
      "21.036083221435547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Well i don't know I think it's paper actually \n",
      "token:  [S1] ok ok you so you So you would say paper, hair and \n",
      "64.80778503417969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok ok you so you So you would say paper, hair and \n",
      "token:  [S2] meat \n",
      "32.8481559753418\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] meat \n",
      "token:  [S1] meat \n",
      "9.15871810913086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat \n",
      "token:  [MOD] Is that your final decision? \n",
      "70.9613265991211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Is that your final decision? \n",
      "token:  [S1] ok I mean sometimes that's so yeah yeah ok \n",
      "104.73126983642578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok I mean sometimes that's so yeah yeah ok \n",
      "token:  [MOD] Ok, well unfortunately you didn't get this one because it it was hair \n",
      "90.97938537597656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok, well unfortunately you didn't get this one because it it was hair \n",
      "token:  [S1] first \n",
      "80.13752746582031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] first \n",
      "token:  [S2] ok \n",
      "10.643582344055176\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] ok so \n",
      "13.007145881652832\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok so \n",
      "token:  [S2] Ok so you're actually right yeah yeah. \n",
      "25.929519653320312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok so you're actually right yeah yeah. \n",
      "token:  [MOD] So hair paper and meat. \n",
      "252.28094482421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So hair paper and meat. \n",
      "token:  [S2] Ah. \n",
      "48.77602767944336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah. \n",
      "token:  [S1] Ok. \n",
      "7.9115777015686035\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Alright? \n",
      "59.81321334838867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Alright? \n",
      "token:  [S1] Yeah \n",
      "39.18462371826172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah \n",
      "token:  [MOD] But great job well done. \n",
      "125.00657653808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But great job well done. \n",
      "token:  [S1] hmm \n",
      "41.773189544677734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] Well and that was the end of the quiz I hope you enjoyed it. Thank you very much. \n",
      "21.234148025512695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well and that was the end of the quiz I hope you enjoyed it. Thank you very much. \n",
      "token:  [S2] Yeah yeah that was interesting.\n",
      "23.631498336791992\n",
      "MOD : 111.46388146217834\n",
      "S1 : 68.30886415019631\n",
      "S2 : 52.953269593612006\n",
      "speech transcription_Transcriber/S17.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Hello guys, thanks very much for being here today. Eh we're going to play a quiz. So I'm going to ask you three survey questions that were previously posed to a grip group of hundred people. So you'll have to come with the three most popular answers. You need to colla \n",
      "41.261741638183594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Hello guys, thanks very much for being here today. Eh we're going to play a quiz. So I'm going to ask you three survey questions that were previously posed to a grip group of hundred people. So you'll have to come with the three most popular answers. You need to colla \n",
      "token:  [S1] Ok. \n",
      "64.4942398071289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] borate, you need to talk to each other and then you'll have to rank those answers. Ok? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.1881217956543\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] borate, you need to talk to each other and then you'll have to rank those answers. Ok? \n",
      "token:  [S1] Ok. \n",
      "16.575759887695312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Are you ready or would you like an example or what do you feel? You're ready for the first question or \n",
      "42.08979034423828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Are you ready or would you like an example or what do you feel? You're ready for the first question or \n",
      "token:  [S2] Sure go yeah. \n",
      "162.3961639404297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Sure go yeah. \n",
      "token:  [S1] Yeah. Go ahead. \n",
      "7.567086219787598\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. Go ahead. \n",
      "token:  [MOD] Yeah? So can you name a public place where it's more likely for someone to catch a cold or a flu bug. \n",
      "28.521739959716797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? So can you name a public place where it's more likely for someone to catch a cold or a flu bug. \n",
      "token:  [S2] Three most common places. \n",
      "43.82929992675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Three most common places. \n",
      "token:  [MOD] m hmm \n",
      "265.095458984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] m hmm \n",
      "token:  [S1] ok \n",
      "41.6346435546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] hmm \n",
      "5.288430690765381\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] Public transport I'd \n",
      "95.65300750732422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Public transport I'd \n",
      "token:  [S2] yeah \n",
      "24.861248016357422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] say. \n",
      "26.023799896240234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] say. \n",
      "token:  [S2] Public transport \n",
      "48.85274887084961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Public transport \n",
      "token:  [S1] Do we have to be more specific \n",
      "21.754690170288086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Do we have to be more specific \n",
      "token:  [MOD] hmm \n",
      "108.58915710449219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] or \n",
      "31.347875595092773\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] or \n",
      "token:  [MOD] It's better yeah. \n",
      "170.6788787841797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's better yeah. \n",
      "token:  [S1] ok better ok \n",
      "81.24617767333984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok better ok \n",
      "token:  [S2] yeah \n",
      "9.00791072845459\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] \n",
      "9.508689880371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] Restaurants maybe o r \n",
      "195.4676513671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Restaurants maybe o r \n",
      "token:  [S1] Yeah. \n",
      "10.489728927612305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] hm Hospitals? \n",
      "61.477806091308594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm Hospitals? \n",
      "token:  [S1] Hospitals for sure. School \n",
      "37.02958679199219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hospitals for sure. School \n",
      "token:  [S2] Ah may be not because like they have \n",
      "68.80743408203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah may be not because like they have \n",
      "token:  [S1] hm Yeah the thing is that \n",
      "34.66244888305664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hm Yeah the thing is that \n",
      "token:  [S2] yeah, it's very sterile. \n",
      "25.061655044555664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah, it's very sterile. \n",
      "token:  [S1] they say that when you catch a bug in the hospital it's every very strong because it has \n",
      "63.601009368896484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] they say that when you catch a bug in the hospital it's every very strong because it has \n",
      "token:  [S2] so \n",
      "15.81887435913086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so \n",
      "token:  [S1] survived from so many antibiotics and stuff so yeah so ok yeah \n",
      "116.10347747802734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] survived from so many antibiotics and stuff so yeah so ok yeah \n",
      "token:  [S2] yeah maybe that's probably on of them like \n",
      "45.00241470336914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah maybe that's probably on of them like \n",
      "token:  [S1] o k and We have so restaurants hospitals \n",
      "570.3452758789062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] o k and We have so restaurants hospitals \n",
      "token:  [S2] hospitals \n",
      "31.189762115478516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hospitals \n",
      "token:  [S1] and public trans \n",
      "58.04506301879883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and public trans \n",
      "token:  [S2] public transport \n",
      "30.466083526611328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] public transport \n",
      "token:  [S1] port yeah. \n",
      "41.781734466552734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] port yeah. \n",
      "token:  [S2] Yeah. \n",
      "6.869340896606445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Can you be a bit more specific about public transport? \n",
      "28.630720138549805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you be a bit more specific about public transport? \n",
      "token:  [S2] Buses may \n",
      "178.7930145263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Buses may \n",
      "token:  [S1] buses \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.56195831298828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] buses \n",
      "token:  [S2] or \n",
      "14.113424301147461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] or \n",
      "token:  [S1] yeah \n",
      "31.060440063476562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] yeah \n",
      "5.347904205322266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] I'd say bu ses \n",
      "60.43922805786133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'd say bu ses \n",
      "token:  [S2] yeah \n",
      "23.213293075561523\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] I always feel like it's \n",
      "16.670101165771484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I always feel like it's \n",
      "token:  [MOD] Ok you're doing great you found one. \n",
      "110.33064270019531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok you're doing great you found one. \n",
      "token:  [S2] ok \n",
      "67.21415710449219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] o ok great \n",
      "40.275142669677734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] o ok great \n",
      "token:  [MOD] which is the hospital \n",
      "160.08677673339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] which is the hospital \n",
      "token:  [S2] Yeah. \n",
      "104.10957336425781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Alright. \n",
      "7.4670820236206055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright. \n",
      "token:  [MOD] Ok? So maybe you can think more about different age groups like chil \n",
      "115.71023559570312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok? So maybe you can think more about different age groups like chil \n",
      "token:  [S2] Oh! \n",
      "69.99517822265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh! \n",
      "token:  [MOD] dren for ex ample. \n",
      "684.0886840820312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] dren for ex ample. \n",
      "token:  [S2] schools \n",
      "291.90386962890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] schools \n",
      "token:  [S1] Schools for \n",
      "39.52598571777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Schools for \n",
      "token:  [S2] yeah \n",
      "35.945556640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] sure. \n",
      "10.446062088012695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] sure. \n",
      "token:  [MOD] mhmm \n",
      "64.46580505371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] Yeah. \n",
      "39.75992965698242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Yeah. \n",
      "3.992809534072876\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Very good. \n",
      "28.045026779174805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good. \n",
      "token:  [S2] \n",
      "35.393798828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] School \n",
      "71.52664184570312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] School \n",
      "token:  [MOD] And think about traveling. \n",
      "241.10714721679688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And think about traveling. \n",
      "token:  [S2] Airplanes. \n",
      "37.04524230957031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Airplanes. \n",
      "token:  [S1] Airplanes as well yeah. \n",
      "20.956317901611328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Airplanes as well yeah. \n",
      "token:  [S2] Yeah. \n",
      "5.184263229370117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Ok airports and yeah air port. \n",
      "152.64796447753906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok airports and yeah air port. \n",
      "token:  [S2] Yeah. \n",
      "6.588398456573486\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] So, what are your three answers? \n",
      "27.75947380065918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So, what are your three answers? \n",
      "token:  [S1] Ok so hospitals \n",
      "411.0755310058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok so hospitals \n",
      "token:  [S2] So hospital school \n",
      "19.47878074645996\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So hospital school \n",
      "token:  [S1] school and and We can go for airplane. \n",
      "76.46013641357422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] school and and We can go for airplane. \n",
      "token:  [S2] Yeah. \n",
      "14.412200927734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Ok that's great. These are \n",
      "73.37601470947266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok that's great. These are \n",
      "token:  [S2] Yeah. \n",
      "111.82351684570312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] the three answers. And can you rank them please? \n",
      "125.15275573730469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the three answers. And can you rank them please? \n",
      "token:  [S1] Ok so which one was the most popular. \n",
      "30.916112899780273\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok so which one was the most popular. \n",
      "token:  [MOD] mhmm \n",
      "60.78697967529297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] Ok. \n",
      "35.29777526855469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] hm Schools I'd \n",
      "155.06993103027344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm Schools I'd \n",
      "token:  [S1] hmm \n",
      "8.960241317749023\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] say would be pretty poular. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.89102172851562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] say would be pretty poular. \n",
      "token:  [S1] Yeah. \n",
      "12.632354736328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] I don't know. \n",
      "3.658543348312378\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know. \n",
      "token:  [S1] Yeah I think that would be the most popular I'm not sure if \n",
      "20.884418487548828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah I think that would be the most popular I'm not sure if \n",
      "token:  [S2] yeah \n",
      "14.787836074829102\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] it's the m m most correct yeah bu t \n",
      "206.5553436279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it's the m m most correct yeah bu t \n",
      "token:  [S2] but it's it is yeah yeah I know I'm not sure either yeah \n",
      "30.27116584777832\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] but it's it is yeah yeah I know I'm not sure either yeah \n",
      "token:  [S1] and \n",
      "17.046207427978516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and \n",
      "token:  [S2] hm \n",
      "12.423806190490723\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm \n",
      "token:  [S1] then I'd say \n",
      "27.202295303344727\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] then I'd say \n",
      "token:  [S2] I'd say a lot of k \n",
      "19.911300659179688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'd say a lot of k \n",
      "token:  [S1] airplanes \n",
      "130.18606567382812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] airplanes \n",
      "token:  [S2] like kids get sick a lot so \n",
      "54.43037033081055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] like kids get sick a lot so \n",
      "token:  [S1] yeah \n",
      "15.601441383361816\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] like I would say \n",
      "16.720510482788086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] like I would say \n",
      "token:  [S1] yeah \n",
      "11.133658409118652\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] s like \n",
      "26.953845977783203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] s like \n",
      "token:  [S1] s \n",
      "11.769731521606445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] s \n",
      "token:  [S2] schools would probably be number \n",
      "169.98289489746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] schools would probably be number \n",
      "token:  [S1] schools? Schools. \n",
      "30.90731430053711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] schools? Schools. \n",
      "token:  [S2] one \n",
      "25.631380081176758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] one \n",
      "token:  [S1] Number one ok. \n",
      "80.73513793945312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Number one ok. \n",
      "token:  [S2] and \n",
      "20.136362075805664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and \n",
      "token:  [S1] and \n",
      "6.1239447593688965\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and \n",
      "token:  [S2] the n \n",
      "32.78725814819336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the n \n",
      "token:  [S1] the n \n",
      "7.4992475509643555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the n \n",
      "token:  [S2] Maybe Maybe airplanes I'd say and then maybe hospitals that's probably what I would say but \n",
      "106.2314682006836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Maybe Maybe airplanes I'd say and then maybe hospitals that's probably what I would say but \n",
      "token:  [S1] Schools, airplanes, hospitals, ok. Yeah I think \n",
      "36.686710357666016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Schools, airplanes, hospitals, ok. Yeah I think \n",
      "token:  [S2] Yeah. \n",
      "10.832508087158203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] I think I'll agree. \n",
      "10.570055961608887\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think I'll agree. \n",
      "token:  [S2] Cool. \n",
      "7.53903341293335\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cool. \n",
      "token:  [MOD] Almost there. \n",
      "39.18891143798828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Almost there. \n",
      "token:  [S1] Al right \n",
      "105.4216079711914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Al right \n",
      "token:  [S2] Oh \n",
      "10.116750717163086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh \n",
      "token:  [MOD] So it was school then \n",
      "189.65638732910156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So it was school then \n",
      "token:  [S2] yeah \n",
      "63.96141052246094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] hospital and then plane. \n",
      "485.05682373046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hospital and then plane. \n",
      "token:  [S1] and then ok ok \n",
      "79.41446685791016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and then ok ok \n",
      "token:  [MOD] But you did great guys \n",
      "149.6088409423828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But you did great guys \n",
      "token:  [S1] ok \n",
      "63.40195083618164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] well done . Are you ready for the second one? \n",
      "43.468238830566406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] well done . Are you ready for the second one? \n",
      "token:  [S1] yes \n",
      "24.782957077026367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yes \n",
      "token:  [S2] yep \n",
      "7.387513160705566\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yep \n",
      "token:  [S1] s \n",
      "39.073951721191406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] s \n",
      "token:  [MOD] Can you name an instrument you can find in a symphony orchestra. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.0811653137207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you name an instrument you can find in a symphony orchestra. \n",
      "token:  [S1] Flute? \n",
      "22.5559024810791\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Flute? \n",
      "token:  [S2] Violin? Oh we want the three most common aswers \n",
      "49.23714828491211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violin? Oh we want the three most common aswers \n",
      "token:  [MOD] mhmm \n",
      "81.12238311767578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S2] to that. ok. \n",
      "85.91227722167969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] to that. ok. \n",
      "token:  [S1] Alright. \n",
      "12.23332405090332\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright. \n",
      "token:  [S2] So \n",
      "12.679468154907227\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So \n",
      "token:  [S1] Violin I think it's a good \n",
      "34.36917495727539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin I think it's a good \n",
      "token:  [S2] violin \n",
      "10.631823539733887\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] violin \n",
      "token:  [S1] option yeah. \n",
      "121.26982116699219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] option yeah. \n",
      "token:  [S2] Maybe cello? Yes. \n",
      "38.0955924987793\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Maybe cello? Yes. \n",
      "token:  [S1] Bass co c th the big one bass double bass yeah \n",
      "430.93902587890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Bass co c th the big one bass double bass yeah \n",
      "token:  [S2] double bass double bass yeah \n",
      "8.984417915344238\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] double bass double bass yeah \n",
      "token:  [S1] alright \n",
      "23.10750389099121\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] alright \n",
      "token:  [S2] I wouldn't say that's one of the most popular th ones though I'd say violin and cello would probably be pretty po \n",
      "65.88963317871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I wouldn't say that's one of the most popular th ones though I'd say violin and cello would probably be pretty po \n",
      "token:  [S1] Ok. \n",
      "24.12986946105957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] pular and the n Probably flute after that I'd say \n",
      "208.96144104003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] pular and the n Probably flute after that I'd say \n",
      "token:  [S1] Flute. No, from her reaction flute was not one of them \n",
      "38.41455078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Flute. No, from her reaction flute was not one of them \n",
      "token:  [MOD] I'm trying \n",
      "67.32283020019531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'm trying \n",
      "token:  [S2] Oh really? \n",
      "37.90317916870117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh really? \n",
      "token:  [MOD] I'm trying not to show too much now. But I have to say you found two already. \n",
      "34.9986686706543\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'm trying not to show too much now. But I have to say you found two already. \n",
      "token:  [S1] Ok Can you tell us \n",
      "66.99864196777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok Can you tell us \n",
      "token:  [S2] Ok. \n",
      "9.89538288116455\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] which one, no you can't \n",
      "33.22443771362305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] which one, no you can't \n",
      "token:  [MOD] Ok well look it's the violin and cello. \n",
      "95.27912902832031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok well look it's the violin and cello. \n",
      "token:  [S1] Alright \n",
      "59.023189544677734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright \n",
      "token:  [S2] Yeah. \n",
      "8.534111022949219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] So you have a third one. \n",
      "31.801559448242188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have a third one. \n",
      "token:  [S1] perfect. \n",
      "54.98278045654297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] perfect. \n",
      "token:  [MOD] Which might be \n",
      "137.56808471679688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Which might be \n",
      "token:  [S2] A third one. \n",
      "77.8446273803711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A third one. \n",
      "token:  [MOD] very different from the other two. \n",
      "30.2679386138916\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very different from the other two. \n",
      "token:  [S2] So maybe a woodwind or \n",
      "180.21566772460938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So maybe a woodwind or \n",
      "token:  [S1] hmm \n",
      "38.33281326293945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] \n",
      "7.081153392791748\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] Could you help in any way or not? \n",
      "23.29381561279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Could you help in any way or not? \n",
      "token:  [MOD] t it's very different from the other two. \n",
      "55.682090759277344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] t it's very different from the other two. \n",
      "token:  [S1] Alright. \n",
      "29.852174758911133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright. \n",
      "token:  [MOD] And maybe no \n",
      "267.720458984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And maybe no \n",
      "token:  [S2] Ok. \n",
      "57.02876281738281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] strings. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347.1676025390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] strings. \n",
      "token:  [S2] Ok, no strings. \n",
      "55.88539123535156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok, no strings. \n",
      "token:  [S1] No strings. Ok. Like something with percussion or? \n",
      "56.911598205566406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No strings. Ok. Like something with percussion or? \n",
      "token:  [MOD] Could be. \n",
      "37.2971076965332\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Could be. \n",
      "token:  [S2] Timpani? or Maybe piano? But it's not they're not usually \n",
      "111.02336883544922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Timpani? or Maybe piano? But it's not they're not usually \n",
      "token:  [S1] y yea h \n",
      "150.6965789794922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] y yea h \n",
      "token:  [S2] used in orchestras hm without strings. Is it with wood like wind? Maybe trumpet? \n",
      "184.69215393066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] used in orchestras hm without strings. Is it with wood like wind? Maybe trumpet? \n",
      "token:  [S1] hmm \n",
      "20.554601669311523\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] No. \n",
      "86.20951080322266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S2] Not trumpet. \n",
      "253.09884643554688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Not trumpet. \n",
      "token:  [MOD] It's not trumpet. No. \n",
      "19.47736167907715\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's not trumpet. No. \n",
      "token:  [S2] hm \n",
      "67.95066833496094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm \n",
      "token:  [S1] Clarinet? \n",
      "41.84407424926758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Clarinet? \n",
      "token:  [MOD] No. \n",
      "35.55912399291992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S1] No it's different from the other two you said. yeah Harp? \n",
      "82.29432678222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No it's different from the other two you said. yeah Harp? \n",
      "token:  [S2] Yeah. No? \n",
      "10.11290168762207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. No? \n",
      "token:  [MOD] No. \n",
      "18.75640869140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S1] No. \n",
      "17.284198760986328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No. \n",
      "token:  [MOD] No this is a diffi \n",
      "211.61212158203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No this is a diffi \n",
      "token:  [S2] Trombone? \n",
      "115.55557250976562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Trombone? \n",
      "token:  [MOD] cult one actually the the this question I think it's difficult. \n",
      "335.9344482421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] cult one actually the the this question I think it's difficult. \n",
      "token:  [S1] Oboe? \n",
      "90.44329071044922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oboe? \n",
      "token:  [S2] Yeah. \n",
      "6.2291131019592285\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] No. \n",
      "23.841318130493164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S1] I said something not common let's see \n",
      "124.55989074707031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I said something not common let's see \n",
      "token:  [S2] Viola? \n",
      "30.88543701171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Viola? \n",
      "token:  [MOD] No. \n",
      "44.71867370605469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S2] Ok. \n",
      "72.99781799316406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] So you have \n",
      "72.57080078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have \n",
      "token:  [S2] I'm trying to stick to the layout of the orchestra now. \n",
      "60.97349548339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'm trying to stick to the layout of the orchestra now. \n",
      "token:  [S1] yeah \n",
      "24.042146682739258\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] You have vio lin you have cello \n",
      "358.97735595703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have vio lin you have cello \n",
      "token:  [S2] Yeah. \n",
      "51.270545959472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] and the last one \n",
      "98.1549072265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and the last one \n",
      "token:  [S1] violin cello \n",
      "172.0478057861328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] violin cello \n",
      "token:  [S2] \n",
      "6.63739538192749\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] Trumpet? \n",
      "46.901153564453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Trumpet? \n",
      "token:  [S2] We've alr no. \n",
      "77.87268829345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] We've alr no. \n",
      "token:  [S1] Saxophone you said trump no . \n",
      "244.6654510498047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Saxophone you said trump no . \n",
      "token:  [S2] Trombone? \n",
      "13.325413703918457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Trombone? \n",
      "token:  [MOD] You need to \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.02225494384766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You need to \n",
      "token:  [S2] Tuba? \n",
      "160.02427673339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Tuba? \n",
      "token:  [MOD] come up with the last one. \n",
      "53.68950271606445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] come up with the last one. \n",
      "token:  [S1] No? \n",
      "38.23398208618164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No? \n",
      "token:  [S2] Oh we need to come up with the last one. \n",
      "6.447992324829102\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh we need to come up with the last one. \n",
      "token:  [MOD] Yeah. \n",
      "30.46751594543457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] yes. Otherwise this would never end. it could go forever hm hm \n",
      "61.96083450317383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yes. Otherwise this would never end. it could go forever hm hm \n",
      "token:  [S2] \n",
      "8.56412124633789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] No strings \n",
      "331.8567199707031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No strings \n",
      "token:  [S2] No strings. \n",
      "37.30926513671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No strings. \n",
      "token:  [MOD] very different from the \n",
      "188.9279022216797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very different from the \n",
      "token:  [S1] Is it f \n",
      "122.8035659790039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Is it f \n",
      "token:  [MOD] other two. \n",
      "686.154052734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] other two. \n",
      "token:  [S1] ah \n",
      "182.03211975097656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah \n",
      "token:  [MOD] No you don't use your \n",
      "85.1216812133789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No you don't use your \n",
      "token:  [S2] you don't use your mouth \n",
      "26.359251022338867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] you don't use your mouth \n",
      "token:  [MOD] mouth No. \n",
      "190.74310302734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mouth No. \n",
      "token:  [S1] alr ight \n",
      "102.42402648925781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] alr ight \n",
      "token:  [S2] You don't use your mouth ok. \n",
      "24.151535034179688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You don't use your mouth ok. \n",
      "token:  [S1] So I believe it's something \n",
      "31.77593994140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So I believe it's something \n",
      "token:  [S2] Do you hit it? \n",
      "20.581058502197266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Do you hit it? \n",
      "token:  [S1] Yeah s I thi I but \n",
      "82.42349243164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah s I thi I but \n",
      "token:  [MOD] So think of an instrument that you might hit it yeah. \n",
      "114.32941436767578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So think of an instrument that you might hit it yeah. \n",
      "token:  [S2] You might hit it. the drums? \n",
      "36.15726852416992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You might hit it. the drums? \n",
      "token:  [MOD] Yeah. \n",
      "47.81650161743164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] in a s \n",
      "105.39918518066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] in a s \n",
      "token:  [MOD] It's the drum. \n",
      "159.5330047607422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's the drum. \n",
      "token:  [S2] Oh ok. I I did say \n",
      "99.74527740478516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh ok. I I did say \n",
      "token:  [S1] Ok. \n",
      "9.673510551452637\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] tim \n",
      "66.07803344726562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] tim \n",
      "token:  [S1] Yeah. \n",
      "15.68311595916748\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] timpani before which \n",
      "117.81733703613281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] timpani before which \n",
      "token:  [S1] yeah \n",
      "31.049474716186523\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] is I \n",
      "29.810218811035156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] is I \n",
      "token:  [MOD] oh \n",
      "230.72125244140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] oh \n",
      "token:  [S2] ok I know yeah it's ok yeah. \n",
      "75.66295623779297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok I know yeah it's ok yeah. \n",
      "token:  [MOD] So can you \n",
      "85.88163757324219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So can you \n",
      "token:  [S1] Alright. \n",
      "66.16978454589844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright. \n",
      "token:  [MOD] rank them now? \n",
      "183.68214416503906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] rank them now? \n",
      "token:  [S2] Violin. \n",
      "142.02528381347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violin. \n",
      "token:  [S1] Ok. Violin. Then cello \n",
      "45.142181396484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. Violin. Then cello \n",
      "token:  [S2] Yeah \n",
      "14.538104057312012\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [S1] and then drum \n",
      "125.77847290039062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and then drum \n",
      "token:  [S2] then drums yeah. \n",
      "46.05180740356445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] then drums yeah. \n",
      "token:  [MOD] Yeah? You both agree on that? \n",
      "51.98441696166992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? You both agree on that? \n",
      "token:  [S2] Yeah. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.195422172546387\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Yes. \n",
      "4.998136520385742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yes. \n",
      "token:  [MOD] That's correct \n",
      "66.80220031738281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's correct \n",
      "token:  [S1] ok well done guys. \n",
      "75.72529602050781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok well done guys. \n",
      "token:  [MOD] So we have the third question which is the last one. \n",
      "32.564903259277344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So we have the third question which is the last one. \n",
      "token:  [S1] mhmm \n",
      "45.33793640136719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] Can you name something that people cut? \n",
      "97.83472442626953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you name something that people cut? \n",
      "token:  [S1] Vegetables. \n",
      "28.557331085205078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Vegetables. \n",
      "token:  [S2] Bread? \n",
      "15.041987419128418\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Bread? \n",
      "token:  [S1] Not neither of them is correct I feel. \n",
      "67.01701354980469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Not neither of them is correct I feel. \n",
      "token:  [MOD] You have to work toge \n",
      "299.9849853515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have to work toge \n",
      "token:  [S1] ok \n",
      "118.72492980957031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] ther you need to come up \n",
      "151.97962951660156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ther you need to come up \n",
      "token:  [S2] Top three things \n",
      "85.61941528320312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Top three things \n",
      "token:  [MOD] with this together Don't look at me now for the answers. \n",
      "107.21372985839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] with this together Don't look at me now for the answers. \n",
      "token:  [S1] Smoking? \n",
      "84.0947265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Smoking? \n",
      "token:  [S2] Ok. Top three things that people cut. \n",
      "45.75986862182617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. Top three things that people cut. \n",
      "token:  [S1] hmm hm I agree with bread. \n",
      "50.34379959106445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm hm I agree with bread. \n",
      "token:  [S2] Yeah. \n",
      "9.754100799560547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] hmm Meat? \n",
      "53.72731399536133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm Meat? \n",
      "token:  [S2] hm Meat yeah. That would probably be pretty high up there I'd say. \n",
      "19.817716598510742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm Meat yeah. That would probably be pretty high up there I'd say. \n",
      "token:  [S1] Ok. \n",
      "12.332817077636719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] And the n \n",
      "51.961490631103516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] And the n \n",
      "token:  [S1] hmm \n",
      "83.9823226928711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] Think of something both men and women cut. And maybe men cut it more often. \n",
      "60.932342529296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think of something both men and women cut. And maybe men cut it more often. \n",
      "token:  [S2] Wood. \n",
      "106.59934997558594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Wood. \n",
      "token:  [S1] \n",
      "9.378791809082031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] No? Chopping wood? Like the No ok. \n",
      "105.4447250366211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No? Chopping wood? Like the No ok. \n",
      "token:  [S1] \n",
      "11.659493446350098\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] Men and women cut. hm \n",
      "18.13920021057129\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Men and women cut. hm \n",
      "token:  [MOD] Men and women. \n",
      "26.39044189453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Men and women. \n",
      "token:  [S1] Hair. \n",
      "56.60860061645508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hair. \n",
      "token:  [S2] ! But that's probably a good one yeah. \n",
      "44.068634033203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ! But that's probably a good one yeah. \n",
      "token:  [S1] Yeah. \n",
      "6.85091495513916\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Yeah I'd say \n",
      "16.453453063964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah I'd say \n",
      "token:  [S1] Ok \n",
      "25.86188316345215\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok \n",
      "token:  [S2] it's definitely from her description \n",
      "66.32008361816406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] it's definitely from her description \n",
      "token:  [S1] alright \n",
      "21.158767700195312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] alright \n",
      "token:  [S2] yeah yeah yeah men more often yeah \n",
      "46.42518997192383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah yeah yeah men more often yeah \n",
      "token:  [S1] So we have you need us to \n",
      "64.03849792480469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So we have you need us to \n",
      "token:  [S2] bread \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.69911193847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] bread \n",
      "token:  [S1] ra ah we don't will you confirm which are the correct ones? \n",
      "80.2726058959961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ra ah we don't will you confirm which are the correct ones? \n",
      "token:  [MOD] Which ones do you have now? \n",
      "25.604419708251953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Which ones do you have now? \n",
      "token:  [S1] So we have \n",
      "47.068695068359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So we have \n",
      "token:  [S2] bread meat \n",
      "131.82470703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] bread meat \n",
      "token:  [S1] hair and \n",
      "31.292430877685547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hair and \n",
      "token:  [S2] hair \n",
      "9.18663215637207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair \n",
      "token:  [S1] hair. \n",
      "11.380743026733398\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hair. \n",
      "token:  [S2] yeah. \n",
      "8.160933494567871\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah. \n",
      "token:  [MOD] Ok you found two. \n",
      "85.34098052978516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok you found two. \n",
      "token:  [S2] Ok. \n",
      "18.451608657836914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] The vegetables? \n",
      "45.739871978759766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The vegetables? \n",
      "token:  [MOD] Which are Which are hair and \n",
      "460.85736083984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Which are Which are hair and \n",
      "token:  [S1] ok \n",
      "110.05599212646484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] meat. \n",
      "278.83465576171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] meat. \n",
      "token:  [S1] Alright, hair and meat. \n",
      "60.477046966552734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright, hair and meat. \n",
      "token:  [MOD] Now you need one more. \n",
      "36.82062530517578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Now you need one more. \n",
      "token:  [S2] hm \n",
      "65.77417755126953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm \n",
      "token:  [MOD] And it doesn't have to do with \n",
      "50.27640151977539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And it doesn't have to do with \n",
      "token:  [S1] Nails? \n",
      "131.01712036132812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Nails? \n",
      "token:  [MOD] food. It doesn't have to do with food. \n",
      "41.3228874206543\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] food. It doesn't have to do with food. \n",
      "token:  [S1] Ok. \n",
      "29.234577178955078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] hm \n",
      "19.865467071533203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm \n",
      "token:  [S1] Nails? Ah yeah \n",
      "71.29241180419922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Nails? Ah yeah \n",
      "token:  [S2] hmm I don't know. hm \n",
      "14.213067054748535\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm I don't know. hm \n",
      "token:  [S1] hmm \n",
      "8.493637084960938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] I can't really think of anything else. Yeah. \n",
      "8.52330493927002\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I can't really think of anything else. Yeah. \n",
      "token:  [MOD] You see it a lot. \n",
      "22.30083656311035\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You see it a lot. \n",
      "token:  [S2] You see it \n",
      "30.496824264526367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You see it \n",
      "token:  [MOD] In every \n",
      "224.70057678222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] In every \n",
      "token:  [S2] a lot. \n",
      "163.6151580810547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] a lot. \n",
      "token:  [MOD] day basis. You say Can you cut a \n",
      "516.0440063476562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] day basis. You say Can you cut a \n",
      "token:  [S2] Grass? \n",
      "234.5787353515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Grass? \n",
      "token:  [MOD] piece of \n",
      "193.53070068359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] piece of \n",
      "token:  [S2] Grass maybe? \n",
      "368.5176696777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Grass maybe? \n",
      "token:  [MOD] hm \n",
      "106.21682739257812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S2] No? \n",
      "53.343177795410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No? \n",
      "token:  [S1] hmm \n",
      "12.126876831054688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] What do you think? \n",
      "17.715770721435547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] What do you think? \n",
      "token:  [S1] So you said you can you repeat? \n",
      "55.07810974121094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So you said you can you repeat? \n",
      "token:  [MOD] Yeah, you can see it quite often at an everyday \n",
      "113.3752212524414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah, you can see it quite often at an everyday \n",
      "token:  [S1] ok \n",
      "179.69154357910156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] basis and you can say well can you cut a piece of \n",
      "184.4447784423828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] basis and you can say well can you cut a piece of \n",
      "token:  [S1] Cake? \n",
      "107.38681030273438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cake? \n",
      "token:  [MOD] this It doesn't have to do with food. \n",
      "52.16177749633789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] this It doesn't have to do with food. \n",
      "token:  [S1] Alright. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.87508010864258\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright. \n",
      "token:  [S2] Ok. \n",
      "5.4255452156066895\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] piece of what \n",
      "48.063316345214844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] piece of what \n",
      "token:  [S2] hm \n",
      "19.07562255859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm \n",
      "token:  [S1] Fabric? \n",
      "69.68670654296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Fabric? \n",
      "token:  [S2] ok cut So we see it everyday like \n",
      "201.4953155517578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok cut So we see it everyday like \n",
      "token:  [MOD] Almost everyday it's something very common. \n",
      "93.39008331298828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Almost everyday it's something very common. \n",
      "token:  [S2] hmm \n",
      "62.607208251953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] You might need it to write on. \n",
      "104.92431640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You might need it to write on. \n",
      "token:  [S2] Oh paper. \n",
      "78.69732666015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh paper. \n",
      "token:  [S1] mhmm yeah \n",
      "31.62053871154785\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm yeah \n",
      "token:  [S2] Maybe paper? \n",
      "39.5104866027832\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Maybe paper? \n",
      "token:  [S1] Yeah. \n",
      "7.38340425491333\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Yeah. \n",
      "4.441160202026367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Yeah do you agree? Yeah that's paper. \n",
      "80.74992370605469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah do you agree? Yeah that's paper. \n",
      "token:  [S1] Alright \n",
      "53.11381912231445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright \n",
      "token:  [S2] Ok So you have the thr the \n",
      "67.35911560058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok So you have the thr the \n",
      "token:  [MOD] three answers. You have \n",
      "110.3294906616211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] three answers. You have \n",
      "token:  [S1] Ok. \n",
      "58.54962921142578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] hair you have \n",
      "533.998291015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hair you have \n",
      "token:  [S2] mhmm \n",
      "34.34010696411133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] meat and paper. \n",
      "322.93792724609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] meat and paper. \n",
      "token:  [S1] Meat. Ok. \n",
      "39.42330551147461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Meat. Ok. \n",
      "token:  [MOD] So can you rank them please? \n",
      "69.97199249267578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So can you rank them please? \n",
      "token:  [S1] I think I 'd like the order you mentioned \n",
      "51.89368438720703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think I 'd like the order you mentioned \n",
      "token:  [S2] yeah yeah \n",
      "18.772043228149414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah yeah \n",
      "token:  [S1] because ok paper it's kind yeah \n",
      "155.2504425048828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] because ok paper it's kind yeah \n",
      "token:  [S2] No I'd agree. \n",
      "23.26045036315918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No I'd agree. \n",
      "token:  [MOD] So the \n",
      "132.71380615234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So the \n",
      "token:  [S1] Yeah. \n",
      "98.712890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] first one? \n",
      "110.17855072021484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] first one? \n",
      "token:  [S2] Yeah. \n",
      "39.83279800415039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Hair \n",
      "99.90939331054688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hair \n",
      "token:  [S2] Hair meat \n",
      "24.55575180053711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair meat \n",
      "token:  [MOD] mhmm \n",
      "67.71206665039062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] meat paper. \n",
      "270.8749694824219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat paper. \n",
      "token:  [S2] Yeah. Ah! Almost there. \n",
      "28.57200050354004\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. Ah! Almost there. \n",
      "token:  [MOD] The first one is hel hair and then paper and then meat. \n",
      "125.32122039794922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] The first one is hel hair and then paper and then meat. \n",
      "token:  [S1] Alright. \n",
      "31.51789665222168\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright. \n",
      "token:  [S2] Alright. \n",
      "4.223769664764404\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Alright. \n",
      "token:  [MOD] But well done guys, you did great! \n",
      "45.57356643676758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But well done guys, you did great! \n",
      "token:  [S1] Thank you . \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.477603912353516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Thank you . \n",
      "token:  [MOD] So that was it. I hope you enjoyed it. \n",
      "16.68807601928711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So that was it. I hope you enjoyed it. \n",
      "token:  [S1] Yes. \n",
      "15.044355392456055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yes. \n",
      "token:  [S2] Yeah. \n",
      "5.793904781341553\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Thanks for coming again. \n",
      "54.24306869506836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Thanks for coming again. \n",
      "token:  [S2] It was a lot of fun. Thank you very much.\n",
      "9.81164836883545\n",
      "MOD : 135.2597967147827\n",
      "S1 : 64.47907392567602\n",
      "S2 : 56.265954314411935\n",
      "speech transcription_Transcriber/S10.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Ok. So I would like us to play a quiz. Ok? I'm going to ask you three questions that were posed to a group of one hundred people and I would like you to guess the most popular answers to these questions. And then I will ask you to talk to each other and decide upon the ranking in terms of popularity. Ok? So I might just ask questions like ah what do you usually use to transfer patients you know in a hospital you wou might say an ambulance, a patient's eh bed or a wheelchair. Alright? And then I will ask you to tell me which one was the most popular answer so \n",
      "23.600143432617188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok. So I would like us to play a quiz. Ok? I'm going to ask you three questions that were posed to a group of one hundred people and I would like you to guess the most popular answers to these questions. And then I will ask you to talk to each other and decide upon the ranking in terms of popularity. Ok? So I might just ask questions like ah what do you usually use to transfer patients you know in a hospital you wou might say an ambulance, a patient's eh bed or a wheelchair. Alright? And then I will ask you to tell me which one was the most popular answer so \n",
      "token:  [S1] Mhmm. \n",
      "26.681028366088867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Mhmm. \n",
      "token:  [MOD] Ah that's all really. Do you have any questions? \n",
      "30.153392791748047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ah that's all really. Do you have any questions? \n",
      "token:  [S2] No that \n",
      "131.4713592529297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No that \n",
      "token:  [S1] No. \n",
      "13.136515617370605\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No. \n",
      "token:  [S2] seems \n",
      "95.96521759033203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] seems \n",
      "token:  [MOD] No? \n",
      "146.90298461914062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No? \n",
      "token:  [S2] fi \n",
      "217.8566436767578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] fi \n",
      "token:  [S1] yeah \n",
      "28.807939529418945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] ne. \n",
      "21.898088455200195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ne. \n",
      "token:  [MOD] Ok right. So Let's go for the first question now I would like you to name public places where people y wou we you would be more likely to catch the flu or a cold. So public places where you would catch a cold or a flu bug. \n",
      "43.47980880737305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok right. So Let's go for the first question now I would like you to name public places where people y wou we you would be more likely to catch the flu or a cold. So public places where you would catch a cold or a flu bug. \n",
      "token:  [S2] Ok well ah school \n",
      "150.95460510253906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok well ah school \n",
      "token:  [S1] Yeah. \n",
      "10.690902709960938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Very good you got the \n",
      "119.03499603271484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good you got the \n",
      "token:  [S1] ah \n",
      "143.7609100341797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah \n",
      "token:  [MOD] one yeah . \n",
      "454.6096496582031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] one yeah . \n",
      "token:  [S1] Oh like are we supposed to collaborate with this \n",
      "91.45658874511719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh like are we supposed to collaborate with this \n",
      "token:  [MOD] Yep yes. \n",
      "124.10575866699219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yep yes. \n",
      "token:  [S2] together? ok \n",
      "158.5809326171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] together? ok \n",
      "token:  [S1] ok yeah school is one probably like a nursing home or like what'd you think yeah like carehome? \n",
      "100.11603546142578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok yeah school is one probably like a nursing home or like what'd you think yeah like carehome? \n",
      "token:  [S2] Yeah that's a good one yeah a hospital as well. \n",
      "10.678154945373535\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah that's a good one yeah a hospital as well. \n",
      "token:  [S1] Yeah \n",
      "15.304373741149902\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah \n",
      "token:  [MOD] That's the \n",
      "51.44942092895508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's the \n",
      "token:  [S1] like a yeah \n",
      "151.01329040527344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like a yeah \n",
      "token:  [MOD] second one \n",
      "141.2401123046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] second one \n",
      "token:  [S1] yeah. \n",
      "52.78317642211914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah. \n",
      "token:  [MOD] you found the second one yes. So you n eed to find one more. \n",
      "54.945953369140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you found the second one yes. So you n eed to find one more. \n",
      "token:  [S2] Maybe public transport? \n",
      "96.48291778564453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Maybe public transport? \n",
      "token:  [MOD] hmm \n",
      "87.91423797607422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] Yeah. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.03059387207031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Can you give \n",
      "94.77132415771484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you give \n",
      "token:  [S1] ah \n",
      "177.69650268554688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah \n",
      "token:  [MOD] a specific examples? \n",
      "326.881103515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] a specific examples? \n",
      "token:  [S1] I'd guess a \n",
      "67.12316131591797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'd guess a \n",
      "token:  [S2] bus it ten \n",
      "175.3490447998047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] bus it ten \n",
      "token:  [S1] bus \n",
      "14.592778205871582\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] bus \n",
      "token:  [S2] ds to be pretty confined \n",
      "130.13275146484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ds to be pretty confined \n",
      "token:  [MOD] Sure, but that was not one of the popular most popular \n",
      "74.00286865234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Sure, but that was not one of the popular most popular \n",
      "token:  [S2] Ok. \n",
      "61.18601989746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] answers. Yeah. \n",
      "119.89179229736328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] answers. Yeah. \n",
      "token:  [S1] Ok. Is it not like what I've \n",
      "58.20931625366211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. Is it not like what I've \n",
      "token:  [MOD] It is a means of transport \n",
      "140.01393127441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It is a means of transport \n",
      "token:  [S1] like ot's a public tran \n",
      "304.4774475097656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like ot's a public tran \n",
      "token:  [MOD] ation \n",
      "142.39315795898438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ation \n",
      "token:  [S1] Ok. \n",
      "51.25048828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] but it's not the bus. \n",
      "55.35844421386719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] but it's not the bus. \n",
      "token:  [S1] \n",
      "25.114704132080078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] Guess ah trains \n",
      "232.20416259765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Guess ah trains \n",
      "token:  [S1] Train yeah \n",
      "35.37226867675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Train yeah \n",
      "token:  [S2] planes \n",
      "41.58060073852539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] planes \n",
      "token:  [MOD] That's it planes ok so you got the \n",
      "116.29879760742188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's it planes ok so you got the \n",
      "token:  [S2] oh ok \n",
      "82.54439544677734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh ok \n",
      "token:  [MOD] three now so \n",
      "259.8800354003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] three now so \n",
      "token:  [S1] mhmm \n",
      "39.09315490722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] what would you think about their ranking? Which one was the most popular answer? \n",
      "53.66072082519531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] what would you think about their ranking? Which one was the most popular answer? \n",
      "token:  [S1] I'd say hospital or what would \n",
      "82.76305389404297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'd say hospital or what would \n",
      "token:  [S2] It's that people would associate hospital more with the flu. \n",
      "26.623239517211914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It's that people would associate hospital more with the flu. \n",
      "token:  [S1] Yeah. \n",
      "7.505204200744629\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Maybe it's a bias that they would I mean people would be less likely to be in a hospital than to be in school perhaps or to be in some forms of public transp ort. \n",
      "49.616886138916016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Maybe it's a bias that they would I mean people would be less likely to be in a hospital than to be in school perhaps or to be in some forms of public transp ort. \n",
      "token:  [S1] Yeah that's true yeah. So it's just one two three kind of what we think? \n",
      "28.78412437438965\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah that's true yeah. So it's just one two three kind of what we think? \n",
      "token:  [MOD] Yeah. Yep. I can give you \n",
      "38.31747817993164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. Yep. I can give you \n",
      "token:  [S1] Oh \n",
      "95.7556381225586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh \n",
      "token:  [MOD] my feedback at the end. \n",
      "132.4340057373047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] my feedback at the end. \n",
      "token:  [S1] ok. So what what do you think like if you were to do one two three. \n",
      "39.40953063964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok. So what what do you think like if you were to do one two three. \n",
      "token:  [S2] And we need to think about what one hundred people answered. \n",
      "31.711681365966797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] And we need to think about what one hundred people answered. \n",
      "token:  [MOD] Yes what came first to their mind, to most people's minds. \n",
      "53.258365631103516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes what came first to their mind, to most people's minds. \n",
      "token:  [S2] Ok. \n",
      "33.863216400146484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] Yeah. \n",
      "36.711395263671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] I would guess ho spital \n",
      "234.640380859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I would guess ho spital \n",
      "token:  [S1] Hospital I would have so hospi \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143.1768798828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hospital I would have so hospi \n",
      "token:  [MOD] mhmm \n",
      "160.15786743164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] tal first yeah. probably then school cause I wouldn't immediately jump to public transport \n",
      "424.8908386230469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] tal first yeah. probably then school cause I wouldn't immediately jump to public transport \n",
      "token:  [S2] Yeah ha. \n",
      "41.50859832763672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah ha. \n",
      "token:  [S1] Yeah. \n",
      "6.308543682098389\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Ah then \n",
      "36.35565185546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah then \n",
      "token:  [S1] But mine would be that \n",
      "29.804658889770508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But mine would be that \n",
      "token:  [S2] airplanes \n",
      "79.30257415771484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] airplanes \n",
      "token:  [S1] that that's my first that one anyway it would be the hospital then the school then the plane but what what do you think? \n",
      "58.71920394897461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] that that's my first that one anyway it would be the hospital then the school then the plane but what what do you think? \n",
      "token:  [S2] Yeah, I'd put the hospital first \n",
      "14.462844848632812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah, I'd put the hospital first \n",
      "token:  [S1] mhmm \n",
      "5.692026138305664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [S2] and then yeah it seems like a reasonable order to me. \n",
      "38.861976623535156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and then yeah it seems like a reasonable order to me. \n",
      "token:  [S1] Ok. \n",
      "11.749128341674805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Is that your final ranking yeah? Ok well I'm afraid you got the first two wrong because \n",
      "72.04698944091797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Is that your final ranking yeah? Ok well I'm afraid you got the first two wrong because \n",
      "token:  [S1] Really? \n",
      "40.64056396484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Really? \n",
      "token:  [MOD] yeah most people went for the school first and then hospital and the airplane came last. Alright? Ok. \n",
      "151.58358764648438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah most people went for the school first and then hospital and the airplane came last. Alright? Ok. \n",
      "token:  [S1] Ok. \n",
      "12.726812362670898\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Ok? Good job! We're going \n",
      "66.1196060180664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok? Good job! We're going \n",
      "token:  [S2] Ok. \n",
      "36.74546813964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] Moving on to the second one. I would like you to name a musical instrument in a symphony orchestra. \n",
      "28.345157623291016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Moving on to the second one. I would like you to name a musical instrument in a symphony orchestra. \n",
      "token:  [S1] V violin was my first \n",
      "132.66864013671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] V violin was my first \n",
      "token:  [S2] Yeah that was what \n",
      "31.44300079345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah that was what \n",
      "token:  [MOD] Yes \n",
      "301.0831298828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes \n",
      "token:  [S2] first came came \n",
      "323.5572509765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] first came came \n",
      "token:  [MOD] yeah \n",
      "187.66281127929688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S2] my head as well \n",
      "68.70763397216797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] my head as well \n",
      "token:  [S1] oh yeah \n",
      "8.057266235351562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh yeah \n",
      "token:  [S2] yeah. \n",
      "9.259818077087402\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah. \n",
      "token:  [MOD] Great very good yeah, that's it. \n",
      "50.45597457885742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Great very good yeah, that's it. \n",
      "token:  [S1] Cello ? \n",
      "114.49624633789062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cello ? \n",
      "token:  [S2] Yeah \n",
      "12.293160438537598\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [MOD] Very good \n",
      "62.96851348876953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good \n",
      "token:  [S2] that's a \n",
      "78.1584701538086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] that's a \n",
      "token:  [MOD] yes \n",
      "359.0754699707031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes \n",
      "token:  [S2] cello \n",
      "105.43809509277344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cello \n",
      "token:  [MOD] yes, that was another one. \n",
      "68.66643524169922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes, that was another one. \n",
      "token:  [S1] \n",
      "26.861339569091797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] Double bass. \n",
      "50.80364227294922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Double bass. \n",
      "token:  [MOD] Nope. \n",
      "61.88760757446289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Nope. \n",
      "token:  [S2] A bit more So \n",
      "153.1935272216797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A bit more So \n",
      "token:  [S1] s I'd say w would be like some sort of like a flute \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.15168380737305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] s I'd say w would be like some sort of like a flute \n",
      "token:  [S2] The flute? \n",
      "9.540661811828613\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The flute? \n",
      "token:  [S1] yeah \n",
      "21.661882400512695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] hmm Not really \n",
      "112.3855972290039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm Not really \n",
      "token:  [S2] Is it a wind instrument? \n",
      "51.45106506347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Is it a wind instrument? \n",
      "token:  [MOD] not really. It's something that you would find in all sorts of you know even in in live concert really \n",
      "90.4664535522461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] not really. It's something that you would find in all sorts of you know even in in live concert really \n",
      "token:  [S2] Pe percussion? \n",
      "617.6820678710938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Pe percussion? \n",
      "token:  [S1] it dr yeah \n",
      "135.3136749267578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it dr yeah \n",
      "token:  [MOD] Nope. Sonething very basic that allows you to you that gives you the rhythm. \n",
      "153.5959014892578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Nope. Sonething very basic that allows you to you that gives you the rhythm. \n",
      "token:  [S1] The rhythm. \n",
      "25.905006408691406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The rhythm. \n",
      "token:  [S2] The rhythm? hmm \n",
      "19.500036239624023\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The rhythm? hmm \n",
      "token:  [MOD] hmm You ca it's usually in the background. Doesn't have a prominent role \n",
      "111.7157974243164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm You ca it's usually in the background. Doesn't have a prominent role \n",
      "token:  [S1] uh wow \n",
      "118.22377014160156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] uh wow \n",
      "token:  [S2] Well in a typical band you could have \n",
      "59.142250061035156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Well in a typical band you could have \n",
      "token:  [S1] mhmm \n",
      "16.079282760620117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [S2] guit a r, drums \n",
      "159.46014404296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] guit a r, drums \n",
      "token:  [S1] keyboard yeah \n",
      "61.02043914794922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] keyboard yeah \n",
      "token:  [MOD] That's it. \n",
      "28.80554962158203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's it. \n",
      "token:  [S1] oh the drums \n",
      "153.8311767578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh the drums \n",
      "token:  [S2] ok \n",
      "12.248620986938477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] yeah \n",
      "9.397981643676758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] ok? So what would be your ranking then? \n",
      "59.44205093383789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok? So what would be your ranking then? \n",
      "token:  [S1] f violin like we both \n",
      "679.254638671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] f violin like we both \n",
      "token:  [S2] yeah \n",
      "13.185623168945312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] thought that fi rst \n",
      "54.843971252441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] thought that fi rst \n",
      "token:  [MOD] hmm \n",
      "288.1289978027344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] yeah f w I don't know it's hard to say between drums and cello \n",
      "74.63076782226562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah f w I don't know it's hard to say between drums and cello \n",
      "token:  [S2] I'd say cello was \n",
      "26.192026138305664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'd say cello was \n",
      "token:  [S1] yeah \n",
      "19.52435302734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] second least \n",
      "45.41481018066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] second least \n",
      "token:  [S1] yeah \n",
      "17.011096954345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] to my mind that's what would pop in first \n",
      "51.21441650390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] to my mind that's what would pop in first \n",
      "token:  [S1] yeah we we both kind of thought like that anyway yeah. I think that would be our ranking as \n",
      "49.58476638793945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah we we both kind of thought like that anyway yeah. I think that would be our ranking as \n",
      "token:  [MOD] mhmm \n",
      "103.18772888183594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] well. \n",
      "55.740718841552734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] well. \n",
      "token:  [MOD] Ok? Is that your \n",
      "117.84880828857422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok? Is that your \n",
      "token:  [S1] ok \n",
      "107.81133270263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] final decision, the violin, the cello and then the drum. Yeah? \n",
      "125.8354721069336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] final decision, the violin, the cello and then the drum. Yeah? \n",
      "token:  [S1] I'm happy with that \n",
      "32.220375061035156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'm happy with that \n",
      "token:  [S2] Yeah \n",
      "9.399297714233398\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [S1] yeah \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.964885234832764\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] it see ms reasonable. \n",
      "162.03762817382812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] it see ms reasonable. \n",
      "token:  [MOD] Well done \n",
      "184.70289611816406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well done \n",
      "token:  [S1] yeah \n",
      "58.649410247802734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] that's it you found it. \n",
      "53.33615493774414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] that's it you found it. \n",
      "token:  [S2] Well \n",
      "91.5318832397461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Well \n",
      "token:  [S1] Yeah. \n",
      "11.10364818572998\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Well done. \n",
      "7.689731121063232\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Well done. \n",
      "token:  [S1] Good job. \n",
      "4.954564571380615\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Good job. \n",
      "token:  [MOD] Great. So moving on to the third question I would like you to name something that people cut. \n",
      "47.559322357177734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Great. So moving on to the third question I would like you to name something that people cut. \n",
      "token:  [S2] Possible \n",
      "156.50167846679688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Possible \n",
      "token:  [S1] See I s \n",
      "92.06258392333984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] See I s \n",
      "token:  [S2] is bread \n",
      "100.63697814941406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] is bread \n",
      "token:  [S1] yeah Well I study like nutrition stuff so I thought a lot of things but \n",
      "88.44955444335938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah Well I study like nutrition stuff so I thought a lot of things but \n",
      "token:  [MOD] hmm \n",
      "108.24195861816406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] might as probably like v vegetable \n",
      "485.0931396484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] might as probably like v vegetable \n",
      "token:  [MOD] You're thinking in terms of food yes, you're very close thi nk about a different category of food though \n",
      "79.92439270019531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You're thinking in terms of food yes, you're very close thi nk about a different category of food though \n",
      "token:  [S1] Ok. \n",
      "55.97206497192383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] Well I would think of you know of slice of bread \n",
      "42.52861404418945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Well I would think of you know of slice of bread \n",
      "token:  [S1] mhmm \n",
      "18.859704971313477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] mhmm \n",
      "12.629229545593262\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S2] or chees \n",
      "429.86834716796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] or chees \n",
      "token:  [MOD] mhmm \n",
      "107.8963394165039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] or meat yeah \n",
      "250.3709259033203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] or meat yeah \n",
      "token:  [MOD] That's it \n",
      "48.028663635253906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's it \n",
      "token:  [S1] ok \n",
      "44.24370574951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] meat. \n",
      "278.83465576171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] meat. \n",
      "token:  [S1] ok \n",
      "73.23238372802734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] Meat yeah that's one of the an wers. \n",
      "210.1302947998047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Meat yeah that's one of the an wers. \n",
      "token:  [S1] ok meat and then \n",
      "98.01197052001953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok meat and then \n",
      "token:  [S2] Eh timber? \n",
      "81.42749786376953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Eh timber? \n",
      "token:  [MOD] Nope. \n",
      "41.85154724121094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Nope. \n",
      "token:  [S1] god \n",
      "141.9090576171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] god \n",
      "token:  [MOD] Try again. Think about your everyday life you know \n",
      "89.51192474365234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Try again. Think about your everyday life you know \n",
      "token:  [S2] Ok so fingernails, toenails. \n",
      "50.559410095214844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok so fingernails, toenails. \n",
      "token:  [MOD] Yeah that's a good answer but it wasn't one of the po most popular answers really. \n",
      "47.91774368286133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah that's a good answer but it wasn't one of the po most popular answers really. \n",
      "token:  [S1] Ok grass? \n",
      "125.16593933105469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok grass? \n",
      "token:  [MOD] Nope. \n",
      "42.54203796386719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Nope. \n",
      "token:  [S2] Ah people get their hair cut. \n",
      "110.70169067382812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah people get their hair cut. \n",
      "token:  [MOD] Exactly very good \n",
      "318.5830078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly very good \n",
      "token:  [S1] Yeah that's good. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.780399322509766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah that's good. \n",
      "token:  [MOD] yes. \n",
      "42.43696975708008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes. \n",
      "token:  [S2] So it's two. \n",
      "38.928680419921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So it's two. \n",
      "token:  [MOD] mhmm So one more. \n",
      "51.223819732666016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm So one more. \n",
      "token:  [S1] It's not another food item \n",
      "67.88472747802734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] It's not another food item \n",
      "token:  [MOD] No, no \n",
      "48.74916076660156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No, no \n",
      "token:  [S1] so no it's not. \n",
      "37.88143539428711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so no it's not. \n",
      "token:  [MOD] it's not. \n",
      "15.54462718963623\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it's not. \n",
      "token:  [S1] Ok. \n",
      "22.26559829711914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] Oh I can't think of anything very comm \n",
      "45.97048568725586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh I can't think of anything very comm \n",
      "token:  [S1] pa \n",
      "58.46551513671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] pa \n",
      "token:  [S2] on \n",
      "29.45602035522461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] on \n",
      "token:  [S1] like paper \n",
      "99.44432067871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like paper \n",
      "token:  [S2] good \n",
      "10.726181030273438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] good \n",
      "token:  [MOD] If you're in a wo excell \n",
      "337.194580078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] If you're in a wo excell \n",
      "token:  [S1] yeah \n",
      "132.57940673828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] ent that's it yes. So what would be your ranking then? \n",
      "108.08650970458984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ent that's it yes. So what would be your ranking then? \n",
      "token:  [S1] Meat first I like well I go to \n",
      "205.06834411621094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Meat first I like well I go to \n",
      "token:  [MOD] hmm \n",
      "168.16668701171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] food when I thi \n",
      "194.5920867919922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] food when I thi \n",
      "token:  [MOD] hmm \n",
      "258.6095275878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] nk cutting \n",
      "183.29298400878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] nk cutting \n",
      "token:  [MOD] mhmm \n",
      "124.54522705078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] but I don't know about we what \n",
      "56.95547103881836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but I don't know about we what \n",
      "token:  [S2] Yeah I think of meat first and then they ah I'd be you know really unsure of what would come second. \n",
      "77.55992126464844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah I think of meat first and then they ah I'd be you know really unsure of what would come second. \n",
      "token:  [S1] Yeah. So it's \n",
      "18.172170639038086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. So it's \n",
      "token:  [S2] maybe paper would be \n",
      "96.20855712890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] maybe paper would be \n",
      "token:  [S1] paper or \n",
      "15.022920608520508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] paper or \n",
      "token:  [S2] be a more common thing. \n",
      "34.311805725097656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] be a more common thing. \n",
      "token:  [S1] yeah Paper and then hair yeah well just cause paper is kind of more everyday \n",
      "215.5116424560547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah Paper and then hair yeah well just cause paper is kind of more everyday \n",
      "token:  [MOD] hmm \n",
      "69.77245330810547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] kinf of s \n",
      "163.7295684814453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] kinf of s \n",
      "token:  [MOD] hmm \n",
      "151.0315704345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] ta \n",
      "76.2801742553711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ta \n",
      "token:  [MOD] hmm \n",
      "166.9719696044922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] sk as opposed to cutting your hair \n",
      "141.2559356689453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] sk as opposed to cutting your hair \n",
      "token:  [MOD] mhmm mhmm \n",
      "33.41792297363281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm mhmm \n",
      "token:  [S1] yeah but are you ok with that yeah yeah \n",
      "56.68739700317383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah but are you ok with that yeah yeah \n",
      "token:  [S2] yeah that soun ds fine to me \n",
      "45.67471694946289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah that soun ds fine to me \n",
      "token:  [MOD] Yes. \n",
      "52.023681640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes. \n",
      "token:  [S1] yeah \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.13555145263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] Now you didn't get this one ri ght it was the hair first paper second and meat came third. \n",
      "189.58189392089844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Now you didn't get this one ri ght it was the hair first paper second and meat came third. \n",
      "token:  [S1] Ok. \n",
      "26.048046112060547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] If you think about the most frequently used phrase you you know most people say have a haircut right? It's a very frequently used word combination. I'm going to have a haircut and \n",
      "39.06939697265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] If you think about the most frequently used phrase you you know most people say have a haircut right? It's a very frequently used word combination. I'm going to have a haircut and \n",
      "token:  [S1] hmm \n",
      "106.80174255371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] then paper I suppose you know you if you work in an office or and then meat I I think vegetables might be a very popular answer and then you also have vegetarians who would never you know think about \n",
      "111.08479309082031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] then paper I suppose you know you if you work in an office or and then meat I I think vegetables might be a very popular answer and then you also have vegetarians who would never you know think about \n",
      "token:  [S1] use meat \n",
      "81.64242553710938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] use meat \n",
      "token:  [MOD] yeah \n",
      "216.37225341796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] yeah \n",
      "16.380800247192383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] But well done you did great and that is the end of the quiz, I hope you enjoyed it. Thanks very \n",
      "46.91298294067383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But well done you did great and that is the end of the quiz, I hope you enjoyed it. Thanks very \n",
      "token:  [S1] hm yeah \n",
      "79.91780090332031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hm yeah \n",
      "token:  [MOD] much. \n",
      "187.83523559570312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] much. \n",
      "token:  [S2] Ok \n",
      "125.31733703613281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok \n",
      "token:  [S1] Thank you. \n",
      "8.220455169677734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Thank you. \n",
      "token:  [S2] well thank you. \n",
      "10.629459381103516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] well thank you. \n",
      "token:  [S1] Thanks very much. \n",
      "6.651040554046631\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Thanks very much. \n",
      "token:  [MOD] Alright.\n",
      "43.94082260131836\n",
      "MOD : 118.27756194608757\n",
      "S1 : 83.84164221262195\n",
      "S2 : 89.1837826569875\n",
      "speech transcription_Transcriber/S21.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Ok so hello guys. Thanks very \n",
      "668.6472778320312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok so hello guys. Thanks very \n",
      "token:  [S1] Hi. \n",
      "40.7334098815918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hi. \n",
      "token:  [MOD] much for being here today. We are going to play a quiz. So I'm going to ask you three questions that were previously posed to a group of hundred people. You'll have to give me the three most popular anwers for each question you need to talk to each other in order to collaborate and then order those answers in terms of popularity. \n",
      "32.1947135925293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] much for being here today. We are going to play a quiz. So I'm going to ask you three questions that were previously posed to a group of hundred people. You'll have to give me the three most popular anwers for each question you need to talk to each other in order to collaborate and then order those answers in terms of popularity. \n",
      "token:  [S2] mhmm \n",
      "47.419578552246094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] Is it clear? \n",
      "59.15418243408203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Is it clear? \n",
      "token:  [S1] Ok. \n",
      "22.358675003051758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Yeah? \n",
      "45.48149490356445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S2] Yeah. \n",
      "14.285598754882812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Are you ready for the first question? \n",
      "20.522945404052734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Are you ready for the first question? \n",
      "token:  [S2] mhmm \n",
      "60.12601852416992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [S1] Yeah. \n",
      "10.152067184448242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Yeah? Can you name a public place where you're likely to catch a cold or a flu bug. \n",
      "30.66668128967285\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? Can you name a public place where you're likely to catch a cold or a flu bug. \n",
      "token:  [S1] Sea shore? \n",
      "39.86906814575195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Sea shore? \n",
      "token:  [S2] Sea shore hm. So we need how many three? \n",
      "52.593692779541016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Sea shore hm. So we need how many three? \n",
      "token:  [MOD] Three. \n",
      "39.77064514160156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Three. \n",
      "token:  [S2] Three. \n",
      "19.010517120361328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Three. \n",
      "token:  [MOD] Three. \n",
      "28.187952041625977\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Three. \n",
      "token:  [S2] I would go for airport. And now we need a third one. And actually \n",
      "86.2397232055664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I would go for airport. And now we need a third one. And actually \n",
      "token:  [MOD] it's a \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.56281661987305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it's a \n",
      "token:  [S2] decide which are the populars eh? \n",
      "193.6833038330078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] decide which are the populars eh? \n",
      "token:  [S1] Yeah. \n",
      "15.434473037719727\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] More. \n",
      "15.61414623260498\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] More. \n",
      "token:  [MOD] th think about there's something connected to the airport \n",
      "326.88018798828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] th think about there's something connected to the airport \n",
      "token:  [S2] hmm \n",
      "29.436573028564453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] It's more like public transport. \n",
      "79.78433990478516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's more like public transport. \n",
      "token:  [S2] Yeah. \n",
      "25.095916748046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] So it's not the an airport, but it's the actual \n",
      "62.22591781616211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So it's not the an airport, but it's the actual \n",
      "token:  [S2] yyyes \n",
      "301.73577880859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yyyes \n",
      "token:  [S1] The transport itself. \n",
      "55.939544677734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The transport itself. \n",
      "token:  [S2] mhmm \n",
      "21.489654541015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [S1] So public places p public transport like buses \n",
      "160.89329528808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So public places p public transport like buses \n",
      "token:  [S2] public \n",
      "15.21703815460205\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] public \n",
      "token:  [MOD] But which one \n",
      "228.76263427734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But which one \n",
      "token:  [S2] transportation in general \n",
      "252.42848205566406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] transportation in general \n",
      "token:  [MOD] which means of transport? \n",
      "94.0294189453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] which means of transport? \n",
      "token:  [S2] hmm \n",
      "61.617706298828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] Related to the airport. \n",
      "172.6809844970703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Related to the airport. \n",
      "token:  [S1] The bus I guess. \n",
      "42.05342102050781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The bus I guess. \n",
      "token:  [S2] I would go for bus or some sort of metro yeah. \n",
      "35.34714126586914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I would go for bus or some sort of metro yeah. \n",
      "token:  [MOD] Somethi ng \n",
      "231.64659118652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Somethi ng \n",
      "token:  [S2] You were thinking probably of the plane itself. \n",
      "118.23876953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You were thinking probably of the plane itself. \n",
      "token:  [MOD] Plane, that's that's one answer actually. yeah \n",
      "227.67559814453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Plane, that's that's one answer actually. yeah \n",
      "token:  [S2] Yes. \n",
      "32.96077346801758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes. \n",
      "token:  [MOD] So you need to find two more. \n",
      "44.17559814453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you need to find two more. \n",
      "token:  [S2] Ok. \n",
      "24.2193603515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] So it should be like somewhere closed like \n",
      "73.63577270507812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So it should be like somewhere closed like \n",
      "token:  [MOD] mhmm \n",
      "105.72395324707031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] where p yeah many \n",
      "374.6206359863281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] where p yeah many \n",
      "token:  [MOD] where there are many people probably \n",
      "58.033634185791016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] where there are many people probably \n",
      "token:  [S1] people \n",
      "31.819656372070312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] people \n",
      "token:  [S2] yes So concert hall? \n",
      "131.88877868652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes So concert hall? \n",
      "token:  [S1] it works good but like somewhere \n",
      "74.93476104736328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it works good but like somewhere \n",
      "token:  [S2] No. Well, you can catch a cold probably at the hospotal to be ho \n",
      "145.02667236328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No. Well, you can catch a cold probably at the hospotal to be ho \n",
      "token:  [MOD] Yeah \n",
      "156.0579071044922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah \n",
      "token:  [S2] nest yes \n",
      "318.348388671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] nest yes \n",
      "token:  [MOD] hospital is another answer actually, that's that's good. \n",
      "151.12904357910156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hospital is another answer actually, that's that's good. \n",
      "token:  [S1] Usually it happens in the kinder gartens yeah. \n",
      "103.67253875732422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Usually it happens in the kinder gartens yeah. \n",
      "token:  [MOD] Yeah. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.92127227783203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] If you got a child. \n",
      "30.61693000793457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] If you got a child. \n",
      "token:  [MOD] So it's the school. \n",
      "47.015079498291016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So it's the school. \n",
      "token:  [S1] School ok. \n",
      "57.36444091796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] School ok. \n",
      "token:  [MOD] Yeah. That's great guys, so you have the three answ ers. \n",
      "71.82865142822266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. That's great guys, so you have the three answ ers. \n",
      "token:  [S2] mhmm \n",
      "49.14949035644531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] So now you need to talk to each other in order to order these answers in terms of popularity. \n",
      "37.896324157714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So now you need to talk to each other in order to order these answers in terms of popularity. \n",
      "token:  [S2] Ok. \n",
      "30.49462890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] Well I vote for the kindergarten and school cause \n",
      "109.00235748291016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Well I vote for the kindergarten and school cause \n",
      "token:  [S2] I think \n",
      "9.196283340454102\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think \n",
      "token:  [S1] whenever I send my kid \n",
      "74.51325225830078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] whenever I send my kid \n",
      "token:  [S2] Yeah. \n",
      "15.201136589050293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] he's always si back sick \n",
      "237.046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] he's always si back sick \n",
      "token:  [S2] Yeah. I think I will agree in the sense that p most people that have children would would say first the school. So yeah I think school is would be \n",
      "77.44609832763672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. I think I will agree in the sense that p most people that have children would would say first the school. So yeah I think school is would be \n",
      "token:  [S1] Yeah. \n",
      "8.31068229675293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] first answer. Now the other two were? \n",
      "41.65086364746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] first answer. Now the other two were? \n",
      "token:  [S1] Hospital and the plane. \n",
      "41.15760040283203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hospital and the plane. \n",
      "token:  [S2] Hospital and the plane. I would say first hospital, because most people go to hospitals unless people travel. \n",
      "18.13345718383789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hospital and the plane. I would say first hospital, because most people go to hospitals unless people travel. \n",
      "token:  [S1] I agree with that. \n",
      "7.884407043457031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I agree with that. \n",
      "token:  [S2] But You agree? \n",
      "24.928874969482422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] But You agree? \n",
      "token:  [S1] And there's so many people like like I mean li the number increases \n",
      "122.22643280029297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] And there's so many people like like I mean li the number increases \n",
      "token:  [S2] yeah \n",
      "16.3795108795166\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] like people coming coming and giving it so the number of the potential people are \n",
      "116.19097900390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like people coming coming and giving it so the number of the potential people are \n",
      "token:  [S2] hmm \n",
      "18.956783294677734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] who are sick they're increasing all the time. \n",
      "55.693084716796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] who are sick they're increasing all the time. \n",
      "token:  [S2] Yes. \n",
      "11.438322067260742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes. \n",
      "token:  [S1] In the plane you have this like limited number \n",
      "106.88733673095703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] In the plane you have this like limited number \n",
      "token:  [S2] mhmm \n",
      "27.9138126373291\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [S1] like it's not growing it's just that fixed number. \n",
      "51.780609130859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like it's not growing it's just that fixed number. \n",
      "token:  [S2] Ok. \n",
      "11.978927612304688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] I guess so. \n",
      "6.864580154418945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I guess so. \n",
      "token:  [S2] So \n",
      "23.518325805664062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So \n",
      "token:  [S1] Other thing \n",
      "48.413482666015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Other thing \n",
      "token:  [S2] we go we g I I agree we go with that? \n",
      "81.03041076660156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] we go we g I I agree we go with that? \n",
      "token:  [S1] Yeah. I agree. \n",
      "9.924330711364746\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. I agree. \n",
      "token:  [S2] School hospital \n",
      "193.9477996826172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] School hospital \n",
      "token:  [S1] and this plane \n",
      "49.040069580078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and this plane \n",
      "token:  [S2] and plane. \n",
      "23.12210464477539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and plane. \n",
      "token:  [MOD] Brilliant, that's correct. Well done. \n",
      "48.89686584472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Brilliant, that's correct. Well done. \n",
      "token:  [S1] Ok. \n",
      "19.588287353515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Very good. Ready for the second one? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.940719604492188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good. Ready for the second one? \n",
      "token:  [S2] mhmm \n",
      "37.116737365722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] Yeah? \n",
      "86.58048248291016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S1] Ok. \n",
      "14.51305103302002\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Can you name an instrument you can find in a symphony orchestra. \n",
      "38.42345428466797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you name an instrument you can find in a symphony orchestra. \n",
      "token:  [S2] Ok. \n",
      "31.453487396240234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] Harp? \n",
      "8.149555206298828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Harp? \n",
      "token:  [S2] You'll go for harp. \n",
      "16.672107696533203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You'll go for harp. \n",
      "token:  [S1] Since since we're in Ireland, I guess the harp is the first \n",
      "30.966495513916016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Since since we're in Ireland, I guess the harp is the first \n",
      "token:  [S2] yeah \n",
      "22.63286590576172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] one that comes to mind. \n",
      "14.893691062927246\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] one that comes to mind. \n",
      "token:  [S2] I would go for for violin. \n",
      "16.53313446044922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I would go for for violin. \n",
      "token:  [MOD] Violin is the right one yeah. \n",
      "58.44424819946289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Violin is the right one yeah. \n",
      "token:  [S1] Yeah. \n",
      "15.897660255432129\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] And we need a third one no? \n",
      "22.705814361572266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] And we need a third one no? \n",
      "token:  [MOD] You need two. \n",
      "34.8447380065918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You need two. \n",
      "token:  [S2] Two. \n",
      "30.638669967651367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Two. \n",
      "token:  [MOD] Two more yeah. \n",
      "115.07357025146484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Two more yeah. \n",
      "token:  [S2] Two more \n",
      "42.63861083984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Two more \n",
      "token:  [S1] There should be definitely be hmm violin \n",
      "114.87784576416016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] There should be definitely be hmm violin \n",
      "token:  [MOD] There is another one with strings. \n",
      "54.22023391723633\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] There is another one with strings. \n",
      "token:  [S2] Yeah. \n",
      "32.868614196777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] The big one the big \n",
      "59.79093933105469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The big one the big \n",
      "token:  [MOD] yeah \n",
      "415.9372253417969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] one well I just can't remember \n",
      "70.06273651123047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] one well I just can't remember \n",
      "token:  [S2] you can go for the cello? or the \n",
      "32.40574264526367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] you can go for the cello? or the \n",
      "token:  [MOD] yeah \n",
      "348.70611572265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] cello is that one ce cello cello \n",
      "135.05210876464844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cello is that one ce cello cello \n",
      "token:  [MOD] is that that's correct. Very good. So you need to find one more. Which is quite different from this instrument. \n",
      "55.828609466552734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] is that that's correct. Very good. So you need to find one more. Which is quite different from this instrument. \n",
      "token:  [S2] Ok. \n",
      "32.26585006713867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] No strings. \n",
      "95.95469665527344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No strings. \n",
      "token:  [S1] I think \n",
      "41.57270812988281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think \n",
      "token:  [S2] No strings. \n",
      "4.608022689819336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No strings. \n",
      "token:  [S1] something blowing? \n",
      "126.08586883544922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] something blowing? \n",
      "token:  [S2] Could be. That I I to be honest I don't remember if piano is considered the symphonic orchestra. no. \n",
      "64.74030303955078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Could be. That I I to be honest I don't remember if piano is considered the symphonic orchestra. no. \n",
      "token:  [MOD] No it's not. It's not in in the three answers. \n",
      "30.3071346282959\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No it's not. It's not in in the three answers. \n",
      "token:  [S2] So Clarinet? It's a bit not that close. \n",
      "66.7245864868164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So Clarinet? It's a bit not that close. \n",
      "token:  [S1] It's not a string so \n",
      "21.5693416595459\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] It's not a string so \n",
      "token:  [MOD] You might hit it. \n",
      "72.28138732910156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You might hit it. \n",
      "token:  [S2] Hit it? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.90727424621582\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hit it? \n",
      "token:  [MOD] Yeah. \n",
      "48.06699752807617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] Yes. So drums \n",
      "179.32220458984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes. So drums \n",
      "token:  [S1] Drums? \n",
      "10.237733840942383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Drums? \n",
      "token:  [MOD] Drums yeah very good. \n",
      "57.22486114501953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Drums yeah very good. \n",
      "token:  [S2] hm hmm hm \n",
      "32.54014587402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm hmm hm \n",
      "token:  [MOD] So you have three answers. Can you order them now in terms of popularity please? \n",
      "55.02253723144531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have three answers. Can you order them now in terms of popularity please? \n",
      "token:  [S1] Violin is the first I guess. \n",
      "47.34796905517578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin is the first I guess. \n",
      "token:  [S2] Yes, probably violin would be first. \n",
      "10.995784759521484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes, probably violin would be first. \n",
      "token:  [S1] Yeah. Well \n",
      "29.00082015991211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. Well \n",
      "token:  [S2] now \n",
      "20.168764114379883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] now \n",
      "token:  [S1] maybe drum Now I think it's drum could be more like yeah \n",
      "95.92486572265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] maybe drum Now I think it's drum could be more like yeah \n",
      "token:  [S2] more popular? \n",
      "16.5906982421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] more popular? \n",
      "token:  [S1] cause I mean if you s think of this way like you don't see people like mostly like playing and the violin I mean \n",
      "92.90217590332031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cause I mean if you s think of this way like you don't see people like mostly like playing and the violin I mean \n",
      "token:  [S2] hmm \n",
      "11.648695945739746\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] there are violin players are less than the drum players \n",
      "98.70502471923828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] there are violin players are less than the drum players \n",
      "token:  [S2] Yes. \n",
      "13.156030654907227\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes. \n",
      "token:  [S1] I guess so. So, I would say the drum is the first. \n",
      "15.70642375946045\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I guess so. So, I would say the drum is the first. \n",
      "token:  [S2] But on the for example in the orchestra the second person in charge a after the the master is the vio the fi the first violinist \n",
      "125.81668853759766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] But on the for example in the orchestra the second person in charge a after the the master is the vio the fi the first violinist \n",
      "token:  [S1] Ok then \n",
      "17.591882705688477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok then \n",
      "token:  [S2] and is also \n",
      "42.778141021728516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and is also \n",
      "token:  [S1] if \n",
      "14.072993278503418\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] if \n",
      "token:  [S2] on the on the front let's say of the of the orchestra and the drum is is always in the \n",
      "66.3578872680664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] on the on the front let's say of the of the orchestra and the drum is is always in the \n",
      "token:  [S1] Yeah in the \n",
      "22.369504928588867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah in the \n",
      "token:  [S2] back. So, in that sense probably people would associate violin with the picture of an orchestra playing. \n",
      "49.51211166381836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] back. So, in that sense probably people would associate violin with the picture of an orchestra playing. \n",
      "token:  [S1] Ok. But then the cello is always in this middle in the centre since it's big one \n",
      "55.76456832885742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. But then the cello is always in this middle in the centre since it's big one \n",
      "token:  [S2] yes \n",
      "16.001911163330078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes \n",
      "token:  [S1] yeah \n",
      "8.705379486083984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] hmm \n",
      "43.12217330932617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] and and and and yeah I have I don't have deep knowledge of that \n",
      "56.2760009765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and and and and yeah I have I don't have deep knowledge of that \n",
      "token:  [S2] ah ok \n",
      "20.602218627929688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah ok \n",
      "token:  [S1] of the music stuff you know . \n",
      "89.94573211669922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] of the music stuff you know . \n",
      "token:  [S2] So we fix violin first? \n",
      "98.49336242675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So we fix violin first? \n",
      "token:  [S1] ok but \n",
      "25.133459091186523\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok but \n",
      "token:  [S2] and and discuss which goes second is cello or the or the drum? \n",
      "133.8302459716797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and and discuss which goes second is cello or the or the drum? \n",
      "token:  [S1] Well, I I support your point that that drums are always in the back \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.81010818481445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Well, I I support your point that that drums are always in the back \n",
      "token:  [S2] yes \n",
      "11.755651473999023\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes \n",
      "token:  [S1] I think that makes a sense to put even the third place \n",
      "55.51790237426758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think that makes a sense to put even the third place \n",
      "token:  [S2] The third place. \n",
      "10.456238746643066\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The third place. \n",
      "token:  [S1] Makes a sense to me. \n",
      "14.024653434753418\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Makes a sense to me. \n",
      "token:  [S2] So you go for violin, cello, drum. \n",
      "35.91212463378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So you go for violin, cello, drum. \n",
      "token:  [S1] Yeah. \n",
      "7.650793552398682\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] I see why why cello why wh drum is not first, a at least in my opinion, but I would go for violin drum and and then cello. \n",
      "73.24625396728516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I see why why cello why wh drum is not first, a at least in my opinion, but I would go for violin drum and and then cello. \n",
      "token:  [S1] Ah \n",
      "25.89436149597168\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ah \n",
      "token:  [S2] Because ok somehow you have the violin that it should be there because it's the it's the it's the boss after the the maestro but then what you always assume that is there is some sort of rhythm. So, the second thing that you would say a as far as I think would be drum. That definitely there should there should be drum there. And then the cello I think le ll least the least people would think of cello. \n",
      "63.52202606201172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Because ok somehow you have the violin that it should be there because it's the it's the it's the boss after the the maestro but then what you always assume that is there is some sort of rhythm. So, the second thing that you would say a as far as I think would be drum. That definitely there should there should be drum there. And then the cello I think le ll least the least people would think of cello. \n",
      "token:  [S1] Yeah I I would rely on your opinion cause I have this as I don't have the deep knowledge of that. \n",
      "27.133602142333984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah I I would rely on your opinion cause I have this as I don't have the deep knowledge of that. \n",
      "token:  [MOD] hmm \n",
      "72.4265365600586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] I mean I love music especially the classical music but I never pay attention on how they how they are \n",
      "58.495880126953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I mean I love music especially the classical music but I never pay attention on how they how they are \n",
      "token:  [MOD] yeah exactly it's difficult. Yeah. \n",
      "123.4682846069336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah exactly it's difficult. Yeah. \n",
      "token:  [S1] I just love it I just love to listen. \n",
      "25.36933708190918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I just love it I just love to listen. \n",
      "token:  [MOD] Yeah. \n",
      "42.92317199707031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] and give attention there. \n",
      "119.01910400390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and give attention there. \n",
      "token:  [S2] So we we go with this ordering? eh \n",
      "103.26422119140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So we we go with this ordering? eh \n",
      "token:  [S1] I oh I agree with that why not. \n",
      "25.134017944335938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I oh I agree with that why not. \n",
      "token:  [MOD] Almost right \n",
      "159.06053161621094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Almost right \n",
      "token:  [S2] Almost \n",
      "44.746158599853516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Almost \n",
      "token:  [MOD] almost. \n",
      "134.11830139160156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] almost. \n",
      "token:  [S2] right \n",
      "108.22818756103516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] right \n",
      "token:  [MOD] So violin is first \n",
      "563.9801635742188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So violin is first \n",
      "token:  [S2] Mhmm. \n",
      "38.77225875854492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Mhmm. \n",
      "token:  [MOD] Then it's cello and then is drum. \n",
      "116.28032684326172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Then it's cello and then is drum. \n",
      "token:  [S2] ok \n",
      "99.5147705078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] But you did well, you almost found it. \n",
      "52.093971252441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But you did well, you almost found it. \n",
      "token:  [S2] Yeah \n",
      "90.15992736816406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [MOD] Yeah. Ready ready for the last one? \n",
      "70.70381927490234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. Ready ready for the last one? \n",
      "token:  [S2] mhmm \n",
      "37.99155807495117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] Yeah? \n",
      "86.58048248291016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S1] Yeah. Yeah. \n",
      "11.826464653015137\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. Yeah. \n",
      "token:  [MOD] Can you name something that people cut. \n",
      "81.59638214111328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you name something that people cut. \n",
      "token:  [S1] Well, if you think of this straight like not abs abstract thing \n",
      "213.28878784179688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Well, if you think of this straight like not abs abstract thing \n",
      "token:  [S2] hm \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.699899673461914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm \n",
      "token:  [S1] cut the paper \n",
      "28.66712760925293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cut the paper \n",
      "token:  [MOD] Paper is right actually. \n",
      "179.8455810546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Paper is right actually. \n",
      "token:  [S1] or cut the crap if it's something else \n",
      "62.92634201049805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] or cut the crap if it's something else \n",
      "token:  [MOD] m no we need something more tangible \n",
      "192.2998046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] m no we need something more tangible \n",
      "token:  [S2] yeah \n",
      "65.2257308959961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] but yeah pa \n",
      "364.9847717285156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] but yeah pa \n",
      "token:  [S2] yeah \n",
      "71.53582763671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] per is one yeah. \n",
      "372.0888671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] per is one yeah. \n",
      "token:  [S1] yeah. \n",
      "20.61509132385254\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah. \n",
      "token:  [S2] I thought of bread to be honest I o The third I thought wa was veins. actually but let's go for bread. Let's go for bread. \n",
      "119.93102264404297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I thought of bread to be honest I o The third I thought wa was veins. actually but let's go for bread. Let's go for bread. \n",
      "token:  [S1] Ok. They cut and ts they slice the \n",
      "143.119140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. They cut and ts they slice the \n",
      "token:  [S2] I hope ths was not the popular answer. \n",
      "34.35391616821289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I hope ths was not the popular answer. \n",
      "token:  [MOD] It's not bread but it's something related to food. \n",
      "35.65130615234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's not bread but it's something related to food. \n",
      "token:  [S2] food \n",
      "94.28156280517578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] food \n",
      "token:  [MOD] So \n",
      "229.44508361816406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So \n",
      "token:  [S1] Cheese. \n",
      "94.53352355957031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cheese. \n",
      "token:  [MOD] hmm \n",
      "138.1875457763672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] What they cut? \n",
      "98.1855697631836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] What they cut? \n",
      "token:  [S2] hm \n",
      "9.524274826049805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm \n",
      "token:  [MOD] It's like a main ingredient. \n",
      "74.71355438232422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's like a main ingredient. \n",
      "token:  [S2] Probably meat. \n",
      "75.73633575439453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Probably meat. \n",
      "token:  [MOD] Meat, that's correct. \n",
      "39.14155960083008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Meat, that's correct. \n",
      "token:  [S2] Yes. \n",
      "17.42017936706543\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes. \n",
      "token:  [MOD] Very good. So now you have one last answer left, you have to find another one. \n",
      "36.15803527832031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good. So now you have one last answer left, you have to find another one. \n",
      "token:  [S1] So paper \n",
      "283.64453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So paper \n",
      "token:  [S2] So up to now paper, meat \n",
      "71.18934631347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So up to now paper, meat \n",
      "token:  [S1] What they can it's a tangible, right? It's like straight away and so \n",
      "80.60319519042969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] What they can it's a tangible, right? It's like straight away and so \n",
      "token:  [MOD] yeah \n",
      "186.92771911621094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] What people \n",
      "115.41157531738281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] What people \n",
      "token:  [MOD] And think of appearance for example, what would both \n",
      "216.66629028320312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And think of appearance for example, what would both \n",
      "token:  [S1] Hair? \n",
      "178.62002563476562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hair? \n",
      "token:  [MOD] men and women, yeah. \n",
      "74.87969207763672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] men and women, yeah. \n",
      "token:  [S2] Ah, hair. Hair. \n",
      "80.64894104003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah, hair. Hair. \n",
      "token:  [S1] Hair. \n",
      "7.156919479370117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hair. \n",
      "token:  [MOD] That's great. So you have \n",
      "56.262020111083984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's great. So you have \n",
      "token:  [S2] mhmm \n",
      "69.21971130371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] all three answers. Can you order them now in terms of popularity? \n",
      "77.5868911743164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] all three answers. Can you order them now in terms of popularity? \n",
      "token:  [S1] I say this way pa meat, hair and k paper. so like if you are not a vegetarian you would cut meat everyday. \n",
      "130.66891479492188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I say this way pa meat, hair and k paper. so like if you are not a vegetarian you would cut meat everyday. \n",
      "token:  [S2] hm \n",
      "19.494874954223633\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm \n",
      "token:  [S1] I'm not a vegetarian. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.166196823120117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'm not a vegetarian. \n",
      "token:  [S2] So you well meat hair and eh pa \n",
      "590.8807373046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So you well meat hair and eh pa \n",
      "token:  [S1] paper \n",
      "41.90790939331055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] paper \n",
      "token:  [S2] per \n",
      "53.22109603881836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] per \n",
      "token:  [S1] Oh in this digital world you don't cut the paper so much. \n",
      "52.30253219604492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh in this digital world you don't cut the paper so much. \n",
      "token:  [S2] Yeah yeah. \n",
      "9.288822174072266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah yeah. \n",
      "token:  [MOD] hmm \n",
      "76.57942199707031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] I'll just think of new things so. \n",
      "46.68067932128906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'll just think of new things so. \n",
      "token:  [S2] I thhhhhink I would I I would go for haircut fir hair cut first because haircut is a very common word so I think that although we for us it took time to to think of hair it it it's some thought that most people would do directly this cut this association of cut and haircut. \n",
      "102.90058898925781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I thhhhhink I would I I would go for haircut fir hair cut first because haircut is a very common word so I think that although we for us it took time to to think of hair it it it's some thought that most people would do directly this cut this association of cut and haircut. \n",
      "token:  [S1] Ok. \n",
      "10.730278968811035\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] But I'm not sure. The thing there is also the word papercut to describe it when you get cut by by a paper, so I w even if somebody would say mention the word cut you might may consider the association with papercut. \n",
      "60.62039566040039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] But I'm not sure. The thing there is also the word papercut to describe it when you get cut by by a paper, so I w even if somebody would say mention the word cut you might may consider the association with papercut. \n",
      "token:  [S1] Which is cutting the paper itself? Not, being cut with the paper. \n",
      "24.482776641845703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Which is cutting the paper itself? Not, being cut with the paper. \n",
      "token:  [S2] Yes. But then \n",
      "22.011995315551758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes. But then \n",
      "token:  [S1] Well And I as a as I'm not a vegetarian I as I the meat I cut the meat every day \n",
      "80.30741119384766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Well And I as a as I'm not a vegetarian I as I the meat I cut the meat every day \n",
      "token:  [S2] yeah \n",
      "15.848648071289062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] so for me that stands for first I'm not stylish \n",
      "84.50450134277344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so for me that stands for first I'm not stylish \n",
      "token:  [S2] hmm \n",
      "7.220255374908447\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] hmm \n",
      "16.621774673461914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] I don't go to the barber everyday \n",
      "23.016929626464844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't go to the barber everyday \n",
      "token:  [S2] hmm \n",
      "7.501787185668945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] so \n",
      "14.661978721618652\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so \n",
      "token:  [MOD] hmm \n",
      "72.96619415283203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] ah yeah \n",
      "80.5472183227539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah yeah \n",
      "token:  [S1] once a month maybe \n",
      "28.013813018798828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] once a month maybe \n",
      "token:  [MOD] hmm \n",
      "95.16838836669922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] twi w t t once in a month \n",
      "135.6921844482422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] twi w t t once in a month \n",
      "token:  [S2] so we we fix it like meat hair and \n",
      "200.5325927734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so we we fix it like meat hair and \n",
      "token:  [S1] Well, I can dis we can discuss about the th hair and the paper but I th I I would put the meat \n",
      "87.75269317626953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Well, I can dis we can discuss about the th hair and the paper but I th I I would put the meat \n",
      "token:  [S2] hmm \n",
      "6.9599609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] I mean of the \n",
      "35.13261413574219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I mean of the \n",
      "token:  [S2] oh yeah \n",
      "20.13387107849121\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh yeah \n",
      "token:  [S1] three I would put the meat in the first place. \n",
      "46.92811965942383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] three I would put the meat in the first place. \n",
      "token:  [S2] You have some reason to believe that paper would be more popular than hair? Ok. \n",
      "26.815275192260742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You have some reason to believe that paper would be more popular than hair? Ok. \n",
      "token:  [S1] No, I just want \n",
      "14.986696243286133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No, I just want \n",
      "token:  [S2] Ah, ah. \n",
      "19.67678451538086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah, ah. \n",
      "token:  [S1] ch to discuss if you have d if you disagree with. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.59741973876953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ch to discuss if you have d if you disagree with. \n",
      "token:  [S2] Ah oh no. No, I think then we can go for meat , hair and then paper. \n",
      "64.7562026977539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah oh no. No, I think then we can go for meat , hair and then paper. \n",
      "token:  [S1] Ok. Ok. Works for me. \n",
      "10.238398551940918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. Ok. Works for me. \n",
      "token:  [MOD] Yeah? \n",
      "35.444034576416016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S1] No? \n",
      "15.189308166503906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No? \n",
      "token:  [MOD] Almost there, first is hair then it's paper then it's meat. \n",
      "102.45572662353516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Almost there, first is hair then it's paper then it's meat. \n",
      "token:  [S2] Last is meat \n",
      "68.24287414550781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Last is meat \n",
      "token:  [MOD] Last yeah. \n",
      "230.82281494140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Last yeah. \n",
      "token:  [S2] eh yeah. \n",
      "44.12709045410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh yeah. \n",
      "token:  [MOD] But that's \n",
      "78.0647964477539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But that's \n",
      "token:  [S1] But I guess \n",
      "38.4995002746582\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But I guess \n",
      "token:  [MOD] very interesting the thinking process you know? \n",
      "212.20919799804688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very interesting the thinking process you know? \n",
      "token:  [S2] hmm \n",
      "39.51532745361328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] But I think the most few people they're maybe they were like females their haircuts does in the fir rst place \n",
      "177.9727783203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But I think the most few people they're maybe they were like females their haircuts does in the fir rst place \n",
      "token:  [MOD] Yeah. \n",
      "60.70219802856445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] I think. \n",
      "14.800126075744629\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think. \n",
      "token:  [MOD] It was a random sample, I don't know more about it. But \n",
      "32.38608932495117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It was a random sample, I don't know more about it. But \n",
      "token:  [S2] hmm \n",
      "83.50131225585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] it's very interesting ah? Your thinking process was very intere sting. Ok well done guys. Thanks very much I hope you \n",
      "150.51638793945312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it's very interesting ah? Your thinking process was very intere sting. Ok well done guys. Thanks very much I hope you \n",
      "token:  [S2] Ok, thanks. \n",
      "40.131805419921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok, thanks. \n",
      "token:  [MOD] enjoyed it. \n",
      "80.2992172241211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] enjoyed it. \n",
      "token:  [S1] Thanks.\n",
      "35.5260009765625\n",
      "MOD : 118.2149256970509\n",
      "S1 : 62.258546761104036\n",
      "S2 : 60.995676500900935\n",
      "speech transcription_Transcriber/S18.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Ok hi guys Thanks very much for coming \n",
      "185.94775390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok hi guys Thanks very much for coming \n",
      "token:  [S1] Hello \n",
      "30.739362716674805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hello \n",
      "token:  [MOD] here today \n",
      "163.7083282470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] here today \n",
      "token:  [S2] Thanks \n",
      "82.2472915649414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Thanks \n",
      "token:  [MOD] We're going to play a quiz. So I'm going to ask you three survey questions that were previously posed to a group of hundred people \n",
      "29.406129837036133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] We're going to play a quiz. So I'm going to ask you three survey questions that were previously posed to a group of hundred people \n",
      "token:  [S2] hmm \n",
      "77.45858764648438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] So for each question you have to give me the three most popular answers. You have to talk to each other, you need to work together and you will have to order these answers in terms of popularity. \n",
      "23.64715003967285\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So for each question you have to give me the three most popular answers. You have to talk to each other, you need to work together and you will have to order these answers in terms of popularity. \n",
      "token:  [S2] ok \n",
      "79.6064224243164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] Yeah? \n",
      "81.48902893066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S2] Yeah. \n",
      "14.285598754882812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Is it clear or do you want me to give you an example? No, you're fine? \n",
      "22.83578109741211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Is it clear or do you want me to give you an example? No, you're fine? \n",
      "token:  [S2] No \n",
      "61.358985900878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No \n",
      "token:  [MOD] eh? first question? \n",
      "274.27374267578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] eh? first question? \n",
      "token:  [S1] We think yeah \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.93805694580078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] We think yeah \n",
      "token:  [S2] We think yeah \n",
      "5.3654656410217285\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] We think yeah \n",
      "token:  [MOD] Yeah? \n",
      "59.97245788574219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S2] Yeah go ahead. \n",
      "28.297452926635742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah go ahead. \n",
      "token:  [MOD] Can you name a public place where it's likely to catch a cold or a flu bug. \n",
      "45.53079605102539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you name a public place where it's likely to catch a cold or a flu bug. \n",
      "token:  [S2] and we three w you'll give us three options? \n",
      "204.378173828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and we three w you'll give us three options? \n",
      "token:  [MOD] No you \n",
      "202.9424591064453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No you \n",
      "token:  [S2] or \n",
      "47.73858642578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] or \n",
      "token:  [MOD] have to give me the answers yeah. \n",
      "129.2613067626953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] have to give me the answers yeah. \n",
      "token:  [S2] ah three options \n",
      "368.98822021484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah three options \n",
      "token:  [S1] An airplane? \n",
      "34.0823860168457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] An airplane? \n",
      "token:  [MOD] You have to discuss \n",
      "107.83621978759766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have to discuss \n",
      "token:  [S1] ah \n",
      "200.7891082763672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah \n",
      "token:  [MOD] with each other yeah \n",
      "329.0897216796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] with each other yeah \n",
      "token:  [S2] ok cold the airplane and there maybe the the airport is more \n",
      "317.62091064453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok cold the airplane and there maybe the the airport is more \n",
      "token:  [S1] bus \n",
      "34.92265319824219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] bus \n",
      "token:  [S2] ba yes \n",
      "37.526885986328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ba yes \n",
      "token:  [S1] airport yes bus \n",
      "116.01470184326172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] airport yes bus \n",
      "token:  [S2] bus \n",
      "11.557584762573242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] bus \n",
      "token:  [S1] train \n",
      "11.269163131713867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] train \n",
      "token:  [S2] train yes in general hospital \n",
      "54.737430572509766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] train yes in general hospital \n",
      "token:  [S1] nursery school \n",
      "34.126792907714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] nursery school \n",
      "token:  [S2] nursery school ha most definitely so yeah nursery school is I think the the th th th the guys are immune p possibly after \n",
      "209.7445831298828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] nursery school ha most definitely so yeah nursery school is I think the the th th th the guys are immune p possibly after \n",
      "token:  [MOD] hm \n",
      "89.45748138427734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S2] a certain age so it doesn't so yeah the airport I think is the first because you know they have all these measures when some diseases are \n",
      "159.6864471435547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] a certain age so it doesn't so yeah the airport I think is the first because you know they have all these measures when some diseases are \n",
      "token:  [S1] yeah yeah yeah yeah \n",
      "18.242300033569336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah yeah yeah yeah \n",
      "token:  [S2] spread. \n",
      "40.7010612487793\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] spread. \n",
      "token:  [S1] So airport? \n",
      "81.36808013916016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So airport? \n",
      "token:  [S2] Airport, I would go for airport number one \n",
      "30.987747192382812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Airport, I would go for airport number one \n",
      "token:  [S1] number two? \n",
      "19.158397674560547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] number two? \n",
      "token:  [S2] if you agree. number two eh Bus? \n",
      "123.32177734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] if you agree. number two eh Bus? \n",
      "token:  [S1] Bus? \n",
      "10.069388389587402\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Bus? \n",
      "token:  [S2] eh number three let's go to not again transport, something else, let's think of something else \n",
      "88.46537017822266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh number three let's go to not again transport, something else, let's think of something else \n",
      "token:  [S1] \n",
      "12.16808795928955\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] \n",
      "5.054042816162109\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] How about \n",
      "26.776094436645508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] How about \n",
      "token:  [S2] catch a cold Hospital? \n",
      "91.57872772216797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] catch a cold Hospital? \n",
      "token:  [S1] Hospital yeah. \n",
      "30.302949905395508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hospital yeah. \n",
      "token:  [S2] yeah well Ok hospital is number three. \n",
      "74.38417053222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah well Ok hospital is number three. \n",
      "token:  [MOD] Ok you're doing very well. You found hospital Can you try a little bit more with traveling? It's not the airport, it might be a means of transport \n",
      "52.887516021728516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok you're doing very well. You found hospital Can you try a little bit more with traveling? It's not the airport, it might be a means of transport \n",
      "token:  [S2] hmm ok So the airplane. air \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.53195190429688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm ok So the airplane. air \n",
      "token:  [S1] airplane yeah \n",
      "40.881832122802734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] airplane yeah \n",
      "token:  [MOD] You agree? \n",
      "83.876708984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You agree? \n",
      "token:  [S1] yeah \n",
      "62.4335823059082\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] yeah \n",
      "4.482073783874512\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] So you have eh plane \n",
      "400.4423828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have eh plane \n",
      "token:  [S2] umhm \n",
      "163.5659942626953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] umhm \n",
      "token:  [MOD] hospital and which is the third one? \n",
      "135.7129669189453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hospital and which is the third one? \n",
      "token:  [S2] bus we said \n",
      "377.4518737792969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] bus we said \n",
      "token:  [MOD] hmm \n",
      "68.4009780883789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] hmm \n",
      "9.166403770446777\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] no \n",
      "12.02365779876709\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no \n",
      "token:  [MOD] you've \n",
      "109.11083984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you've \n",
      "token:  [S1] so \n",
      "34.82378387451172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so \n",
      "token:  [MOD] mentioned it before \n",
      "130.1912078857422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mentioned it before \n",
      "token:  [S1] Train? No, nursery school? \n",
      "219.72576904296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Train? No, nursery school? \n",
      "token:  [MOD] It's the school. \n",
      "37.0914306640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's the school. \n",
      "token:  [S2] nursery school \n",
      "167.9195556640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] nursery school \n",
      "token:  [MOD] yeah \n",
      "217.87213134765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] yeah \n",
      "16.380800247192383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] school yeah \n",
      "47.01925277709961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] school yeah \n",
      "token:  [MOD] Can you rank them please? \n",
      "78.81261444091797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you rank them please? \n",
      "token:  [S2] Sorry? Can we? \n",
      "56.35395812988281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Sorry? Can we? \n",
      "token:  [MOD] Can you order them? in terms \n",
      "166.8530731201172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you order them? in terms \n",
      "token:  [S2] yeah \n",
      "118.56011962890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] of popularity, which one you think comes for first? \n",
      "121.4892349243164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] of popularity, which one you think comes for first? \n",
      "token:  [S1] So firs one would be hospit al \n",
      "244.50473022460938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So firs one would be hospit al \n",
      "token:  [S2] hospital I would say yeah uhm \n",
      "72.38096618652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hospital I would say yeah uhm \n",
      "token:  [S1] second one would be \n",
      "20.113576889038086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] second one would be \n",
      "token:  [S2] nursery and fourth and \n",
      "199.37794494628906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] nursery and fourth and \n",
      "token:  [S1] school and third would be \n",
      "22.18963623046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] school and third would be \n",
      "token:  [S2] third school \n",
      "18.365070343017578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] third school \n",
      "token:  [S1] the airplane \n",
      "37.17947006225586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the airplane \n",
      "token:  [S2] yeah \n",
      "16.647537231445312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] Almost there \n",
      "107.51782989501953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Almost there \n",
      "token:  [S2] ah so we're going to swap I suppose \n",
      "85.09745025634766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah so we're going to swap I suppose \n",
      "token:  [MOD] ehm \n",
      "61.55374526977539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ehm \n",
      "token:  [S2] the nursery with the plane right? \n",
      "316.389404296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the nursery with the plane right? \n",
      "token:  [MOD] the first \n",
      "118.78189086914062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the first \n",
      "token:  [S2] nursery \n",
      "436.8739318847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] nursery \n",
      "token:  [MOD] one is school yeah the se \n",
      "956.2282104492188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] one is school yeah the se \n",
      "token:  [S2] yeah \n",
      "94.44841003417969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] cond is \n",
      "601.742919921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] cond is \n",
      "token:  [S2] nurs \n",
      "316.0784606933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] nurs \n",
      "token:  [MOD] hospital \n",
      "157.483154296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hospital \n",
      "token:  [S2] hospital \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.92849349975586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hospital \n",
      "token:  [S1] hmm \n",
      "18.114465713500977\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] eh \n",
      "11.237034797668457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh \n",
      "token:  [MOD] and third is \n",
      "235.5081024169922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and third is \n",
      "token:  [S2] ok \n",
      "141.2379608154297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] plane \n",
      "341.4992370605469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] plane \n",
      "token:  [S1] ok \n",
      "61.73463821411133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] But well done yeah? \n",
      "185.83998107910156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But well done yeah? \n",
      "token:  [S2] eh it took us some time I suppose \n",
      "75.84490966796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh it took us some time I suppose \n",
      "token:  [MOD] No no you're \n",
      "83.49092102050781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No no you're \n",
      "token:  [S1] yeah yeah yeah \n",
      "39.729618072509766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah yeah yeah \n",
      "token:  [MOD] doing fine, you're doing fine So the second one. Can you name an instrument you can find in a symphony orchestra. \n",
      "56.189979553222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] doing fine, you're doing fine So the second one. Can you name an instrument you can find in a symphony orchestra. \n",
      "token:  [S2] An instrument yeah ah \n",
      "250.65342712402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] An instrument yeah ah \n",
      "token:  [S1] ok \n",
      "18.739341735839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] ah pro pro probably this is a language issue now can't can't tell you in Greek \n",
      "140.38623046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah pro pro probably this is a language issue now can't can't tell you in Greek \n",
      "token:  [S1] Ok, first there's the violin \n",
      "28.000110626220703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok, first there's the violin \n",
      "token:  [S2] Yeah violin is a common one I suppose and also \n",
      "35.84292984008789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah violin is a common one I suppose and also \n",
      "token:  [S1] second one is a \n",
      "24.567646026611328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] second one is a \n",
      "token:  [S2] now there's the big ones \n",
      "37.42165756225586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] now there's the big ones \n",
      "token:  [S1] the cello? \n",
      "10.877388000488281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the cello? \n",
      "token:  [S2] that cello is a I think cello is yet another type of \n",
      "40.3699951171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] that cello is a I think cello is yet another type of \n",
      "token:  [S1] yeah but probably it's popular. \n",
      "39.08955001831055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah but probably it's popular. \n",
      "token:  [S2] yeah it yeah violin yeah both of them are popular. And the other ones thAt don't know how they call then trombonia trum trumpet or trumpet \n",
      "160.0128173828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah it yeah violin yeah both of them are popular. And the other ones thAt don't know how they call then trombonia trum trumpet or trumpet \n",
      "token:  [S1] trombone \n",
      "8.1626615524292\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] trombone \n",
      "token:  [S2] trumpet or the other \n",
      "20.994060516357422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] trumpet or the other \n",
      "token:  [S1] Ok, so we'll go for violin, cello and trombone \n",
      "19.9610652923584\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok, so we'll go for violin, cello and trombone \n",
      "token:  [S2] trum yeah agreed \n",
      "260.9161071777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] trum yeah agreed \n",
      "token:  [MOD] Ok you've found two answers which are violin and cello \n",
      "127.02794647216797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok you've found two answers which are violin and cello \n",
      "token:  [S1] hmm \n",
      "39.659122467041016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] ok ok \n",
      "7.1880717277526855\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok ok \n",
      "token:  [MOD] so maybe you can give \n",
      "79.10066986083984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] so maybe you can give \n",
      "token:  [S2] and \n",
      "24.744403839111328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and \n",
      "token:  [MOD] it another go? \n",
      "302.9349670410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it another go? \n",
      "token:  [S2] yeah \n",
      "58.50907897949219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] It's a very different instrument to the ones mentioned already. \n",
      "51.611175537109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's a very different instrument to the ones mentioned already. \n",
      "token:  [S2] so the dishes no \n",
      "451.5289306640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so the dishes no \n",
      "token:  [S1] \n",
      "11.78920841217041\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] \n",
      "4.0172576904296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] A drum? \n",
      "35.113346099853516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] A drum? \n",
      "token:  [S2] drum \n",
      "38.94684600830078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] drum \n",
      "token:  [MOD] You agree both of you? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154.89190673828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You agree both of you? \n",
      "token:  [S2] yeah yeah \n",
      "104.90445709228516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah yeah \n",
      "token:  [S1] hmm \n",
      "8.355359077453613\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] yeah it can be the drum \n",
      "45.90712356567383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah it can be the drum \n",
      "token:  [MOD] yeah it's the drum, well done! And can you order now the answers please? \n",
      "72.2256088256836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah it's the drum, well done! And can you order now the answers please? \n",
      "token:  [S1] ah \n",
      "88.89482116699219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah \n",
      "token:  [S2] eh violin might be right one that comes out of your \n",
      "120.32746887207031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh violin might be right one that comes out of your \n",
      "token:  [S1] violin first \n",
      "48.82542037963867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] violin first \n",
      "token:  [S2] mind directly yeah violin first drums and cello. \n",
      "136.982177734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mind directly yeah violin first drums and cello. \n",
      "token:  [S1] yeah \n",
      "15.452091217041016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] You agree? \n",
      "82.10508728027344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You agree? \n",
      "token:  [S1] We'll go with it yeah we'll go with it. \n",
      "17.93168067932129\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] We'll go with it yeah we'll go with it. \n",
      "token:  [S2] yes yeah \n",
      "23.82768440246582\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes yeah \n",
      "token:  [MOD] almost \n",
      "176.48095703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] almost \n",
      "token:  [S2] ah yet again \n",
      "181.547119140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah yet again \n",
      "token:  [MOD] violin, cello and drum \n",
      "174.17788696289062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] violin, cello and drum \n",
      "token:  [S2] violin, cello and drum ok \n",
      "14.6520414352417\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] violin, cello and drum ok \n",
      "token:  [S1] ok ok ok ok yeah \n",
      "13.437821388244629\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok ok ok ok yeah \n",
      "token:  [MOD] Yeah? \n",
      "58.69143295288086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S2] Yeah. \n",
      "14.285598754882812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Ready for the third one that's the last question now \n",
      "98.08089447021484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ready for the third one that's the last question now \n",
      "token:  [S2] ok \n",
      "67.02851867675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] wow \n",
      "11.089454650878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] wow \n",
      "token:  [MOD] Can you name something people cut? \n",
      "174.57725524902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you name something people cut? \n",
      "token:  [S2] People cut \n",
      "52.112030029296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] People cut \n",
      "token:  [MOD] umhm \n",
      "1281.8275146484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] umhm \n",
      "token:  [S2] bread \n",
      "145.8787384033203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] bread \n",
      "token:  [S1] So bread? \n",
      "30.425607681274414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So bread? \n",
      "token:  [S2] yes well at least g for the Greeks that's straightforward one \n",
      "119.3284683227539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes well at least g for the Greeks that's straightforward one \n",
      "token:  [S1] Cheese? \n",
      "53.24065017700195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cheese? \n",
      "token:  [MOD] a very co mmon answer actually here \n",
      "355.18634033203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] a very co mmon answer actually here \n",
      "token:  [S2] yeah cheese \n",
      "228.18325805664062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah cheese \n",
      "token:  [S1] cheese \n",
      "12.468683242797852\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cheese \n",
      "token:  [S2] cheese \n",
      "8.647726058959961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cheese \n",
      "token:  [S1] wood \n",
      "33.05436706542969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] wood \n",
      "token:  [S2] and yeah \n",
      "24.084245681762695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and yeah \n",
      "token:  [S1] and cut my fingers or nails \n",
      "68.46817016601562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and cut my fingers or nails \n",
      "token:  [S2] ok you can cut yourself as well \n",
      "25.10749053955078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok you can cut yourself as well \n",
      "token:  [S1] right \n",
      "14.647210121154785\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] right \n",
      "token:  [S2] \n",
      "9.56019115447998\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] so \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.420289993286133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so \n",
      "token:  [S2] yeah I mean I mean I mean the bread seems ok I mean I \n",
      "45.325096130371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah I mean I mean I mean the bread seems ok I mean I \n",
      "token:  [S1] ok let's go for bread first so bread first \n",
      "36.033905029296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok let's go for bread first so bread first \n",
      "token:  [S2] do you think we should opt for for another food eh than cheese \n",
      "54.21983337402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] do you think we should opt for for another food eh than cheese \n",
      "token:  [S1] ok ok bread bread bread most definitely then cheese I think is less popular I \n",
      "157.27146911621094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok ok bread bread bread most definitely then cheese I think is less popular I \n",
      "token:  [S2] less possible option I suppose \n",
      "89.91031646728516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] less possible option I suppose \n",
      "token:  [S1] ok \n",
      "15.863788604736328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] but you can cut yourself \n",
      "30.304821014404297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] but you can cut yourself \n",
      "token:  [S1] we go for \n",
      "40.7755012512207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] we go for \n",
      "token:  [S2] that ok \n",
      "37.941925048828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] that ok \n",
      "token:  [S1] veins as well \n",
      "71.78605651855469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] veins as well \n",
      "token:  [S2] wow ok eh bread we should iteratively refine that one actually we can propose something and then ok bread cheese \n",
      "273.2155456542969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] wow ok eh bread we should iteratively refine that one actually we can propose something and then ok bread cheese \n",
      "token:  [S1] or fruits \n",
      "72.61007690429688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] or fruits \n",
      "token:  [S2] or fruits \n",
      "9.942770004272461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] or fruits \n",
      "token:  [S1] could be fruits as well \n",
      "22.180761337280273\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] could be fruits as well \n",
      "token:  [S2] ok bread cheese or cut yoursel \n",
      "241.20306396484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok bread cheese or cut yoursel \n",
      "token:  [S1] cut ne your nails nails \n",
      "177.8115997314453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cut ne your nails nails \n",
      "token:  [S2] your nails ok Are we \n",
      "64.5213394165039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] your nails ok Are we \n",
      "token:  [MOD] Yeah \n",
      "271.6556091308594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah \n",
      "token:  [S2] close with that order? \n",
      "164.14683532714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] close with that order? \n",
      "token:  [MOD] They are all very good answers but they're not the popular answers. \n",
      "42.19218063354492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] They are all very good answers but they're not the popular answers. \n",
      "token:  [S1] ok so good \n",
      "81.25183868408203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok so good \n",
      "token:  [MOD] so maybe you can give it another go? \n",
      "38.335838317871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] so maybe you can give it another go? \n",
      "token:  [S2] yeah ok what people cut Smoking? \n",
      "488.1553649902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah ok what people cut Smoking? \n",
      "token:  [MOD] \n",
      "62.8511962890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [S1] ok so wood? let's go for \n",
      "158.67388916015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok so wood? let's go for \n",
      "token:  [S2] sorry? \n",
      "26.192338943481445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] sorry? \n",
      "token:  [S1] for wood wood \n",
      "99.03536987304688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] for wood wood \n",
      "token:  [S2] wood yeah \n",
      "26.019271850585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] wood yeah \n",
      "token:  [S1] go for wood or cut a tree \n",
      "39.590335845947266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] go for wood or cut a tree \n",
      "token:  [S2] things that ok go \n",
      "65.36263275146484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] things that ok go \n",
      "token:  [S1] something like that \n",
      "14.120014190673828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] something like that \n",
      "token:  [S2] cut a tree yeah \n",
      "57.06344223022461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cut a tree yeah \n",
      "token:  [S1] we can go for cut my \n",
      "56.18419647216797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] we can go for cut my \n",
      "token:  [S2] hmm \n",
      "13.079381942749023\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] finger? \n",
      "31.017061233520508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] finger? \n",
      "token:  [S2] I think I didn't we didn't say \n",
      "28.537628173828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think I didn't we didn't say \n",
      "token:  [S1] no \n",
      "15.504257202148438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] no \n",
      "token:  [S2] `that no ok and \n",
      "137.6895751953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] `that no ok and \n",
      "token:  [MOD] Think of something that both men and women cut. maybe men more often \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.59286499023438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think of something that both men and women cut. maybe men more often \n",
      "token:  [S2] ah smoking is for certain f f smoking is \n",
      "326.0688171386719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah smoking is for certain f f smoking is \n",
      "token:  [MOD] hmm \n",
      "80.86455535888672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] one thing eh if we if we'd use it metaphorically though but \n",
      "191.51730346679688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] one thing eh if we if we'd use it metaphorically though but \n",
      "token:  [MOD] It has to do with appearance. \n",
      "44.564273834228516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It has to do with appearance. \n",
      "token:  [S2] Hair. \n",
      "78.39933776855469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair. \n",
      "token:  [S1] ah hair yeah yeah hair \n",
      "120.89401245117188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah hair yeah yeah hair \n",
      "token:  [S2] hair \n",
      "11.794733047485352\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair \n",
      "token:  [S1] hair hair \n",
      "13.453045845031738\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hair hair \n",
      "token:  [MOD] umhm hair \n",
      "383.8945617675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] umhm hair \n",
      "token:  [S2] we got \n",
      "59.85652160644531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] we got \n",
      "token:  [MOD] is one \n",
      "154.6041259765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] is one \n",
      "token:  [S2] hair \n",
      "392.15093994140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair \n",
      "token:  [S1] so hair \n",
      "33.888004302978516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so hair \n",
      "token:  [S2] people cut hair, people cut \n",
      "30.37773895263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] people cut hair, people cut \n",
      "token:  [S1] so nails we tried it it's not among the three eh? \n",
      "121.20807647705078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so nails we tried it it's not among the three eh? \n",
      "token:  [MOD] No, unfortunately not. \n",
      "31.154481887817383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No, unfortunately not. \n",
      "token:  [S1] hmm \n",
      "44.93255615234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] so you have two more \n",
      "89.49690246582031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] so you have two more \n",
      "token:  [S1] two more \n",
      "23.42726707458496\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] two more \n",
      "token:  [S2] so hair people \n",
      "105.16755676269531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so hair people \n",
      "token:  [S1] How about \n",
      "24.453411102294922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] How about \n",
      "token:  [S2] cut \n",
      "54.506011962890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cut \n",
      "token:  [S1] wood? \n",
      "42.497093200683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] wood? \n",
      "token:  [S2] I agree I \n",
      "31.32170867919922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I agree I \n",
      "token:  [S1] No? \n",
      "26.985437393188477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No? \n",
      "token:  [S2] agree we should test it \n",
      "35.110687255859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] agree we should test it \n",
      "token:  [MOD] ah no \n",
      "153.85267639160156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ah no \n",
      "token:  [S1] no it's \n",
      "27.938140869140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] no it's \n",
      "token:  [S2] no \n",
      "7.735316753387451\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no \n",
      "token:  [S1] not \n",
      "11.1279296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] not \n",
      "token:  [MOD] no \n",
      "83.50131225585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no \n",
      "token:  [S1] ok \n",
      "39.340023040771484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] Think about food as well. \n",
      "107.32589721679688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think about food as well. \n",
      "token:  [S1] ok \n",
      "79.75642395019531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] but \n",
      "91.33956909179688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] but \n",
      "token:  [S1] but is not \n",
      "33.640079498291016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but is not \n",
      "token:  [S2] cut bread \n",
      "102.68824768066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cut bread \n",
      "token:  [MOD] more general yeah \n",
      "448.9068298339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] more general yeah \n",
      "token:  [S2] no isn't bread they cut \n",
      "289.8199768066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no isn't bread they cut \n",
      "token:  [S1] meat \n",
      "22.07604217529297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat \n",
      "token:  [S2] meat yes \n",
      "9.687016487121582\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] meat yes \n",
      "token:  [MOD] meat is \n",
      "60.19515609741211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] meat is \n",
      "token:  [S1] meat meat \n",
      "36.71466064453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat meat \n",
      "token:  [MOD] is a correct answer \n",
      "73.14628601074219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] is a correct answer \n",
      "token:  [S2] meat meat \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287.27911376953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] meat meat \n",
      "token:  [S1] ok \n",
      "19.954315185546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] then \n",
      "71.5307388305664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] then \n",
      "token:  [S2] hmm \n",
      "60.17437744140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] there is one more left. \n",
      "56.183685302734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] there is one more left. \n",
      "token:  [S2] o k \n",
      "126.91854095458984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] o k \n",
      "token:  [S1] so hair meat \n",
      "210.29949951171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so hair meat \n",
      "token:  [S2] cut cheese no we said that we said \n",
      "73.91460418701172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cut cheese no we said that we said \n",
      "token:  [MOD] no more food \n",
      "151.60260009765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no more food \n",
      "token:  [S2] we said that we said that \n",
      "43.95531463623047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] we said that we said that \n",
      "token:  [MOD] hmm \n",
      "75.75985717773438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] yeah I'm sure So metaphorically is there a possibility that is used metaphorically? No. you the definitely you refer to cutting the action yeah \n",
      "154.51678466796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah I'm sure So metaphorically is there a possibility that is used metaphorically? No. you the definitely you refer to cutting the action yeah \n",
      "token:  [MOD] yeah something you actually cut \n",
      "111.92546081542969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah something you actually cut \n",
      "token:  [S2] ok so then exclude all of the se cases \n",
      "199.45440673828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok so then exclude all of the se cases \n",
      "token:  [MOD] eh this is some thing you see quite often everyday \n",
      "127.69245910644531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] eh this is some thing you see quite often everyday \n",
      "token:  [S2] yes umhm they cut people cut hmm \n",
      "285.866455078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes umhm they cut people cut hmm \n",
      "token:  [MOD] Tricky eh? no \n",
      "113.76519775390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Tricky eh? no \n",
      "token:  [S1] umhm \n",
      "125.48123168945312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] umhm \n",
      "token:  [S2] but have to \n",
      "28.98461151123047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] but have to \n",
      "token:  [S1] cut cut cutting every day you say everyday \n",
      "152.36849975585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cut cut cutting every day you say everyday \n",
      "token:  [S2] cutting everyday \n",
      "20.246854782104492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cutting everyday \n",
      "token:  [MOD] Yeah but you you see it often. You see it often, doesn't mean you have to cut it but you can see it then you can cut it as well. You can write on it. \n",
      "27.1582088470459\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah but you you see it often. You see it often, doesn't mean you have to cut it but you can see it then you can cut it as well. You can write on it. \n",
      "token:  [S2] ah cut a piece of pa no \n",
      "275.0648193359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah cut a piece of pa no \n",
      "token:  [S1] Paper yeah. \n",
      "43.03144836425781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Paper yeah. \n",
      "token:  [S2] piece of paper? \n",
      "14.101460456848145\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] piece of paper? \n",
      "token:  [MOD] p it's paper \n",
      "206.79322814941406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] p it's paper \n",
      "token:  [S2] yeah because \n",
      "98.40802001953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah because \n",
      "token:  [S1] ah ok \n",
      "18.953962326049805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah ok \n",
      "token:  [S2] you t you heard us a lot ok \n",
      "60.1578254699707\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] you t you heard us a lot ok \n",
      "token:  [MOD] yeah \n",
      "61.89430618286133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S2] how about \n",
      "38.37212371826172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] how about \n",
      "token:  [MOD] so you you ha ve the three answers \n",
      "226.3759002685547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] so you you ha ve the three answers \n",
      "token:  [S2] ok \n",
      "56.64645767211914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] then \n",
      "75.18928527832031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] then \n",
      "token:  [S2] yes and we have to put the \n",
      "62.8935546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes and we have to put the \n",
      "token:  [S1] yeah we have to sort them \n",
      "37.97889709472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah we have to sort them \n",
      "token:  [S2] order \n",
      "25.2537841796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] order \n",
      "token:  [MOD] yes \n",
      "142.1887969970703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes \n",
      "token:  [S2] yes you go I would go for hair first yes \n",
      "127.2884292602539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes you go I would go for hair first yes \n",
      "token:  [S1] so hair would be first yeah \n",
      "32.67900085449219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so hair would be first yeah \n",
      "token:  [S2] and then meat and then no paper meat \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.20984649658203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and then meat and then no paper meat \n",
      "token:  [S1] ok we'll go with that yeah \n",
      "24.97891616821289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok we'll go with that yeah \n",
      "token:  [S2] hair pa per meat \n",
      "402.6614074707031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair pa per meat \n",
      "token:  [S1] hair paper meat \n",
      "47.26845169067383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hair paper meat \n",
      "token:  [MOD] you're sure? \n",
      "71.9852066040039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you're sure? \n",
      "token:  [S1] yeah \n",
      "31.7186279296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] yes \n",
      "6.084225177764893\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes \n",
      "token:  [MOD] So it's hair, paper and meat well done \n",
      "190.12307739257812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So it's hair, paper and meat well done \n",
      "token:  [S1] great great great \n",
      "59.48483657836914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] great great great \n",
      "token:  [MOD] You found it, great! \n",
      "80.87484741210938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You found it, great! \n",
      "token:  [S1] great great \n",
      "67.27375793457031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] great great \n",
      "token:  [S2] we are lucky today we'll play the lottery \n",
      "44.98177719116211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] we are lucky today we'll play the lottery \n",
      "token:  [MOD] Well I hope you enjoyed it. \n",
      "28.885635375976562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well I hope you enjoyed it. \n",
      "token:  [S2] we did we did we did \n",
      "21.311012268066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] we did we did we did \n",
      "token:  [S1] yeah we did we did we did \n",
      "3.7053215503692627\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah we did we did we did \n",
      "token:  [MOD] Thanks very much guys. \n",
      "58.26324462890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Thanks very much guys. \n",
      "token:  [S1] Thank you. \n",
      "13.91071891784668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Thank you. \n",
      "token:  [S2] Thanks.\n",
      "5.913646697998047\n",
      "MOD : 157.33978289023213\n",
      "S1 : 49.90653240560281\n",
      "S2 : 105.11564357956844\n",
      "speech transcription_Transcriber/S14.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Hello guys thanks very much for coming here today. We're going to play a quiz. So I'm going to ask you s three survey questions thsat were previously eh posed to a group of hundred people. \n",
      "70.74600982666016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Hello guys thanks very much for coming here today. We're going to play a quiz. So I'm going to ask you s three survey questions thsat were previously eh posed to a group of hundred people. \n",
      "token:  [S2] \n",
      "27.407358169555664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] For each question I'd like you to give me the three most popular answers. You have to discuss and you need to collaborate with each other and then you need to rank those answers eh in terms of popularity. \n",
      "35.51273727416992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] For each question I'd like you to give me the three most popular answers. You have to discuss and you need to collaborate with each other and then you need to rank those answers eh in terms of popularity. \n",
      "token:  [S1] mhmm \n",
      "43.78058624267578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] Is it clear, do you like me to give eh I can give you an example if you want or \n",
      "75.88687133789062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Is it clear, do you like me to give eh I can give you an example if you want or \n",
      "token:  [S2] Yes why not? \n",
      "37.56601333618164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes why not? \n",
      "token:  [MOD] Yeah an example? yeah. \n",
      "138.77325439453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah an example? yeah. \n",
      "token:  [S1] Ok. \n",
      "16.739044189453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] say the question is what does a hospital use in order to transport patients and the answers are an ambulance a wheelchair and a hospital bed. So you use these answers, you talk to each other and then you rank them in terms of popularity. \n",
      "35.57270050048828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] say the question is what does a hospital use in order to transport patients and the answers are an ambulance a wheelchair and a hospital bed. So you use these answers, you talk to each other and then you rank them in terms of popularity. \n",
      "token:  [S1] mhmm \n",
      "49.24106979370117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] Yeah? Is it clear? \n",
      "67.02407836914062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? Is it clear? \n",
      "token:  [S1] Ok. \n",
      "16.80282974243164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Yeah? \n",
      "45.48149490356445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S1] mhmm \n",
      "29.386281967163086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] Ok, so the first question is name a public place ok where you're likely to catch a cold or a flu bug. \n",
      "75.37401580810547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok, so the first question is name a public place ok where you're likely to catch a cold or a flu bug. \n",
      "token:  [S1] Ok. Oh, so there's no options. \n",
      "29.642841339111328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. Oh, so there's no options. \n",
      "token:  [MOD] No, you have to give me the answers. \n",
      "15.553327560424805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No, you have to give me the answers. \n",
      "token:  [S1] Oh yeah ri ah ok \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.93643188476562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh yeah ri ah ok \n",
      "token:  [S2] Yeah. \n",
      "9.22781753540039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Ok so \n",
      "27.930130004882812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok so \n",
      "token:  [S2] A bus maybe, public transportation bus a bus \n",
      "117.9043960571289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A bus maybe, public transportation bus a bus \n",
      "token:  [S1] Yeah, something that has like the you know the air conditioning? \n",
      "36.38888168334961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah, something that has like the you know the air conditioning? \n",
      "token:  [S2] Ah! \n",
      "13.482733726501465\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah! \n",
      "token:  [S1] So it transfers the viruses quickly \n",
      "165.35682678222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So it transfers the viruses quickly \n",
      "token:  [S2] oh that's yeah yeah \n",
      "39.32450485229492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh that's yeah yeah \n",
      "token:  [S1] but I mean buses have it so ah \n",
      "122.0726089477539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but I mean buses have it so ah \n",
      "token:  [S2] yeah I thought through contamination in the bus from others \n",
      "108.70001983642578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah I thought through contamination in the bus from others \n",
      "token:  [S1] yeah yeah yeah yeah so somewhere there's lot of people and \n",
      "36.55553436279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah yeah yeah yeah so somewhere there's lot of people and \n",
      "token:  [S2] a a \n",
      "34.71334457397461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] a a \n",
      "token:  [S1] lot of air conditioning. \n",
      "63.60419464111328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] lot of air conditioning. \n",
      "token:  [S2] air conditioning so \n",
      "28.205610275268555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] air conditioning so \n",
      "token:  [S1] yeah so bus could be plane \n",
      "104.47518920898438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah so bus could be plane \n",
      "token:  [S2] or a shopping mall or \n",
      "22.117630004882812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] or a shopping mall or \n",
      "token:  [S1] Shopping mall yeah. hmm \n",
      "39.676666259765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Shopping mall yeah. hmm \n",
      "token:  [S2] your office maybe \n",
      "39.972373962402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] your office maybe \n",
      "token:  [MOD] \n",
      "63.50146484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [S2] eh not your \n",
      "402.65985107421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh not your \n",
      "token:  [S1] yes some \n",
      "29.288785934448242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yes some \n",
      "token:  [S2] office in particular \n",
      "70.34319305419922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] office in particular \n",
      "token:  [S1] yeah so it has to be very a lot of people together very close to each other \n",
      "28.109798431396484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah so it has to be very a lot of people together very close to each other \n",
      "token:  [S2] mhmm \n",
      "8.697900772094727\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [S1] maybe everywhere then oh yeah So are we going for bus? \n",
      "151.0349578857422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] maybe everywhere then oh yeah So are we going for bus? \n",
      "token:  [MOD] Maybe think of a bigger means of transport. \n",
      "47.9637451171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Maybe think of a bigger means of transport. \n",
      "token:  [S2] yeah \n",
      "121.35774993896484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] hmm \n",
      "8.52652645111084\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] A double bus? a yeah double decker bus a a train or \n",
      "86.02751159667969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A double bus? a yeah double decker bus a a train or \n",
      "token:  [S1] hmm \n",
      "42.05624771118164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] A hospi \n",
      "64.77217102050781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A hospi \n",
      "token:  [S1] Plane? \n",
      "53.0420036315918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Plane? \n",
      "token:  [S2] tal as well you can catch a no no maybe no right? \n",
      "215.0247802734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] tal as well you can catch a no no maybe no right? \n",
      "token:  [MOD] hmm \n",
      "76.67972564697266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] So \n",
      "66.30825805664062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So \n",
      "token:  [S1] Plane definitely. \n",
      "140.65478515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Plane definitely. \n",
      "token:  [MOD] mhmm \n",
      "97.18099975585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S2] Yeah. And there is an air condition in the in the plane \n",
      "107.4760513305664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. And there is an air condition in the in the plane \n",
      "token:  [MOD] mhmm \n",
      "50.91550064086914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S2] oh yeah \n",
      "60.64569091796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh yeah \n",
      "token:  [S1] yeah \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.926351547241211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] You already found two. \n",
      "104.22848510742188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You already found two. \n",
      "token:  [S1] Ok, plane bus? \n",
      "171.52886962890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok, plane bus? \n",
      "token:  [MOD] You have plane hospital \n",
      "297.9273986816406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have plane hospital \n",
      "token:  [S1] Oh hospit \n",
      "116.64512634277344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh hospit \n",
      "token:  [S2] hospital \n",
      "11.962661743164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hospital \n",
      "token:  [S1] al \n",
      "30.123165130615234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] al \n",
      "token:  [MOD] yeah \n",
      "439.8525695800781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] oh ok \n",
      "31.397132873535156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh ok \n",
      "token:  [S2] hospital \n",
      "40.96625900268555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hospital \n",
      "token:  [S1] \n",
      "10.188096046447754\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] What would the third one be? \n",
      "33.76747131347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] What would the third one be? \n",
      "token:  [S1] \n",
      "23.214826583862305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] So or you why do I catch a cold? while I'm sleeping actually \n",
      "80.42034149169922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So or you why do I catch a cold? while I'm sleeping actually \n",
      "token:  [MOD] No way. \n",
      "65.1968765258789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No way. \n",
      "token:  [S2] No way yeah. So your o the your office your working place \n",
      "281.61505126953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No way yeah. So your o the your office your working place \n",
      "token:  [S1] workplace yeah \n",
      "37.831233978271484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] workplace yeah \n",
      "token:  [S2] if not then eh ep a park for example like public outdoor space \n",
      "192.40005493164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] if not then eh ep a park for example like public outdoor space \n",
      "token:  [S1] hm \n",
      "12.227836608886719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hm \n",
      "token:  [S2] hmm \n",
      "7.274570941925049\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] Maybe think of different age groups. \n",
      "89.98237609863281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Maybe think of different age groups. \n",
      "token:  [S1] \n",
      "27.568103790283203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] Maybe children. \n",
      "357.6463928222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Maybe children. \n",
      "token:  [S1] Oh kindergarten \n",
      "277.5862121582031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh kindergarten \n",
      "token:  [S2] Ah of cour yeah. \n",
      "87.8683853149414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah of cour yeah. \n",
      "token:  [S1] yeah \n",
      "21.775718688964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] mhmm \n",
      "39.5537109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] Yeah ok. \n",
      "48.19855499267578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah ok. \n",
      "token:  [S2] It's the school right? \n",
      "19.582555770874023\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It's the school right? \n",
      "token:  [S1] yeah school. \n",
      "22.161191940307617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah school. \n",
      "token:  [MOD] Yeah. \n",
      "29.08077049255371\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] hm \n",
      "43.25202560424805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hm \n",
      "token:  [MOD] That's great guys you found all three. \n",
      "89.68281555175781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's great guys you found all three. \n",
      "token:  [S1] Ah cool \n",
      "77.46319580078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ah cool \n",
      "token:  [MOD] So it's hospital, plane and school. And can you please rank those answers now? \n",
      "138.60951232910156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So it's hospital, plane and school. And can you please rank those answers now? \n",
      "token:  [S1] Ok \n",
      "59.82579040527344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok \n",
      "token:  [MOD] Which would be the most popular. \n",
      "51.60919189453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Which would be the most popular. \n",
      "token:  [S2] Kindergarten \n",
      "85.6107177734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Kindergarten \n",
      "token:  [S1] yeah probably \n",
      "47.1622428894043\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah probably \n",
      "token:  [S2] yeah \n",
      "7.724841117858887\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] a school \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.51115036010742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] a school \n",
      "token:  [S2] school and then \n",
      "21.79804039001465\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] school and then \n",
      "token:  [S1] hospital, plane hm \n",
      "101.62501525878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hospital, plane hm \n",
      "token:  [S2] hospital you're not supposed to get cold \n",
      "28.004362106323242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hospital you're not supposed to get cold \n",
      "token:  [S1] yeah we're just surrounded with sick people ah yeah so \n",
      "66.13534545898438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah we're just surrounded with sick people ah yeah so \n",
      "token:  [S2] so if we don't count those being there alrea dy \n",
      "70.96385955810547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so if we don't count those being there alrea dy \n",
      "token:  [S1] yeah \n",
      "19.275182723999023\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] maybe plane and then hospital \n",
      "100.58287048339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] maybe plane and then hospital \n",
      "token:  [S1] let's let's say that they're focusing on hygiene there so it should be plane and hospital \n",
      "33.480403900146484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] let's let's say that they're focusing on hygiene there so it should be plane and hospital \n",
      "token:  [MOD] mmm \n",
      "69.97148895263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mmm \n",
      "token:  [S1] Ah! Dammit! Ok hospital \n",
      "177.3971405029297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ah! Dammit! Ok hospital \n",
      "token:  [MOD] So the first one is school \n",
      "88.89389038085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So the first one is school \n",
      "token:  [S1] mhmm \n",
      "46.31546401977539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] yeah the second one is hospi tal and the third \n",
      "179.37435913085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah the second one is hospi tal and the third \n",
      "token:  [S1] mhmm \n",
      "46.82426834106445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] one is plane. \n",
      "340.8494567871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] one is plane. \n",
      "token:  [S1] Ok. \n",
      "25.232023239135742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Yeah? \n",
      "45.48149490356445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S2] I see. \n",
      "17.79256248474121\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I see. \n",
      "token:  [MOD] But well done guys eh? \n",
      "186.5397491455078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But well done guys eh? \n",
      "token:  [S1] Ah! \n",
      "41.63248062133789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ah! \n",
      "token:  [MOD] Yeah \n",
      "149.8460235595703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah \n",
      "token:  [S1] Woo-hoo! \n",
      "20.423524856567383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Woo-hoo! \n",
      "token:  [MOD] Are you ready \n",
      "60.35196304321289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Are you ready \n",
      "token:  [S1] We're awesome. \n",
      "42.01044845581055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] We're awesome. \n",
      "token:  [MOD] for the second one? Yeah? \n",
      "90.2137222290039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] for the second one? Yeah? \n",
      "token:  [S1] Ok. \n",
      "20.25433349609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Eh can you name an instrument in a symphony orchestra. \n",
      "93.86103057861328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Eh can you name an instrument in a symphony orchestra. \n",
      "token:  [S2] Oh! \n",
      "38.669639587402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh! \n",
      "token:  [S1] There's more than three there \n",
      "36.726173400878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] There's more than three there \n",
      "token:  [MOD] Yeah yeah. \n",
      "84.08827209472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah yeah. \n",
      "token:  [S2] So the most popular one. \n",
      "38.64046096801758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So the most popular one. \n",
      "token:  [MOD] Yes, the most popu \n",
      "98.66917419433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes, the most popu \n",
      "token:  [S2] yeah \n",
      "261.5231018066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] popular answers. \n",
      "365.2778015136719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] popular answers. \n",
      "token:  [S1] Oboe \n",
      "109.49658203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oboe \n",
      "token:  [MOD] Ah \n",
      "272.4953918457031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ah \n",
      "token:  [S1] That's not popular at all \n",
      "30.88799285888672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] That's not popular at all \n",
      "token:  [MOD] Oh \n",
      "99.3152847290039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Oh \n",
      "token:  [S2] Maybe a violin, what \n",
      "170.81629943847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Maybe a violin, what \n",
      "token:  [S1] Violin yeah. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.18852996826172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin yeah. \n",
      "token:  [S2] do you think? \n",
      "14.991884231567383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] do you think? \n",
      "token:  [S1] \n",
      "7.911811828613281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] So gui Flute? f floute flu te? \n",
      "449.9436340332031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So gui Flute? f floute flu te? \n",
      "token:  [S1] Flute yeah. \n",
      "18.056333541870117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Flute yeah. \n",
      "token:  [S2] le let's first say those that we remember. \n",
      "97.28142547607422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] le let's first say those that we remember. \n",
      "token:  [S1] Yeah because I I don't know the En \n",
      "59.939605712890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah because I I don't know the En \n",
      "token:  [S2] and then \n",
      "25.5651912689209\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and then \n",
      "token:  [S1] glish terms. violin yes yes and then contrabass, bass \n",
      "241.94107055664062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] glish terms. violin yes yes and then contrabass, bass \n",
      "token:  [S2] cello maybe cello \n",
      "32.48827362060547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cello maybe cello \n",
      "token:  [S1] cello yeah \n",
      "8.883689880371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cello yeah \n",
      "token:  [S2] flute \n",
      "13.173345565795898\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] flute \n",
      "token:  [S1] cello flute saxophone \n",
      "26.519155502319336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cello flute saxophone \n",
      "token:  [S2] a saxophone yeah th this is this is this I always go for the weird ones is one yeah \n",
      "81.69047546386719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] a saxophone yeah th this is this is this I always go for the weird ones is one yeah \n",
      "token:  [S1] ah tuba \n",
      "51.59489440917969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah tuba \n",
      "token:  [S2] tuba yeah trumpet trumpet yeah there you go trumpet trumpet yes What do you think, the rank \n",
      "62.75712966918945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] tuba yeah trumpet trumpet yeah there you go trumpet trumpet yes What do you think, the rank \n",
      "token:  [S1] trinagle \n",
      "184.47097778320312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] trinagle \n",
      "token:  [S2] ing triangle ob \n",
      "277.682861328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ing triangle ob \n",
      "token:  [S1] scure one, why not \n",
      "89.23870849609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] scure one, why not \n",
      "token:  [MOD] why not, why not \n",
      "20.43476676940918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] why not, why not \n",
      "token:  [S1] eh the \n",
      "121.61507415771484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] eh the \n",
      "token:  [S2] The drums? \n",
      "72.05986785888672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The drums? \n",
      "token:  [S1] ah what you call it the \n",
      "51.6240348815918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah what you call it the \n",
      "token:  [S2] Oh I see yeah yeah \n",
      "28.863821029663086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh I see yeah yeah \n",
      "token:  [MOD] That's that's great You found three. \n",
      "97.50104522705078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's that's great You found three. \n",
      "token:  [S1] Oh, oh we have already, so we don't \n",
      "50.3115348815918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh, oh we have already, so we don't \n",
      "token:  [MOD] Yeah yeah \n",
      "76.88640594482422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah yeah \n",
      "token:  [S1] need to \n",
      "64.19879913330078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] need to \n",
      "token:  [MOD] That 's great you have drum ah the violin and cello. \n",
      "250.01385498046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That 's great you have drum ah the violin and cello. \n",
      "token:  [S1] Ok. \n",
      "20.48641586303711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] hmm \n",
      "16.01919937133789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] So can you do the ranking please? \n",
      "81.43914794921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So can you do the ranking please? \n",
      "token:  [S2] What was the first one you said? \n",
      "18.89037322998047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] What was the first one you said? \n",
      "token:  [S1] Drum. \n",
      "45.282875061035156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Drum. \n",
      "token:  [MOD] Drum. \n",
      "29.786211013793945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Drum. \n",
      "token:  [S2] Drum. \n",
      "19.476749420166016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Drum. \n",
      "token:  [S1] Ok. Ah I'd say violin maybe? That was the first one \n",
      "64.37383270263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. Ah I'd say violin maybe? That was the first one \n",
      "token:  [S2] mhmm I agree with you. \n",
      "14.618114471435547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm I agree with you. \n",
      "token:  [S1] you said. \n",
      "19.315792083740234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] you said. \n",
      "token:  [S2] Yeah. \n",
      "7.5395026206970215\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Then cello, drum? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.1905403137207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Then cello, drum? \n",
      "token:  [S2] mhmm \n",
      "19.340431213378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] That's correct yeah, well done! That's brilliant. \n",
      "64.50267028808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's correct yeah, well done! That's brilliant. \n",
      "token:  [S1] I just know what's the most obscure so I go for the last one ok. \n",
      "39.23000717163086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I just know what's the most obscure so I go for the last one ok. \n",
      "token:  [MOD] Perfect. Are you ready for the third question? \n",
      "26.0228328704834\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect. Are you ready for the third question? \n",
      "token:  [S2] Yes. \n",
      "16.835731506347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes. \n",
      "token:  [MOD] Yeah? \n",
      "58.09257888793945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S1] Absolutely. \n",
      "18.839496612548828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Absolutely. \n",
      "token:  [MOD] Can you please name something that people cut. \n",
      "78.8630599975586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you please name something that people cut. \n",
      "token:  [S1] Oh cucumber. \n",
      "43.85129165649414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh cucumber. \n",
      "token:  [S2] Bread? \n",
      "13.982845306396484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Bread? \n",
      "token:  [S1] Bread hmm. People's necks, no that's very bad no. They do that too, but it's \n",
      "49.49647521972656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Bread hmm. People's necks, no that's very bad no. They do that too, but it's \n",
      "token:  [S2] So is it only food or \n",
      "27.06830406188965\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So is it only food or \n",
      "token:  [MOD] No, it can be anything. \n",
      "28.59940528869629\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No, it can be anything. \n",
      "token:  [S2] no oh Oh, ok. So your hand? \n",
      "126.98851776123047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no oh Oh, ok. So your hand? \n",
      "token:  [S1] Meat. \n",
      "23.727128982543945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Meat. \n",
      "token:  [S2] As \n",
      "38.912513732910156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] As \n",
      "token:  [S1] Meat yeah \n",
      "242.67372131347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Meat yeah \n",
      "token:  [S2] Meat? \n",
      "7.135432720184326\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Meat? \n",
      "token:  [S1] hm \n",
      "19.01784324645996\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hm \n",
      "token:  [S2] Meat. \n",
      "27.903825759887695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Meat. \n",
      "token:  [S1] Cut meat, cut wire, cut rope, cut \n",
      "31.212169647216797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cut meat, cut wire, cut rope, cut \n",
      "token:  [S2] cut wire, cu \n",
      "57.32722473144531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cut wire, cu \n",
      "token:  [S1] Cut the no No, no, ok so serious eh cut vegetables. \n",
      "178.39622497558594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cut the no No, no, ok so serious eh cut vegetables. \n",
      "token:  [S2] Vegetables yes. I agree, so it's for food we have eh bread perhaps, although he here it's usually slices right? yeah \n",
      "157.05548095703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Vegetables yes. I agree, so it's for food we have eh bread perhaps, although he here it's usually slices right? yeah \n",
      "token:  [MOD] slice \n",
      "405.025146484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] slice \n",
      "token:  [S1] yeah it's toast \n",
      "122.86962890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah it's toast \n",
      "token:  [MOD] bread yeah \n",
      "216.55030822753906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] bread yeah \n",
      "token:  [S2] yeah so my Greek background eh is \n",
      "379.7791748046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah so my Greek background eh is \n",
      "token:  [S1] I guess so yeah \n",
      "12.662534713745117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I guess so yeah \n",
      "token:  [S2] eh \n",
      "20.188003540039062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh \n",
      "token:  [S1] yeah a Greek background \n",
      "101.40249633789062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah a Greek background \n",
      "token:  [S2] yeah so you usually you some probably bread is not very popular \n",
      "71.8510513305664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah so you usually you some probably bread is not very popular \n",
      "token:  [S1] no \n",
      "9.026865005493164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] no \n",
      "token:  [S2] here so food or vegetables I think right \n",
      "110.98976135253906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] here so food or vegetables I think right \n",
      "token:  [S1] yeah \n",
      "11.407279014587402\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] you are right meat and then you cut your hand or you cut the story short ok that was a bad joke \n",
      "50.67420196533203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] you are right meat and then you cut your hand or you cut the story short ok that was a bad joke \n",
      "token:  [S1] yeah I can remember I don't know what to cut cut \n",
      "28.92296028137207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah I can remember I don't know what to cut cut \n",
      "token:  [S2] Cut wire you said? \n",
      "58.53879928588867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cut wire you said? \n",
      "token:  [S1] Yeah. \n",
      "8.633230209350586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] rope \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.82054901123047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] rope \n",
      "token:  [S1] Cut paper? \n",
      "52.87858963012695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cut paper? \n",
      "token:  [S2] mhmm \n",
      "13.369482040405273\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] of course paper \n",
      "274.2367248535156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] of course paper \n",
      "token:  [S2] yes you're right. \n",
      "37.106101989746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes you're right. \n",
      "token:  [S1] paper cut \n",
      "48.246864318847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] paper cut \n",
      "token:  [MOD] mhmm \n",
      "77.66343688964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] \n",
      "18.500125885009766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] You already have two. \n",
      "71.70504760742188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You already have two. \n",
      "token:  [S2] Two. \n",
      "34.1003303527832\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Two. \n",
      "token:  [S1] what the first one \n",
      "46.07619857788086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] what the first one \n",
      "token:  [MOD] You have meat and paper \n",
      "289.0868225097656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have meat and paper \n",
      "token:  [S1] meat meat paper vegetables are \n",
      "86.84696197509766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat meat paper vegetables are \n",
      "token:  [S2] meat and paper ok \n",
      "13.415077209472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] meat and paper ok \n",
      "token:  [S1] not ok \n",
      "13.170793533325195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] not ok \n",
      "token:  [S2] So \n",
      "22.14764976501465\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So \n",
      "token:  [MOD] I'll let you select the third \n",
      "78.96002960205078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'll let you select the third \n",
      "token:  [S2] because you found both of these so thank you \n",
      "114.82450103759766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] because you found both of these so thank you \n",
      "token:  [S1] Thank you \n",
      "9.6753511428833\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Thank you \n",
      "token:  [S2] meat pa per what else do we cut Cut with a knife or with a \n",
      "160.3390350341797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] meat pa per what else do we cut Cut with a knife or with a \n",
      "token:  [S1] cut Would you cut wood? Yeah you yeah you can cut wood \n",
      "49.57606887817383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cut Would you cut wood? Yeah you yeah you can cut wood \n",
      "token:  [S2] you cut wood yes \n",
      "11.443445205688477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] you cut wood yes \n",
      "token:  [S1] Cut grass of course, we're in Ireland. \n",
      "44.01866912841797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cut grass of course, we're in Ireland. \n",
      "token:  [S2] of course of course No? No! \n",
      "25.159772872924805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] of course of course No? No! \n",
      "token:  [MOD] Sorry. \n",
      "65.90170288085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Sorry. \n",
      "token:  [S2] They don't cut the grass? \n",
      "35.92353057861328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] They don't cut the grass? \n",
      "token:  [S1] But it's so good so cu t \n",
      "78.98194122314453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But it's so good so cu t \n",
      "token:  [MOD] Think of something both men and women cut. and \n",
      "134.49639892578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think of something both men and women cut. and \n",
      "token:  [S2] ah of course \n",
      "115.27836608886719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah of course \n",
      "token:  [S1] Oh hair. \n",
      "44.80005645751953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh hair. \n",
      "token:  [S2] Yeah. \n",
      "5.081119060516357\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] jesus \n",
      "15.259920120239258\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] jesus \n",
      "token:  [S2] How should I know? \n",
      "18.041685104370117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] How should I know? \n",
      "token:  [MOD] So these are the three answers \n",
      "94.53897094726562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So these are the three answers \n",
      "token:  [S1] Oh very good. \n",
      "43.365264892578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh very good. \n",
      "token:  [S2] Ok. \n",
      "6.66367769241333\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] So how do we rank them? \n",
      "8.437307357788086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So how do we rank them? \n",
      "token:  [S2] Maybe hair \n",
      "108.00933074951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Maybe hair \n",
      "token:  [S1] hmm \n",
      "17.041173934936523\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] What do you think? \n",
      "5.40906286239624\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] What do you think? \n",
      "token:  [S1] ok \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.770164489746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] But I'm not \n",
      "16.386554718017578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] But I'm not \n",
      "token:  [S1] yeah \n",
      "21.03838348388672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] hundred per cent sure. \n",
      "34.34004211425781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hundred per cent sure. \n",
      "token:  [S1] Yeah me \n",
      "52.87065887451172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah me \n",
      "token:  [S2] so we have hair, paper \n",
      "86.27613067626953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so we have hair, paper \n",
      "token:  [S1] neither cause we didn't think of that at first \n",
      "46.35354232788086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] neither cause we didn't think of that at first \n",
      "token:  [S2] yes \n",
      "7.192375183105469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes \n",
      "token:  [S1] yeah. \n",
      "14.846429824829102\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah. \n",
      "token:  [S2] yes so we have hair, paper and meat. Hair, paper and meat. So let's I have a very scientific approach let's \n",
      "54.01911544799805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes so we have hair, paper and meat. Hair, paper and meat. So let's I have a very scientific approach let's \n",
      "token:  [S1] ok \n",
      "32.674381256103516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] rank them alphabetically. Hair, meat, paper. \n",
      "82.8816146850586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] rank them alphabetically. Hair, meat, paper. \n",
      "token:  [S1] it's like it's like stone, scissors, pa oh \n",
      "95.20914459228516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it's like it's like stone, scissors, pa oh \n",
      "token:  [S2] or maybe paper is a Yeah maybe paper is more than meat what do you think? \n",
      "45.86532211303711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] or maybe paper is a Yeah maybe paper is more than meat what do you think? \n",
      "token:  [S1] paper it's more than it covers meat yeah so it could be \n",
      "34.53843688964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] paper it's more than it covers meat yeah so it could be \n",
      "token:  [S2] yeah \n",
      "12.755105018615723\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] paper \n",
      "32.83262252807617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] paper \n",
      "token:  [S2] the answer \n",
      "12.295666694641113\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the answer \n",
      "token:  [S1] meat well le let's go with what we found, so meat would be the first one then paper and hair. \n",
      "100.947509765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat well le let's go with what we found, so meat would be the first one then paper and hair. \n",
      "token:  [S2] Yeah. Yeah. \n",
      "12.093656539916992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. Yeah. \n",
      "token:  [S1] But that's probably not \n",
      "16.749109268188477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But that's probably not \n",
      "token:  [MOD] Are you sure? \n",
      "39.18824768066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Are you sure? \n",
      "token:  [S1] Is that our final answer? No we're not of course we're not. I just I don't know. I guess the first thing that comes to my mind is cutting food so \n",
      "25.434085845947266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Is that our final answer? No we're not of course we're not. I just I don't know. I guess the first thing that comes to my mind is cutting food so \n",
      "token:  [MOD] hmm \n",
      "122.24584197998047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] but it could be ahm \n",
      "55.3289680480957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but it could be ahm \n",
      "token:  [S2] hmm \n",
      "5.285541534423828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] you know I don't know to eat. \n",
      "28.35164451599121\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] you know I don't know to eat. \n",
      "token:  [S2] No let's let's go with meat then maybe hair and paper? because we tried other way and it didn't work \n",
      "65.46906280517578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No let's let's go with meat then maybe hair and paper? because we tried other way and it didn't work \n",
      "token:  [S1] We're just kind of reading her verbal ah non-verbal commnunication ah ok so meat \n",
      "106.04920959472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] We're just kind of reading her verbal ah non-verbal commnunication ah ok so meat \n",
      "token:  [S2] But I'm not very confident really I \n",
      "35.63187026977539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] But I'm not very confident really I \n",
      "token:  [S1] not me I'm not confident I'm \n",
      "17.07335662841797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] not me I'm not confident I'm \n",
      "token:  [S2] ok \n",
      "12.276707649230957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] super uncon \n",
      "163.46823120117188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] super uncon \n",
      "token:  [S2] fident \n",
      "34.627872467041016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] fident \n",
      "token:  [S1] We're just trying things out there. it's a very \n",
      "40.21133804321289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] We're just trying things out there. it's a very \n",
      "token:  [S2] important decision so I think \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.67164611816406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] important decision so I think \n",
      "token:  [S1] It is it is ok so meat \n",
      "76.00321960449219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] It is it is ok so meat \n",
      "token:  [S2] e e \n",
      "26.548921585083008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] e e \n",
      "token:  [S1] first \n",
      "24.357419967651367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] first \n",
      "token:  [S2] meat, hair and paper \n",
      "72.68701934814453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] meat, hair and paper \n",
      "token:  [S1] Meat, hair, paper. \n",
      "8.974527359008789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Meat, hair, paper. \n",
      "token:  [MOD] Ok, I'm sorry. \n",
      "23.961132049560547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok, I'm sorry. \n",
      "token:  [S1] Oh! \n",
      "26.410036087036133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh! \n",
      "token:  [MOD] The first one is hair then it's paper and then it's meat. \n",
      "54.861549377441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] The first one is hair then it's paper and then it's meat. \n",
      "token:  [S2] Oh we did it \n",
      "66.1713638305664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh we did it \n",
      "token:  [MOD] But you did gr \n",
      "259.6026306152344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But you did gr \n",
      "token:  [S2] totally wrong. \n",
      "73.93754577636719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] totally wrong. \n",
      "token:  [MOD] eat now come on, you found all of them. Well done. \n",
      "70.03080749511719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] eat now come on, you found all of them. Well done. \n",
      "token:  [S1] You know these people that say hair are vain, I'm just gonna put it out there, cause that's all they think about, I think about food, which is most important \n",
      "35.7906608581543\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] You know these people that say hair are vain, I'm just gonna put it out there, cause that's all they think about, I think about food, which is most important \n",
      "token:  [MOD] hmm \n",
      "80.86003875732422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] so I think we win. \n",
      "40.66761016845703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so I think we win. \n",
      "token:  [MOD] Well done. I hope you enjoyed that and thanks for \n",
      "43.98360824584961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well done. I hope you enjoyed that and thanks for \n",
      "token:  [S1] Yeah we did. \n",
      "48.38325119018555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah we did. \n",
      "token:  [MOD] coming again \n",
      "327.4972229003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] coming again \n",
      "token:  [S1] Thank you. \n",
      "22.268503189086914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Thank you. \n",
      "token:  [S2] Ok.\n",
      "7.954718589782715\n",
      "MOD : 118.32493306549502\n",
      "S1 : 54.799971132567435\n",
      "S2 : 66.10241195505316\n",
      "speech transcription_Transcriber/S19.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Perfect. Well hi guys. Welcome. \n",
      "205.48336791992188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect. Well hi guys. Welcome. \n",
      "token:  [S1] Hi. \n",
      "15.986151695251465\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hi. \n",
      "token:  [S2] Hi. Thanks for coming here today. so we're going to play a quiz. I'm going to ask you three survey questions that were previously posed to a group of hundred people. \n",
      "15.062910079956055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hi. Thanks for coming here today. so we're going to play a quiz. I'm going to ask you three survey questions that were previously posed to a group of hundred people. \n",
      "token:  [S1] mhmm \n",
      "22.55482292175293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] you'll have to give me the three most popular answers and after talking to each other you'll have to order these answers in terms of popularity. o k? \n",
      "44.771873474121094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you'll have to give me the three most popular answers and after talking to each other you'll have to order these answers in terms of popularity. o k? \n",
      "token:  [S2] Ok the ones that we think are the three most popular answers. I'll let you know if they are correct or no \n",
      "21.195884704589844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok the ones that we think are the three most popular answers. I'll let you know if they are correct or no \n",
      "token:  [S2] ok. \n",
      "9.1782865524292\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] t and then you'll have to order them. Yeah? You'll ra ank them from the ok. most popular to the least popular. \n",
      "116.02792358398438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] t and then you'll have to order them. Yeah? You'll ra ank them from the ok. most popular to the least popular. \n",
      "token:  [S2] Yeah to the least popular. In collaboration? \n",
      "58.075435638427734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah to the least popular. In collaboration? \n",
      "token:  [MOD] Yes you \n",
      "135.86155700683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes you \n",
      "token:  [S1] Yep. \n",
      "56.676177978515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yep. \n",
      "token:  [MOD] have to talk to \n",
      "105.74810028076172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] have to talk to \n",
      "token:  [S1] Yep. \n",
      "85.64203643798828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yep. \n",
      "token:  [MOD] each other. \n",
      "89.5040283203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] each other. \n",
      "token:  [S2] ok. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.85484313964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] Is it clear? Ye \n",
      "191.41432189941406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Is it clear? Ye \n",
      "token:  [S1] Yep. \n",
      "57.41337203979492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yep. \n",
      "token:  [MOD] ah. \n",
      "80.26112365722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ah. \n",
      "token:  [S2] Yes yeah. \n",
      "48.50630569458008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes yeah. \n",
      "token:  [MOD] ok \n",
      "164.3433380126953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok \n",
      "token:  [S1] Think so yeah. \n",
      "101.45918273925781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Think so yeah. \n",
      "token:  [MOD] So First question. Name a public place where you're likely to catch a cold or a flu bug. \n",
      "47.39030838012695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So First question. Name a public place where you're likely to catch a cold or a flu bug. \n",
      "token:  [S1] Cold or a flu. \n",
      "24.228561401367188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cold or a flu. \n",
      "token:  [S2] Ok. \n",
      "9.439906120300293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] Public place. \n",
      "137.40052795410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Public place. \n",
      "token:  [S2] A public place ok. And we just come up with the \n",
      "68.65743255615234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A public place ok. And we just come up with the \n",
      "token:  [MOD] Yeah? o \n",
      "375.8084411621094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? o \n",
      "token:  [S1] Yeah. \n",
      "24.18967056274414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] k \n",
      "27.576669692993164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] k \n",
      "token:  [S1] Public transport? \n",
      "40.50315856933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Public transport? \n",
      "token:  [S2] Public transport a nd a plane. \n",
      "20.443927764892578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Public transport a nd a plane. \n",
      "token:  [S1] I don't think that would Yeah. \n",
      "34.711124420166016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't think that would Yeah. \n",
      "token:  [S2] It could be a plane. \n",
      "16.22300910949707\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It could be a plane. \n",
      "token:  [S1] Yeah an airplane. \n",
      "14.041542053222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah an airplane. \n",
      "token:  [MOD] That's great. That's one answer. Perfect. \n",
      "35.01048278808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's great. That's one answer. Perfect. \n",
      "token:  [S2] A public transport in general? \n",
      "109.18702697753906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A public transport in general? \n",
      "token:  [MOD] No plane is \n",
      "424.0498352050781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No plane is \n",
      "token:  [S1] oh ok. \n",
      "80.88063049316406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh ok. \n",
      "token:  [MOD] is good yeah. \n",
      "86.02787780761719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] is good yeah. \n",
      "token:  [S2] Oh ok. \n",
      "33.21217727661133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh ok. \n",
      "token:  [S1] \n",
      "10.507535934448242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] It could also be somewhere like it's very exposed as in like or where it's cold. \n",
      "68.5067367553711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It could also be somewhere like it's very exposed as in like or where it's cold. \n",
      "token:  [S1] hospital? \n",
      "42.25761032104492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hospital? \n",
      "token:  [MOD] That's good. \n",
      "30.768802642822266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's good. \n",
      "token:  [S2] oh \n",
      "89.30000305175781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh \n",
      "token:  [MOD] Yeah. \n",
      "103.09698486328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] Yeah. \n",
      "10.67185115814209\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] That's another answer. \n",
      "34.04950714111328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's another answer. \n",
      "token:  [S2] A hospital yes. \n",
      "130.11264038085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A hospital yes. \n",
      "token:  [MOD] Very good. \n",
      "40.67410659790039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good. \n",
      "token:  [S1] \n",
      "24.83478355407715\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] So you have two answers so far. The third missing. \n",
      "75.00679779052734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have two answers so far. The third missing. \n",
      "token:  [S1] Do you've any ideas? \n",
      "32.81201934814453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Do you've any ideas? \n",
      "token:  [S2] I don't know like a swimming pool or some thing. \n",
      "17.17719078063965\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know like a swimming pool or some thing. \n",
      "token:  [MOD] hmm think of f different age groups. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167.98306274414062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm think of f different age groups. \n",
      "token:  [S2] Different age groups as \n",
      "66.59906005859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Different age groups as \n",
      "token:  [MOD] Think about \n",
      "125.22139739990234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think about \n",
      "token:  [S2] in \n",
      "36.22412872314453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] in \n",
      "token:  [MOD] ch children for example. \n",
      "406.5423278808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ch children for example. \n",
      "token:  [S1] Oh a \n",
      "146.9903564453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh a \n",
      "token:  [S2] school. \n",
      "17.732257843017578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] school. \n",
      "token:  [S1] school. \n",
      "5.825679302215576\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] school. \n",
      "token:  [S2] Yes yeah yeah \n",
      "54.203033447265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes yeah yeah \n",
      "token:  [S1] There we go \n",
      "12.91187572479248\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] There we go \n",
      "token:  [MOD] That's good. Yeah you found all three ans ers \n",
      "114.43624877929688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's good. Yeah you found all three ans ers \n",
      "token:  [S2] top three \n",
      "73.80928802490234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] top three \n",
      "token:  [S1] ok \n",
      "33.230735778808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] So now \n",
      "112.10299682617188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So now \n",
      "token:  [S2] ok \n",
      "109.96094512939453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] you have to rank them in terms of popularity. \n",
      "38.33866500854492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you have to rank them in terms of popularity. \n",
      "token:  [S1] Ok. \n",
      "27.242958068847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] Oh popularity. \n",
      "36.19191360473633\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh popularity. \n",
      "token:  [MOD] Which one was the most popular answer? \n",
      "23.090614318847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Which one was the most popular answer? \n",
      "token:  [S2] Proba bly hospital first? \n",
      "470.7619934082031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Proba bly hospital first? \n",
      "token:  [S1] Yeah. \n",
      "10.727660179138184\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] What d' you an hosp yeah like \n",
      "288.4065246582031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] What d' you an hosp yeah like \n",
      "token:  [S1] Maybe hospitals \n",
      "102.413818359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Maybe hospitals \n",
      "token:  [S2] school and plane? \n",
      "58.29392623901367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] school and plane? \n",
      "token:  [S1] Yeah. That's what I think. \n",
      "10.504204750061035\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. That's what I think. \n",
      "token:  [S2] What did that's whaat you think yeah yeah yeah \n",
      "53.00737762451172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] What did that's whaat you think yeah yeah yeah \n",
      "token:  [S1] Yeah yeah no that sou that s ounds right. \n",
      "73.40016174316406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah yeah no that sou that s ounds right. \n",
      "token:  [MOD] Are you sure? \n",
      "17.54012680053711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Are you sure? \n",
      "token:  [S1] Yeah. It's wrong. \n",
      "18.131223678588867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. It's wrong. \n",
      "token:  [MOD] Almost. \n",
      "47.30519104003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Almost. \n",
      "token:  [S1] Ah \n",
      "132.0673065185547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ah \n",
      "token:  [MOD] You were almost \n",
      "190.80003356933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You were almost \n",
      "token:  [S2] Almost \n",
      "58.70649337768555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Almost \n",
      "token:  [MOD] First one \n",
      "137.40582275390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] First one \n",
      "token:  [S2] why which one \n",
      "161.4554901123047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] why which one \n",
      "token:  [MOD] is the school \n",
      "131.24229431152344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] is the school \n",
      "token:  [S1] Oh really? \n",
      "86.29303741455078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh really? \n",
      "token:  [S2] Oh re eally? \n",
      "30.501447677612305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh re eally? \n",
      "token:  [MOD] Yeah. Yeah yeah yeah. \n",
      "29.277273178100586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. Yeah yeah yeah. \n",
      "token:  [S1] Wow. \n",
      "16.78788185119629\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Wow. \n",
      "token:  [MOD] The second one is hospital and the third is the plane. So you just missed \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.28202056884766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] The second one is hospital and the third is the plane. So you just missed \n",
      "token:  [S2] ok. \n",
      "84.4184341430664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] the first two but \n",
      "167.33168029785156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the first two but \n",
      "token:  [S1] Yeah. \n",
      "68.21853637695312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Yeah. \n",
      "18.43769073486328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] ok. \n",
      "31.74310302734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [S1] I wouldn't have thought of plane. \n",
      "24.93307113647461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I wouldn't have thought of plane. \n",
      "token:  [MOD] You ready for the second one? The second question? \n",
      "43.05246353149414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You ready for the second one? The second question? \n",
      "token:  [S1] Yeah sure yeah. \n",
      "40.64386749267578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah sure yeah. \n",
      "token:  [MOD] Name an instrument you can find in a symphony orchestra. \n",
      "38.471458435058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Name an instrument you can find in a symphony orchestra. \n",
      "token:  [S2] A violin? \n",
      "34.5045166015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A violin? \n",
      "token:  [MOD] Perfect. \n",
      "64.61629486083984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect. \n",
      "token:  [S1] Yeah. \n",
      "25.039268493652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] \n",
      "12.096805572509766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] That's correct. \n",
      "34.788150787353516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's correct. \n",
      "token:  [S2] A a saxophone? \n",
      "72.90139770507812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A a saxophone? \n",
      "token:  [S1] n \n",
      "26.104833602905273\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] n \n",
      "token:  [S2] hmm not necessarily no well a flute? \n",
      "123.8652572631836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm not necessarily no well a flute? \n",
      "token:  [S1] hmm sy phony or there is one more \n",
      "100.580322265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm sy phony or there is one more \n",
      "token:  [S2] in a symphonic orchestra? \n",
      "19.840688705444336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] in a symphonic orchestra? \n",
      "token:  [MOD] A symphony orchestra yeah. \n",
      "51.7940788269043\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] A symphony orchestra yeah. \n",
      "token:  [S1] There's one piano isn't there? \n",
      "26.887224197387695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] There's one piano isn't there? \n",
      "token:  [S2] Not always. \n",
      "11.909966468811035\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Not always. \n",
      "token:  [S1] Oh \n",
      "25.996013641357422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh \n",
      "token:  [S2] Only if there \n",
      "31.285396575927734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Only if there \n",
      "token:  [S1] ok. \n",
      "18.164018630981445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok. \n",
      "token:  [S2] is a eh only if there is like it's a specific symphony f or piano \n",
      "82.4002685546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] is a eh only if there is like it's a specific symphony f or piano \n",
      "token:  [S1] Oh ok. but Well \n",
      "83.15693664550781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh ok. but Well \n",
      "token:  [S2] well the \n",
      "26.67740821838379\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] well the \n",
      "token:  [S1] we've one string instrument so one \n",
      "74.4839096069336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] we've one string instrument so one \n",
      "token:  [S2] Yeah well the cello. \n",
      "24.327890396118164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah well the cello. \n",
      "token:  [MOD] That's good yeah that's the second one. Violin, cello and \n",
      "48.90852355957031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's good yeah that's the second one. Violin, cello and \n",
      "token:  [S1] Violin c ello \n",
      "104.8240966796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin c ello \n",
      "token:  [MOD] Think of a different a complete different instrument, no strings. \n",
      "157.92080688476562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think of a different a complete different instrument, no strings. \n",
      "token:  [S2] ok. I used to know these things. \n",
      "47.846435546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. I used to know these things. \n",
      "token:  [MOD] \n",
      "74.80895233154297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [S2] I don't know. \n",
      "17.830629348754883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know. \n",
      "token:  [S1] You sound like you know more than I do anyway. \n",
      "9.232637405395508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] You sound like you know more than I do anyway. \n",
      "token:  [S2] The harp? Oh well that's also string. \n",
      "51.66621780395508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The harp? Oh well that's also string. \n",
      "token:  [MOD] hmm \n",
      "122.75631713867188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] and th there's eh well one of those eh trumpet a trumpet eh eh cla \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501.3931579589844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and th there's eh well one of those eh trumpet a trumpet eh eh cla \n",
      "token:  [S1] Clarinet. \n",
      "62.206398010253906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Clarinet. \n",
      "token:  [S2] arinet clari \n",
      "97.63428497314453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] arinet clari \n",
      "token:  [MOD] No \n",
      "142.64065551757812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No \n",
      "token:  [S2] net \n",
      "138.57177734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] net \n",
      "token:  [S1] No. \n",
      "16.643024444580078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No. \n",
      "token:  [MOD] It's a very different instrument from these. \n",
      "76.1509780883789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's a very different instrument from these. \n",
      "token:  [S1] Oh. \n",
      "23.67232894897461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh. \n",
      "token:  [MOD] You might need a stick or use your hands to to hit the instrument. \n",
      "71.97045135498047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You might need a stick or use your hands to to hit the instrument. \n",
      "token:  [S1] Oh a drum? \n",
      "50.0056266784668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh a drum? \n",
      "token:  [MOD] A \n",
      "120.58910369873047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] A \n",
      "token:  [S2] A drum. \n",
      "189.392333984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A drum. \n",
      "token:  [MOD] drum. \n",
      "97.38910675048828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] drum. \n",
      "token:  [S2] Oh \n",
      "124.86109161376953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh \n",
      "token:  [S1] Yeah. \n",
      "10.809792518615723\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] That's great. \n",
      "17.736196517944336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's great. \n",
      "token:  [S2] kay alright. \n",
      "180.40774536132812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] kay alright. \n",
      "token:  [MOD] So you have three answers, do you remember them? The drum \n",
      "89.6436538696289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have three answers, do you remember them? The drum \n",
      "token:  [S2] The drum, the violin \n",
      "41.76267623901367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The drum, the violin \n",
      "token:  [MOD] and \n",
      "125.47955322265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and \n",
      "token:  [S2] and the c \n",
      "125.4598159790039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and the c \n",
      "token:  [MOD] cello. \n",
      "504.68505859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] cello. \n",
      "token:  [S2] ello ok. \n",
      "71.72785186767578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ello ok. \n",
      "token:  [MOD] Can you order them please in terms of popularity? \n",
      "63.325870513916016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you order them please in terms of popularity? \n",
      "token:  [S2] In order of popularity. \n",
      "25.55471420288086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] In order of popularity. \n",
      "token:  [MOD] Yeah. \n",
      "95.06905364990234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] Violin \n",
      "100.75596618652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin \n",
      "token:  [S2] I think the violin is the most obvious \n",
      "15.66834545135498\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think the violin is the most obvious \n",
      "token:  [S1] I think the yeah yeah \n",
      "33.0327262878418\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think the yeah yeah \n",
      "token:  [S2] one yeah. and \n",
      "42.44586181640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] one yeah. and \n",
      "token:  [S1] A drum or cello? \n",
      "50.66108322143555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] A drum or cello? \n",
      "token:  [S2] I eh yeah I think bu I think violin is the most obvious one and so it has to be between the \n",
      "72.989990234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I eh yeah I think bu I think violin is the most obvious one and so it has to be between the \n",
      "token:  [S1] Yeah yeah I think so too I think so too. \n",
      "14.688825607299805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah yeah I think so too I think so too. \n",
      "token:  [S2] drum and the cello. \n",
      "61.08751678466797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] drum and the cello. \n",
      "token:  [S1] Yeah Drum or the cello? \n",
      "14.288603782653809\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah Drum or the cello? \n",
      "token:  [S2] I would think that the cello's probab \n",
      "21.267662048339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I would think that the cello's probab \n",
      "token:  [S1] ly more pop \n",
      "159.13966369628906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ly more pop \n",
      "token:  [S2] Yeah I don't think ular. \n",
      "30.77035140991211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah I don't think ular. \n",
      "token:  [S1] Drum \n",
      "99.16962432861328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Drum \n",
      "token:  [S2] Drum doesn't real \n",
      "39.53378677368164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Drum doesn't real \n",
      "token:  [S1] ly yeah Drum i \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158.74769592285156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ly yeah Drum i \n",
      "token:  [S2] ah is more like for a rock band. \n",
      "39.97986602783203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah is more like for a rock band. \n",
      "token:  [S1] Yeah \n",
      "15.227802276611328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah \n",
      "token:  [S2] You know like you don't this is not the first thing that comes to mind with a symphony orchestra. \n",
      "17.776859283447266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You know like you don't this is not the first thing that comes to mind with a symphony orchestra. \n",
      "token:  [S1] So we've violin cello and drum. \n",
      "52.44007110595703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So we've violin cello and drum. \n",
      "token:  [S2] Yeah. \n",
      "4.790886878967285\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Yeah. \n",
      "3.1081197261810303\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Yeah do you both agree? \n",
      "64.67137145996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah do you both agree? \n",
      "token:  [S1] Yeah. \n",
      "12.969062805175781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Perfect guys. That's correc \n",
      "379.26739501953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect guys. That's correc \n",
      "token:  [S1] Great. \n",
      "63.40376281738281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Great. \n",
      "token:  [MOD] t well done. we've one left Very good. And the third question and the last one. \n",
      "108.59646606445312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] t well done. we've one left Very good. And the third question and the last one. \n",
      "token:  [S1] mhmm \n",
      "35.05289840698242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] Name something that people cut. \n",
      "181.6175079345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Name something that people cut. \n",
      "token:  [S2] That people c \n",
      "261.7072448730469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] That people c \n",
      "token:  [MOD] cut What would they cut? \n",
      "378.84967041015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] cut What would they cut? \n",
      "token:  [S2] Oh cut as in \n",
      "144.05316162109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh cut as in \n",
      "token:  [MOD] Yeah. \n",
      "120.13604736328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] like cut in oh well a steak? \n",
      "402.4707946777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] like cut in oh well a steak? \n",
      "token:  [MOD] \n",
      "60.234920501708984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [S2] Paper? \n",
      "137.40333557128906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Paper? \n",
      "token:  [S1] Paper yeah. \n",
      "20.210081100463867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Paper yeah. \n",
      "token:  [S2] Paper \n",
      "10.597555160522461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Paper \n",
      "token:  [S1] I think pa \n",
      "67.06381225585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think pa \n",
      "token:  [MOD] That's \n",
      "100.83223724365234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's \n",
      "token:  [S1] per \n",
      "100.44114685058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] per \n",
      "token:  [MOD] correct paper is one of the answers. \n",
      "132.77540588378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] correct paper is one of the answers. \n",
      "token:  [S1] hmm \n",
      "50.507015228271484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] I don't know fabric? \n",
      "23.55133628845215\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know fabric? \n",
      "token:  [MOD] mhmm \n",
      "72.95199584960938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S2] hmm \n",
      "25.083890914916992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] No? maybe the \n",
      "65.93533325195312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No? maybe the \n",
      "token:  [MOD] No. \n",
      "105.99304962158203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S1] It's the w ood like firewood. \n",
      "97.64537048339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] It's the w ood like firewood. \n",
      "token:  [S2] Wood yeah. \n",
      "25.188812255859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Wood yeah. \n",
      "token:  [S1] You know? No \n",
      "20.291217803955078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] You know? No \n",
      "token:  [S2] Wood no for a \n",
      "131.01681518554688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Wood no for a \n",
      "token:  [S1] \n",
      "11.142515182495117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] \n",
      "39.93152618408203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [S2] Oh your skin as in like paper cuts? or some or \n",
      "436.2165832519531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh your skin as in like paper cuts? or some or \n",
      "token:  [MOD] It could be. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.06706237792969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It could be. \n",
      "token:  [S2] or when y \n",
      "228.9556884765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] or when y \n",
      "token:  [MOD] It could \n",
      "408.6750793457031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It could \n",
      "token:  [S2] you're shaving. When you \n",
      "95.26500701904297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] you're shaving. When you \n",
      "token:  [S1] Like an injury yeah. \n",
      "95.48516845703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Like an injury yeah. \n",
      "token:  [S2] shave and you get a cut no? No? \n",
      "42.07748031616211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] shave and you get a cut no? No? \n",
      "token:  [MOD] no. \n",
      "41.33537292480469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no. \n",
      "token:  [S1] \n",
      "25.761812210083008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] Think of the you \n",
      "175.4733428955078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think of the you \n",
      "token:  [S2] No \n",
      "62.55498504638672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No \n",
      "token:  [MOD] mentioned steak so something more general. \n",
      "847.9274291992188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mentioned steak so something more general. \n",
      "token:  [S2] Food? Meat? \n",
      "49.941768646240234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Food? Meat? \n",
      "token:  [MOD] eh i meat. \n",
      "466.522216796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] eh i meat. \n",
      "token:  [S2] Meat. \n",
      "29.640581130981445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Meat. \n",
      "token:  [MOD] Yeah and you have one more answer missing. \n",
      "91.92900848388672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah and you have one more answer missing. \n",
      "token:  [S1] Food? Are we still \n",
      "140.56300354003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Food? Are we still \n",
      "token:  [S2] Is is i is the other one food \n",
      "100.28579711914062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Is is i is the other one food \n",
      "token:  [S1] food related \n",
      "32.706932067871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] food related \n",
      "token:  [S2] related or \n",
      "35.83649826049805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] related or \n",
      "token:  [MOD] No. \n",
      "106.07566833496094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S1] No. \n",
      "17.284198760986328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No. \n",
      "token:  [S2] No. And it's not wood? Not firewood? \n",
      "36.64309310913086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No. And it's not wood? Not firewood? \n",
      "token:  [MOD] It's something that has to do with appearance. \n",
      "21.511077880859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's something that has to do with appearance. \n",
      "token:  [S1] Appearance? Oh hair. Yeah. \n",
      "85.63562774658203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Appearance? Oh hair. Yeah. \n",
      "token:  [S2] ok. \n",
      "21.254854202270508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] Yeah. \n",
      "46.47164535522461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] Cut your \n",
      "152.69717407226562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cut your \n",
      "token:  [S1] Yeah. \n",
      "9.535005569458008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] hair yes \n",
      "152.62612915039062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair yes \n",
      "token:  [MOD] That's great \n",
      "57.38977813720703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's great \n",
      "token:  [S2] yeah yeah \n",
      "64.77059173583984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah yeah \n",
      "token:  [S1] Yeah. \n",
      "11.2760591506958\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Perfect, so you have all \n",
      "96.7010498046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect, so you have all \n",
      "token:  [S2] Ok very good. \n",
      "80.24130249023438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok very good. \n",
      "token:  [MOD] three answers. \n",
      "135.34561157226562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] three answers. \n",
      "token:  [S2] Ok. \n",
      "46.54459762573242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] Ok. \n",
      "4.397305488586426\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Would you rank them now? \n",
      "56.51054000854492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Would you rank them now? \n",
      "token:  [S1] I think hair \n",
      "184.3394317626953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think hair \n",
      "token:  [S2] You think hair \n",
      "9.949020385742188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You think hair \n",
      "token:  [S1] might be \n",
      "11.238950729370117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] might be \n",
      "token:  [S2] is the most \n",
      "12.92011547088623\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] is the most \n",
      "token:  [S1] m the most way yeah \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.23682403564453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] m the most way yeah \n",
      "token:  [S2] So is is a gain it's hai \n",
      "109.33958435058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So is is a gain it's hai \n",
      "token:  [S1] in \n",
      "27.311279296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] in \n",
      "token:  [S2] air \n",
      "38.894065856933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] air \n",
      "token:  [MOD] Meat \n",
      "357.3693542480469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Meat \n",
      "token:  [S2] eh me \n",
      "228.08546447753906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh me \n",
      "token:  [S1] eat \n",
      "18.648168563842773\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] eat \n",
      "token:  [MOD] Hair, meat \n",
      "488.86236572265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Hair, meat \n",
      "token:  [S1] and \n",
      "33.31447982788086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and \n",
      "token:  [MOD] paper paper \n",
      "350.8941345214844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] paper paper \n",
      "token:  [S1] Paper though paper though yeah yeah yeah \n",
      "47.96315383911133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Paper though paper though yeah yeah yeah \n",
      "token:  [S2] I think paper is p I think it's paper is more pop I think \n",
      "32.96916198730469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think paper is p I think it's paper is more pop I think \n",
      "token:  [S1] More popular than hair yeah yeah I agree. \n",
      "63.18157958984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] More popular than hair yeah yeah I agree. \n",
      "token:  [S2] Probably paper maybe \n",
      "34.58881759643555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Probably paper maybe \n",
      "token:  [S1] Paper \n",
      "12.015213012695312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Paper \n",
      "token:  [S2] hair \n",
      "38.11368179321289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair \n",
      "token:  [S1] hair and then meat. \n",
      "55.48984909057617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hair and then meat. \n",
      "token:  [S2] meat. \n",
      "8.73188304901123\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] meat. \n",
      "token:  [S1] That's all of them. \n",
      "11.454447746276855\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] That's all of them. \n",
      "token:  [S2] Ok I think paper is the most obvious one. \n",
      "12.302937507629395\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok I think paper is the most obvious one. \n",
      "token:  [S1] Yeah I think so too. \n",
      "6.8674421310424805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah I think so too. \n",
      "token:  [S2] Pape and then \n",
      "54.08942413330078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Pape and then \n",
      "token:  [S1] Yeah yeah hair \n",
      "81.46206665039062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah yeah hair \n",
      "token:  [S2] between he meat and hair. I think it depends who you ask. If you're very stylish eh eh sty you know like say stylish or v ery you know like fashion aware you know \n",
      "127.67626190185547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] between he meat and hair. I think it depends who you ask. If you're very stylish eh eh sty you know like say stylish or v ery you know like fashion aware you know \n",
      "token:  [S1] Hair's gonna be first yeah \n",
      "114.94441986083984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hair's gonna be first yeah \n",
      "token:  [S2] if you are more like a foodie \n",
      "38.388065338134766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] if you are more like a foodie \n",
      "token:  [S1] Yeah \n",
      "27.907217025756836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah \n",
      "token:  [S2] you like eating a lot. What like overall I don't know actually . \n",
      "83.11357116699219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] you like eating a lot. What like overall I don't know actually . \n",
      "token:  [S1] I don't know either. \n",
      "6.24167013168335\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't know either. \n",
      "token:  [S2] \n",
      "9.304192543029785\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] I think hair. \n",
      "49.80006408691406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think hair. \n",
      "token:  [S2] You think hair? \n",
      "8.709271430969238\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You think hair? \n",
      "token:  [S1] Just \n",
      "41.10211944580078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Just \n",
      "token:  [S2] Oh \n",
      "12.592385292053223\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh \n",
      "token:  [S1] personally but \n",
      "81.6787109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] personally but \n",
      "token:  [S2] ok let's go for hair for hair I'm I'm not ok that's your I I'm not too sure about about too \n",
      "66.22967529296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok let's go for hair for hair I'm I'm not ok that's your I I'm not too sure about about too \n",
      "token:  [S1] I'm not sure about the yeah \n",
      "13.757434844970703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'm not sure about the yeah \n",
      "token:  [S2] sure but let's say \n",
      "20.58755111694336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] sure but let's say \n",
      "token:  [MOD] First place is hair. The second one \n",
      "214.18751525878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] First place is hair. The second one \n",
      "token:  [S1] Oh. \n",
      "54.58482360839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh. \n",
      "token:  [MOD] No I'm Then what's the second one? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.4993896484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No I'm Then what's the second one? \n",
      "token:  [S2] I don't know like the first one no the first c is paper. \n",
      "55.05736541748047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know like the first one no the first c is paper. \n",
      "token:  [MOD] It's pape \n",
      "126.08238220214844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's pape \n",
      "token:  [S2] The \n",
      "69.95323944091797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The \n",
      "token:  [MOD] r. \n",
      "300.6296691894531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] r. \n",
      "token:  [S2] first one is paper \n",
      "332.4837646484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] first one is paper \n",
      "token:  [S1] Yeah s \n",
      "110.14319610595703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah s \n",
      "token:  [S2] the sec \n",
      "42.05268859863281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the sec \n",
      "token:  [S1] orry paper \n",
      "147.7459716796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] orry paper \n",
      "token:  [S2] hai air \n",
      "64.48255920410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hai air \n",
      "token:  [S1] a hai ir and then meat. \n",
      "96.39273834228516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] a hai ir and then meat. \n",
      "token:  [S2] and meat. Yeah. \n",
      "16.543188095092773\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and meat. Yeah. \n",
      "token:  [MOD] You were almost t almost there a gain guys. \n",
      "506.75823974609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You were almost t almost there a gain guys. \n",
      "token:  [S2] Almost there no. \n",
      "40.194576263427734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Almost there no. \n",
      "token:  [MOD] The first one was hair actually. \n",
      "141.54241943359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] The first one was hair actually. \n",
      "token:  [S1] Oh! \n",
      "29.05731773376465\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh! \n",
      "token:  [MOD] And then paper and then n meat. \n",
      "388.3986511230469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And then paper and then n meat. \n",
      "token:  [S2] Who are you ask ing these questions \n",
      "111.56855010986328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Who are you ask ing these questions \n",
      "token:  [S1] You got that \n",
      "34.046504974365234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] You got that \n",
      "token:  [S2] to? \n",
      "29.050966262817383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] to? \n",
      "token:  [MOD] It was a random samp le no yeah. it's a random sam \n",
      "223.56163024902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It was a random samp le no yeah. it's a random sam \n",
      "token:  [S2] ple yeah. \n",
      "145.48243713378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ple yeah. \n",
      "token:  [MOD] But well \n",
      "368.99615478515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But well \n",
      "token:  [S2] Yeah yeah. \n",
      "59.80500030517578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah yeah. \n",
      "token:  [MOD] done guys you know? \n",
      "224.10829162597656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] done guys you know? \n",
      "token:  [S1] ok. \n",
      "28.215181350708008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok. \n",
      "token:  [MOD] At least \n",
      "114.25223541259766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] At least \n",
      "token:  [S2] ok. \n",
      "98.6622543334961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] you found it the an \n",
      "313.2267150878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you found it the an \n",
      "token:  [S1] Cool. \n",
      "63.26020050048828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cool. \n",
      "token:  [MOD] swers so good. Thank you. That was it. I hope you en \n",
      "124.91290283203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] swers so good. Thank you. That was it. I hope you en \n",
      "token:  [S2] Ok thanks. \n",
      "85.45423126220703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok thanks. \n",
      "token:  [MOD] joyed it.\n",
      "241.7943878173828\n",
      "MOD : 154.41113531709922\n",
      "S1 : 50.135205667709634\n",
      "S2 : 79.0809454336399\n",
      "speech transcription_Transcriber/S22.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Ah it's fine. Hello guys. Thanks very much for being here today. We're going to play a quiz. I'm going to ask you three questions that were previously posed to a group of hundred people. You'll have to find the three most popular answers and then you need to talk to each other, you need to collaborate in order to order these answers in terms of popularity. Is it cl \n",
      "24.974634170532227\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ah it's fine. Hello guys. Thanks very much for being here today. We're going to play a quiz. I'm going to ask you three questions that were previously posed to a group of hundred people. You'll have to find the three most popular answers and then you need to talk to each other, you need to collaborate in order to order these answers in terms of popularity. Is it cl \n",
      "token:  [S1] ok. \n",
      "48.15195846557617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok. \n",
      "token:  [MOD] ear? \n",
      "216.921630859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ear? \n",
      "token:  [S1] Yeah. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.458276748657227\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Yeah. \n",
      "4.207853317260742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Ready to start? \n",
      "32.9071044921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ready to start? \n",
      "token:  [S1] Yeah. \n",
      "19.238344192504883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Yeah. \n",
      "18.43769073486328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] Yeah. \n",
      "13.424955368041992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] So the first question is name a public place where you're likely to catch a cold or a flu bug. \n",
      "39.05392837524414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So the first question is name a public place where you're likely to catch a cold or a flu bug. \n",
      "token:  [S2] Ok. \n",
      "31.22532844543457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] A cold or a flu bug? \n",
      "5.066891670227051\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] A cold or a flu bug? \n",
      "token:  [S2] I guess a hospital is the \n",
      "26.60809898376465\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I guess a hospital is the \n",
      "token:  [MOD] That's correc \n",
      "403.72052001953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's correc \n",
      "token:  [S1] Yeah. \n",
      "59.90046310424805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] t. Very good. \n",
      "79.68400573730469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] t. Very good. \n",
      "token:  [S2] obvious one. \n",
      "87.14036560058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] obvious one. \n",
      "token:  [S1] A hospital Somewhere else you gonna be \n",
      "157.13465881347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] A hospital Somewhere else you gonna be \n",
      "token:  [S2] Public \n",
      "31.36572265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Public \n",
      "token:  [S1] around \n",
      "57.74980163574219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] around \n",
      "token:  [S2] place \n",
      "31.422489166259766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] place \n",
      "token:  [S1] sick people, around lots of people in and in close proximi \n",
      "163.52256774902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] sick people, around lots of people in and in close proximi \n",
      "token:  [S2] hmm \n",
      "25.18662452697754\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] ty then. \n",
      "37.716426849365234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ty then. \n",
      "token:  [S2] Yeah. \n",
      "9.14894962310791\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] \n",
      "11.329378128051758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] Probably college, a lecture maybe? \n",
      "76.68038177490234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Probably college, a lecture maybe? \n",
      "token:  [MOD] yeah You're ve ry close in that th \n",
      "250.30491638183594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah You're ve ry close in that th \n",
      "token:  [S2] Or close \n",
      "224.11770629882812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Or close \n",
      "token:  [MOD] is \n",
      "205.98898315429688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] is \n",
      "token:  [S2] Classroom? \n",
      "160.84727478027344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Classroom? \n",
      "token:  [MOD] Yeah. \n",
      "67.24130249023438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] Ye ah. \n",
      "53.64588165283203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ye ah. \n",
      "token:  [MOD] So it's \n",
      "66.99215698242188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So it's \n",
      "token:  [S1] Oh with kids an and unhygienic \n",
      "117.47105407714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh with kids an and unhygienic \n",
      "token:  [MOD] So it's \n",
      "60.02355194091797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So it's \n",
      "token:  [S1] mhmm A school? \n",
      "127.42731475830078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm A school? \n",
      "token:  [MOD] A school yeah very good. \n",
      "71.48716735839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] A school yeah very good. \n",
      "token:  [S2] So a school ok. \n",
      "32.57396697998047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So a school ok. \n",
      "token:  [S1] ok. \n",
      "8.061891555786133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok. \n",
      "token:  [MOD] So you have two. You need one more. \n",
      "33.6994514465332\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have two. You need one more. \n",
      "token:  [S2] Two of the to \n",
      "169.78945922851562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Two of the to \n",
      "token:  [MOD] Yeah yeah yeah yeah. \n",
      "87.4666976928711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah yeah yeah yeah. \n",
      "token:  [S2] p three? Ok. Oh we're doing fairly \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309.600830078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] p three? Ok. Oh we're doing fairly \n",
      "token:  [S1] Awh good. \n",
      "38.74245834350586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Awh good. \n",
      "token:  [MOD]  doing grea So nice. \n",
      "301.5030822753906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]  doing grea So nice. \n",
      "token:  [MOD] doing well. \n",
      "43.1670036315918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] doing well. \n",
      "token:  [S2] t. Yeah. \n",
      "77.97394561767578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] t. Yeah. \n",
      "token:  [S1] Somewhere that's gonna be dirty? Somewhere there's lots of germs arou nd s \n",
      "86.51280212402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Somewhere that's gonna be dirty? Somewhere there's lots of germs arou nd s \n",
      "token:  [S2] hmm \n",
      "55.385562896728516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] o \n",
      "26.607572555541992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] o \n",
      "token:  [MOD] Think about travelling. \n",
      "276.04473876953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think about travelling. \n",
      "token:  [S1] A train? A bus? \n",
      "19.6844482421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] A train? A bus? \n",
      "token:  [S2] Plane? \n",
      "10.099695205688477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Plane? \n",
      "token:  [MOD] Plane. Yeah. Very good. \n",
      "61.965087890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Plane. Yeah. Very good. \n",
      "token:  [S1] Awh cause it's very Yeah. \n",
      "158.53208923339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Awh cause it's very Yeah. \n",
      "token:  [MOD] So you have all three answers. \n",
      "44.897891998291016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have all three answers. \n",
      "token:  [S2] O k. \n",
      "96.66886901855469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] O k. \n",
      "token:  [S1] Ok. \n",
      "6.206825256347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] So you need to order them now in terms of \n",
      "61.34901428222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you need to order them now in terms of \n",
      "token:  [S2] Ok. \n",
      "121.09063720703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] popularity. \n",
      "239.71043395996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] popularity. \n",
      "token:  [S1] I would say \n",
      "54.07972717285156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I would say \n",
      "token:  [S2] I'd say we probably got it righ t. \n",
      "22.137619018554688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'd say we probably got it righ t. \n",
      "token:  [S1] Yeah \n",
      "15.550921440124512\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah \n",
      "token:  [S2] Ah \n",
      "11.872842788696289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah \n",
      "token:  [S1] I'd say a hospital would spr ing to mi \n",
      "243.11256408691406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'd say a hospital would spr ing to mi \n",
      "token:  [S2] Yeah. \n",
      "15.52747631072998\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] nd first. \n",
      "32.8946647644043\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] nd first. \n",
      "token:  [S2] And then what do you think? Classroom next? \n",
      "42.05614471435547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] And then what do you think? Classroom next? \n",
      "token:  [MOD] A sch ool \n",
      "250.64541625976562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] A sch ool \n",
      "token:  [S2] Or School sorry. \n",
      "383.3807067871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Or School sorry. \n",
      "token:  [S1] Eh yeah I'd I'd go with the order that we ha d. \n",
      "77.33446502685547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Eh yeah I'd I'd go with the order that we ha d. \n",
      "token:  [S2] Yeah. \n",
      "14.33836841583252\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Are you sure? Are you read \n",
      "60.61961364746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Are you sure? Are you read \n",
      "token:  [S1] I \n",
      "40.152793884277344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I \n",
      "token:  [MOD] y you re \n",
      "298.39385986328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] y you re \n",
      "token:  [S2] If it's a \n",
      "42.98057174682617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] If it's a \n",
      "token:  [S1] I'm co I reckon a hospital and then the other two could go one way or the other. \n",
      "59.432613372802734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'm co I reckon a hospital and then the other two could go one way or the other. \n",
      "token:  [S2] Yeah could go either way but \n",
      "16.537986755371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah could go either way but \n",
      "token:  [S1] But I'd be I'd be \n",
      "21.559511184692383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But I'd be I'd be \n",
      "token:  [S2] If that's the way we wen \n",
      "20.721891403198242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] If that's the way we wen \n",
      "token:  [S1] Yeah yeah exactly. \n",
      "47.750267028808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah yeah exactly. \n",
      "token:  [S2] t in ours but probably \n",
      "127.61265563964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] t in ours but probably \n",
      "token:  [MOD] So hos \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325.7045593261719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So hos \n",
      "token:  [S1] Yeah. \n",
      "65.1232681274414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] pital first then? \n",
      "478.66522216796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] pital first then? \n",
      "token:  [S2] Yeah. \n",
      "47.10780334472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Then \n",
      "14.148193359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Then \n",
      "token:  [S2] Then \n",
      "4.075507640838623\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Then \n",
      "token:  [S1] school then aeroplane. \n",
      "37.25994873046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] school then aeroplane. \n",
      "token:  [MOD] You're almost there guys. School was the first one. \n",
      "40.39791488647461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You're almost there guys. School was the first one. \n",
      "token:  [S1] Oh \n",
      "52.8604850769043\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh \n",
      "token:  [S2] Alright \n",
      "14.462769508361816\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Alright \n",
      "token:  [MOD] Yeah there was school, h ospita \n",
      "433.4425354003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah there was school, h ospita \n",
      "token:  [S2] hmm \n",
      "60.84059524536133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] l and then airplane. But you did \n",
      "311.3450927734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] l and then airplane. But you did \n",
      "token:  [S2] That's alright. \n",
      "38.630863189697266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] That's alright. \n",
      "token:  [MOD] very well now. \n",
      "84.09440612792969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very well now. \n",
      "token:  [S1] We did ok. \n",
      "34.620304107666016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] We did ok. \n",
      "token:  [S2] Yeah I'd I in fairness I think we were more correct than that h undred hundred people you asked No but they \n",
      "194.7122802734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah I'd I in fairness I think we were more correct than that h undred hundred people you asked No but they \n",
      "token:  [MOD] it's not that they are wrong you know it's just the most popular answer. \n",
      "21.946178436279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it's not that they are wrong you know it's just the most popular answer. \n",
      "token:  [S2] Ah then they're definitel y wrong. \n",
      "91.90056610107422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah then they're definitel y wrong. \n",
      "token:  [MOD] Are you ready for the second one? Yeah? \n",
      "27.863571166992188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Are you ready for the second one? Yeah? \n",
      "token:  [S1] Yeah. \n",
      "12.876151084899902\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Can you name an instrument in a symphony orchestra? \n",
      "39.49577713012695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you name an instrument in a symphony orchestra? \n",
      "token:  [S2] Ok. \n",
      "29.064023971557617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] What do they play in a symphony orchestra? \n",
      "5.244857311248779\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] What do they play in a symphony orchestra? \n",
      "token:  [S2] I I've first think stringed instruments and then \n",
      "106.92745971679688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I I've first think stringed instruments and then \n",
      "token:  [S1] Yeah. \n",
      "12.633520126342773\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] very most commonly be violin I would think? \n",
      "118.07250213623047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] very most commonly be violin I would think? \n",
      "token:  [MOD] That's great. \n",
      "31.1745662689209\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's great. \n",
      "token:  [S1] Yeah. \n",
      "16.037025451660156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Yeah. Violin's one of the answers. \n",
      "51.183475494384766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. Violin's one of the answers. \n",
      "token:  [S1] Would they play a cello? \n",
      "28.65546226501465\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Would they play a cello? \n",
      "token:  [S2] Yeah cello \n",
      "33.90495300292969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah cello \n",
      "token:  [MOD] Perfect yeah you have two. \n",
      "202.02484130859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect yeah you have two. \n",
      "token:  [S2] I thought of as well so. Brilliant cello. \n",
      "109.05534362792969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I thought of as well so. Brilliant cello. \n",
      "token:  [MOD] So there is one more. \n",
      "33.55667495727539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So there is one more. \n",
      "token:  [S1] Violin, a cello \n",
      "69.77161407470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin, a cello \n",
      "token:  [MOD] No strings this time. \n",
      "77.68550872802734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No strings this time. \n",
      "token:  [S2] Ok. \n",
      "34.35091781616211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] No strings. \n",
      "6.152732849121094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No strings. \n",
      "token:  [MOD] No. \n",
      "66.24969482421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S1] And is a sym phony. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269.23199462890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] And is a sym phony. \n",
      "token:  [MOD] For the la st one. \n",
      "147.202880859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] For the la st one. \n",
      "token:  [S2] I'm trying to think what's probably the most What jumps out when you think symphony orchestra? \n",
      "65.76708984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'm trying to think what's probably the most What jumps out when you think symphony orchestra? \n",
      "token:  [S1] Y your \n",
      "82.14413452148438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Y your \n",
      "token:  [S2] Y yes. \n",
      "9.991506576538086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Y yes. \n",
      "token:  [S1] man at the front. Or your woman at the fro \n",
      "103.3358383178711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] man at the front. Or your woman at the fro \n",
      "token:  [S2] The conductor? \n",
      "34.51910400390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The conductor? \n",
      "token:  [MOD]  ductor yeah. \n",
      "386.62939453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]  ductor yeah. \n",
      "token:  [S1] nt the conduct or and then everyone's sat down playing a violin and he's playing their c ellos. \n",
      "195.2350616455078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] nt the conduct or and then everyone's sat down playing a violin and he's playing their c ellos. \n",
      "token:  [S2] I think it might be percussion might come up as well \n",
      "41.64308166503906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think it might be percussion might come up as well \n",
      "token:  [MOD] Can you be \n",
      "101.94529724121094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you be \n",
      "token:  [S2] so \n",
      "64.3287582397461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so \n",
      "token:  [MOD] more speci fic \n",
      "70.39923095703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] more speci fic \n",
      "token:  [S2] mayb e cymbals? \n",
      "115.67465209960938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mayb e cymbals? \n",
      "token:  [MOD] hmm \n",
      "123.3118896484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] Or drums \n",
      "340.4695129394531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Or drums \n",
      "token:  [MOD] Yeah dr \n",
      "555.5222778320312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah dr \n",
      "token:  [S2] of some kind? \n",
      "77.98577117919922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] of some kind? \n",
      "token:  [MOD] ums. \n",
      "299.0395202636719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ums. \n",
      "token:  [S1] Drum \n",
      "283.2895812988281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Drum \n",
      "token:  [MOD] Yeah very good! \n",
      "165.11956787109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah very good! \n",
      "token:  [S1] s ok drums. \n",
      "207.77967834472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] s ok drums. \n",
      "token:  [MOD] So you have three answers. Can you rank them please? \n",
      "45.18877410888672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have three answers. Can you rank them please? \n",
      "token:  [S2] hmm do we trust ourselves a gain? \n",
      "131.0749969482422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm do we trust ourselves a gain? \n",
      "token:  [S1] I reckon everyone thinks stringed instrument \n",
      "112.44905853271484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I reckon everyone thinks stringed instrument \n",
      "token:  [S2] Yeah. \n",
      "11.43834114074707\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] and so violin would come out top. \n",
      "58.01897048950195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and so violin would come out top. \n",
      "token:  [S2] Could be cello top though? I'm not su \n",
      "73.65084075927734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Could be cello top though? I'm not su \n",
      "token:  [S1] Do you reckon? \n",
      "27.847326278686523\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Do you reckon? \n",
      "token:  [S2] re. Cell \n",
      "298.62274169921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] re. Cell \n",
      "token:  [S1] To be fair \n",
      "26.409709930419922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] To be fair \n",
      "token:  [S2] oh \n",
      "20.845809936523438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh \n",
      "token:  [S1] cell I I had cell \n",
      "122.01859283447266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cell I I had cell \n",
      "token:  [S2] You cause you had cello first. \n",
      "68.27787017822266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You cause you had cello first. \n",
      "token:  [S1] o in my h ead before I had \n",
      "93.44945526123047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] o in my h ead before I had \n",
      "token:  [S2] Yeah yeah. \n",
      "22.359699249267578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah yeah. \n",
      "token:  [S1] violin. \n",
      "38.24383544921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] violin. \n",
      "token:  [S2] Let's try let's go cello first maybe. \n",
      "32.94300079345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Let's try let's go cello first maybe. \n",
      "token:  [S1] Ok and then \n",
      "20.137292861938477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok and then \n",
      "token:  [S2] Then violin? \n",
      "38.42116165161133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Then violin? \n",
      "token:  [S1] Yeah. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.243498802185059\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Yeah? And then what? The drums wa \n",
      "144.26309204101562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah? And then what? The drums wa \n",
      "token:  [S1] And then drums. \n",
      "31.420196533203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] And then drums. \n",
      "token:  [S2] s the third one we had. \n",
      "41.75739669799805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] s the third one we had. \n",
      "token:  [S1] Yeah. \n",
      "8.116808891296387\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] You were very close again guys first is violin then cello and then drum \n",
      "264.75439453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You were very close again guys first is violin then cello and then drum \n",
      "token:  [S1] Always. \n",
      "54.60270309448242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Always. \n",
      "token:  [S2] We were close. \n",
      "8.724210739135742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] We were close. \n",
      "token:  [MOD] Third question? \n",
      "133.97601318359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Third question? \n",
      "token:  [S1] Yep. \n",
      "34.15657424926758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yep. \n",
      "token:  [MOD] Yeah? Name something that people cut. \n",
      "108.11186218261719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? Name something that people cut. \n",
      "token:  [S1] People cut Fruit? \n",
      "44.62266159057617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] People cut Fruit? \n",
      "token:  [MOD] Cut yeah. Bit more specific. \n",
      "134.70530700683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Cut yeah. Bit more specific. \n",
      "token:  [S1] An \n",
      "85.3962631225586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] An \n",
      "token:  [S2] An apple? \n",
      "19.654949188232422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] An apple? \n",
      "token:  [S1] An apple. \n",
      "4.130378723144531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] An apple. \n",
      "token:  [MOD] \n",
      "73.08904266357422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [S2] cut \n",
      "220.7469482421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cut \n",
      "token:  [S1] People cut. \n",
      "33.358760833740234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] People cut. \n",
      "token:  [S2] Alright so type of fruit people cut. \n",
      "61.75621795654297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Alright so type of fruit people cut. \n",
      "token:  [MOD] It's not fruit. \n",
      "20.24459457397461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's not fruit. \n",
      "token:  [S2] ok not fruit. \n",
      "40.253936767578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok not fruit. \n",
      "token:  [S1] Vegetables? \n",
      "13.784919738769531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Vegetables? \n",
      "token:  [S2] Carrots? \n",
      "6.493250846862793\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Carrots? \n",
      "token:  [S1] Food? B \n",
      "43.357208251953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Food? B \n",
      "token:  [S2] read. \n",
      "32.10100555419922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] read. \n",
      "token:  [MOD] More specific it's not bread no. \n",
      "291.2352600097656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] More specific it's not bread no. \n",
      "token:  [S2] hmm were these Irish people you asked? \n",
      "112.40570068359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm were these Irish people you asked? \n",
      "token:  [S1] Onions? \n",
      "19.62800407409668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Onions? \n",
      "token:  [S2] Potatoes? \n",
      "5.639657497406006\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Potatoes? \n",
      "token:  [S1] Potatoes. \n",
      "5.846989154815674\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Potatoes. \n",
      "token:  [MOD] No. It's not vegetables. \n",
      "34.507198333740234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. It's not vegetables. \n",
      "token:  [S1] It's not vegetables. \n",
      "6.487853050231934\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] It's not vegetables. \n",
      "token:  [MOD] No. \n",
      "31.64769172668457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S2] Ok. \n",
      "72.99781799316406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] And it might be more specific than fruit. \n",
      "34.56605911254883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] And it might be more specific than fruit. \n",
      "token:  [MOD] Than food. \n",
      "118.5548095703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Than food. \n",
      "token:  [S1] Than food oh. \n",
      "52.063682556152344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Than food oh. \n",
      "token:  [S2] Than food? \n",
      "5.9078049659729\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Than food? \n",
      "token:  [S1] So it is a food? \n",
      "11.003969192504883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So it is a food? \n",
      "token:  [S2] God. \n",
      "14.165404319763184\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] God. \n",
      "token:  [S1] And it's not a vegetable. \n",
      "14.545499801635742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] And it's not a vegetable. \n",
      "token:  [MOD] No. It's the opposite actually. \n",
      "30.709829330444336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. It's the opposite actually. \n",
      "token:  [S2] The opposite of ve getable? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130.5613555908203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The opposite of ve getable? \n",
      "token:  [MOD] If you're a vegetarian like think of what you would \n",
      "89.43244171142578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] If you're a vegetarian like think of what you would \n",
      "token:  [S1] Meat? \n",
      "44.83694076538086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Meat? \n",
      "token:  [MOD] Meat. Yeah. \n",
      "56.470428466796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Meat. Yeah. \n",
      "token:  [S2] Ok. \n",
      "24.80381202697754\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] That's correct. \n",
      "22.114728927612305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's correct. \n",
      "token:  [S1] Is it just Oh right yeah. \n",
      "69.97222137451172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Is it just Oh right yeah. \n",
      "token:  [S2] Oh ok Meat. \n",
      "46.07148742675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh ok Meat. \n",
      "token:  [MOD] yeah \n",
      "217.85975646972656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S2] Ok. \n",
      "45.45832824707031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] So you have two m \n",
      "102.5246353149414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have two m \n",
      "token:  [S2] Ok. \n",
      "156.64263916015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] ore. You have to find two more answers. \n",
      "78.01689910888672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ore. You have to find two more answers. \n",
      "token:  [S2] What things pe ople cut. \n",
      "265.2330322265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] What things pe ople cut. \n",
      "token:  [MOD] They don't have to do now with food. \n",
      "66.17420196533203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] They don't have to do now with food. \n",
      "token:  [S1] With scissors you'd cut things. Paper? \n",
      "87.44293212890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] With scissors you'd cut things. Paper? \n",
      "token:  [S2] So you'd \n",
      "24.20264434814453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So you'd \n",
      "token:  [S1] Pape r. \n",
      "56.08900833129883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Pape r. \n",
      "token:  [MOD] Yeah. Great. Yeah. So one more. \n",
      "72.06037902832031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. Great. Yeah. So one more. \n",
      "token:  [S1] What else would you cut? \n",
      "30.337976455688477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] What else would you cut? \n",
      "token:  [S2] Hair maybe? \n",
      "28.64414405822754\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair maybe? \n",
      "token:  [S1] Yes that's \n",
      "25.6033935546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yes that's \n",
      "token:  [MOD] Yea h. correct. Well done. \n",
      "157.78231811523438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yea h. correct. Well done. \n",
      "token:  [S1] Good shot. \n",
      "31.454133987426758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Good shot. \n",
      "token:  [S2] I have a super efficient at this. \n",
      "25.96895980834961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I have a super efficient at this. \n",
      "token:  [MOD] Really? So can you order them now please in terms of popu \n",
      "157.76727294921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Really? So can you order them now please in terms of popu \n",
      "token:  [S1] Right. \n",
      "52.625022888183594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Right. \n",
      "token:  [MOD] larity agai \n",
      "1603.8682861328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] larity agai \n",
      "token:  [S1] Mea \n",
      "105.09832000732422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Mea \n",
      "token:  [MOD] n? \n",
      "563.8809204101562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] n? \n",
      "token:  [S1] t, paper, hair. \n",
      "150.5786895751953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] t, paper, hair. \n",
      "token:  [S2] Yea h. Maybe. \n",
      "37.7308464050293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yea h. Maybe. \n",
      "token:  [S1] Cutting meat doesn't \n",
      "104.72921752929688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cutting meat doesn't \n",
      "token:  [S2] Hair \n",
      "31.204267501831055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair \n",
      "token:  [S1] strike string spring to mind \n",
      "217.3944549560547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] strike string spring to mind \n",
      "token:  [S2] I did think food straight away though. \n",
      "97.57225036621094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I did think food straight away though. \n",
      "token:  [S1] Ye ah. \n",
      "25.699785232543945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ye ah. \n",
      "token:  [S2] So hmm \n",
      "20.76424789428711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So hmm \n",
      "token:  [S1] And not many people well not many people actually cut hair. \n",
      "76.10977935791016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] And not many people well not many people actually cut hair. \n",
      "token:  [S2] Yeah maybe hair would be third. \n",
      "39.67603302001953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah maybe hair would be third. \n",
      "token:  [S1] But then who cut \n",
      "76.88819885253906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But then who cut \n",
      "token:  [S2] But every time we've \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.342357635498047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] But every time we've \n",
      "token:  [S1] s paper either? \n",
      "143.93678283691406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] s paper either? \n",
      "token:  [S2] Yeah. I'd say meat paper, hair maybe? \n",
      "92.42871856689453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. I'd say meat paper, hair maybe? \n",
      "token:  [S1] Meat, paper, hair? \n",
      "6.344846725463867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Meat, paper, hair? \n",
      "token:  [S2] We've been wrong with the order every time so far so \n",
      "40.42560577392578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] We've been wrong with the order every time so far so \n",
      "token:  [S1] Yeah. Why not \n",
      "30.903268814086914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. Why not \n",
      "token:  [MOD] Never know now. \n",
      "151.42250061035156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Never know now. \n",
      "token:  [S1] meat, paper, hair. \n",
      "108.34508514404297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat, paper, hair. \n",
      "token:  [MOD] Yeah? \n",
      "81.51055908203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S1] Yeah. \n",
      "10.913925170898438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Do you \n",
      "69.5676498413086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Do you \n",
      "token:  [S2] Ok. \n",
      "63.621150970458984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] agree? \n",
      "117.35023498535156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] agree? \n",
      "token:  [S1] Yeah why not? \n",
      "38.93105697631836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah why not? \n",
      "token:  [S2] Yeah. \n",
      "7.448570251464844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Yeah. \n",
      "4.3605546951293945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Almost th ere guys. Hair is the most pop ular answer. \n",
      "235.00161743164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Almost th ere guys. Hair is the most pop ular answer. \n",
      "token:  [S2] Alright. \n",
      "36.07979965209961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Alright. \n",
      "token:  [MOD] Yeah h \n",
      "442.3939514160156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah h \n",
      "token:  [S1] hmm \n",
      "70.46038818359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] it's hair, paper and meat. \n",
      "165.8857879638672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it's hair, paper and meat. \n",
      "token:  [S2] hmm \n",
      "51.99669647216797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] But well done guys like you found all the an swers. \n",
      "220.18630981445312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But well done guys like you found all the an swers. \n",
      "token:  [S2] We did pretty well now. \n",
      "35.76416778564453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] We did pretty well now. \n",
      "token:  [MOD] I hope \n",
      "113.5377426147461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I hope \n",
      "token:  [S1] Yeah \n",
      "65.24893951416016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah \n",
      "token:  [MOD] you enjoyed it. Thanks very much f \n",
      "205.14903259277344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you enjoyed it. Thanks very much f \n",
      "token:  [S1] Is that \n",
      "114.11497497558594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Is that \n",
      "token:  [MOD] or coming. That's it. \n",
      "111.82687377929688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] or coming. That's it. \n",
      "token:  [S1] Oh.\n",
      "47.01918029785156\n",
      "MOD : 165.7796297418066\n",
      "S1 : 61.795695304870605\n",
      "S2 : 70.23284389078617\n",
      "speech transcription_Transcriber/S11.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Right. So, I would like us to play a quiz. I'm going to ask you three questions and I would \n",
      "34.878082275390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Right. So, I would like us to play a quiz. I'm going to ask you three questions and I would \n",
      "token:  [S1] Ok. \n",
      "45.85927963256836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] lie that were were posed to a group of one hundred people and I would like you to guess the most popular answers to these questions. Ok? And then I will ask you to talk to each other and decide a on their ranking in terms of popularity. So for example I might ask you what are some ways in which you can carry patients in a hospital. So you \n",
      "34.35983657836914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] lie that were were posed to a group of one hundred people and I would like you to guess the most popular answers to these questions. Ok? And then I will ask you to talk to each other and decide a on their ranking in terms of popularity. So for example I might ask you what are some ways in which you can carry patients in a hospital. So you \n",
      "token:  [S1] hmm \n",
      "77.4687728881836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] would probably say some things like ah an ambulance, patient's bed eh a wheelchair, ok? And then you will have to talk to each other and see what you know how would you order these items. Is that clear? \n",
      "76.25598907470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] would probably say some things like ah an ambulance, patient's bed eh a wheelchair, ok? And then you will have to talk to each other and see what you know how would you order these items. Is that clear? \n",
      "token:  [S1] Ok. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.56334686279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] Ok. \n",
      "3.769420623779297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] Are you ready for the first question? \n",
      "17.934473037719727\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Are you ready for the first question? \n",
      "token:  [S1] Yeah. \n",
      "19.63398551940918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Ok. \n",
      "23.830276489257812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok. \n",
      "token:  [S2] Ok. \n",
      "14.052390098571777\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] I would like you to tell me what are the public places where you would be more likely to get a f the flu or a cold. Where would you catch a cold or a flu bug. \n",
      "26.781118392944336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I would like you to tell me what are the public places where you would be more likely to get a f the flu or a cold. Where would you catch a cold or a flu bug. \n",
      "token:  [S1] Ok, so we're supposed to discuss there with our partner, come up with \n",
      "56.599586486816406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok, so we're supposed to discuss there with our partner, come up with \n",
      "token:  [MOD] Yes. \n",
      "237.71107482910156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes. \n",
      "token:  [S1] the answer. \n",
      "37.55946731567383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the answer. \n",
      "token:  [MOD] Yeah. \n",
      "76.77681732177734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] How many options you need? \n",
      "34.00164794921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] How many options you need? \n",
      "token:  [MOD] You thi need to come up with three. Yeah. \n",
      "79.31183624267578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You thi need to come up with three. Yeah. \n",
      "token:  [S1] three ok Yeah. \n",
      "58.73731994628906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] three ok Yeah. \n",
      "token:  [MOD] Yeah. \n",
      "30.812644958496094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] Ok. \n",
      "13.906325340270996\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] mhmm So I can think of public transports. \n",
      "48.95053482055664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm So I can think of public transports. \n",
      "token:  [MOD] mhmm \n",
      "17.905555725097656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] The hospital. \n",
      "99.05865478515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The hospital. \n",
      "token:  [S2] mhmm \n",
      "5.626471042633057\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] You got the one. \n",
      "51.81871032714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You got the one. \n",
      "token:  [S1] the \n",
      "74.0121841430664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the \n",
      "token:  [MOD] Hospital. \n",
      "573.8430786132812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Hospital. \n",
      "token:  [S1] So Maybe a place with lot of people? who are \n",
      "116.47405242919922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So Maybe a place with lot of people? who are \n",
      "token:  [S2] mhmm \n",
      "27.244314193725586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [S1] vulnerable Be a public transportation \n",
      "251.99107360839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] vulnerable Be a public transportation \n",
      "token:  [MOD] Can you be more specific \n",
      "64.24907684326172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can you be more specific \n",
      "token:  [S1] when you're saying me \n",
      "45.48863220214844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] when you're saying me \n",
      "token:  [MOD] ok ns of transport? Could you Give some exam ples? bus for exa \n",
      "1051.794921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok ns of transport? Could you Give some exam ples? bus for exa \n",
      "token:  [S2] mple? \n",
      "94.58875274658203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mple? \n",
      "token:  [S1] Like a a crowded bus. \n",
      "46.140750885009766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Like a a crowded bus. \n",
      "token:  [S2] Hm. \n",
      "9.79966926574707\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hm. \n",
      "token:  [MOD] Keep guessing. \n",
      "79.93102264404297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Keep guessing. \n",
      "token:  [S1] Yeah. hmm \n",
      "61.20282745361328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. hmm \n",
      "token:  [S2] hmm \n",
      "9.086308479309082\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] Something with bad ventilation? \n",
      "84.82990264892578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Something with bad ventilation? \n",
      "token:  [S2] trains maybe I don't know \n",
      "52.32931137084961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] trains maybe I don't know \n",
      "token:  [S1] Yes also so \n",
      "68.47920227050781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yes also so \n",
      "token:  [MOD] You're very close \n",
      "56.709293365478516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You're very close \n",
      "token:  [S1] yes so some \n",
      "132.72811889648438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yes so some \n",
      "token:  [MOD] yes \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.93988037109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes \n",
      "token:  [S1] where with bad ventilation like in the theatre in \n",
      "264.9595031738281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] where with bad ventilation like in the theatre in \n",
      "token:  [MOD] If you stick to the means of transport you me \n",
      "124.2529067993164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] If you stick to the means of transport you me \n",
      "token:  [S1] ok \n",
      "90.44139862060547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] ntion some more. \n",
      "347.2777404785156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ntion some more. \n",
      "token:  [S1] Bus, train, you you've already mentioned bus and train and \n",
      "101.84185791015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Bus, train, you you've already mentioned bus and train and \n",
      "token:  [S2] dog run no no \n",
      "87.84174346923828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] dog run no no \n",
      "token:  [S1] In a taxi? \n",
      "36.23655319213867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] In a taxi? \n",
      "token:  [MOD] No try again \n",
      "254.3436279296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No try again \n",
      "token:  [S1] Not, not again Oh at a plane \n",
      "173.6585693359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Not, not again Oh at a plane \n",
      "token:  [MOD] Exactly \n",
      "139.73561096191406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly \n",
      "token:  [S1] is it? yes the plane \n",
      "137.3680877685547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] is it? yes the plane \n",
      "token:  [S2] The plane? \n",
      "13.475892066955566\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The plane? \n",
      "token:  [S1] Yeah bad ventilation and \n",
      "182.1878204345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah bad ventilation and \n",
      "token:  [MOD] Yeah. \n",
      "68.09591674804688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] like long long time yeah \n",
      "134.70614624023438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like long long time yeah \n",
      "token:  [S2] yeah didn't I wouldn't have \n",
      "29.44610023498535\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah didn't I wouldn't have \n",
      "token:  [S1] gathered yeah \n",
      "89.15347290039062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] gathered yeah \n",
      "token:  [S2] thought of that actua \n",
      "100.8333969116211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] thought of that actua \n",
      "token:  [S1] yeah \n",
      "18.35047721862793\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] lly. \n",
      "22.04073715209961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] lly. \n",
      "token:  [MOD] So you have one more. \n",
      "41.23810577392578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have one more. \n",
      "token:  [S1] Ok. \n",
      "19.14876365661621\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] You need to find one more. \n",
      "27.21341323852539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You need to find one more. \n",
      "token:  [S1] Get sick At a party in a nightclub \n",
      "118.29724884033203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Get sick At a party in a nightclub \n",
      "token:  [MOD] Not really \n",
      "91.85548400878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Not really \n",
      "token:  [S1] No no ok. \n",
      "57.400203704833984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No no ok. \n",
      "token:  [S2] hmm \n",
      "12.84073257446289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] So so it'd be some place like some place with a lot of people \n",
      "28.305042266845703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So so it'd be some place like some place with a lot of people \n",
      "token:  [MOD] mhmm \n",
      "58.13167953491211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] in a like cramped space. \n",
      "143.51242065429688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] in a like cramped space. \n",
      "token:  [MOD] Think about different ages s \n",
      "429.5599670410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think about different ages s \n",
      "token:  [S1] oh ok \n",
      "114.7140121459961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh ok \n",
      "token:  [MOD] age groups. \n",
      "305.197509765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] age groups. \n",
      "token:  [S1] Oh like in in th the s school for kids like ki ki \n",
      "363.8551025390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh like in in th the s school for kids like ki ki \n",
      "token:  [MOD] Exactly. \n",
      "73.00729370117188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly. \n",
      "token:  [S1] dergarten \n",
      "268.31536865234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] dergarten \n",
      "token:  [S2] Ah yes, schools of course. hmm \n",
      "73.9877700805664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah yes, schools of course. hmm \n",
      "token:  [MOD] Schools. Ok, so you've got \n",
      "64.93866729736328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Schools. Ok, so you've got \n",
      "token:  [S1] Yeah the the creche yeah \n",
      "345.3394470214844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah the the creche yeah \n",
      "token:  [S2] makes sense. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.526985168457031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] makes sense. \n",
      "token:  [MOD] exactly. \n",
      "77.81526947021484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] exactly. \n",
      "token:  [S1] yeah \n",
      "116.24861907958984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] So you have the three, alright? Schools \n",
      "218.51187133789062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you have the three, alright? Schools \n",
      "token:  [S1] mhmm \n",
      "41.92586898803711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] hospitals airplanes. What would be the ranking? \n",
      "313.7434997558594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hospitals airplanes. What would be the ranking? \n",
      "token:  [S1] It doesn't matter who gets sick right? So \n",
      "52.76704406738281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] It doesn't matter who gets sick right? So \n",
      "token:  [MOD] You have to think what came f to most people's minds first what was the most popular answer \n",
      "81.96868133544922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have to think what came f to most people's minds first what was the most popular answer \n",
      "token:  [S1] more ok so so Oh so is a pop answer ok \n",
      "253.5859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] more ok so so Oh so is a pop answer ok \n",
      "token:  [MOD] Yeah it doesn't have to do with the probability of you know where would \n",
      "63.890838623046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah it doesn't have to do with the probability of you know where would \n",
      "token:  [S1] Oh ok yeah oh ok \n",
      "63.46168518066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh ok yeah oh ok \n",
      "token:  [MOD] you get \n",
      "135.9414520263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you get \n",
      "token:  [S2] mhmm So it's not actually necessarily the right answer, it's \n",
      "34.281585693359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm So it's not actually necessarily the right answer, it's \n",
      "token:  [S1] yeah \n",
      "27.27849578857422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] the most popular yeah \n",
      "40.012027740478516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the most popular yeah \n",
      "token:  [MOD] Exactly, the most popular the most common answer that \n",
      "57.97032928466797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly, the most popular the most common answer that \n",
      "token:  [S2] hmm \n",
      "134.4789581298828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] most people gave. \n",
      "352.52239990234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] most people gave. \n",
      "token:  [S1] So I think kindergarten 'd be the lowest because even us we never thought about it. \n",
      "161.3461151123047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So I think kindergarten 'd be the lowest because even us we never thought about it. \n",
      "token:  [S2] hmm \n",
      "17.381961822509766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] For now it's just either the plane or the or the hospital that's the higher \n",
      "70.44416046142578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] For now it's just either the plane or the or the hospital that's the higher \n",
      "token:  [S2] hmm \n",
      "21.548601150512695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] \n",
      "7.601269721984863\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] I would say the hospital because well plane I wouldn't have thought of it my self but \n",
      "74.96761322021484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I would say the hospital because well plane I wouldn't have thought of it my self but \n",
      "token:  [S1] yeah \n",
      "15.398035049438477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] \n",
      "10.0300931930542\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] Yeah so I think that does that that does agree with our discussion too so it'd be hos \n",
      "88.61262512207031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah so I think that does that that does agree with our discussion too so it'd be hos \n",
      "token:  [S2] hmm \n",
      "18.79741096496582\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] pital \n",
      "33.05984115600586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] pital \n",
      "token:  [MOD] mhmm \n",
      "88.8753662109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] a \n",
      "46.106529235839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] a \n",
      "token:  [S2] hm \n",
      "7.932750701904297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm \n",
      "token:  [S1] plane and a the the school. \n",
      "137.82107543945312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] plane and a the the school. \n",
      "token:  [MOD] Do you agree? \n",
      "27.439611434936523\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Do you agree? \n",
      "token:  [S2] Yes yes \n",
      "60.959049224853516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes yes \n",
      "token:  [S1] Yeah. \n",
      "12.722158432006836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] I'm sorry you got that wrong it's \n",
      "39.03909683227539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'm sorry you got that wrong it's \n",
      "token:  [S1] Oh ok. \n",
      "39.35230255126953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh ok. \n",
      "token:  [MOD] the school is the first one was the fi \n",
      "202.31634521484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the school is the first one was the fi \n",
      "token:  [S1] Ok. \n",
      "96.33470916748047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] rst answer \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198.11155700683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] rst answer \n",
      "token:  [S2] hmm \n",
      "55.788902282714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] right? Hospital is number two airplane is number three \n",
      "216.8293914794922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] right? Hospital is number two airplane is number three \n",
      "token:  [S1] Ok. \n",
      "44.910369873046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] you you were right about airplanes. \n",
      "186.89830017089844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you you were right about airplanes. \n",
      "token:  [S1] Maybe because \n",
      "82.23074340820312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Maybe because \n",
      "token:  [MOD] I \n",
      "162.8070831298828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I \n",
      "token:  [S1] we didn'r have have kids so we never thought bout it yeah \n",
      "116.74423217773438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] we didn'r have have kids so we never thought bout it yeah \n",
      "token:  [S2] Yeah yeah exactly that's what I thought \n",
      "17.57666778564453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah yeah exactly that's what I thought \n",
      "token:  [S1] yeah \n",
      "12.85187816619873\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] Exactly exactly. \n",
      "143.22010803222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly exactly. \n",
      "token:  [MOD] But let's just try the second question ok, I would like you \n",
      "109.94977569580078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But let's just try the second question ok, I would like you \n",
      "token:  [S1] mhmm \n",
      "36.32158660888672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] to name musical instruments in a symphony orchestra. \n",
      "105.91968536376953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] to name musical instruments in a symphony orchestra. \n",
      "token:  [S1] Ok. \n",
      "32.67449188232422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] in a symphony orchestra, I'm not symphony orchestra \n",
      "20.211660385131836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] in a symphony orchestra, I'm not symphony orchestra \n",
      "token:  [S1] Symphony orchestra. \n",
      "19.19500160217285\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Symphony orchestra. \n",
      "token:  [S2] The violin? \n",
      "14.672056198120117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The violin? \n",
      "token:  [MOD] Very good that's one. \n",
      "69.47651672363281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good that's one. \n",
      "token:  [S1] Cello? \n",
      "61.126182556152344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cello? \n",
      "token:  [MOD] Yeah. That's two, yeah. \n",
      "42.7807502746582\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. That's two, yeah. \n",
      "token:  [S1] \n",
      "22.700098037719727\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] \n",
      "39.93152618408203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [S1] This should be easy \n",
      "46.0145263671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] This should be easy \n",
      "token:  [S2] The thing is my English vocabulary is might not be \n",
      "62.694976806640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The thing is my English vocabulary is might not be \n",
      "token:  [S1] ah ok \n",
      "53.85543441772461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah ok \n",
      "token:  [S2] as extended as a \n",
      "108.58383178710938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] as extended as a \n",
      "token:  [MOD] It's a sim ple word and it's something that you can find in all sorts of you know different kinds of music and vn even in live \n",
      "81.3185043334961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's a sim ple word and it's something that you can find in all sorts of you know different kinds of music and vn even in live \n",
      "token:  [S1] Ok. \n",
      "84.82427978515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] concert. So \n",
      "518.7283935546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] concert. So \n",
      "token:  [S1] Clarinet? \n",
      "87.1399917602539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Clarinet? \n",
      "token:  [MOD] Nnnno try again. \n",
      "119.78717041015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Nnnno try again. \n",
      "token:  [S1] the \n",
      "66.39041900634766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the \n",
      "token:  [S2] Drums? \n",
      "37.731590270996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Drums? \n",
      "token:  [MOD] Sorry? \n",
      "63.912200927734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Sorry? \n",
      "token:  [S2] Drums? \n",
      "49.74929428100586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Drums? \n",
      "token:  [MOD] Drums. \n",
      "24.575952529907227\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Drums. \n",
      "token:  [S1] Eh drums? \n",
      "144.51734924316406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Eh drums? \n",
      "token:  [S2] Yeah. \n",
      "6.087975978851318\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Yes that's it \n",
      "59.26228332519531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes that's it \n",
      "token:  [S1] Ok. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.985227584838867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] the drum. So what would be the right order then in terms of popularity. \n",
      "84.21904754638672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the drum. So what would be the right order then in terms of popularity. \n",
      "token:  [S1] Oh v v v Violin o pro probably the first. and drum I think drum would be the the last. \n",
      "134.65367126464844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh v v v Violin o pro probably the first. and drum I think drum would be the the last. \n",
      "token:  [S2] So sorry what was the second one? \n",
      "16.49104118347168\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So sorry what was the second one? \n",
      "token:  [S1] So \n",
      "19.094751358032227\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So \n",
      "token:  [S2] what was that \n",
      "19.60988426208496\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] what was that \n",
      "token:  [S1] violin and cello and drums. \n",
      "32.90780258178711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] violin and cello and drums. \n",
      "token:  [S2] cello yeah. uh-huh Yeah. \n",
      "18.05107307434082\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cello yeah. uh-huh Yeah. \n",
      "token:  [MOD] What do you think? \n",
      "16.341331481933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] What do you think? \n",
      "token:  [S1] I would say \n",
      "29.44753074645996\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I would say \n",
      "token:  [MOD] Do you agree? \n",
      "32.9566650390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Do you agree? \n",
      "token:  [S1] violin cause you cou because \n",
      "1331.5772705078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] violin cause you cou because \n",
      "token:  [S2] hmm honestly I don't have a strong opinion about that \n",
      "16.630006790161133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm honestly I don't have a strong opinion about that \n",
      "token:  [S1] Ok. \n",
      "12.094278335571289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] I don't know what would people think about that yeah. \n",
      "16.68975830078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know what would people think about that yeah. \n",
      "token:  [MOD] mhmm \n",
      "64.90118408203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] mhmm \n",
      "7.213385105133057\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [S2] Yeah I a I agree why not ah but I'm \n",
      "134.84645080566406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah I a I agree why not ah but I'm \n",
      "token:  [S1] Ok. \n",
      "16.504497528076172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] not convinced \n",
      "35.502960205078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] not convinced \n",
      "token:  [MOD] Ok. \n",
      "74.97969055175781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok. \n",
      "token:  [S2] but why not I mean I don't have \n",
      "59.74721908569336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] but why not I mean I don't have \n",
      "token:  [MOD] ok \n",
      "319.91351318359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok \n",
      "token:  [S2] more better ideas \n",
      "206.7602996826172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] more better ideas \n",
      "token:  [MOD] right? So that's the right ranking, well done. \n",
      "57.706031799316406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] right? So that's the right ranking, well done. \n",
      "token:  [S1] Ok \n",
      "78.18434143066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok \n",
      "token:  [MOD] Yes \n",
      "67.00144958496094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes \n",
      "token:  [S1] Ok. \n",
      "30.029197692871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] It's violin \n",
      "221.99697875976562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's violin \n",
      "token:  [S2] Oh! \n",
      "52.370140075683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh! \n",
      "token:  [MOD] cello and drum alright? \n",
      "427.8880920410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] cello and drum alright? \n",
      "token:  [S1] and drums ok. \n",
      "31.99529457092285\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and drums ok. \n",
      "token:  [MOD] Very good. Now I would like you to think about things that people cut. Name something that people cut. \n",
      "38.81914520263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good. Now I would like you to think about things that people cut. Name something that people cut. \n",
      "token:  [S1] Cut their own fingers. \n",
      "19.774770736694336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cut their own fingers. \n",
      "token:  [S2] Ah it depends because cut can have many meanings \n",
      "60.03182601928711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah it depends because cut can have many meanings \n",
      "token:  [MOD] hmm \n",
      "65.32576751708984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] actually. \n",
      "80.7564697265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] actually. \n",
      "token:  [S1] Yeah. \n",
      "9.654596328735352\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] I for some reasons a first I that came to my mind was a queue cutting in a queue. But it's it's probably not \n",
      "73.66446685791016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I for some reasons a first I that came to my mind was a queue cutting in a queue. But it's it's probably not \n",
      "token:  [MOD] hmm \n",
      "117.55219268798828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] the I mean it's not the literal meaning \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.868133544921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the I mean it's not the literal meaning \n",
      "token:  [MOD] Let's think about the literal meaning of \n",
      "26.982080459594727\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Let's think about the literal meaning of \n",
      "token:  [S2] yeah \n",
      "280.8720703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] the wo rd \n",
      "173.637939453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the wo rd \n",
      "token:  [S2] hmm \n",
      "131.3003692626953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] ok? \n",
      "75.73226165771484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok? \n",
      "token:  [S1] cut \n",
      "141.12721252441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cut \n",
      "token:  [MOD] Not a metaphorical sense. \n",
      "135.44537353515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Not a metaphorical sense. \n",
      "token:  [S1] Ok, vegetables? \n",
      "104.00885009765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok, vegetables? \n",
      "token:  [MOD] hmm you're thinking about food. \n",
      "44.20182800292969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm you're thinking about food. \n",
      "token:  [S1] Ok. \n",
      "20.528776168823242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Think about a different category of food. \n",
      "48.096431732177734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think about a different category of food. \n",
      "token:  [S1] Meat? \n",
      "44.96882247924805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Meat? \n",
      "token:  [MOD] Excellent that's it \n",
      "168.96815490722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent that's it \n",
      "token:  [S1] Ok. \n",
      "32.828468322753906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] yeas, very good. \n",
      "63.72823715209961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeas, very good. \n",
      "token:  [S1] Are we still with food or \n",
      "115.698486328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Are we still with food or \n",
      "token:  [MOD] No, let's move away from food now \n",
      "35.17177200317383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No, let's move away from food now \n",
      "token:  [S1] no no we move ok So we have the meat So people don't think \n",
      "128.55418395996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] no no we move ok So we have the meat So people don't think \n",
      "token:  [S2] mhmm \n",
      "12.769917488098145\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [S1] about vegetable at all? Like \n",
      "130.15191650390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] about vegetable at all? Like \n",
      "token:  [MOD] Not really it's the meat that came yeah. \n",
      "252.42100524902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Not really it's the meat that came yeah. \n",
      "token:  [S1] Ok that's hmm Ok like when when you cut it like we cut it \n",
      "89.31082153320312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok that's hmm Ok like when when you cut it like we cut it \n",
      "token:  [MOD] hmm \n",
      "33.0312385559082\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] like chopping as we ususally say vegetables. \n",
      "198.3769073486328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like chopping as we ususally say vegetables. \n",
      "token:  [MOD] Yes, because some people tend to be vegetari ans so they wouldn't \n",
      "87.98175811767578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes, because some people tend to be vegetari ans so they wouldn't \n",
      "token:  [S1] oh yeah \n",
      "66.79060363769531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh yeah \n",
      "token:  [MOD] think about meat \n",
      "200.18099975585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] think about meat \n",
      "token:  [S1] oh yeah yeah \n",
      "51.98554611206055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh yeah yeah \n",
      "token:  [MOD] right? \n",
      "70.10918426513672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] right? \n",
      "token:  [S1] cut \n",
      "176.33383178710938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cut \n",
      "token:  [MOD] hmm \n",
      "97.72576141357422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] Wood? \n",
      "108.60961151123047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Wood? \n",
      "token:  [MOD] hmm \n",
      "84.52941131591797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] like like stacks of wood no? like \n",
      "196.21090698242188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like like stacks of wood no? like \n",
      "token:  [MOD] There is something related to wood \n",
      "117.46192932128906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] There is something related to wood \n",
      "token:  [S1] Ok. \n",
      "44.42580795288086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] Eh hair. No? \n",
      "71.17179870605469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Eh hair. No? \n",
      "token:  [MOD] Sorry? \n",
      "42.035728454589844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Sorry? \n",
      "token:  [S2] Hair. \n",
      "112.6971664428711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair. \n",
      "token:  [MOD] Excellent, yes yes. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.4261703491211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent, yes yes. \n",
      "token:  [S1] mhmm \n",
      "37.52107238769531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] So you need one more. \n",
      "68.47508239746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you need one more. \n",
      "token:  [S1] Meat, hair and cu t Paper? \n",
      "429.0921936035156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Meat, hair and cu t Paper? \n",
      "token:  [MOD] Very good so you have the \n",
      "122.66029357910156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good so you have the \n",
      "token:  [S1] Ok ok. \n",
      "71.54141998291016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok ok. \n",
      "token:  [MOD] three now, what would be your ranking?. \n",
      "109.14730834960938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] three now, what would be your ranking?. \n",
      "token:  [S1] I think paper be more common to cut paper paper paper or hair? \n",
      "145.56459045410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think paper be more common to cut paper paper paper or hair? \n",
      "token:  [S2] paper Actually I would think paper, meat but I don't know. \n",
      "21.84697723388672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] paper Actually I would think paper, meat but I don't know. \n",
      "token:  [S1] ok. s so probably paper meat and hair \n",
      "112.1871109008789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok. s so probably paper meat and hair \n",
      "token:  [S2] yes \n",
      "10.894786834716797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes \n",
      "token:  [S1] Ok. Paper, meat and hair? \n",
      "131.64962768554688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. Paper, meat and hair? \n",
      "token:  [MOD] No. \n",
      "27.96086311340332\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S1] Ok \n",
      "140.16998291015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok \n",
      "token:  [MOD] I'm afraid you got it wrong this time, it was actually hair first \n",
      "54.82420349121094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'm afraid you got it wrong this time, it was actually hair first \n",
      "token:  [S1] Ok. \n",
      "34.729652404785156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] Hair first! \n",
      "8.902314186096191\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair first! \n",
      "token:  [MOD] paper is next \n",
      "283.1888122558594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] paper is next \n",
      "token:  [S1] hmm \n",
      "33.53732681274414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] and the last one was meat. \n",
      "106.002197265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and the last one was meat. \n",
      "token:  [S1] Ok. \n",
      "31.195430755615234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] Probably because I don't know it's you know very frequently used word combination haircut. Haircut it's the standa ok ok. rd word combination isn't it? So but yes I mean you did very well and that is the end of the quiz. I hope you enjoyed it \n",
      "87.65078735351562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Probably because I don't know it's you know very frequently used word combination haircut. Haircut it's the standa ok ok. rd word combination isn't it? So but yes I mean you did very well and that is the end of the quiz. I hope you enjoyed it \n",
      "token:  [S1] Ok. \n",
      "29.148698806762695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] thank you very much. \n",
      "29.57167625427246\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] thank you very much. \n",
      "token:  [S2] Ok. Thank you. \n",
      "17.3414306640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. Thank you. \n",
      "token:  [S1] Ok.\n",
      "4.319509983062744\n",
      "MOD : 127.78185152053832\n",
      "S1 : 96.79262205532619\n",
      "S2 : 49.758374553615766\n",
      "speech transcription_Transcriber/S20.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] So hello. Thanks very \n",
      "1055.130859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So hello. Thanks very \n",
      "token:  [S1] Hi. \n",
      "38.92638397216797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hi. \n",
      "token:  [MOD] much for coming here today. \n",
      "113.846435546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] much for coming here today. \n",
      "token:  [S2] Thank you. \n",
      "18.83224868774414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Thank you. \n",
      "token:  [MOD] Ah we're going to play a quiz I'm going to ask you three survey questions that were eh previously posed to a group of hundred people. \n",
      "58.531036376953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ah we're going to play a quiz I'm going to ask you three survey questions that were eh previously posed to a group of hundred people. \n",
      "token:  [S1] Oh wow. \n",
      "20.753414154052734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh wow. \n",
      "token:  [MOD] You have to come up with the three most popular answers. And after \n",
      "56.419776916503906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have to come up with the three most popular answers. And after \n",
      "token:  [S2] Ok. \n",
      "98.14811706542969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] talking to each other you you need to collaborate in order to order these answers in terms of popularity. \n",
      "104.48799896240234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] talking to each other you you need to collaborate in order to order these answers in terms of popularity. \n",
      "token:  [S2] Ok. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.44369125366211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] Is it clear? \n",
      "39.235721588134766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Is it clear? \n",
      "token:  [S1] Yeah. \n",
      "20.525400161743164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Are you ready \n",
      "69.02218627929688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Are you ready \n",
      "token:  [S2] Yeah. \n",
      "47.60600280761719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] for the first question? \n",
      "81.02925872802734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] for the first question? \n",
      "token:  [S2] Yeah. \n",
      "49.44767761230469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Yeah? \n",
      "30.027114868164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S1] Do we h ave a pen or do we use just like \n",
      "81.12211608886719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Do we h ave a pen or do we use just like \n",
      "token:  [MOD] No no jus t yeah. \n",
      "159.9834442138672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No no jus t yeah. \n",
      "token:  [S1] think about \n",
      "80.0315170288086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] think about \n",
      "token:  [MOD] Yeah. \n",
      "148.35365295410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] ok. \n",
      "23.918867111206055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok. \n",
      "token:  [S2] And do we do we talk to each other? Or t \n",
      "50.04050064086914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] And do we do we talk to each other? Or t \n",
      "token:  [MOD] Yeah. \n",
      "211.99266052246094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] ok. \n",
      "31.74310302734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] Yeah. So Name a public place where you're likely to catch a cold or a flu bug. \n",
      "48.928924560546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. So Name a public place where you're likely to catch a cold or a flu bug. \n",
      "token:  [S1] hmm \n",
      "45.397621154785156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] A park? \n",
      "11.29149055480957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A park? \n",
      "token:  [S1] A a flu bug? Like \n",
      "53.07179260253906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] A a flu bug? Like \n",
      "token:  [MOD] mhmm \n",
      "165.01992797851562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] a stomach stomach bug? \n",
      "219.21194458007812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] a stomach stomach bug? \n",
      "token:  [MOD] Or anything or a co \n",
      "588.9923706054688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Or anything or a co \n",
      "token:  [S2] Hospital? \n",
      "186.15846252441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hospital? \n",
      "token:  [MOD] ld \n",
      "306.3821105957031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ld \n",
      "token:  [S1] Or a flu , so viruses basically. \n",
      "616.8588256835938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Or a flu , so viruses basically. \n",
      "token:  [S2] A hospital? \n",
      "34.9911994934082\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A hospital? \n",
      "token:  [MOD] Perfect. Yeah. \n",
      "77.74069213867188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect. Yeah. \n",
      "token:  [S1] A t rain? I'd say pub \n",
      "258.1300354003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] A t rain? I'd say pub \n",
      "token:  [S2] A train? \n",
      "15.1786470413208\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A train? \n",
      "token:  [S1] lic plubli public trans port prob probably. \n",
      "1140.416015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] lic plubli public trans port prob probably. \n",
      "token:  [S2] Public transport's good as well. \n",
      "23.232351303100586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Public transport's good as well. \n",
      "token:  [S1] Yeah. \n",
      "5.43934440612793\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Yeah. \n",
      "3.14760160446167\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Places where there's loads of people. \n",
      "26.29524040222168\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Places where there's loads of people. \n",
      "token:  [S2] Yeah. \n",
      "6.73552942276001\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Like Schools? \n",
      "57.229122161865234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Like Schools? \n",
      "token:  [MOD] Perfect. \n",
      "63.17272186279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect. \n",
      "token:  [S2] Yeah schools. \n",
      "198.6958465576172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah schools. \n",
      "token:  [S1] Yeah. \n",
      "5.654327869415283\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Yeah. \n",
      "4.163616180419922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Perfect so you ha you found two \n",
      "665.1809692382812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect so you ha you found two \n",
      "token:  [S1] Something like that yeah. \n",
      "51.91938781738281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Something like that yeah. \n",
      "token:  [MOD] already. You found the school and hospital. \n",
      "181.98541259765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] already. You found the school and hospital. \n",
      "token:  [S2] Ok \n",
      "89.85091400146484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok \n",
      "token:  [MOD] So \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.23469543457031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So \n",
      "token:  [S2] so we need one more? \n",
      "56.9674186706543\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so we need one more? \n",
      "token:  [MOD] one more and it's you mentioned public transpo rt \n",
      "229.5259552001953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] one more and it's you mentioned public transpo rt \n",
      "token:  [S1] Hmm we mentioned public tran sport, work? No. \n",
      "149.22802734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hmm we mentioned public tran sport, work? No. \n",
      "token:  [MOD] It it's it's about public trans port. \n",
      "79.71452331542969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It it's it's about public trans port. \n",
      "token:  [S2] Oh is it? \n",
      "23.273286819458008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh is it? \n",
      "token:  [MOD] So what which means? \n",
      "77.30128479003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So what which means? \n",
      "token:  [S2] Oh you mean it's \n",
      "46.4278564453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh you mean it's \n",
      "token:  [MOD] Yeah. \n",
      "99.00963592529297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] a specific one? \n",
      "61.42356491088867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] a specific one? \n",
      "token:  [S1] Sma \n",
      "52.09362030029297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Sma \n",
      "token:  [S2] A bus? \n",
      "26.80658721923828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A bus? \n",
      "token:  [S1] ll places. \n",
      "62.570499420166016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ll places. \n",
      "token:  [S2] A train? \n",
      "16.500146865844727\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A train? \n",
      "token:  [S1] Small cr owded places. \n",
      "171.83184814453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Small cr owded places. \n",
      "token:  [S2] But they want a s \n",
      "37.61549758911133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] But they want a s \n",
      "token:  [S1] A bus? \n",
      "34.768524169921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] A bus? \n",
      "token:  [S2] pecific \n",
      "109.84491729736328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] pecific \n",
      "token:  [S1] Yeah yeah. \n",
      "13.809377670288086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah yeah. \n",
      "token:  [S2] tran public tran sport system so \n",
      "316.08978271484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] tran public tran sport system so \n",
      "token:  [S1] Dublin bus? \n",
      "80.20148468017578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Dublin bus? \n",
      "token:  [S2] Plane? \n",
      "15.235620498657227\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Plane? \n",
      "token:  [MOD] Plane \n",
      "176.70816040039062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Plane \n",
      "token:  [S2] A plane. \n",
      "45.320899963378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A plane. \n",
      "token:  [S1] A plane? \n",
      "7.995412826538086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] A plane? \n",
      "token:  [MOD] Yeah guys you f \n",
      "698.0230712890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah guys you f \n",
      "token:  [S1] Oh wow. \n",
      "67.33782196044922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh wow. \n",
      "token:  [MOD] ound all three. \n",
      "238.05374145507812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ound all three. \n",
      "token:  [S2] I I I always get sick on the plane. Yeah \n",
      "98.60130310058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I I I always get sick on the plane. Yeah \n",
      "token:  [S1] Really? \n",
      "12.179909706115723\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Really? \n",
      "token:  [S2] Always. Always. \n",
      "13.598177909851074\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Always. Always. \n",
      "token:  [S1] I didn't kn \n",
      "47.28291320800781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I didn't kn \n",
      "token:  [S2] Every \n",
      "32.180606842041016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Every \n",
      "token:  [S1] I didn \n",
      "52.04539108276367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I didn \n",
      "token:  [S2] ime so \n",
      "35.16758728027344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ime so \n",
      "token:  [S1] ok. \n",
      "16.90694808959961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok. \n",
      "token:  [MOD] So can you rank those answers now please? Do you remember which ones they are? It's sc \n",
      "75.69132232666016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So can you rank those answers now please? Do you remember which ones they are? It's sc \n",
      "token:  [S1] Yeah. \n",
      "61.647830963134766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] hool yeah? \n",
      "294.3173522949219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hool yeah? \n",
      "token:  [S2] Yeah. \n",
      "25.478347778320312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] ok. \n",
      "52.267005920410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok. \n",
      "token:  [S2] It's the it was a hospital \n",
      "118.4372329711914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It's the it was a hospital \n",
      "token:  [S1] Plane and school. \n",
      "61.681556701660156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Plane and school. \n",
      "token:  [S2] plane and school. \n",
      "6.127912521362305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] plane and school. \n",
      "token:  [MOD] Perfect. So which one is first do you think? You have to rank them from the most popular to the least popular. \n",
      "25.751914978027344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect. So which one is first do you think? You have to rank them from the most popular to the least popular. \n",
      "token:  [S1] Most popular. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.672386169433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Most popular. \n",
      "token:  [S2] Think hospital might be most popular. \n",
      "53.5261344909668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Think hospital might be most popular. \n",
      "token:  [S1] Ok. \n",
      "11.730086326599121\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] What do you think? \n",
      "4.730863094329834\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] What do you think? \n",
      "token:  [S1] I'll go with that cause there's I don't know, I just think it's safe safe enough. Should be safe to be in a hospital \n",
      "31.625980377197266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'll go with that cause there's I don't know, I just think it's safe safe enough. Should be safe to be in a hospital \n",
      "token:  [S2] Yeah if oh but that i \n",
      "108.8284912109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah if oh but that i \n",
      "token:  [S1] because they clean all the time that you're in contact with sick people. So I I think school is the easiest becase for kids lik kids get it easier. \n",
      "98.42021942138672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] because they clean all the time that you're in contact with sick people. So I I think school is the easiest becase for kids lik kids get it easier. \n",
      "token:  [S2] ok. Yeah. \n",
      "20.023056030273438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. Yeah. \n",
      "token:  [S1] Well I'd say between school an a nd hospital. \n",
      "56.981224060058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Well I'd say between school an a nd hospital. \n",
      "token:  [S2] Hospit al. \n",
      "20.83708953857422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hospit al. \n",
      "token:  [S1] Choose one. \n",
      "13.866856575012207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Choose one. \n",
      "token:  [S2] It could be sch I mean it could be either one really. \n",
      "36.9498291015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It could be sch I mean it could be either one really. \n",
      "token:  [S1] We go for hospital? \n",
      "74.14952850341797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] We go for hospital? \n",
      "token:  [S2] Let's go for hos pital? \n",
      "15.571623802185059\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Let's go for hos pital? \n",
      "token:  [S1] We go for hospital? \n",
      "20.4310359954834\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] We go for hospital? \n",
      "token:  [MOD] So you your answers are hospital? And then? \n",
      "114.38841247558594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you your answers are hospital? And then? \n",
      "token:  [S1] For the most popular and then a school. \n",
      "61.44618225097656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] For the most popular and then a school. \n",
      "token:  [MOD] And then \n",
      "116.49010467529297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And then \n",
      "token:  [S1] And then plane. \n",
      "78.31926727294922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] And then plane. \n",
      "token:  [S2] Plane. \n",
      "6.997419834136963\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Plane. \n",
      "token:  [MOD] You were almost there. \n",
      "37.77693176269531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You were almost there. \n",
      "token:  [S2] Awh was it \n",
      "120.54075622558594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Awh was it \n",
      "token:  [S1] No way! \n",
      "10.715970039367676\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No way! \n",
      "token:  [MOD]  school. \n",
      "227.08306884765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]  school. \n",
      "token:  [S2] School so we should have like yeah exactly yeah \n",
      "149.90176391601562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] School so we should have like yeah exactly yeah \n",
      "token:  [S1] School yeah I was right. Because I \n",
      "38.65372085571289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] School yeah I was right. Because I \n",
      "token:  [MOD] Hospital? \n",
      "210.59864807128906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Hospital? \n",
      "token:  [S1] I I think of kid s and I in my \n",
      "202.0403594970703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I I think of kid s and I in my \n",
      "token:  [S2] You think of no but that makes perfect sense yeah. \n",
      "36.6101188659668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You think of no but that makes perfect sense yeah. \n",
      "token:  [S1] Yeah and then the kids bring it home and the parents get sick and so \n",
      "41.21007537841797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah and then the kids bring it home and the parents get sick and so \n",
      "token:  [S2] Yeah \n",
      "9.592500686645508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [S1] on so it's def \n",
      "105.57916259765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] on so it's def \n",
      "token:  [MOD] Teachers \n",
      "970.887451171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Teachers \n",
      "token:  [S1] Teachers yeah yeah it's def \n",
      "148.00242614746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Teachers yeah yeah it's def \n",
      "token:  [S2] right so it's teachers as well that's right that's right. Yeah. \n",
      "32.58007049560547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] right so it's teachers as well that's right that's right. Yeah. \n",
      "token:  [MOD] and the third answer was plane. \n",
      "120.83799743652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and the third answer was plane. \n",
      "token:  [S2] Plane ok. \n",
      "93.59577178955078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Plane ok. \n",
      "token:  [S1] Yeah yeah I'd think so. \n",
      "17.5858097076416\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah yeah I'd think so. \n",
      "token:  [S2] So we got one right. \n",
      "14.146496772766113\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So we got one right. \n",
      "token:  [MOD] Ah but still ah that's good. Are you ready for the second one? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.27540969848633\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ah but still ah that's good. Are you ready for the second one? \n",
      "token:  [S2] Sure. \n",
      "17.1470947265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Sure. \n",
      "token:  [S1] Yeah. \n",
      "6.353737831115723\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Name an instrument you can find in a symphony orchestra. \n",
      "39.60953140258789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Name an instrument you can find in a symphony orchestra. \n",
      "token:  [S1] Violin? \n",
      "36.119873046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin? \n",
      "token:  [S2] Violin? \n",
      "4.31160831451416\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violin? \n",
      "token:  [MOD] That's perfect. You got it. Yeah. Yeah. \n",
      "26.53849220275879\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's perfect. You got it. Yeah. Yeah. \n",
      "token:  [S1] Eh it's the first thing that comes to mind. \n",
      "14.563821792602539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Eh it's the first thing that comes to mind. \n",
      "token:  [S2] Piano? \n",
      "32.49282455444336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Piano? \n",
      "token:  [S1] Yeah definitely. \n",
      "16.397930145263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah definitely. \n",
      "token:  [S2] Yeah? \n",
      "6.764288425445557\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah? \n",
      "token:  [S1] Eh Trombone? \n",
      "42.995094299316406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Eh Trombone? \n",
      "token:  [S2] Yeah. \n",
      "5.559067726135254\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Hmm what's it called? Drums? \n",
      "29.188867568969727\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hmm what's it called? Drums? \n",
      "token:  [S2] Yeah. Perfect. Drums. \n",
      "8.803116798400879\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. Perfect. Drums. \n",
      "token:  [MOD] That's the se cond one yeah. \n",
      "157.6941680908203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's the se cond one yeah. \n",
      "token:  [S2] \n",
      "37.046470642089844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] Violin, drums I'm just trying to think like front row. \n",
      "46.149070739746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin, drums I'm just trying to think like front row. \n",
      "token:  [S2] Yeah \n",
      "16.92502784729004\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [S1] string anything so there's violins and then there's cellos Cellos. \n",
      "81.52007293701172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] string anything so there's violins and then there's cellos Cellos. \n",
      "token:  [S2] Cellos That's right cellos \n",
      "26.860153198242188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cellos That's right cellos \n",
      "token:  [MOD] Great guys. \n",
      "154.4235382080078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Great guys. \n",
      "token:  [S2] are there. \n",
      "71.19841003417969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] are there. \n",
      "token:  [S1] Cellos. \n",
      "45.1735954284668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cellos. \n",
      "token:  [S2] That's right. \n",
      "6.9670729637146\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] That's right. \n",
      "token:  [MOD] Perfect so you have all three. \n",
      "78.6267318725586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect so you have all three. \n",
      "token:  [S2] We found three ok. \n",
      "86.88038635253906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] We found three ok. \n",
      "token:  [S1] Three. \n",
      "8.97095012664795\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Three. \n",
      "token:  [MOD] So we have \n",
      "142.1186981201172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So we have \n",
      "token:  [S2] Great. \n",
      "78.24483489990234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Great. \n",
      "token:  [MOD] Violin eh drum and cello. \n",
      "306.9245910644531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Violin eh drum and cello. \n",
      "token:  [S2] Cello yeah. \n",
      "31.48174285888672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cello yeah. \n",
      "token:  [S1] And drums. \n",
      "15.548666954040527\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] And drums. \n",
      "token:  [MOD] And can you order them please now in terms of popularity? \n",
      "80.31954956054688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And can you order them please now in terms of popularity? \n",
      "token:  [S1] Well definitely vio lin. Cellos \n",
      "720.3833618164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Well definitely vio lin. Cellos \n",
      "token:  [S2] Violin is \n",
      "29.186626434326172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violin is \n",
      "token:  [S1] and drums. \n",
      "28.366764068603516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and drums. \n",
      "token:  [S2] I would think so cause that's how you see them when you're sitting \n",
      "31.415273666381836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I would think so cause that's how you see them when you're sitting \n",
      "token:  [S1] How you see them when you're sitting. I think \n",
      "7.838832378387451\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] How you see them when you're sitting. I think \n",
      "token:  [S2] sitting. \n",
      "16.445186614990234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] sitting. \n",
      "token:  [S1] drums are definitely at the back so. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.73981475830078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] drums are definitely at the back so. \n",
      "token:  [S2] And violin should be number one. \n",
      "24.095979690551758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] And violin should be number one. \n",
      "token:  [S1] Probably. \n",
      "11.437103271484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Probably. \n",
      "token:  [S2] I think so. \n",
      "4.3493804931640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think so. \n",
      "token:  [MOD] So what do you think? \n",
      "11.331825256347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So what do you think? \n",
      "token:  [S1] \n",
      "24.544660568237305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] Think \n",
      "28.369728088378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Think \n",
      "token:  [S1] Violin \n",
      "29.9620304107666\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin \n",
      "token:  [S2] Violin, \n",
      "12.240726470947266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violin, \n",
      "token:  [S1] first? \n",
      "34.19189453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] first? \n",
      "token:  [S2] cello and drums. \n",
      "56.76667785644531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cello and drums. \n",
      "token:  [MOD] Perfect. That's \n",
      "131.03387451171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect. That's \n",
      "token:  [S2] Yeah. \n",
      "85.15103912353516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] it. \n",
      "83.91923522949219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it. \n",
      "token:  [S2] Oh yay! \n",
      "45.056785583496094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh yay! \n",
      "token:  [MOD] That's correct. Well done guys very \n",
      "130.78175354003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's correct. Well done guys very \n",
      "token:  [S1] Very good, very good, very good. \n",
      "13.00357723236084\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Very good, very good, very good. \n",
      "token:  [S2] Woohoo! \n",
      "8.326902389526367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Woohoo! \n",
      "token:  [S1] Yes. We're good at this. Sorry \n",
      "16.28683853149414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yes. We're good at this. Sorry \n",
      "token:  [S2] This \n",
      "18.466005325317383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] This \n",
      "token:  [MOD] \n",
      "86.89037322998047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [good.] \n",
      "3668.55078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [good.] \n",
      "token:  [S2] should be my career. \n",
      "4.18095064163208\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] should be my career. \n",
      "token:  [MOD] I think so. \n",
      "24.89470100402832\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I think so. \n",
      "token:  [S2] ok. ok \n",
      "73.5457992553711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. ok \n",
      "token:  [MOD] Third question, the last question now. \n",
      "80.60150146484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Third question, the last question now. \n",
      "token:  [S2] Ok. \n",
      "32.862831115722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] Name something excuse me that people cut. \n",
      "286.6220703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Name something excuse me that people cut. \n",
      "token:  [S1] That people \n",
      "70.0372543334961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] That people \n",
      "token:  [MOD] excuse me. Cut. What do they cut? \n",
      "123.88037872314453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] excuse me. Cut. What do they cut? \n",
      "token:  [S1] I don't \n",
      "27.307315826416016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't \n",
      "token:  [S2] Oh \n",
      "13.06472110748291\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh \n",
      "token:  [S1] I don't get it what they \n",
      "14.2650146484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't get it what they \n",
      "token:  [S2] Like is this open ended like anything? \n",
      "2.330928087234497\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Like is this open ended like anything? \n",
      "token:  [MOD] Can be anything yeah that they cut. \n",
      "165.29083251953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Can be anything yeah that they cut. \n",
      "token:  [S2] Oh \n",
      "79.44882202148438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh \n",
      "token:  [MOD] People would cut. \n",
      "307.0766906738281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] People would cut. \n",
      "token:  [S2] a f \n",
      "134.56703186035156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] a f \n",
      "token:  [S1] Oh cut. Oh ye \n",
      "4.288982391357422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh cut. Oh ye \n",
      "token:  [MOD] Yeah. \n",
      "97.0721664428711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] ah oh yeah yeah yeah. \n",
      "42.97024154663086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah oh yeah yeah yeah. \n",
      "token:  [S2] Oh ok. Eh paper? Paper? \n",
      "3.1051316261291504\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh ok. Eh paper? Paper? \n",
      "token:  [MOD] Paper is one yeah very good. \n",
      "132.63485717773438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Paper is one yeah very good. \n",
      "token:  [S1] Grass? I don't know, cut the \n",
      "67.48404693603516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Grass? I don't know, cut the \n",
      "token:  [S2] Yeah. \n",
      "10.401836395263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] grass? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.780033111572266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] grass? \n",
      "token:  [S2] Tape? \n",
      "17.425617218017578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Tape? \n",
      "token:  [S1] Tape. \n",
      "10.225043296813965\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Tape. \n",
      "token:  [S2] \n",
      "8.150042533874512\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] Cut. \n",
      "22.6580753326416\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cut. \n",
      "token:  [S2] Hair? \n",
      "5.114971160888672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair? \n",
      "token:  [MOD] Hair. \n",
      "42.22378158569336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Hair. \n",
      "token:  [S1] Hair. \n",
      "13.67948055267334\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hair. \n",
      "token:  [MOD] Very good. \n",
      "39.25511169433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good. \n",
      "token:  [S1] Yea h. \n",
      "70.5194091796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yea h. \n",
      "token:  [S2] ok. \n",
      "6.221015930175781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] You have two so one more. \n",
      "80.41071319580078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have two so one more. \n",
      "token:  [S2] So we've got paper, h air. \n",
      "125.93931579589844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So we've got paper, h air. \n",
      "token:  [S1] Cut your sk cut I don't know. Cut vegetables? \n",
      "135.926025390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cut your sk cut I don't know. Cut vegetables? \n",
      "token:  [S2] Cut yourself? \n",
      "8.054182052612305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cut yourself? \n",
      "token:  [S1] sk \n",
      "6.304434776306152\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] sk \n",
      "token:  [MOD] Hmm you're cl \n",
      "450.5911560058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Hmm you're cl \n",
      "token:  [S1] Kitchen \n",
      "259.0849609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Kitchen \n",
      "token:  [MOD] ose. \n",
      "250.8534698486328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ose. \n",
      "token:  [S1] like foo \n",
      "133.9626007080078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like foo \n",
      "token:  [S2] Food? \n",
      "20.664772033691406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Food? \n",
      "token:  [S1] d cook? Yeah but something food? Meat? \n",
      "3.0099775791168213\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] d cook? Yeah but something food? Meat? \n",
      "token:  [MOD] Meat per \n",
      "540.9840087890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Meat per \n",
      "token:  [S2] Meat yeah. \n",
      "119.9039077758789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Meat yeah. \n",
      "token:  [MOD] fect. \n",
      "184.3514862060547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] fect. \n",
      "token:  [S2] There you go. \n",
      "29.304031372070312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] There you go. \n",
      "token:  [MOD] You have all three answ ers. \n",
      "81.84479522705078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have all three answ ers. \n",
      "token:  [S2] ok. \n",
      "77.10823822021484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] Great. And would you order them now please? \n",
      "66.29650115966797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Great. And would you order them now please? \n",
      "token:  [S2] I think paper might be first. \n",
      "46.35102462768555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think paper might be first. \n",
      "token:  [S1] It's the first thing that came to your mind so ye the definitely cut p \n",
      "75.57929992675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] It's the first thing that came to your mind so ye the definitely cut p \n",
      "token:  [S2] to mind so maybe. \n",
      "44.510826110839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] to mind so maybe. \n",
      "token:  [S1] aper. Meat maybe second \n",
      "466.1701965332031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] aper. Meat maybe second \n",
      "token:  [S2] And then hai \n",
      "43.89740753173828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] And then hai \n",
      "token:  [S1] and then hair. \n",
      "34.76564025878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and then hair. \n",
      "token:  [S2] r yeah. Yeah. \n",
      "33.8851203918457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] r yeah. Yeah. \n",
      "token:  [S1] So we go for that? \n",
      "25.8067684173584\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So we go for that? \n",
      "token:  [S2] Yeah let's go for that. \n",
      "2.556302070617676\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah let's go for that. \n",
      "token:  [MOD] Are you sure? Yeah? \n",
      "20.814044952392578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Are you sure? Yeah? \n",
      "token:  [S1] I don't know. Is it? It's not No. \n",
      "16.365427017211914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't know. Is it? It's not No. \n",
      "token:  [MOD] No. The first one is hair. The most po \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.76282501220703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. The first one is hair. The most po \n",
      "token:  [S2] Oh! \n",
      "128.31686401367188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh! \n",
      "token:  [MOD] pular answer was eh was hair \n",
      "2295.2890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] pular answer was eh was hair \n",
      "token:  [S1] Cut my \n",
      "145.76275634765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cut my \n",
      "token:  [MOD] actually. \n",
      "439.77960205078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] actually. \n",
      "token:  [S1] hair. \n",
      "66.73015594482422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hair. \n",
      "token:  [MOD] Yeah \n",
      "258.7803649902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah \n",
      "token:  [S2] ok \n",
      "60.5491828918457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] and then paper and the last one was meat. \n",
      "165.4991912841797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and then paper and the last one was meat. \n",
      "token:  [S2] was meat ok \n",
      "117.31230163574219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] was meat ok \n",
      "token:  [S1] meat \n",
      "7.825641632080078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat \n",
      "token:  [MOD] But you did great. Well done. \n",
      "69.38371276855469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But you did great. Well done. \n",
      "token:  [S2] Thanks. \n",
      "24.069686889648438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Thanks. \n",
      "token:  [S1] I don't know how we get to meat from \n",
      "18.066184997558594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't know how we get to meat from \n",
      "token:  [S2] I know. \n",
      "10.470459938049316\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I know. \n",
      "token:  [S1] from paper and hair. \n",
      "74.23945617675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] from paper and hair. \n",
      "token:  [S2] I know. \n",
      "3.8646702766418457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I know. \n",
      "token:  [MOD] But eh thanks very much for coming. \n",
      "115.5477523803711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But eh thanks very much for coming. \n",
      "token:  [S2] Oh we're finished. \n",
      "30.291126251220703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh we're finished. \n",
      "token:  [S1] No worries, that's it? \n",
      "3.0949554443359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No worries, that's it? \n",
      "token:  [MOD] Yeah that was it. \n",
      "27.598176956176758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah that was it. \n",
      "token:  [S1] Absolutely. \n",
      "19.82996368408203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Absolutely. \n",
      "token:  [S2] Oh dear. Thanks very much. \n",
      "12.961468696594238\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh dear. Thanks very much. \n",
      "token:  [S1] It was so easy.\n",
      "12.166211128234863\n",
      "MOD : 137.21784808967686\n",
      "S1 : 109.97252718607585\n",
      "S2 : 99.20943812970762\n",
      "speech transcription_Transcriber/S13.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD]: Well hello, thanks very much for coming here today. Eh we're going to play a quiz. \n",
      "60.579681396484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Well hello, thanks very much for coming here today. Eh we're going to play a quiz. \n",
      "token:  [S1]: hm \n",
      "36.641963958740234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hm \n",
      "token:  [MOD]: I'm going \n",
      "64.39612579345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: I'm going \n",
      "token:  [S2]: ok \n",
      "75.7791519165039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: ok \n",
      "token:  [MOD]: to ask you three survey questions that \n",
      "224.76187133789062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: to ask you three survey questions that \n",
      "token:  [S1]: ok \n",
      "114.98690032958984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: ok \n",
      "token:  [MOD]: were previously ah posed in a group of hundred people. For each \n",
      "266.9358825683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: were previously ah posed in a group of hundred people. For each \n",
      "token:  [S1]: umhm \n",
      "449.12713623046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: umhm \n",
      "token:  [MOD]: question I'd like you to give me the three most popular answers. You'll have to talk to each other, you need to collaborate so \n",
      "37.19087219238281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: question I'd like you to give me the three most popular answers. You'll have to talk to each other, you need to collaborate so \n",
      "token:  [S2]: umhm \n",
      "279.8279113769531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: umhm \n",
      "token:  [MOD]: that you can rank those answers. \n",
      "166.87184143066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: that you can rank those answers. \n",
      "token:  [S1]: umhm \n",
      "91.05985260009766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: umhm \n",
      "token:  [MOD]: ok? \n",
      "52.774253845214844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: ok? \n",
      "token:  [S2]: ok \n",
      "25.94454574584961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: ok \n",
      "token:  [MOD]: eh is it clear or would you like me to give you an example or \n",
      "34.88408660888672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: eh is it clear or would you like me to give you an example or \n",
      "token:  [S2]: So you will be giving us the list of \n",
      "34.41527557373047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: So you will be giving us the list of \n",
      "token:  [MOD]: I'll give you \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.61334991455078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: I'll give you \n",
      "token:  [S2]: answers \n",
      "209.04347229003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: answers \n",
      "token:  [MOD]: No, I'll give you the question \n",
      "45.9296989440918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: No, I'll give you the question \n",
      "token:  [S2]: yeah \n",
      "61.41923141479492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [MOD]: you'll come up with answers \n",
      "60.725563049316406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: you'll come up with answers \n",
      "token:  [S1]: umhm \n",
      "82.06175994873047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: umhm \n",
      "token:  [MOD]: we need three of them \n",
      "69.10932159423828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: we need three of them \n",
      "token:  [S2]: ok \n",
      "34.43912887573242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: ok \n",
      "token:  [MOD]: and then you need to decide the ranking of the answers, which is the most \n",
      "46.15658187866211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: and then you need to decide the ranking of the answers, which is the most \n",
      "token:  [S1]: ok \n",
      "94.92021942138672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: ok \n",
      "token:  [S2]: popular \n",
      "19.79512596130371\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: popular \n",
      "token:  [MOD]: ok for example. \n",
      "166.1959991455078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: ok for example. \n",
      "token:  [S1]: ok \n",
      "22.801956176757812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: ok \n",
      "token:  [MOD]: Yeah? Are you ready? \n",
      "41.02707290649414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Yeah? Are you ready? \n",
      "token:  [S2]: yeah \n",
      "37.71223831176758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [S1]: yeah yeah \n",
      "13.91999626159668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah yeah \n",
      "token:  [S2]: yeah \n",
      "6.72012996673584\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [S1]: yeah, Yeah? \n",
      "17.212263107299805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah, Yeah? \n",
      "token:  [MOD]: eh Can you please name a public place where you're likely to catch a cold or a flu bug. \n",
      "44.63350296020508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: eh Can you please name a public place where you're likely to catch a cold or a flu bug. \n",
      "token:  [S2]: So y y you do you want to know the locations \n",
      "90.86384582519531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: So y y you do you want to know the locations \n",
      "token:  [MOD]: yes \n",
      "76.85920715332031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yes \n",
      "token:  [S2]: or type of place three places yeah where there where there is lots of people where someone can catch a cold. \n",
      "132.4340057373047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: or type of place three places yeah where there where there is lots of people where someone can catch a cold. \n",
      "token:  [MOD]: Imagine you \n",
      "349.93438720703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Imagine you \n",
      "token:  [S2]: hm \n",
      "88.68330383300781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: hm \n",
      "token:  [MOD]: go to this place and then you might \n",
      "92.3228759765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: go to this place and then you might \n",
      "token:  [S2]: get a flu or a cold \n",
      "47.873252868652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: get a flu or a cold \n",
      "token:  [S1]: umhm \n",
      "36.55710983276367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: umhm \n",
      "token:  [MOD]: or \n",
      "108.53987121582031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: or \n",
      "token:  [S2]: maybe \n",
      "63.943172454833984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: maybe \n",
      "token:  [S1]: hmm hospital yeah \n",
      "92.26667022705078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hmm hospital yeah \n",
      "token:  [S2]: and \n",
      "11.037762641906738\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: and \n",
      "token:  [S1]: train some train station and all the people \n",
      "133.5382843017578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: train some train station and all the people \n",
      "token:  [S2]: yeah yeah \n",
      "15.444744110107422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah yeah \n",
      "token:  [S1]: hmm \n",
      "8.808123588562012\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hmm \n",
      "token:  [S2]: makes sense \n",
      "10.172662734985352\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: makes sense \n",
      "token:  [S2]: so first thing I would say hospital might be the \n",
      "89.30409240722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: so first thing I would say hospital might be the \n",
      "token:  [S1]: hospital ok \n",
      "41.42213821411133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hospital ok \n",
      "token:  [S2]: yeah \n",
      "8.410416603088379\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [S1]: and then \n",
      "12.365920066833496\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: and then \n",
      "token:  [S2]: then \n",
      "5.8633341789245605\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: then \n",
      "token:  [S1]: se \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.886247634887695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: se \n",
      "token:  [S2]: public transport like train station \n",
      "86.78296661376953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: public transport like train station \n",
      "token:  [S1]: yeah public transport train station ah station or airport or something like \n",
      "49.09475326538086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah public transport train station ah station or airport or something like \n",
      "token:  [S2]: yeah \n",
      "9.081487655639648\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [S1]: that yeah and the third is hmm \n",
      "55.38738250732422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: that yeah and the third is hmm \n",
      "token:  [S2]: can you differentiate among these transport \n",
      "88.61626434326172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: can you differentiate among these transport \n",
      "token:  [MOD]: umhm \n",
      "515.2134399414062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: umhm \n",
      "token:  [S2]: stations \n",
      "183.45335388183594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: stations \n",
      "token:  [MOD]: I think you\n",
      "67.28145599365234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: I think you\n",
      "token:  [oo] you're very close ah you need to find a different means of transport. \n",
      "130.85386657714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [oo] you're very close ah you need to find a different means of transport. \n",
      "token:  [S1]: hmm \n",
      "7.326610088348389\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hmm \n",
      "token:  [MOD]: It's not the train it's something else \n",
      "45.03065490722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: It's not the train it's something else \n",
      "token:  [MOD]: that you can use when you want to escape from Ireland you want to go somewhere warm. \n",
      "65.11627960205078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: that you can use when you want to escape from Ireland you want to go somewhere warm. \n",
      "token:  [S2]: Ferry? \n",
      "92.66295623779297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: Ferry? \n",
      "token:  [MOD]: The most common \n",
      "94.47516632080078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: The most common \n",
      "token:  [MOD]: means of transport that Irish people would take. \n",
      "255.0561981201172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: means of transport that Irish people would take. \n",
      "token:  [S2]: airport and \n",
      "227.93109130859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: airport and \n",
      "token:  [MOD]: the pla \n",
      "184.65103149414062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: the pla \n",
      "token:  [S2]: planes \n",
      "278.8350830078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: planes \n",
      "token:  [S1]: hmm \n",
      "6.646677017211914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hmm \n",
      "token:  [MOD]: nes yeah \n",
      "256.1054992675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: nes yeah \n",
      "token:  [S2]: so \n",
      "50.4356575012207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: so \n",
      "token:  [MOD]: umhm \n",
      "459.9083557128906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: umhm \n",
      "token:  [S2]: yeah \n",
      "33.50124740600586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [S1]: umhm yeah \n",
      "6.5899152755737305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: umhm yeah \n",
      "token:  [MOD]: So you already found the plane \n",
      "146.7699432373047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: So you already found the plane \n",
      "token:  [S1]: umhm \n",
      "126.66865539550781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: umhm \n",
      "token:  [MOD]: you found the hospital \n",
      "174.4100799560547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: you found the hospital \n",
      "token:  [S1]: umhm \n",
      "99.18276977539062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: umhm \n",
      "token:  [MOD]: and there is a third one. \n",
      "44.41166305541992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: and there is a third one. \n",
      "token:  [S1]: hmm \n",
      "26.079761505126953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hmm \n",
      "token:  [S2]: Maybe a school or university? \n",
      "35.39621353149414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: Maybe a school or university? \n",
      "token:  [S1]: yeah school \n",
      "7.547165870666504\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah school \n",
      "token:  [MOD]: perfect that \n",
      "225.68309020996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: perfect that \n",
      "token:  [S1]: yeah \n",
      "36.04184341430664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah \n",
      "token:  [MOD]: 's the third one \n",
      "90.7582778930664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: 's the third one \n",
      "token:  [S1]: hmm \n",
      "23.435819625854492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hmm \n",
      "token:  [S2]: yeah \n",
      "5.88154935836792\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [MOD]: that's great. And could you rank those answers please? \n",
      "76.97638702392578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: that's great. And could you rank those answers please? \n",
      "token:  [S2]: The hospital definitely for first for me I'm not sure \n",
      "171.45591735839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: The hospital definitely for first for me I'm not sure \n",
      "token:  [S1]: first one yeah \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.99715805053711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: first one yeah \n",
      "token:  [S2]: what you \n",
      "21.989633560180664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: what you \n",
      "token:  [S1]: Yeah it's first for me. \n",
      "37.12928009033203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: Yeah it's first for me. \n",
      "token:  [S2]: yeah \n",
      "7.472891330718994\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [S1]: and then the \n",
      "26.18282699584961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: and then the \n",
      "token:  [S2]: airport \n",
      "5.824283599853516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: airport \n",
      "token:  [MOD]: The plane? \n",
      "112.90080261230469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: The plane? \n",
      "token:  [S1]: the plane \n",
      "19.229570388793945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: the plane \n",
      "token:  [S2]: yeah \n",
      "11.397331237792969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [S1]: yeah \n",
      "11.11449909210205\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah \n",
      "token:  [S1]: And third is uhm \n",
      "72.35425567626953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: And third is uhm \n",
      "token:  [S1]: the education place \n",
      "82.40679168701172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: the education place \n",
      "token:  [S2]: school \n",
      "9.807754516601562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: school \n",
      "token:  [S1]: yeah school \n",
      "6.002810478210449\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah school \n",
      "token:  [MOD]: Almost there. \n",
      "107.85364532470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Almost there. \n",
      "token:  [MOD]: The first one is the ho the school \n",
      "257.2448425292969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: The first one is the ho the school \n",
      "token:  [MOD]: Second is \n",
      "96.47560119628906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Second is \n",
      "token:  [S2]: ok \n",
      "107.30855560302734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: ok \n",
      "token:  [MOD]: hospital and third one is plane. \n",
      "424.17376708984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: hospital and third one is plane. \n",
      "token:  [S2]: That's interesting \n",
      "48.153480529785156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: That's interesting \n",
      "token:  [MOD]: You almost found \n",
      "199.93069458007812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: You almost found \n",
      "token:  [S1]: Oh\n",
      "55.26396942138672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: Oh\n",
      "token:  [oh] ! \n",
      "479.3865661621094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [oh] ! \n",
      "token:  [S2]: it ah? \n",
      "5.831857681274414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: it ah? \n",
      "token:  [S2]: yeah \n",
      "12.98897647857666\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [MOD]: well done. \n",
      "84.76884460449219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: well done. \n",
      "token:  [S1]: Yeah! \n",
      "28.175291061401367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: Yeah! \n",
      "token:  [S2]: \n",
      "9.298212051391602\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: \n",
      "token:  [MOD]: Eh are you ready to move to the second question? \n",
      "58.15308380126953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Eh are you ready to move to the second question? \n",
      "token:  [S2]: sure \n",
      "40.3311653137207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: sure \n",
      "token:  [S1]: yeah sure \n",
      "5.303576469421387\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah sure \n",
      "token:  [S2]: yeah \n",
      "5.346323490142822\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [MOD]: Can you name an instrument in a symphony orchestra. \n",
      "78.1762466430664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Can you name an instrument in a symphony orchestra. \n",
      "token:  [MOD]: A musical instrument. \n",
      "20.321828842163086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: A musical instrument. \n",
      "token:  [S1]: using instrument using what? \n",
      "132.79345703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: using instrument using what? \n",
      "token:  [MOD]: in a symphony orchestra? Like a musical instrument? \n",
      "45.76301956176758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: in a symphony orchestra? Like a musical instrument? \n",
      "token:  [S1]: umhm \n",
      "83.96578979492188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: umhm \n",
      "token:  [S2]: Maybe a saxophone? \n",
      "14.646937370300293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: Maybe a saxophone? \n",
      "token:  [S1]: yeah \n",
      "21.310100555419922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah \n",
      "token:  [S2]: piano \n",
      "13.149914741516113\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: piano \n",
      "token:  [S2]: and like might third might be flute \n",
      "2.8021955490112305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: and like might third might be flute \n",
      "token:  [S2]: but not sure whether you would find it guitar \n",
      "37.1011962890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: but not sure whether you would find it guitar \n",
      "token:  [MOD]: They're good answers but they're not the most popular ones \n",
      "42.8974609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: They're good answers but they're not the most popular ones \n",
      "token:  [S2]: ok \n",
      "43.829498291015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: ok \n",
      "token:  [S1]: sorry can you ah explain the question again? \n",
      "49.984230041503906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: sorry can you ah explain the question again? \n",
      "token:  [MOD]: eh you n you need to name an instrument where you \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.90625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: eh you n you need to name an instrument where you \n",
      "token:  [S1]: uhmh \n",
      "67.1258544921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: uhmh \n",
      "token:  [MOD]: find in a symphony orchestra. \n",
      "147.87240600585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: find in a symphony orchestra. \n",
      "token:  [S1]: symphony orchestra \n",
      "17.2187557220459\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: symphony orchestra \n",
      "token:  [MOD]: Yeah like a big orchestra \n",
      "97.31929016113281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Yeah like a big orchestra \n",
      "token:  [MOD]: or could it be like any music concert or \n",
      "95.37377166748047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: or could it be like any music concert or \n",
      "token:  [MOD]: yeah \n",
      "447.878173828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah \n",
      "token:  [S1]: any musi \n",
      "95.88919067382812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: any musi \n",
      "token:  [S2]: ok \n",
      "6.1135358810424805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: ok \n",
      "token:  [S1]: c instrument \n",
      "134.1210479736328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: c instrument \n",
      "token:  [MOD]: yeah yeah \n",
      "190.25057983398438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah yeah \n",
      "token:  [S1]: which is big \n",
      "68.82036590576172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: which is big \n",
      "token:  [MOD]: it could be big or small \n",
      "25.73970603942871\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: it could be big or small \n",
      "token:  [S1]: but what \n",
      "51.729515075683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: but what \n",
      "token:  [MOD]: there can be strings for example \n",
      "155.55982971191406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: there can be strings for example \n",
      "token:  [S1]: yeah \n",
      "53.36827087402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah \n",
      "token:  [MOD]: on the instrument \n",
      "184.2839813232422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: on the instrument \n",
      "token:  [S2]: which is which is used in a say music concert or big orchestras \n",
      "196.84100341796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: which is which is used in a say music concert or big orchestras \n",
      "token:  [MOD]: in a big concert hall for example \n",
      "43.55183410644531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: in a big concert hall for example \n",
      "token:  [S1]: umhm \n",
      "79.40401458740234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: umhm \n",
      "token:  [S1]: hmm \n",
      "12.768352508544922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hmm \n",
      "token:  [S2]: it's like I mentioned guitar for example \n",
      "2.6660964488983154\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: it's like I mentioned guitar for example \n",
      "token:  [S1]: violin? \n",
      "25.27434730529785\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: violin? \n",
      "token:  [MOD]: violin is one \n",
      "111.44641876220703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: violin is one \n",
      "token:  [S2]: yeah \n",
      "55.564701080322266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [MOD]: yeah very good \n",
      "60.47263717651367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah very good \n",
      "token:  [S2]: what else \n",
      "40.469261169433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: what else \n",
      "token:  [S2]: the one th those I I mentioned are they \n",
      "157.31488037109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: the one th those I I mentioned are they \n",
      "token:  [MOD]: They're not unfortunately \n",
      "112.68132019042969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: They're not unfortunately \n",
      "token:  [S2]: close or not? Ah ok. \n",
      "125.35379028320312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: close or not? Ah ok. \n",
      "token:  [MOD]: but they \n",
      "212.3643798828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: but they \n",
      "token:  [S1]: no no no \n",
      "38.01587677001953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: no no no \n",
      "token:  [MOD]: 're good answers but they're not the popular answers yeah \n",
      "251.61178588867188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: 're good answers but they're not the popular answers yeah \n",
      "token:  [S2]: not close ok \n",
      "109.22816467285156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: not close ok \n",
      "token:  [S1]: hmm \n",
      "16.409006118774414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hmm \n",
      "token:  [MOD]: So you have violin, you need to find two more. \n",
      "82.3006820678711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: So you have violin, you need to find two more. \n",
      "token:  [S2]: hm \n",
      "47.93367004394531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: hm \n",
      "token:  [S2]: anything related to key\n",
      "35.48900604248047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: anything related to key\n",
      "token:  [ii] board so \n",
      "5.815393924713135\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [ii] board so \n",
      "token:  [S2]: say electric keyboard or piano \n",
      "418.751708984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: say electric keyboard or piano \n",
      "token:  [S1]: no \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.809695720672607\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: no \n",
      "token:  [MOD]: unfortunately not \n",
      "130.0292205810547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: unfortunately not \n",
      "token:  [S1]: ahm there are different types of \n",
      "53.371559143066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: ahm there are different types of \n",
      "token:  [MOD]: yeah \n",
      "213.56295776367188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah \n",
      "token:  [S1]: violin \n",
      "119.66150665283203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: violin \n",
      "token:  [MOD]: yeah \n",
      "98.459228515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah \n",
      "token:  [S1]: there are big ones, small one \n",
      "62.77128219604492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: there are big ones, small one \n",
      "token:  [MOD]: umhm \n",
      "194.5897674560547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: umhm \n",
      "token:  [S1]: it just only I need to only mention violins now \n",
      "179.6318359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: it just only I need to only mention violins now \n",
      "token:  [MOD]: yeah \n",
      "51.22650909423828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah \n",
      "token:  [S1]: ok \n",
      "23.64881706237793\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: ok \n",
      "token:  [MOD]: \n",
      "68.0751724243164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: \n",
      "token:  [S1]: \n",
      "18.38289451599121\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: \n",
      "token:  [MOD]: I know it's tricky, isn't it? with instruments \n",
      "88.14787292480469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: I know it's tricky, isn't it? with instruments \n",
      "token:  [S2]: yeah and at least the one I knew I already \n",
      "81.7939224243164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah and at least the one I knew I already \n",
      "token:  [MOD]: \n",
      "63.87542724609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: \n",
      "token:  [MOD]: might be one where use your hands you hit it with your hands you tap it \n",
      "134.66549682617188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: might be one where use your hands you hit it with your hands you tap it \n",
      "token:  [S1]: oh ok drum \n",
      "112.1923599243164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: oh ok drum \n",
      "token:  [S2]: drums yeah \n",
      "5.657330513000488\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: drums yeah \n",
      "token:  [MOD]: What do you think, yeah drum \n",
      "50.3656005859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: What do you think, yeah drum \n",
      "token:  [S2]: yeah \n",
      "47.18113708496094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [MOD]: yeah \n",
      "42.96859359741211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah \n",
      "token:  [S1]: hmm \n",
      "19.094701766967773\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hmm \n",
      "token:  [MOD]: So, one more left. \n",
      "83.54109954833984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: So, one more left. \n",
      "token:  [S2]: Any other clue? \n",
      "45.89187240600586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: Any other clue? \n",
      "token:  [MOD]: \n",
      "84.83123016357422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: \n",
      "token:  [S2]: \n",
      "25.018396377563477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: \n",
      "token:  [S2]: So we have covered strings we have covered when where you hit it \n",
      "2.205486536026001\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: So we have covered strings we have covered when where you hit it \n",
      "token:  [S1]: hmm \n",
      "18.577007293701172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: hmm \n",
      "token:  [S2]: third one is entirely different \n",
      "38.14791488647461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: third one is entirely different \n",
      "token:  [MOD]: hmm \n",
      "47.37606430053711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: hmm \n",
      "token:  [S1]: is it \n",
      "29.200637817382812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: is it \n",
      "token:  [S2]: is that it? \n",
      "9.805095672607422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: is that it? \n",
      "token:  [MOD]: will I will I tell you? What it is? \n",
      "45.202178955078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: will I will I tell you? What it is? \n",
      "token:  [S1]: ok \n",
      "34.843257904052734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: ok \n",
      "token:  [S2]: or the way it is played \n",
      "32.329505920410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: or the way it is played \n",
      "token:  [MOD]: \n",
      "99.03849029541016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: \n",
      "token:  [S2]: perhaps that maybe \n",
      "192.11512756347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: perhaps that maybe \n",
      "token:  [S1]: \n",
      "12.365360260009766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: \n",
      "token:  [MOD]: You have violin you have drum and \n",
      "295.7504577636719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: You have violin you have drum and \n",
      "token:  [MOD]: The last one is cello. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.05738830566406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: The last one is cello. \n",
      "token:  [S2]: Sorry? \n",
      "37.437522888183594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: Sorry? \n",
      "token:  [MOD]: Cello? \n",
      "86.51217651367188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Cello? \n",
      "token:  [S2]: No idea what it \n",
      "78.63078308105469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: No idea what it \n",
      "token:  [MOD]: No? \n",
      "86.7461929321289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: No? \n",
      "token:  [S2]: is \n",
      "107.752685546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: is \n",
      "token:  [S1]: cello \n",
      "48.0805778503418\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: cello \n",
      "token:  [MOD]: It's like bigger \n",
      "198.2347869873047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: It's like bigger \n",
      "token:  [MOD]: cello yeah \n",
      "536.8734130859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: cello yeah \n",
      "token:  [S1]: It is sello cello \n",
      "98.33714294433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: It is sello cello \n",
      "token:  [MOD]: may be cello \n",
      "80.08927917480469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: may be cello \n",
      "token:  [S1]: yeah \n",
      "41.04563522338867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah \n",
      "token:  [MOD]: that's why \n",
      "40.141845703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: that's why \n",
      "token:  [MOD]: a bigger like \n",
      "363.8027038574219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: a bigger like \n",
      "token:  [S1]: a bigger \n",
      "28.657238006591797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: a bigger \n",
      "token:  [MOD]: yeah can't I don't even know how to describe that \n",
      "70.29654693603516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah can't I don't even know how to describe that \n",
      "token:  [MOD]: a cello \n",
      "143.50401306152344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: a cello \n",
      "token:  [S1]: ia a very big violin and you p \n",
      "164.24134826660156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: ia a very big violin and you p \n",
      "token:  [MOD]: but it's not like contrabasso you know there is this instrument as well which is very big \n",
      "55.68891525268555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: but it's not like contrabasso you know there is this instrument as well which is very big \n",
      "token:  [S1]: ah \n",
      "46.79932403564453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: ah \n",
      "token:  [S2]: and you play it with like how do you play it? \n",
      "2.2943837642669678\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: and you play it with like how do you play it? \n",
      "token:  [MOD]: I don't know \n",
      "15.52180290222168\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: I don't know \n",
      "token:  [S1]: it's string \n",
      "60.20603561401367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: it's string \n",
      "token:  [MOD]: I'm not sure actually yeah with \n",
      "97.27362823486328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: I'm not sure actually yeah with \n",
      "token:  [S2]: ok \n",
      "74.69642639160156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: ok \n",
      "token:  [MOD]: with strings yeah \n",
      "538.2683715820312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: with strings yeah \n",
      "token:  [S1]: yeah \n",
      "24.179235458374023\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah \n",
      "token:  [MOD]: yeah \n",
      "39.926177978515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah \n",
      "token:  [S2]: ok \n",
      "31.503803253173828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: ok \n",
      "token:  [MOD]: I'm not very musical myself. \n",
      "57.2767333984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: I'm not very musical myself. \n",
      "token:  [S2]: same here \n",
      "67.6261978149414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: same here \n",
      "token:  [MOD]: unfor \n",
      "1485.95068359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: unfor \n",
      "token:  [S1]: yeah \n",
      "67.32359313964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah \n",
      "token:  [MOD]: tunately \n",
      "435.11181640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: tunately \n",
      "token:  [S2]: same here \n",
      "63.0700569152832\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: same here \n",
      "token:  [MOD]: yeah \n",
      "64.32160949707031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah \n",
      "token:  [S1]: yeah II know a little bit \n",
      "98.22523498535156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah II know a little bit \n",
      "token:  [MOD]: yeah \n",
      "54.314762115478516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah \n",
      "token:  [S1]: I just I can't remeber them \n",
      "51.70759201049805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: I just I can't remeber them \n",
      "token:  [MOD]: and can you rank those answers please Which one do you think it's first? \n",
      "75.40065002441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: and can you rank those answers please Which one do you think it's first? \n",
      "token:  [S2]: Violin would be my first. How about you? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.97849655151367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: Violin would be my first. How about you? \n",
      "token:  [S1]: yeah violin and the second is uhm \n",
      "53.98653793334961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah violin and the second is uhm \n",
      "token:  [S2]: drum \n",
      "23.0399169921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: drum \n",
      "token:  [S1]: drum \n",
      "9.447959899902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: drum \n",
      "token:  [S2]: or \n",
      "17.565170288085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: or \n",
      "token:  [S1]: and then \n",
      "13.660590171813965\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: and then \n",
      "token:  [S1]: this \n",
      "13.646559715270996\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: this \n",
      "token:  [S2]: the \n",
      "5.3823418617248535\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: the \n",
      "token:  [S1]: cello \n",
      "50.86427688598633\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: cello \n",
      "token:  [S2]: cello \n",
      "5.33006477355957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: cello \n",
      "token:  [MOD]: \n",
      "87.57303619384766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: \n",
      "token:  [S2]: ok yeah \n",
      "116.48943328857422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: ok yeah \n",
      "token:  [S1]: \n",
      "11.006865501403809\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: \n",
      "token:  [MOD]: first one is N/A: \n",
      "96.96636199951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: first one is N/A: \n",
      "token:  [DO NOT DEAL WITH THIS SEGMENT] \n",
      "73.71678924560547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [DO NOT DEAL WITH THIS SEGMENT] \n",
      "token:  [MOD]: So will we move to the third question? then? \n",
      "90.5622329711914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: So will we move to the third question? then? \n",
      "token:  [S1]: ok \n",
      "33.14612579345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: ok \n",
      "token:  [MOD]: yeah? \n",
      "58.7067985534668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah? \n",
      "token:  [S2]: sure \n",
      "41.56104278564453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: sure \n",
      "token:  [S1]: yeah \n",
      "9.415830612182617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah \n",
      "token:  [MOD]: Can you name something that people cut. \n",
      "128.8647918701172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Can you name something that people cut. \n",
      "token:  [S1]: people cut \n",
      "34.04825973510742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: people cut \n",
      "token:  [MOD]: yeah \n",
      "96.6520004272461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah \n",
      "token:  [S1]: oh yeah \n",
      "20.779685974121094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: oh yeah \n",
      "token:  [S2]: cake \n",
      "23.689939498901367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: cake \n",
      "token:  [MOD]: \n",
      "67.51964569091797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: \n",
      "token:  [S2]: meat \n",
      "196.60641479492188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: meat \n",
      "token:  [S2]: What else? \n",
      "29.790700912475586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: What else? \n",
      "token:  [S1]: vegetables \n",
      "28.195680618286133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: vegetables \n",
      "token:  [S2]: yeah \n",
      "5.659544944763184\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [S1]: So meat \n",
      "120.90243530273438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: So meat \n",
      "token:  [S2]: yeah \n",
      "7.201665878295898\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [S1]: is it \n",
      "16.244211196899414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: is it \n",
      "token:  [MOD]: That's right, meat. \n",
      "167.34722900390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: That's right, meat. \n",
      "token:  [S2]: meat \n",
      "46.29316329956055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: meat \n",
      "token:  [MOD]: That's a correct answer yeah and then you need two more. \n",
      "75.5090560913086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: That's a correct answer yeah and then you need two more. \n",
      "token:  [S2]: so \n",
      "77.14254760742188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: so \n",
      "token:  [S1]: Is it \n",
      "24.06267547607422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: Is it \n",
      "token:  [S2]: cake or vegetables? \n",
      "55.02083206176758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: cake or vegetables? \n",
      "token:  [S1]: vegetable no \n",
      "6.776455402374268\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: vegetable no \n",
      "token:  [MOD]: no \n",
      "41.35199737548828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: no \n",
      "token:  [S1]: e ok \n",
      "73.4128646850586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: e ok \n",
      "token:  [S2]: after meat \n",
      "73.99958801269531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: after meat \n",
      "token:  [MOD]: Something that both men and women \n",
      "106.53750610351562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Something that both men and women \n",
      "token:  [MOD]: cut \n",
      "459.45111083984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: cut \n",
      "token:  [MOD]: Men maybe more often than women. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.9731903076172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Men maybe more often than women. \n",
      "token:  [S1]: oh \n",
      "57.79952621459961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: oh \n",
      "token:  [MOD]: \n",
      "87.11236572265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: \n",
      "token:  [S2]: Hair? \n",
      "151.97825622558594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: Hair? \n",
      "token:  [S1]: oh yeah \n",
      "18.321969985961914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: oh yeah \n",
      "token:  [MOD]: Hair yeah. Very good. \n",
      "227.88131713867188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Hair yeah. Very good. \n",
      "token:  [S1]: ok \n",
      "47.521366119384766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: ok \n",
      "token:  [MOD]: and the last one? Any ideas? \n",
      "57.4207649230957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: and the last one? Any ideas? \n",
      "token:  [S2]: Is it \n",
      "85.5838623046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: Is it \n",
      "token:  [S1]: Is it not food \n",
      "52.41136169433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: Is it not food \n",
      "token:  [S2]: some food or \n",
      "4.525524616241455\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: some food or \n",
      "token:  [MOD]: No \n",
      "259.3146057128906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: No \n",
      "token:  [S2]: Ok so not a food. \n",
      "113.0510482788086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: Ok so not a food. \n",
      "token:  [S1]: It's not food oh ok \n",
      "21.271760940551758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: It's not food oh ok \n",
      "token:  [MOD]: no \n",
      "62.77313995361328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: no \n",
      "token:  [S2]: so \n",
      "34.68173599243164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: so \n",
      "token:  [S1]: \n",
      "10.86758041381836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: \n",
      "token:  [S2]: No need to think about food. \n",
      "2.6038880348205566\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: No need to think about food. \n",
      "token:  [S2]: Paper? \n",
      "30.385969161987305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: Paper? \n",
      "token:  [MOD]: What do you think? \n",
      "16.628095626831055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: What do you think? \n",
      "token:  [S1]: Yeah \n",
      "36.248260498046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: Yeah \n",
      "token:  [MOD]: yeah paper yeah that's the \n",
      "233.56430053710938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah paper yeah that's the \n",
      "token:  [S1]: so\n",
      "43.22431564331055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: so\n",
      "token:  [oh] \n",
      "811.2343139648438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [oh] \n",
      "token:  [MOD]: the third one. Very good. \n",
      "204.3335418701172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: the third one. Very good. \n",
      "token:  [S2]: Ok rock, paper, scissors. \n",
      "57.90733337402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: Ok rock, paper, scissors. \n",
      "token:  [MOD]: And can you order the answers please? What do you think is the first one? \n",
      "35.33115768432617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: And can you order the answers please? What do you think is the first one? \n",
      "token:  [S1]: oh \n",
      "48.11181640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: oh \n",
      "token:  [S2]: I'd say meat \n",
      "39.38223648071289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: I'd say meat \n",
      "token:  [S1]: you did \n",
      "19.191326141357422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: you did \n",
      "token:  [S2]: for me meat is first For you? \n",
      "133.8656005859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: for me meat is first For you? \n",
      "token:  [S1]: yeah For me meat or hair maybe meat, hair and the \n",
      "62.46580123901367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah For me meat or hair maybe meat, hair and the \n",
      "token:  [MOD]: You need to decide together now on the first one. \n",
      "100.30038452148438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: You need to decide together now on the first one. \n",
      "token:  [S1]: What do you think? \n",
      "8.914072036743164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: What do you think? \n",
      "token:  [S2]: umhm \n",
      "36.73891830444336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: umhm \n",
      "token:  [S1]: People \n",
      "51.212440490722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: People \n",
      "token:  [S2]: like we take food every day so perhaps \n",
      "73.16987609863281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: like we take food every day so perhaps \n",
      "token:  [S1]: yeah Yeah that's right. \n",
      "22.296850204467773\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah Yeah that's right. \n",
      "token:  [S2]: yeah \n",
      "10.105247497558594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah \n",
      "token:  [S1]: that's the first \n",
      "4.094259738922119\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: that's the first \n",
      "token:  [S2]: meat \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.34941864013672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: meat \n",
      "token:  [S1]: First I think we can so meat and the hair and then the \n",
      "1.922260046005249\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: First I think we can so meat and the hair and then the \n",
      "token:  [S2]: I forgot the other one \n",
      "18.58399772644043\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: I forgot the other one \n",
      "token:  [S1]: paper \n",
      "8.838641166687012\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: paper \n",
      "token:  [MOD]: Are you sure? \n",
      "37.60601043701172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Are you sure? \n",
      "token:  [S2]: yeah paper would \n",
      "338.9651184082031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: yeah paper would \n",
      "token:  [MOD]: \n",
      "55.796085357666016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: \n",
      "token:  [S2]: be third \n",
      "221.8672332763672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: be third \n",
      "token:  [MOD]: \n",
      "80.45869445800781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: \n",
      "token:  [MOD]: \n",
      "49.26152420043945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: \n",
      "token:  [MOD]: eh unfortunately the first one is hair \n",
      "538.7588500976562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: eh unfortunately the first one is hair \n",
      "token:  [S2]: oh \n",
      "38.7713737487793\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: oh \n",
      "token:  [MOD]: yeah the second \n",
      "141.28781127929688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: yeah the second \n",
      "token:  [S2]: shit \n",
      "50.855316162109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: shit \n",
      "token:  [MOD]: one is paper and then the third one is meat. \n",
      "121.86294555664062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: one is paper and then the third one is meat. \n",
      "token:  [S2]: oh \n",
      "53.520442962646484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: oh \n",
      "token:  [S1]: oh \n",
      "4.866936683654785\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: oh \n",
      "token:  [S2]: sorry for that \n",
      "3.562178373336792\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: sorry for that \n",
      "token:  [MOD]: But you did great, you found all of them, well done, you know? \n",
      "35.95558547973633\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: But you did great, you found all of them, well done, you know? \n",
      "token:  [S1]: yeah \n",
      "37.8371696472168\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah \n",
      "token:  [MOD]: Well that was it, I hope you enjoyed it. And thanks very \n",
      "55.61803436279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: Well that was it, I hope you enjoyed it. And thanks very \n",
      "token:  [S1]: yeah \n",
      "96.04121398925781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: yeah \n",
      "token:  [MOD]: much for coming again. \n",
      "277.906982421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: much for coming again. \n",
      "token:  [S1]: ok thank you \n",
      "34.87563705444336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1]: ok thank you \n",
      "token:  [S2]: oh that's really good \n",
      "10.844489097595215\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: oh that's really good \n",
      "token:  [MOD]: you were very good you were \n",
      "46.507083892822266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: you were very good you were \n",
      "token:  [S2]: I was looking for more \n",
      "32.79194641113281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2]: I was looking for more \n",
      "token:  [MOD]: very good you know? \n",
      "173.4310760498047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]: very good you know? \n",
      "token:  [S1]: yeah ok\n",
      "42.41254425048828\n",
      "MOD : 82.72232966037357\n",
      "S1 : 88.42898513119796\n",
      "S2 : 106.14006405765727\n",
      "speech transcription_Transcriber/S04.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] ok Hello, thank you for coming today, we're going to play a quiz. \n",
      "44.63914489746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok Hello, thank you for coming today, we're going to play a quiz. \n",
      "token:  [S1] ok \n",
      "28.511138916015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] I'd like to ask you three questions which were posed to a group of one hundred people and I would like you to guess the three most popular answers to these questions. And then I would like you to talk to each other about the ranking of these answers in terms of populartiy. Ok? So for example if I ask you what is typically used to carry patients in a hospital you would say things like you know an ambulance, a wheelchair, a patient's bed or whatever ok? \n",
      "19.61369514465332\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'd like to ask you three questions which were posed to a group of one hundred people and I would like you to guess the three most popular answers to these questions. And then I would like you to talk to each other about the ranking of these answers in terms of populartiy. Ok? So for example if I ask you what is typically used to carry patients in a hospital you would say things like you know an ambulance, a wheelchair, a patient's bed or whatever ok? \n",
      "token:  [S2] hmm \n",
      "40.938785552978516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] And then you will have to say which one is the most popular answer to th that question Is it clear what you have to do? \n",
      "43.79432678222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And then you will have to say which one is the most popular answer to th that question Is it clear what you have to do? \n",
      "token:  [S2] Yeah. \n",
      "25.668010711669922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Yeah? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.027114868164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S1] mhmm \n",
      "29.386281967163086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] So are you ready for the first question? \n",
      "28.951066970825195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So are you ready for the first question? \n",
      "token:  [S2] Yeah. \n",
      "26.360923767089844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] I'm ok \n",
      "19.072599411010742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'm ok \n",
      "token:  [MOD] I would lite like you to m name a public place where people m typically get, are likely to get cold or a flu bug. \n",
      "128.4805145263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I would lite like you to m name a public place where people m typically get, are likely to get cold or a flu bug. \n",
      "token:  [S1] Sorry there \n",
      "98.2665023803711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Sorry there \n",
      "token:  [MOD] I would like you to \n",
      "26.991724014282227\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I would like you to \n",
      "token:  [S1] likely to catch \n",
      "72.06217193603516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] likely to catch \n",
      "token:  [MOD] think about p public places where you would be mnore likely to get a cold \n",
      "105.10663604736328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] think about p public places where you would be mnore likely to get a cold \n",
      "token:  [S1] oh ok \n",
      "47.62673568725586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh ok \n",
      "token:  [MOD] or a f lu bug \n",
      "391.3398742675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] or a f lu bug \n",
      "token:  [S2] ok ah \n",
      "271.68994140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok ah \n",
      "token:  [MOD] Where would you catch a cold in what public place? Or a bug? \n",
      "89.42455291748047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Where would you catch a cold in what public place? Or a bug? \n",
      "token:  [S1] I've heard that airports and airplanes are quite but for this sort of thing. \n",
      "41.29015350341797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I've heard that airports and airplanes are quite but for this sort of thing. \n",
      "token:  [MOD] mhmm You got the first one, well done. It's actually the airplane one of the answe \n",
      "79.14077758789062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm You got the first one, well done. It's actually the airplane one of the answe \n",
      "token:  [S1] ok \n",
      "110.42606353759766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] rs so you have two more. \n",
      "143.2203826904297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] rs so you have two more. \n",
      "token:  [S2] Like where you can find cold is it? \n",
      "93.96734619140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Like where you can find cold is it? \n",
      "token:  [MOD] I mean if you think about different public places \n",
      "78.57568359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I mean if you think about different public places \n",
      "token:  [S2] yeah \n",
      "59.67774963378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] where would you be more likely to catch the flu or the cold. The airplane is one then you'll have to find two more answers. \n",
      "67.32886505126953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] where would you be more likely to catch the flu or the cold. The airplane is one then you'll have to find two more answers. \n",
      "token:  [S1] Do we get hints? Is it always from other people that you get \n",
      "70.09855651855469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Do we get hints? Is it always from other people that you get \n",
      "token:  [MOD] Well \n",
      "461.8129577636719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well \n",
      "token:  [S1] cold \n",
      "102.66156005859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cold \n",
      "token:  [MOD] you could think about places that are crowded, you know if you think about places where you would find more people concentrated in the space and then is easy that it can be contagious within that space. So what kind of think about the different age groups for instance. Where do different people get sick. Ah think about children for instance. \n",
      "62.72050857543945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you could think about places that are crowded, you know if you think about places where you would find more people concentrated in the space and then is easy that it can be contagious within that space. So what kind of think about the different age groups for instance. Where do different people get sick. Ah think about children for instance. \n",
      "token:  [S1] Yeah I guess school or \n",
      "76.3117904663086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah I guess school or \n",
      "token:  [S2] yeah \n",
      "12.830615997314453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] Yeah that's the other place. Especially like \n",
      "32.448795318603516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah that's the other place. Especially like \n",
      "token:  [MOD] hmm \n",
      "133.22402954101562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] pre-school \n",
      "55.62065887451172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] pre-school \n",
      "token:  [MOD] mhmm mhmm So the school is another answer. yeah \n",
      "112.99127960205078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm mhmm So the school is another answer. yeah \n",
      "token:  [S2] May be the ah the hospital? yeah \n",
      "132.5118408203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] May be the ah the hospital? yeah \n",
      "token:  [MOD] Excellent. You're you got the third one yeah, very good. So you have the three. Would you like then to have a quick chat about the ranking of these items. \n",
      "49.617618560791016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent. You're you got the third one yeah, very good. So you have the three. Would you like then to have a quick chat about the ranking of these items. \n",
      "token:  [S2] Eh probably is the first the hospital because it's where \n",
      "172.44869995117188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Eh probably is the first the hospital because it's where \n",
      "token:  [S1] yeah \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.536638259887695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] ah patients are ah certain times but it ah I don't know how to explain like it's eh it's supposed to be ah not contami not contaminated but in fact it is, because when patients are waiting for doctors they all ah transmitting their sickness to each other I think so \n",
      "70.82080841064453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah patients are ah certain times but it ah I don't know how to explain like it's eh it's supposed to be ah not contami not contaminated but in fact it is, because when patients are waiting for doctors they all ah transmitting their sickness to each other I think so \n",
      "token:  [S1] ok So, yes I think in the hospital you would have the strongest disease that you could get because I think that from all the drugs they have in there \n",
      "28.272350311279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok So, yes I think in the hospital you would have the strongest disease that you could get because I think that from all the drugs they have in there \n",
      "token:  [S2] yeah \n",
      "14.528350830078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] only the very strong diseases get but I think that the question was what was it what people would say. \n",
      "61.0696907043457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] only the very strong diseases get but I think that the question was what was it what people would say. \n",
      "token:  [S2] oh \n",
      "22.135683059692383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh \n",
      "token:  [S1] So I think maybe pe people would think of the school more than the hospital because it's not the question where you actually get \n",
      "65.39361572265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So I think maybe pe people would think of the school more than the hospital because it's not the question where you actually get \n",
      "token:  [S2] yeah \n",
      "25.937273025512695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] sick. \n",
      "26.441083908081055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] sick. \n",
      "token:  [S2] but like if I had the three answers ah in face of me and the question I would probably choose the hospital like this is where like I would say in order hospital, then school and then airport \n",
      "74.7946548461914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] but like if I had the three answers ah in face of me and the question I would probably choose the hospital like this is where like I would say in order hospital, then school and then airport \n",
      "token:  [S1] ok \n",
      "15.294897079467773\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] airplane \n",
      "52.90483093261719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] airplane \n",
      "token:  [S1] yeah I I \n",
      "37.3394660949707\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah I I \n",
      "token:  [S2] but your your idea is great because you you're trying to say that this is not where you have sickness, that you can have sickness like pre-school is yeah definitely where you get sick easily. \n",
      "56.29867935180664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] but your your idea is great because you you're trying to say that this is not where you have sickness, that you can have sickness like pre-school is yeah definitely where you get sick easily. \n",
      "token:  [S1] yeah I I I agree that most people would have the airplane last \n",
      "61.689292907714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah I I I agree that most people would have the airplane last \n",
      "token:  [S2] yeah so there you go \n",
      "11.222891807556152\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah so there you go \n",
      "token:  [S1] And then for the top two I don't know. \n",
      "14.647953987121582\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] And then for the top two I don't know. \n",
      "token:  [S2] yeah me neither we can \n",
      "76.73118591308594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah me neither we can \n",
      "token:  [S1] toss a coin yeah \n",
      "30.094499588012695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] toss a coin yeah \n",
      "token:  [MOD] Well you would have to make a final decision now. \n",
      "38.11972427368164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well you would have to make a final decision now. \n",
      "token:  [S1] Ok, so how do we make a final decision? \n",
      "8.1636323928833\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok, so how do we make a final decision? \n",
      "token:  [S2] don't know. \n",
      "13.181734085083008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] don't know. \n",
      "token:  [S1] We can talk about it or we can do rock, paper, scissors \n",
      "19.38343620300293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] We can talk about it or we can do rock, paper, scissors \n",
      "token:  [S2] ok on one time \n",
      "66.94237518310547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok on one time \n",
      "token:  [S1] So, I So I will say school and you get hospital and we do \n",
      "83.83760070800781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So, I So I will say school and you get hospital and we do \n",
      "token:  [S2] If I if I win \n",
      "21.709918975830078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] If I if I win \n",
      "token:  [S1] rock, paper, scissors or? \n",
      "34.55122756958008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] rock, paper, scissors or? \n",
      "token:  [S2] this it's hospital in first and if you win \n",
      "119.18408203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] this it's hospital in first and if you win \n",
      "token:  [S1] it's school first \n",
      "16.446935653686523\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it's school first \n",
      "token:  [S2] school first one time \n",
      "17.65367889404297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] school first one time \n",
      "token:  [MOD] I like your conver sation skills, I like the way you're trying to reach an agreement right \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.40914154052734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I like your conver sation skills, I like the way you're trying to reach an agreement right \n",
      "token:  [S2] but because it's all \n",
      "60.75956726074219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] but because it's all \n",
      "token:  [MOD] hmm \n",
      "181.0186767578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] it's also suits me so yeah it's just a good game \n",
      "70.19947052001953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] it's also suits me so yeah it's just a good game \n",
      "token:  [S1] yeah because both make sense \n",
      "30.33434295654297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah because both make sense \n",
      "token:  [MOD] hmm \n",
      "45.80016326904297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] so let's \n",
      "49.95260238647461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so let's \n",
      "token:  [MOD] hmm hmm \n",
      "55.322662353515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm hmm \n",
      "token:  [S1] chance \n",
      "75.74588012695312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] chance \n",
      "token:  [MOD] hmm \n",
      "141.3179168701172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] decide \n",
      "59.168426513671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] decide \n",
      "token:  [S2] definitely \n",
      "14.794336318969727\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] definitely \n",
      "token:  [S1] it's not \n",
      "8.501832008361816\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it's not \n",
      "token:  [MOD] yeah yeah \n",
      "201.61276245117188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah yeah \n",
      "token:  [S1] ok, so do we go one, two, three and go? \n",
      "25.50912094116211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok, so do we go one, two, three and go? \n",
      "token:  [S2] yeah ok \n",
      "10.577529907226562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah ok \n",
      "token:  [S1] ok one two, three \n",
      "27.41771125793457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok one two, three \n",
      "token:  [S2] two, three \n",
      "9.554180145263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] two, three \n",
      "token:  [S1] go oh ok anyway you still win \n",
      "107.45806121826172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] go oh ok anyway you still win \n",
      "token:  [S2] yeah \n",
      "9.300535202026367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] ok so it's ah hospital first and \n",
      "125.99656677246094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok so it's ah hospital first and \n",
      "token:  [S2] hospital first \n",
      "9.503540992736816\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hospital first \n",
      "token:  [S1] school second. \n",
      "21.923095703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] school second. \n",
      "token:  [MOD] I'm sorry to report that you didn't get it right so it's school is number one \n",
      "45.71694564819336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'm sorry to report that you didn't get it right so it's school is number one \n",
      "token:  [S2] that's alright \n",
      "41.39353942871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] that's alright \n",
      "token:  [MOD] hospital is number two the airplane comes at \n",
      "624.7327880859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hospital is number two the airplane comes at \n",
      "token:  [S1] ah ok \n",
      "93.96859741210938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah ok \n",
      "token:  [MOD] the end Alright? \n",
      "161.43638610839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the end Alright? \n",
      "token:  [S2] yeah \n",
      "68.14344024658203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] But good job, very good. \n",
      "74.99842834472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But good job, very good. \n",
      "token:  [S1] It was fun nevertheless. yes \n",
      "118.99810791015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] It was fun nevertheless. yes \n",
      "token:  [MOD] Now are you ready for the second question? ok \n",
      "30.071062088012695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Now are you ready for the second question? ok \n",
      "token:  [S2] yeah \n",
      "33.433135986328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] So \n",
      "130.91970825195312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So \n",
      "token:  [S1] hmm \n",
      "46.27898406982422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] I would like you to name an instrument in a symphony orchestra. \n",
      "33.551570892333984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I would like you to name an instrument in a symphony orchestra. \n",
      "token:  [S1] Eh I'll say the violin \n",
      "63.19709777832031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Eh I'll say the violin \n",
      "token:  [S2] yeah \n",
      "20.832494735717773\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] very good yep \n",
      "87.1103286743164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very good yep \n",
      "token:  [S2] and piano \n",
      "270.79144287109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and piano \n",
      "token:  [MOD] hmm \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.42349243164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] oh \n",
      "50.434478759765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh \n",
      "token:  [MOD] hmm \n",
      "62.18169403076172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] no there no piano ah trum no yes or I don't have the english word for \n",
      "186.04222106933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no there no piano ah trum no yes or I don't have the english word for \n",
      "token:  [S1] But which one is it, in what langua \n",
      "68.35057067871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But which one is it, in what langua \n",
      "token:  [S2] ah \n",
      "20.62813949584961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah \n",
      "token:  [S1] ge do you have it maybe \n",
      "88.85202026367188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ge do you have it maybe \n",
      "token:  [S2] ah I'm French so ah \n",
      "44.20453643798828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah I'm French so ah \n",
      "token:  [S1] but maybe I will underst and so you can try \n",
      "48.894229888916016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but maybe I will underst and so you can try \n",
      "token:  [S2] \n",
      "6.418043613433838\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] that \n",
      "22.781879425048828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] that \n",
      "token:  [S2] la harpe like when \n",
      "127.77188110351562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] la harpe like when \n",
      "token:  [S1] ah the harp \n",
      "29.485130310058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah the harp \n",
      "token:  [S2] the harp yeah \n",
      "9.6978178024292\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the harp yeah \n",
      "token:  [S1] yeah \n",
      "9.913069725036621\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] ok they have the same meaning makes sense \n",
      "43.85036087036133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok they have the same meaning makes sense \n",
      "token:  [MOD] I'm sorry. \n",
      "32.94181823730469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'm sorry. \n",
      "token:  [S2] no \n",
      "66.09761047363281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no \n",
      "token:  [MOD] no \n",
      "30.540103912353516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no \n",
      "token:  [S2] ok \n",
      "59.77058410644531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] Ah the cello? \n",
      "70.77202606201172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ah the cello? \n",
      "token:  [MOD] Very good yeah you have the two now. \n",
      "129.552490234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good yeah you have the two now. \n",
      "token:  [S2] ah \n",
      "143.28001403808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah \n",
      "token:  [S1] hmm \n",
      "8.82902717590332\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] Think about the instruments that are commonly used even even in live constre concerts or in different kinds of music really not only in a symphony orchestra. \n",
      "122.59556579589844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think about the instruments that are commonly used even even in live constre concerts or in different kinds of music really not only in a symphony orchestra. \n",
      "token:  [S2] Guitar? \n",
      "59.30230712890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Guitar? \n",
      "token:  [MOD] hmm nope \n",
      "61.69655990600586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm nope \n",
      "token:  [S2] oh \n",
      "59.941123962402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh \n",
      "token:  [S1] well it's not \n",
      "13.336639404296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] well it's not \n",
      "token:  [MOD] try again \n",
      "108.5908203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] try again \n",
      "token:  [S1] that much in orchestras \n",
      "235.68885803222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] that much in orchestras \n",
      "token:  [MOD] keep guessing \n",
      "160.1737518310547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] keep guessing \n",
      "token:  [S1] though Trumpet? \n",
      "175.20880126953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] though Trumpet? \n",
      "token:  [MOD] Good idea but it wasn't one of the popu lar answers \n",
      "89.75756072998047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Good idea but it wasn't one of the popu lar answers \n",
      "token:  [S2] ah \n",
      "137.36325073242188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah \n",
      "token:  [MOD] I'm afr \n",
      "127.45466613769531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'm afr \n",
      "token:  [S1] No? \n",
      "65.27847290039062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No? \n",
      "token:  [MOD] aid \n",
      "1024.9296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] aid \n",
      "token:  [S2] now you said violin you said What's the third one? \n",
      "124.88639831542969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] now you said violin you said What's the third one? \n",
      "token:  [MOD] Something that really allows you to give the rhythm as well. \n",
      "71.65756225585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Something that really allows you to give the rhythm as well. \n",
      "token:  [S2] triangle \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271.1465148925781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] triangle \n",
      "token:  [S1] Oh that's amazing. That's an amazing answer. \n",
      "15.851935386657715\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh that's amazing. That's an amazing answer. \n",
      "token:  [S2] \n",
      "12.001670837402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] In Christmas carols yes. \n",
      "269.53216552734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] In Christmas carols yes. \n",
      "token:  [S1] yes yeah \n",
      "96.04647064208984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yes yeah \n",
      "token:  [MOD] Definitely. \n",
      "116.65303039550781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Definitely. \n",
      "token:  [S1] yeah Well yeah I guess that people said drums \n",
      "220.30886840820312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah Well yeah I guess that people said drums \n",
      "token:  [MOD] Exactly. \n",
      "51.088111877441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly. \n",
      "token:  [S1] yes? but now I'm starting to get nervous, because like in in gigs like in concerts and in orchestras they don't have the same \n",
      "62.93885803222656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yes? but now I'm starting to get nervous, because like in in gigs like in concerts and in orchestras they don't have the same \n",
      "token:  [MOD] hm \n",
      "144.4804229736328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S1] drums \n",
      "167.26666259765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] drums \n",
      "token:  [MOD] hm the drum \n",
      "120.79657745361328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm the drum \n",
      "token:  [S1] so it's kind of \n",
      "31.570173263549805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so it's kind of \n",
      "token:  [MOD] it's the drum \n",
      "163.2953643798828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it's the drum \n",
      "token:  [S1] yeah \n",
      "45.157230377197266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] yeah \n",
      "36.475040435791016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] but it's very generic it's \n",
      "47.637977600097656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but it's very generic it's \n",
      "token:  [MOD] hm hm \n",
      "82.28141784667969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm hm \n",
      "token:  [S1] saying oh yeah it's a string instrument \n",
      "166.1348876953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] saying oh yeah it's a string instrument \n",
      "token:  [MOD] hm \n",
      "80.05690002441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S1] and \n",
      "40.829708099365234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and \n",
      "token:  [MOD] hm \n",
      "170.59303283691406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S1] wind instrument and a drum \n",
      "300.2418518066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] wind instrument and a drum \n",
      "token:  [MOD] hm hm hm \n",
      "28.44614028930664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm hm hm \n",
      "token:  [S1] so \n",
      "54.0460090637207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so \n",
      "token:  [MOD] But that was in fact the thir d \n",
      "154.72537231445312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But that was in fact the thir d \n",
      "token:  [S1] yeah \n",
      "130.27586364746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] answer so which of the answers would be the most popular, what would you think? \n",
      "45.32654571533203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] answer so which of the answers would be the most popular, what would you think? \n",
      "token:  [S2] Violin might be the first. \n",
      "62.12701416015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violin might be the first. \n",
      "token:  [S1] I agree. No need to yeah \n",
      "66.42731475830078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I agree. No need to yeah \n",
      "token:  [MOD] And then \n",
      "92.9805679321289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And then \n",
      "token:  [S2] and then I don't know \n",
      "21.01329803466797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and then I don't know \n",
      "token:  [S1] Maybe we need to \n",
      "21.763050079345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Maybe we need to \n",
      "token:  [S2] no no no say say what you think like \n",
      "48.936798095703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no no no say say what you think like \n",
      "token:  [S1] Well to to me they came in the order that I said that so \n",
      "63.109737396240234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Well to to me they came in the order that I said that so \n",
      "token:  [MOD] hmm hmm \n",
      "40.896121978759766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm hmm \n",
      "token:  [S2] I think you you're right yeah. \n",
      "47.20152282714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think you you're right yeah. \n",
      "token:  [MOD] mhmm \n",
      "55.540382385253906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S2] I agree. I won't say any thing more . \n",
      "44.30412673950195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I agree. I won't say any thing more . \n",
      "token:  [MOD] So is that the final decision, violin, cello and then the drum? Yeah? Well congratulations very good \n",
      "114.5750503540039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So is that the final decision, violin, cello and then the drum? Yeah? Well congratulations very good \n",
      "token:  [S1] Oh! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.6873664855957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh! \n",
      "token:  [MOD] you got it right. \n",
      "35.477752685546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you got it right. \n",
      "token:  [S1] Yay! \n",
      "18.237825393676758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yay! \n",
      "token:  [MOD] Ok so you have one more that ll third an final question, I would like you to name something that people cut. \n",
      "129.54489135742188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok so you have one more that ll third an final question, I would like you to name something that people cut. \n",
      "token:  [S2] Don't really \n",
      "49.8510627746582\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Don't really \n",
      "token:  [MOD] What do \n",
      "56.406837463378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] What do \n",
      "token:  [S2] understand. \n",
      "116.5499496459961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] understand. \n",
      "token:  [MOD] people cut. \n",
      "229.28146362304688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] people cut. \n",
      "token:  [S2] ok \n",
      "112.2593002319336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] Oh there are so many ways to interpret this \n",
      "18.13199234008789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh there are so many ways to interpret this \n",
      "token:  [MOD] Let's take it literally. What do you normally cut? In your everyday life? \n",
      "43.30037307739258\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Let's take it literally. What do you normally cut? In your everyday life? \n",
      "token:  [S1] Paper? You had \n",
      "132.00454711914062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Paper? You had \n",
      "token:  [MOD] very good \n",
      "147.2141876220703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very good \n",
      "token:  [S1] before \n",
      "69.07953643798828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] before \n",
      "token:  [MOD] yes \n",
      "199.6053009033203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes \n",
      "token:  [S1] the scissors and I had the paper \n",
      "102.37470245361328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the scissors and I had the paper \n",
      "token:  [MOD] exactly paper is one thing. \n",
      "168.3854217529297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] exactly paper is one thing. \n",
      "token:  [S2] This is so weird have to think about what you're doing every day. ah wood? \n",
      "70.79092407226562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] This is so weird have to think about what you're doing every day. ah wood? \n",
      "token:  [MOD] eh you look like you don't you don't do a lot of cutting \n",
      "49.42780685424805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] eh you look like you don't you don't do a lot of cutting \n",
      "token:  [S2] ah \n",
      "57.026859283447266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah \n",
      "token:  [S1] Yeah like it depends also on a person's \n",
      "50.007572174072266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah like it depends also on a person's \n",
      "token:  [MOD] mhmm \n",
      "104.95924377441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] diet \n",
      "123.17925262451172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] diet \n",
      "token:  [MOD] hmm \n",
      "79.00967407226562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] maybe they cut food but \n",
      "163.9847412109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] maybe they cut food but \n",
      "token:  [MOD] Yes, very good thinks about think about different categories of food. \n",
      "113.18362426757812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes, very good thinks about think about different categories of food. \n",
      "token:  [S2] of cause I I would say wood \n",
      "337.1268615722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] of cause I I would say wood \n",
      "token:  [MOD] Hm? \n",
      "63.96546173095703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Hm? \n",
      "token:  [S2] wood like when you cut a tree or \n",
      "137.1508026123047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] wood like when you cut a tree or \n",
      "token:  [MOD] d sorry did you say wood? \n",
      "101.20376586914062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] d sorry did you say wood? \n",
      "token:  [S2] Wood yeah. \n",
      "54.64219284057617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Wood yeah. \n",
      "token:  [MOD] hmm no But if you're talking about food you're very close. You don't do a lot of cooking, do you? \n",
      "24.196138381958008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm no But if you're talking about food you're very close. You don't do a lot of cooking, do you? \n",
      "token:  [S2] No \n",
      "41.03593063354492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No \n",
      "token:  [S1] We do but that's the thing I think that many people like the vegetables you chop them kind of \n",
      "52.29846954345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] We do but that's the thing I think that many people like the vegetables you chop them kind of \n",
      "token:  [MOD] So what else come to \n",
      "132.52371215820312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So what else come to \n",
      "token:  [S1] so \n",
      "46.04741668701172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so \n",
      "token:  [MOD] what else comes to your mind? \n",
      "43.381813049316406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] what else comes to your mind? \n",
      "token:  [S1] Personally I would say that you would cut bread, because I like to get \n",
      "67.96693420410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Personally I would say that you would cut bread, because I like to get \n",
      "token:  [MOD] don't you normally say we slice \n",
      "230.00143432617188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] don't you normally say we slice \n",
      "token:  [S1] like loaf \n",
      "76.85655975341797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like loaf \n",
      "token:  [S2] yeah \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.85559368133545\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] but most people anyway get it already sliced so I don't \n",
      "64.29395294189453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but most people anyway get it already sliced so I don't \n",
      "token:  [MOD] ok \n",
      "218.39768981933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok \n",
      "token:  [S1] think that \n",
      "53.56752395629883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] think that \n",
      "token:  [MOD] hm hm \n",
      "69.34085083007812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm hm \n",
      "token:  [S1] people would \n",
      "115.48727416992188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] people would \n",
      "token:  [MOD] hm \n",
      "135.1162567138672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S1] do that so that's why that's why I mean the things that I have in my diet \n",
      "52.30157470703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] do that so that's why that's why I mean the things that I have in my diet \n",
      "token:  [MOD] hm \n",
      "66.06395721435547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S1] and what most people would \n",
      "77.33255004882812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and what most people would \n",
      "token:  [MOD] hm \n",
      "206.02670288085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S1] say that's what I find \n",
      "53.75598907470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] say that's what I find \n",
      "token:  [MOD] hm \n",
      "86.64688873291016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hm \n",
      "token:  [S1] difficult to to match. \n",
      "191.02151489257812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] difficult to to match. \n",
      "token:  [MOD] yeah Well, keep guessing. What else in terms of food? \n",
      "138.69300842285156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah Well, keep guessing. What else in terms of food? \n",
      "token:  [S1] Oh meat. \n",
      "47.6800651550293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh meat. \n",
      "token:  [MOD] Excellent. That's it yes. \n",
      "70.21607971191406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent. That's it yes. \n",
      "token:  [S1] Yeah, I don't eat a lot of that that's why it took me a while . \n",
      "24.07801055908203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah, I don't eat a lot of that that's why it took me a while . \n",
      "token:  [MOD] ah ok ok And you're missing one more. \n",
      "97.93849182128906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ah ok ok And you're missing one more. \n",
      "token:  [S2] In food also or? \n",
      "313.8585510253906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] In food also or? \n",
      "token:  [MOD] No \n",
      "126.50428771972656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No \n",
      "token:  [S2] no? \n",
      "83.65092468261719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no? \n",
      "token:  [MOD] let's just think about different things now \n",
      "64.8828353881836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] let's just think about different things now \n",
      "token:  [S2] ok \n",
      "54.3414306640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] Move away from food. I mean this is something you don't cut very frequently very regularly I ma I would think that men usually do that more often than women but it depends again on the individual. \n",
      "79.62452697753906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Move away from food. I mean this is something you don't cut very frequently very regularly I ma I would think that men usually do that more often than women but it depends again on the individual. \n",
      "token:  [S1] I know that she \n",
      "49.497596740722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I know that she \n",
      "token:  [S2] Hair? \n",
      "45.01066970825195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair? \n",
      "token:  [S1] just said that \n",
      "38.60052490234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] just said that \n",
      "token:  [S2] is it no \n",
      "29.87187385559082\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] is it no \n",
      "token:  [S1] but we have to think about something because \n",
      "23.564058303833008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but we have to think about something because \n",
      "token:  [S2] ah no no \n",
      "24.96131134033203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah no no \n",
      "token:  [S1] I'm out of ideas. \n",
      "11.126011848449707\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'm out of ideas. \n",
      "token:  [S2] Hair maybe? \n",
      "47.0576057434082\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair maybe? \n",
      "token:  [MOD] Excellent well done. \n",
      "89.55850219726562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent well done. \n",
      "token:  [S2] Hair. \n",
      "112.24330139160156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair. \n",
      "token:  [MOD] Hair. \n",
      "26.895334243774414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Hair. \n",
      "token:  [S1] Oh ni \n",
      "160.4653778076172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh ni \n",
      "token:  [MOD] yes \n",
      "260.651123046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes \n",
      "token:  [S1] ce! \n",
      "138.6262969970703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ce! \n",
      "token:  [S2] yeah \n",
      "10.589435577392578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] So what would be the ranking in terms of popularity? What would you think? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.448772430419922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So what would be the ranking in terms of popularity? What would you think? \n",
      "token:  [S2] Paper first. \n",
      "114.37258911132812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Paper first. \n",
      "token:  [S1] Yeah. \n",
      "8.317042350769043\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] hmm \n",
      "79.48519134521484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] Hair second and then meat. I would say this. \n",
      "149.69833374023438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair second and then meat. I would say this. \n",
      "token:  [S1] Very good very good yes yes, I like that. \n",
      "15.258626937866211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Very good very good yes yes, I like that. \n",
      "token:  [MOD] Do you agree, is that your final decision? \n",
      "31.9608097076416\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Do you agree, is that your final decision? \n",
      "token:  [S1] yeah \n",
      "57.48744583129883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] Do you agree? \n",
      "8.537909507751465\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Do you agree? \n",
      "token:  [MOD] Yes? \n",
      "31.352113723754883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes? \n",
      "token:  [S2] \n",
      "35.05712127685547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] Yes? \n",
      "70.06727600097656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes? \n",
      "token:  [S1] Yes. \n",
      "12.400620460510254\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yes. \n",
      "token:  [MOD] Well I'm sorry to report that paper is the most popular answer, ok? \n",
      "51.27141189575195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well I'm sorry to report that paper is the most popular answer, ok? \n",
      "token:  [S1] ok, we got \n",
      "50.93901824951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok, we got \n",
      "token:  [MOD] Eh so paper number one, eh sorry hair number one \n",
      "701.629638671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Eh so paper number one, eh sorry hair number one \n",
      "token:  [S1] ! \n",
      "50.45988082885742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ! \n",
      "token:  [MOD] paper number two \n",
      "657.643310546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] paper number two \n",
      "token:  [S2] oh! \n",
      "75.27323150634766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh! \n",
      "token:  [MOD] meat number three. \n",
      "446.4561767578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] meat number three. \n",
      "token:  [S2] ok \n",
      "115.70510864257812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] ! \n",
      "19.66201400756836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ! \n",
      "token:  [MOD] yeah \n",
      "326.5025634765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S2] Almost. \n",
      "79.84253692626953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Almost. \n",
      "token:  [MOD] But well done good job \n",
      "216.80953979492188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But well done good job \n",
      "token:  [S1] thank you \n",
      "31.052419662475586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] thank you \n",
      "token:  [MOD] and and that is the end of the quiz, I hope \n",
      "41.640220642089844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and and that is the end of the quiz, I hope \n",
      "token:  [S1] ok \n",
      "58.176239013671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] you enjoyed it. \n",
      "84.04105377197266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you enjoyed it. \n",
      "token:  [S1] Yeah it was \n",
      "37.78609848022461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah it was \n",
      "token:  [MOD] Thank you very much. \n",
      "33.9859504699707\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Thank you very much. \n",
      "token:  [S1] interesting. \n",
      "35.6326789855957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] interesting. \n",
      "token:  [S2] very interesting. \n",
      "5.39265775680542\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] very interesting. \n",
      "token:  [MOD] thank you Thank\n",
      "122.7334213256836\n",
      "MOD : 130.34848148482186\n",
      "S1 : 64.08092113809847\n",
      "S2 : 71.88806021781195\n",
      "speech transcription_Transcriber/S07.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Ok. So welcome, thank you very much for being here \n",
      "65.17853546142578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok. So welcome, thank you very much for being here \n",
      "token:  [S2] Thank you. \n",
      "23.984270095825195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Thank you. \n",
      "token:  [MOD] today. How do you feel? \n",
      "36.0820198059082\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] today. How do you feel? \n",
      "token:  [S2] Great. \n",
      "45.02313995361328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Great. \n",
      "token:  [S1] I'm fine. \n",
      "5.577706813812256\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'm fine. \n",
      "token:  [MOD] Excellent. Ah \n",
      "285.4527587890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent. Ah \n",
      "token:  [S1] Thanks. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.75456619262695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Thanks. \n",
      "token:  [MOD] so we're going to play a quiz. I'm going to ask you three questions regarding the most ah popular questions about something that people were asked and so you're going to tell me ah the three most popular answers and then you will discuss with each other and you're going to put these answers into the correct rank in terms of popularity, for example if I ask you what do people use in order to transfer a patient your answers would be an ambulance a wheelchair or a hospital bed. And then I would ask you to put these ah answers into the correct ah order. Is everything \n",
      "27.891950607299805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] so we're going to play a quiz. I'm going to ask you three questions regarding the most ah popular questions about something that people were asked and so you're going to tell me ah the three most popular answers and then you will discuss with each other and you're going to put these answers into the correct rank in terms of popularity, for example if I ask you what do people use in order to transfer a patient your answers would be an ambulance a wheelchair or a hospital bed. And then I would ask you to put these ah answers into the correct ah order. Is everything \n",
      "token:  [S1] mhmm \n",
      "66.78238677978516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] ok? \n",
      "86.9915771484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok? \n",
      "token:  [S2] Yes. \n",
      "23.287883758544922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yes. \n",
      "token:  [MOD] Ok? Great, so \n",
      "178.15557861328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok? Great, so \n",
      "token:  [S1] Good. \n",
      "31.357759475708008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Good. \n",
      "token:  [MOD] can we start? \n",
      "78.55171203613281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] can we start? \n",
      "token:  [S1] Yeah. \n",
      "27.589664459228516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Alright. So, I want you the first question I want you to tell me ah the three most popular answers to the question a publi name a public place where people are more likely to catch a cold or a flu bug. \n",
      "46.478538513183594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Alright. So, I want you the first question I want you to tell me ah the three most popular answers to the question a publi name a public place where people are more likely to catch a cold or a flu bug. \n",
      "token:  [S1] Hospital? \n",
      "40.000877380371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hospital? \n",
      "token:  [MOD] Excellent! Yes, this is one of the three most popular answers. Yeah. \n",
      "35.302268981933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent! Yes, this is one of the three most popular answers. Yeah. \n",
      "token:  [S2] To catch a cold? \n",
      "58.13001251220703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] To catch a cold? \n",
      "token:  [S1] \n",
      "9.299666404724121\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] Not swimming pool or \n",
      "124.38705444335938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Not swimming pool or \n",
      "token:  [S1] Yeah public \n",
      "165.2370147705078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah public \n",
      "token:  [S2] school \n",
      "31.95631980895996\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] school \n",
      "token:  [S1] swimming poool \n",
      "136.91334533691406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] swimming poool \n",
      "token:  [S2] yeah public \n",
      "54.810585021972656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah public \n",
      "token:  [S1] and school \n",
      "26.580486297607422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and school \n",
      "token:  [S2] public places \n",
      "29.931407928466797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] public places \n",
      "token:  [S1] yeah \n",
      "17.39871597290039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] Did you just say eh school? \n",
      "106.45879364013672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Did you just say eh school? \n",
      "token:  [S2] Yeah. \n",
      "21.490478515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] School. \n",
      "7.913418769836426\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] School. \n",
      "token:  [MOD] Yes, school is the second one. Great. \n",
      "42.22577667236328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes, school is the second one. Great. \n",
      "token:  [S1] mhmm \n",
      "37.19772720336914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [S2] Another one \n",
      "17.62656593322754\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Another one \n",
      "token:  [S1] What else? \n",
      "10.614679336547852\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] What else? \n",
      "token:  [S2] Outside \n",
      "34.140647888183594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Outside \n",
      "token:  [MOD] Sure a bit more s \n",
      "317.678466796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Sure a bit more s \n",
      "token:  [S2] it's not a place \n",
      "65.30755615234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] it's not a place \n",
      "token:  [MOD] pecific ? Yeah. \n",
      "352.5760498046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] pecific ? Yeah. \n",
      "token:  [S1] Work? No. Not at \n",
      "94.968017578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Work? No. Not at \n",
      "token:  [S2] Yeah I think it's a place that we're supposed to \n",
      "22.0587158203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah I think it's a place that we're supposed to \n",
      "token:  [MOD] A place it could be something more v for example soemthing that people use to commute or a means of transportation \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.41233825683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] A place it could be something more v for example soemthing that people use to commute or a means of transportation \n",
      "token:  [S2] yeah transport yeah the bus and \n",
      "221.98533630371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah transport yeah the bus and \n",
      "token:  [S1] oh yeah the bus Not yet? \n",
      "25.7852725982666\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh yeah the bus Not yet? \n",
      "token:  [MOD] Something else. \n",
      "58.34845733642578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Something else. \n",
      "token:  [S1] Airplanes, air \n",
      "159.79940795898438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Airplanes, air \n",
      "token:  [MOD] Yeah! \n",
      "175.46865844726562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah! \n",
      "token:  [S1] ports airports \n",
      "592.839111328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ports airports \n",
      "token:  [MOD] No! \n",
      "106.51708221435547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No! \n",
      "token:  [S1] whoo \n",
      "77.5245361328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] whoo \n",
      "token:  [S2] Airport? \n",
      "35.1624641418457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Airport? \n",
      "token:  [MOD] air airplane airplane \n",
      "518.4188232421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] air airplane airplane \n",
      "token:  [S2] Oh really? \n",
      "47.8818359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh really? \n",
      "token:  [S1] Hm. \n",
      "8.888785362243652\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hm. \n",
      "token:  [MOD] That's yeah. \n",
      "63.23598098754883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's yeah. \n",
      "token:  [S1] It's so \n",
      "31.7127685546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] It's so \n",
      "token:  [S2] Yeah. \n",
      "6.648408889770508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] confined? Yeah. \n",
      "68.17840576171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] confined? Yeah. \n",
      "token:  [MOD] I guess it's that they answer that most people gave so Ok so \n",
      "229.81089782714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I guess it's that they answer that most people gave so Ok so \n",
      "token:  [S1] hmm \n",
      "41.822906494140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] now you have the three answers, it's hospital, school and plane and I would like you to discuss and put them in the correct order. Actually not the correct \n",
      "57.957088470458984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] now you have the three answers, it's hospital, school and plane and I would like you to discuss and put them in the correct order. Actually not the correct \n",
      "token:  [S1] Ok. \n",
      "61.56184768676758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] the from the most popular to the least popular one. What do you think? \n",
      "26.90424346923828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the from the most popular to the least popular one. What do you think? \n",
      "token:  [S1] hmm \n",
      "41.96329879760742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] I would say help airplane is like \n",
      "85.53135681152344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I would say help airplane is like \n",
      "token:  [S1] Airplane is first. \n",
      "16.565670013427734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Airplane is first. \n",
      "token:  [S2] the third \n",
      "33.37038040161133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the third \n",
      "token:  [S1] The third? \n",
      "18.299560546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The third? \n",
      "token:  [S2] The first? \n",
      "3.480560064315796\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The first? \n",
      "token:  [S1] Oh sorry sorry I don't know I do not agree ok ok \n",
      "42.69096755981445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh sorry sorry I don't know I do not agree ok ok \n",
      "token:  [S2] I don't know but I wouldn't have thought about it yeah at all \n",
      "11.961262702941895\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know but I wouldn't have thought about it yeah at all \n",
      "token:  [S1] ok ok \n",
      "17.004419326782227\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok ok \n",
      "token:  [S2] so \n",
      "11.657920837402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so \n",
      "token:  [S1] yeah maybe third, no no maybe third \n",
      "77.84050750732422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah maybe third, no no maybe third \n",
      "token:  [S2] I don't know maybe just school can be or \n",
      "37.44923400878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know maybe just school can be or \n",
      "token:  [S1] the \n",
      "16.80984115600586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the \n",
      "token:  [S2] well Mothers and father I don't know the parents would say school? \n",
      "86.76778411865234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] well Mothers and father I don't know the parents would say school? \n",
      "token:  [S1] Yeah school because a ar we're dealing with kids \n",
      "108.43289184570312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah school because a ar we're dealing with kids \n",
      "token:  [S2] yeah \n",
      "11.96224594116211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] and kids are more I don't know \n",
      "29.36510467529297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and kids are more I don't know \n",
      "token:  [S2] yeah \n",
      "17.575565338134766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] maybe \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.371320724487305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] maybe \n",
      "token:  [S2] they get cold \n",
      "44.4827880859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] they get cold \n",
      "token:  [S1] yeah \n",
      "11.058295249938965\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] easily \n",
      "21.075273513793945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] easily \n",
      "token:  [S1] School would be first one. \n",
      "55.96881103515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] School would be first one. \n",
      "token:  [S2] mhmm \n",
      "24.123462677001953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [S1] Kids get most more sick than adults. \n",
      "54.90439224243164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Kids get most more sick than adults. \n",
      "token:  [S2] and the other one is \n",
      "25.5606746673584\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and the other one is \n",
      "token:  [S1] Hospital. \n",
      "49.36748123168945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hospital. \n",
      "token:  [S2] hospital. \n",
      "8.250624656677246\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hospital. \n",
      "token:  [S1] Yeah. I don't know I think that's hospital thing is just a imagination, because I've never been sick because I was in the hospital whenever in my life but ok. Maybe but for people usually I'd say that \n",
      "40.32904815673828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. I don't know I think that's hospital thing is just a imagination, because I've never been sick because I was in the hospital whenever in my life but ok. Maybe but for people usually I'd say that \n",
      "token:  [S2] yeah \n",
      "13.115660667419434\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] they think that hospital we have this idea that hospital is f f dirty and full of germs and everything \n",
      "63.73686981201172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] they think that hospital we have this idea that hospital is f f dirty and full of germs and everything \n",
      "token:  [S2] full of yeah of germs \n",
      "31.219669342041016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] full of yeah of germs \n",
      "token:  [S1] so I don't know. \n",
      "11.055854797363281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so I don't know. \n",
      "token:  [S2] I think I would say school in first. \n",
      "22.65513038635254\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think I would say school in first. \n",
      "token:  [S1] School first good. \n",
      "18.705833435058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] School first good. \n",
      "token:  [S2] Like everyone's as yeah as a child \n",
      "93.96546173095703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Like everyone's as yeah as a child \n",
      "token:  [MOD] mhmm \n",
      "54.247337341308594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] mhmm mhmm \n",
      "5.766141414642334\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm mhmm \n",
      "token:  [S2] yeah I don't know. \n",
      "17.546039581298828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah I don't know. \n",
      "token:  [MOD] Ok so Do you have \n",
      "98.95356750488281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok so Do you have \n",
      "token:  [S1] School? \n",
      "90.95466613769531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] School? \n",
      "token:  [MOD] an agreement? \n",
      "119.83931732177734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] an agreement? \n",
      "token:  [S1] Yeah \n",
      "58.12910079956055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah \n",
      "token:  [MOD] Yeah. \n",
      "47.20806121826172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] it's school \n",
      "119.04112243652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it's school \n",
      "token:  [S2] School then \n",
      "26.65447425842285\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] School then \n",
      "token:  [S1] hospital and airplanes? You said the third one? \n",
      "74.47473907470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hospital and airplanes? You said the third one? \n",
      "token:  [S2] Well I don't know it's just that airplane I wouldn't have put it at all in the list \n",
      "18.933286666870117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Well I don't know it's just that airplane I wouldn't have put it at all in the list \n",
      "token:  [S1] Yeah. \n",
      "5.630391597747803\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Ok? \n",
      "48.527774810791016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok? \n",
      "token:  [S1] Ok. \n",
      "12.21041202545166\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] Ok. \n",
      "3.4956257343292236\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] Excellent! it's good job, well done it's the correct order \n",
      "82.094482421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent! it's good job, well done it's the correct order \n",
      "token:  [S1] good \n",
      "69.5948486328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] good \n",
      "token:  [S2] ye ah \n",
      "33.963802337646484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ye ah \n",
      "token:  [MOD] Ok thank you so much. Now let's move on to the second question. So give me the three most popular answers to the question name three instruments eh name an instrument from a symphony orchestra. \n",
      "47.21901321411133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok thank you so much. Now let's move on to the second question. So give me the three most popular answers to the question name three instruments eh name an instrument from a symphony orchestra. \n",
      "token:  [S1] Oh god. \n",
      "22.706193923950195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh god. \n",
      "token:  [MOD] So \n",
      "158.32827758789062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So \n",
      "token:  [S1] Violin \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.57642364501953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin \n",
      "token:  [MOD] I need the th \n",
      "208.94131469726562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I need the th \n",
      "token:  [S2] Yeah violin. \n",
      "484.5538024902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah violin. \n",
      "token:  [S1] \n",
      "19.224666595458984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] Perfect. \n",
      "100.15423583984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect. \n",
      "token:  [S2] I don't know how to say it in English. \n",
      "10.386302947998047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know how to say it in English. \n",
      "token:  [S1] oh gid it's the \n",
      "75.92896270751953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh gid it's the \n",
      "token:  [S2] \n",
      "11.31607723236084\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] I know it's sometimes the terminology is a bit weird but \n",
      "83.1698226928711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I know it's sometimes the terminology is a bit weird but \n",
      "token:  [S1] yeah and eh \n",
      "152.09446716308594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah and eh \n",
      "token:  [S2] Like a wo yeah \n",
      "94.89907836914062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Like a wo yeah \n",
      "token:  [S1] ah \n",
      "21.84482765197754\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah \n",
      "token:  [S2] well can I show it? \n",
      "32.28770065307617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] well can I show it? \n",
      "token:  [S1] depends on the t type of \n",
      "53.48807907104492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] depends on the t type of \n",
      "token:  [MOD] yeah \n",
      "927.78662109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S2] like the \n",
      "60.24422836303711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] like the \n",
      "token:  [MOD] flute? \n",
      "165.89749145507812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] flute? \n",
      "token:  [S1] the flute? \n",
      "14.649749755859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the flute? \n",
      "token:  [S2] ah it's the same word oh \n",
      "49.63557815551758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah it's the same word oh \n",
      "token:  [S1] flute? \n",
      "6.014125823974609\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] flute? \n",
      "token:  [S2] and \n",
      "26.967981338500977\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and \n",
      "token:  [S1] ah and eh \n",
      "79.45386505126953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah and eh \n",
      "token:  [S2] like yeah \n",
      "15.729928016662598\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] like yeah \n",
      "token:  [MOD] it's Yeah it's a very good \n",
      "62.37862014770508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it's Yeah it's a very good \n",
      "token:  [S1] for \n",
      "44.224849700927734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] for \n",
      "token:  [MOD] idea but I'm afraid it's not among the most \n",
      "104.29754638671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] idea but I'm afraid it's not among the most \n",
      "token:  [S2] oh \n",
      "93.28824615478516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh \n",
      "token:  [MOD] popular answers yeah. \n",
      "645.2561645507812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] popular answers yeah. \n",
      "token:  [S1] yeah and the bass that the the \n",
      "157.4247589111328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah and the bass that the the \n",
      "token:  [S2] yeah \n",
      "11.126626968383789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] no, which one is the the big one? \n",
      "18.87216567993164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] no, which one is the the big one? \n",
      "token:  [MOD] Yeah the \n",
      "219.1719970703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah the \n",
      "token:  [S2] I know it in French also but \n",
      "101.00509643554688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I know it in French also but \n",
      "token:  [S1] yeah \n",
      "19.396533966064453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] in English I have no idea \n",
      "25.012252807617188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] in English I have no idea \n",
      "token:  [MOD] but i it's not tha it's \n",
      "114.45791625976562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] but i it's not tha it's \n",
      "token:  [S1] Ok violin would be first f yeah violin first \n",
      "442.5846862792969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok violin would be first f yeah violin first \n",
      "token:  [MOD] violin violin is one of the three yeah. \n",
      "81.7406997680664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] violin violin is one of the three yeah. \n",
      "token:  [S1] I just you like lot of violins actually an orchestra \n",
      "123.6240463256836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I just you like lot of violins actually an orchestra \n",
      "token:  [MOD] Another ah instru ment with strings \n",
      "757.9111328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Another ah instru ment with strings \n",
      "token:  [S1] with strings \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.677627563476562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] with strings \n",
      "token:  [MOD] Not bass \n",
      "1810.7965087890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Not bass \n",
      "token:  [S1] sss \n",
      "64.89066314697266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] sss \n",
      "token:  [MOD] \n",
      "54.22110366821289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [S1] strings or oh guitars \n",
      "925.4987182617188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] strings or oh guitars \n",
      "token:  [S2] I don't know. Harp. \n",
      "18.359193801879883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know. Harp. \n",
      "token:  [MOD] No. no. \n",
      "45.86333465576172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. no. \n",
      "token:  [S1] No guitars. \n",
      "134.81101989746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No guitars. \n",
      "token:  [S2] No. \n",
      "4.877799987792969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No. \n",
      "token:  [MOD] No. \n",
      "26.96780014038086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S1] Or I don't know. \n",
      "26.76630210876465\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Or I don't know. \n",
      "token:  [MOD] Yeah I know it should be because guitar is very popular but \n",
      "110.10554504394531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah I know it should be because guitar is very popular but \n",
      "token:  [S1] yes guitar \n",
      "123.8307113647461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yes guitar \n",
      "token:  [MOD] mahybe not in a symphony it's it's not among the three answers, no. \n",
      "166.90750122070312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mahybe not in a symphony it's it's not among the three answers, no. \n",
      "token:  [S1] Oh ok. \n",
      "26.54471778869629\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh ok. \n",
      "token:  [MOD] So far you just found found only the violin. \n",
      "209.3914337158203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So far you just found found only the violin. \n",
      "token:  [S2] the violin \n",
      "56.22168731689453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the violin \n",
      "token:  [MOD] Yeah. \n",
      "109.61234283447266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] Flute oh yeah well. \n",
      "138.5312042236328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Flute oh yeah well. \n",
      "token:  [MOD] Something not similar to violin, but yeah \n",
      "155.9712371826172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Something not similar to violin, but yeah \n",
      "token:  [S1] ah let me try to remember \n",
      "69.576171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah let me try to remember \n",
      "token:  [S2] yeah \n",
      "9.720280647277832\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] and imagine it in the show the concert. \n",
      "89.91712951660156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and imagine it in the show the concert. \n",
      "token:  [S2] close to the violin \n",
      "24.492246627807617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] close to the violin \n",
      "token:  [MOD] Yes. \n",
      "77.44972229003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes. \n",
      "token:  [S2] Like in the dame category. \n",
      "83.00801086425781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Like in the dame category. \n",
      "token:  [MOD] Exactly. With strings with \n",
      "342.24749755859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly. With strings with \n",
      "token:  [S2] ha \n",
      "338.3216552734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ha \n",
      "token:  [MOD] I can't remember this thing called. I'm habi helping \n",
      "197.61952209472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I can't remember this thing called. I'm habi helping \n",
      "token:  [S1] What's it cello \n",
      "83.931640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] What's it cello \n",
      "token:  [MOD] Exactly! \n",
      "181.57888793945312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly! \n",
      "token:  [S1] Cello, cello, cello. \n",
      "21.549297332763672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cello, cello, cello. \n",
      "token:  [MOD] Thank you \n",
      "127.28739929199219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Thank you \n",
      "token:  [S2] What it is? \n",
      "25.979122161865234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] What it is? \n",
      "token:  [MOD] Yeah. \n",
      "85.69219970703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] I don't know what it is. \n",
      "8.330584526062012\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know what it is. \n",
      "token:  [MOD] The cello is a like a a big violin that you \n",
      "129.06747436523438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] The cello is a like a a big violin that you \n",
      "token:  [S2] place o o o on on the floor \n",
      "95.0323486328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] place o o o on on the floor \n",
      "token:  [MOD] Yeah I think it's the word that I had in French \n",
      "74.41368865966797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah I think it's the word that I had in French \n",
      "token:  [S2] and I thought \n",
      "59.04210662841797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and I thought \n",
      "token:  [S1] hmm \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.742551803588867\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] that yeah \n",
      "24.071041107177734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] that yeah \n",
      "token:  [MOD] ok \n",
      "136.99517822265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok \n",
      "token:  [S2] Yeah I know \n",
      "45.64357376098633\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah I know \n",
      "token:  [MOD] ok \n",
      "126.51243591308594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok \n",
      "token:  [S2] yeah \n",
      "53.02497482299805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] so there is a langua \n",
      "177.72540283203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] so there is a langua \n",
      "token:  [S2] ok well \n",
      "107.86881256103516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok well \n",
      "token:  [MOD] ge eh specificity \n",
      "2829.383056640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ge eh specificity \n",
      "token:  [S1] it'slike a big violin n ro \n",
      "356.0436706542969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it'slike a big violin n ro \n",
      "token:  [S2] yeah yeah \n",
      "14.908001899719238\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah yeah \n",
      "token:  [MOD] this \n",
      "99.46993255615234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] this \n",
      "token:  [S1] the same \n",
      "24.5118350982666\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the same \n",
      "token:  [MOD] yeah yeah yeah yeah yeah \n",
      "47.534156799316406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah yeah yeah yeah yeah \n",
      "token:  [S2] yes exactly the same anyway. \n",
      "58.93878936767578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes exactly the same anyway. \n",
      "token:  [MOD] How i is it in French? \n",
      "119.54779052734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] How i is it in French? \n",
      "token:  [S2] Violoncelle. \n",
      "55.57182693481445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violoncelle. \n",
      "token:  [MOD] yeah \n",
      "305.8356018066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S2] There is the same \n",
      "66.78439331054688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] There is the same \n",
      "token:  [MOD] it's the the cello yeah yeah \n",
      "291.8089294433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it's the the cello yeah yeah \n",
      "token:  [S2] part of the word so \n",
      "45.30093765258789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] part of the word so \n",
      "token:  [MOD] cello \n",
      "280.80419921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] cello \n",
      "token:  [S1] Well I think in i i in Portuguese we have both \n",
      "189.42556762695312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Well I think in i i in Portuguese we have both \n",
      "token:  [MOD] I think yes that's true \n",
      "74.99592590332031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I think yes that's true \n",
      "token:  [S1] and they are different like vio violon \n",
      "320.76171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and they are different like vio violon \n",
      "token:  [MOD] cello and \n",
      "202.5475311279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] cello and \n",
      "token:  [S1] cello and cello \n",
      "13.666740417480469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cello and cello \n",
      "token:  [S2] Ah really? \n",
      "43.2458381652832\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ah really? \n",
      "token:  [S1] I don't know well not the expert but I think \n",
      "27.321252822875977\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't know well not the expert but I think \n",
      "token:  [S2] well ok \n",
      "23.22589874267578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] well ok \n",
      "token:  [S1] that we have both words and \n",
      "42.01454544067383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] that we have both words and \n",
      "token:  [MOD] ok \n",
      "391.4118957519531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok \n",
      "token:  [S1] maybe \n",
      "41.07829284667969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] maybe \n",
      "token:  [S2] ah maybe yeah \n",
      "28.565082550048828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah maybe yeah \n",
      "token:  [S1] they're different I don't know I don't know. What else one more? \n",
      "26.514659881591797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] they're different I don't know I don't know. What else one more? \n",
      "token:  [MOD] Ok great so one more yes now I would like to to think of a different category so not with strings \n",
      "103.29933166503906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok great so one more yes now I would like to to think of a different category so not with strings \n",
      "token:  [S1] o k \n",
      "76.42463684082031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] o k \n",
      "token:  [MOD] Not \n",
      "257.3421325683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Not \n",
      "token:  [S1] pia piano? No. \n",
      "187.0199737548828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] pia piano? No. \n",
      "token:  [S2] No no. \n",
      "9.942404747009277\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No no. \n",
      "token:  [MOD] Ah yeah I why isn't the piano \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358.9715270996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ah yeah I why isn't the piano \n",
      "token:  [S1] No piano. \n",
      "46.70490264892578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No piano. \n",
      "token:  [MOD] among these it's it's \n",
      "195.827392578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] among these it's it's \n",
      "token:  [S2] No no there no piano. \n",
      "219.73196411132812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No no there no piano. \n",
      "token:  [MOD] crazy eh but no, not piano \n",
      "250.2630157470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] crazy eh but no, not piano \n",
      "token:  [S1] not piano \n",
      "24.181875228881836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] not piano \n",
      "token:  [S2] like is similar to the f flute or with \n",
      "92.17234802246094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] like is similar to the f flute or with \n",
      "token:  [MOD] no \n",
      "139.4541015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no \n",
      "token:  [S2] no it's \n",
      "39.45927429199219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no it's \n",
      "token:  [MOD] more to piano but i in terms of I don't know if I \n",
      "147.71961975097656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] more to piano but i in terms of I don't know if I \n",
      "token:  [S2] how to play it \n",
      "34.895416259765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] how to play it \n",
      "token:  [MOD] yes, I'm not sure if I say this word it will be very very helpful. \n",
      "43.982479095458984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes, I'm not sure if I say this word it will be very very helpful. \n",
      "token:  [S1] xylophones oh not xylophone. \n",
      "35.271087646484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] xylophones oh not xylophone. \n",
      "token:  [MOD] ips you \n",
      "175.043212890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ips you \n",
      "token:  [S2] \n",
      "28.70668601989746\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] a different \n",
      "55.464454650878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] a different \n",
      "token:  [MOD] you're \n",
      "145.6609649658203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you're \n",
      "token:  [S2] sound of trum \n",
      "275.47735595703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] sound of trum \n",
      "token:  [MOD] getting \n",
      "432.4385986328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] getting \n",
      "token:  [S2] pet no symphony no no \n",
      "290.3677673339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] pet no symphony no no \n",
      "token:  [MOD] closer no no no it's it doesn't \n",
      "84.17701721191406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] closer no no no it's it doesn't \n",
      "token:  [S1] hmm organ no \n",
      "110.51625061035156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm organ no \n",
      "token:  [MOD] no \n",
      "61.04666519165039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no \n",
      "token:  [S1] \n",
      "20.657054901123047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] no something that gives rhythm in generla and you can also find it it's very common in gigs or other concerts as well. What gives the rhythm? \n",
      "160.7865447998047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no something that gives rhythm in generla and you can also find it it's very common in gigs or other concerts as well. What gives the rhythm? \n",
      "token:  [S1] The battery \n",
      "89.17893981933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The battery \n",
      "token:  [S2] Yeah that's not the what \n",
      "33.81058120727539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah that's not the what \n",
      "token:  [MOD] instrument gives \n",
      "693.3361206054688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] instrument gives \n",
      "token:  [S1] the \n",
      "24.17513084411621\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the \n",
      "token:  [MOD] the beat rhythm \n",
      "283.6097717285156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the beat rhythm \n",
      "token:  [S1] Oh the bass? \n",
      "75.15440368652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh the bass? \n",
      "token:  [MOD] Yeah sure sure \n",
      "130.45687866210938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah sure sure \n",
      "token:  [S2] yeah bass or battery \n",
      "341.6244812011719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah bass or battery \n",
      "token:  [S1] I don't know. I used to play bass so I think that that is. \n",
      "12.613121032714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't know. I used to play bass so I think that that is. \n",
      "token:  [MOD] Apart from the bass so Who would be behind \n",
      "219.29922485351562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Apart from the bass so Who would be behind \n",
      "token:  [S1] I see \n",
      "30.602481842041016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I see \n",
      "token:  [MOD] you, who would be placed behind you? \n",
      "83.65845489501953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you, who would be placed behind you? \n",
      "token:  [S1] The battery \n",
      "106.64139556884766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The battery \n",
      "token:  [S2] Yeah. \n",
      "11.039649963378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] no? \n",
      "15.921374320983887\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] no? \n",
      "token:  [MOD] Battery? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221.04229736328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Battery? \n",
      "token:  [S1] Battery I understand drums \n",
      "431.7166748046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Battery I understand drums \n",
      "token:  [S2] but there \n",
      "58.99347686767578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] but there \n",
      "token:  [S1] drums sorry \n",
      "191.90728759765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] drums sorry \n",
      "token:  [MOD] Yes. \n",
      "56.52495574951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes. \n",
      "token:  [S1] Drums drums. \n",
      "52.105934143066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Drums drums. \n",
      "token:  [MOD] Exactly yes so it's it's th the \n",
      "262.6845397949219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly yes so it's it's th the \n",
      "token:  [S1] ah just saying batteries \n",
      "342.4779968261719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah just saying batteries \n",
      "token:  [MOD] drum since we're talking about the a symphony orche stra it's it's a drum yeah. \n",
      "195.67132568359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] drum since we're talking about the a symphony orche stra it's it's a drum yeah. \n",
      "token:  [S1] Drums. \n",
      "23.523406982421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Drums. \n",
      "token:  [S2] Oh? \n",
      "11.119566917419434\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh? \n",
      "token:  [MOD] I don't know. Yeah this is what people replied yeah. \n",
      "62.164703369140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I don't know. Yeah this is what people replied yeah. \n",
      "token:  [S2] Ok. \n",
      "26.274185180664062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] sorry yeah \n",
      "539.9681396484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] sorry yeah \n",
      "token:  [S1] Wow! \n",
      "37.119728088378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Wow! \n",
      "token:  [MOD] So we ha \n",
      "377.7886047363281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So we ha \n",
      "token:  [S1] I don't imagine violin \n",
      "154.6041259765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't imagine violin \n",
      "token:  [MOD] ve violin \n",
      "1135.0753173828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ve violin \n",
      "token:  [S1] with drums and what else? and and cello? \n",
      "123.70806884765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] with drums and what else? and and cello? \n",
      "token:  [S2] Cello. \n",
      "12.025046348571777\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cello. \n",
      "token:  [S1] No I don't I don't see it. \n",
      "13.943958282470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No I don't I don't see it. \n",
      "token:  [MOD] But sometimes there is this \n",
      "84.3923110961914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But sometimes there is this \n",
      "token:  [S1] all together but well. \n",
      "107.45088958740234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] all together but well. \n",
      "token:  [MOD] you know very big drum that they hit with the \n",
      "199.75775146484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you know very big drum that they hit with the \n",
      "token:  [S2] yeah \n",
      "117.03038024902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] yeah \n",
      "7.36111307144165\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] yeah \n",
      "5.662800312042236\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] But yeah i it's it's it's \n",
      "61.12026596069336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But yeah i it's it's it's \n",
      "token:  [S2] but it's not \n",
      "19.016998291015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] but it's not \n",
      "token:  [MOD] rare it's rare but \n",
      "89.71387481689453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] rare it's rare but \n",
      "token:  [S1] yeah \n",
      "55.378116607666016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] still people replied that so we have \n",
      "309.97027587890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] still people replied that so we have \n",
      "token:  [S1] So \n",
      "49.89022445678711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So \n",
      "token:  [S2] violin first \n",
      "110.93890380859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] violin first \n",
      "token:  [S1] ok violin \n",
      "23.288068771362305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok violin \n",
      "token:  [MOD] violin, cello \n",
      "98.3438949584961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] violin, cello \n",
      "token:  [S1] first \n",
      "85.2754898071289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] first \n",
      "token:  [MOD] and mhmm \n",
      "110.2322998046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and mhmm \n",
      "token:  [S1] cello and then drums that was we \n",
      "567.6732788085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cello and then drums that was we \n",
      "token:  [S2] cello and then drums yes \n",
      "8.126910209655762\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cello and then drums yes \n",
      "token:  [S1] struggling so much \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.77663040161133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] struggling so much \n",
      "token:  [S2] yeah \n",
      "13.203441619873047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] to find so yes \n",
      "64.40773010253906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] to find so yes \n",
      "token:  [MOD] That's grat thank you yeah you're great. That's the correct order of course. \n",
      "102.76034545898438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's grat thank you yeah you're great. That's the correct order of course. \n",
      "token:  [S1] Oh good. \n",
      "21.839326858520508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh good. \n",
      "token:  [MOD] So let's now go to the third que stion \n",
      "107.18704223632812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So let's now go to the third que stion \n",
      "token:  [S1] hmm \n",
      "94.72267150878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] name somethinkg that people cut. \n",
      "404.1895751953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] name somethinkg that people cut. \n",
      "token:  [S2] Paper. \n",
      "92.20655059814453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Paper. \n",
      "token:  [S1] Kni ife. \n",
      "58.027183532714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Kni ife. \n",
      "token:  [MOD] Yes! \n",
      "74.00360870361328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes! \n",
      "token:  [S1] Paper. oh \n",
      "254.39373779296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Paper. oh \n",
      "token:  [MOD] yes Excellent \n",
      "517.2711181640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes Excellent \n",
      "token:  [S1] cute oh you need to you cut not \n",
      "349.81292724609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cute oh you need to you cut not \n",
      "token:  [S2] yeah \n",
      "14.494458198547363\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] you you just to \n",
      "52.758323669433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] you you just to \n",
      "token:  [S2] grass \n",
      "53.66411209106445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] grass \n",
      "token:  [S1] cut yes grass, paper \n",
      "146.8515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cut yes grass, paper \n",
      "token:  [MOD] mhmm \n",
      "70.84168243408203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] You cut \n",
      "175.8966522216797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] You cut \n",
      "token:  [S2] \n",
      "7.393627643585205\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] Hair. \n",
      "74.81526184082031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hair. \n",
      "token:  [MOD] Yes! \n",
      "54.2200813293457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes! \n",
      "token:  [S2] Yeah! \n",
      "23.60137939453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah! \n",
      "token:  [MOD] Excellent, thank you. \n",
      "30.834983825683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent, thank you. \n",
      "token:  [S1] Yeah ! We have the three? \n",
      "117.87252044677734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah ! We have the three? \n",
      "token:  [S2] So we have two? \n",
      "7.994141101837158\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So we have two? \n",
      "token:  [MOD]  more one more \n",
      "274.9532165527344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD]  more one more \n",
      "token:  [S1] no no \n",
      "21.752544403076172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] no no \n",
      "token:  [MOD] yeah you have paper, you have \n",
      "140.85728454589844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah you have paper, you have \n",
      "token:  [S2] because the grass is no \n",
      "141.67977905273438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] because the grass is no \n",
      "token:  [MOD] hair I know it can be \n",
      "160.5247802734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hair I know it can be \n",
      "token:  [S1] The skin \n",
      "127.4910659790039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The skin \n",
      "token:  [MOD] it it's not very popular \n",
      "143.85060119628906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it it's not very popular \n",
      "token:  [S2] \n",
      "31.138648986816406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] at least in terms of answers yeah. \n",
      "151.73379516601562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] at least in terms of answers yeah. \n",
      "token:  [S1] \n",
      "29.98447608947754\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] \n",
      "4.362130641937256\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] \n",
      "5.705223083496094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] How about when you prepare somethi ng for \n",
      "169.72808837890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] How about when you prepare somethi ng for \n",
      "token:  [S1] food \n",
      "221.66229248046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] food \n",
      "token:  [MOD] yes \n",
      "125.29827117919922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes \n",
      "token:  [S1] yeah \n",
      "27.3944149017334\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] good \n",
      "9.064005851745605\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] good \n",
      "token:  [S1] food \n",
      "22.712186813354492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] food \n",
      "token:  [MOD] Something more specific? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.72232055664062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Something more specific? \n",
      "token:  [S2] Tomato \n",
      "298.8824462890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Tomato \n",
      "token:  [S1] eh eh meat \n",
      "119.68867492675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] eh eh meat \n",
      "token:  [MOD] Yes! \n",
      "89.92656707763672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes! \n",
      "token:  [S2] ah \n",
      "165.97320556640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah \n",
      "token:  [MOD] Yes \n",
      "128.38735961914062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes \n",
      "token:  [S2] good meat yeah \n",
      "358.5363464355469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] good meat yeah \n",
      "token:  [MOD] Excellent excellent you you're great, you're very good, good job. Ah so we have paper hair \n",
      "137.85414123535156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent excellent you you're great, you're very good, good job. Ah so we have paper hair \n",
      "token:  [S1] hair \n",
      "89.61600494384766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hair \n",
      "token:  [MOD] and \n",
      "87.68999481201172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and \n",
      "token:  [S1] meat \n",
      "194.0110626220703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat \n",
      "token:  [S2] meat \n",
      "7.922173976898193\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] meat \n",
      "token:  [S1] mhmm \n",
      "25.238609313964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] what would be the ideal order? Not the ideal, the the most popular to less popular. \n",
      "56.66598892211914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] what would be the ideal order? Not the ideal, the the most popular to less popular. \n",
      "token:  [S2] Hair and paper as the first one I think it's better \n",
      "151.63890075683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair and paper as the first one I think it's better \n",
      "token:  [S1] yeah I would say hair \n",
      "18.495100021362305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah I would say hair \n",
      "token:  [S2] hair f yeah \n",
      "46.38893508911133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair f yeah \n",
      "token:  [S1] like cut a hair cut hair I know \n",
      "48.629398345947266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like cut a hair cut hair I know \n",
      "token:  [S2] yeah yeah \n",
      "15.935335159301758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah yeah \n",
      "token:  [S1] it's like good together. \n",
      "32.10935592651367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it's like good together. \n",
      "token:  [S2] I don't know why I \n",
      "15.508918762207031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know why I \n",
      "token:  [S1] and then paper? \n",
      "56.44242858886719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and then paper? \n",
      "token:  [S2] thought of paper at first \n",
      "26.561893463134766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] thought of paper at first \n",
      "token:  [S1] yeah \n",
      "22.012378692626953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] mhmm \n",
      "39.5537109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S2] yeah hair \n",
      "383.08685302734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah hair \n",
      "token:  [S1] paper \n",
      "28.641788482666016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] paper \n",
      "token:  [S2] hair \n",
      "16.810707092285156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair \n",
      "token:  [S1] and then \n",
      "22.698816299438477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and then \n",
      "token:  [S2] paper and then \n",
      "23.808679580688477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] paper and then \n",
      "token:  [S1] meat. \n",
      "27.80263900756836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat. \n",
      "token:  [S2] meat. \n",
      "4.663602828979492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] meat. \n",
      "token:  [MOD] Ok? You you have an agreement? \n",
      "149.23641967773438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok? You you have an agreement? \n",
      "token:  [S1] yeah \n",
      "42.04480743408203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] hmm \n",
      "7.5522308349609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] Yeah? \n",
      "74.06482696533203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? \n",
      "token:  [S1] No? no no wait wait \n",
      "48.33271789550781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No? no no wait wait \n",
      "token:  [S2] Yeah yeah yeah yeah yeah yeah. \n",
      "6.2375640869140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah yeah yeah yeah yeah yeah. \n",
      "token:  [MOD] I'm very \n",
      "86.68846130371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'm very \n",
      "token:  [S1] yeah \n",
      "75.43855285644531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] delighted to say you made it \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138.79290771484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] delighted to say you made it \n",
      "token:  [S1] wow, we're amazing! \n",
      "31.74407958984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] wow, we're amazing! \n",
      "token:  [MOD] three out of three you're fantastic! Thank you thank you so much so yeah that's the end, I hope you enjoyed that. Thank you very much, you're great. Good job \n",
      "25.43142318725586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] three out of three you're fantastic! Thank you thank you so much so yeah that's the end, I hope you enjoyed that. Thank you very much, you're great. Good job \n",
      "token:  [S1] Thank you . That's it was \n",
      "42.27044677734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Thank you . That's it was \n",
      "token:  [S2] Thank you. \n",
      "7.439676284790039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Thank you. \n",
      "token:  [S1] fun. \n",
      "21.82411766052246\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] fun. \n",
      "token:  [MOD] Thank you.\n",
      "51.33919143676758\n",
      "MOD : 205.84981811580374\n",
      "S1 : 83.80401973724365\n",
      "S2 : 61.90560661977337\n",
      "speech transcription_Transcriber/S08.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] So good evening \n",
      "644.18017578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So good evening \n",
      "token:  [S2] Good evening. \n",
      "21.1440486907959\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Good evening. \n",
      "token:  [MOD] a nd welcome \n",
      "146.4335479736328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] a nd welcome \n",
      "token:  [S1] Good evening. \n",
      "27.52676010131836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Good evening. \n",
      "token:  [MOD] nice to see you and thank you for coming. so today we're going to play a quiz. I'm going to eh ask you ah questions that have been previously ah posed to one hundred of people and I want you to give me the three most popular answers to each question. So for example if I ask you what do people use to ahm to transfer eh patients your answers would be like ambulance or wheelchair or hospital bed and then I would ask you to rank these three answers in terms of popularity. Is everything clear? No worries I mean there's no right or wrong you don't have really to know something just guess what would be \n",
      "34.923336029052734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] nice to see you and thank you for coming. so today we're going to play a quiz. I'm going to eh ask you ah questions that have been previously ah posed to one hundred of people and I want you to give me the three most popular answers to each question. So for example if I ask you what do people use to ahm to transfer eh patients your answers would be like ambulance or wheelchair or hospital bed and then I would ask you to rank these three answers in terms of popularity. Is everything clear? No worries I mean there's no right or wrong you don't have really to know something just guess what would be \n",
      "token:  [S2] eh ok I was thinking about the vocabulary. \n",
      "76.04686737060547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh ok I was thinking about the vocabulary. \n",
      "token:  [MOD] ah \n",
      "164.01132202148438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ah \n",
      "token:  [S1] yeah \n",
      "44.541561126708984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] yeah it's Ok yeah maybe the the example I gave you was a bit you know it needed some kind of terminology but I think that the actual questions will be easier. eh no worries you can describe it's it's not \n",
      "75.4134521484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah it's Ok yeah maybe the the example I gave you was a bit you know it needed some kind of terminology but I think that the actual questions will be easier. eh no worries you can describe it's it's not \n",
      "token:  [S2] ok \n",
      "48.88017272949219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] We'll find the the solution. eh so especially with regrding the second part where you have to rank the three eh answers that you give, I want you to collaborate with each other, talk with each other reach a final decision and then ah let me know. Ok? \n",
      "93.87271118164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] We'll find the the solution. eh so especially with regrding the second part where you have to rank the three eh answers that you give, I want you to collaborate with each other, talk with each other reach a final decision and then ah let me know. Ok? \n",
      "token:  [S2] ok \n",
      "49.37468719482422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] I will guide \n",
      "137.02117919921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I will guide \n",
      "token:  [S2] ok \n",
      "163.08602905273438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] you also through the Ah so the first question, I would like you to give me the three most popular answers to the question name a public place where people are likely to catch a cold or a flu bug. \n",
      "59.985557556152344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you also through the Ah so the first question, I would like you to give me the three most popular answers to the question name a public place where people are likely to catch a cold or a flu bug. \n",
      "token:  [S2] \n",
      "26.47246551513672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] So \n",
      "242.73191833496094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So \n",
      "token:  [S1] So \n",
      "19.552152633666992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So \n",
      "token:  [MOD] ah public place what would be a public place \n",
      "198.30747985839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ah public place what would be a public place \n",
      "token:  [S2] each one of us gives different or \n",
      "123.50083923339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] each one of us gives different or \n",
      "token:  [MOD] eh just start \n",
      "723.3328247070312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] eh just start \n",
      "token:  [S2] we just \n",
      "40.9805908203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] we just \n",
      "token:  [MOD] talking \n",
      "138.33819580078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] talking \n",
      "token:  [S2] eh \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.3042755126953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh \n",
      "token:  [MOD] and \n",
      "104.35092163085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and \n",
      "token:  [S1] toge eh the people get cold in it? \n",
      "316.79852294921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] toge eh the people get cold in it? \n",
      "token:  [MOD] yes \n",
      "120.97532653808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes \n",
      "token:  [S1] on it yeah ok \n",
      "70.07947540283203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] on it yeah ok \n",
      "token:  [MOD] What would be th a place the beach \n",
      "311.349853515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] What would be th a place the beach \n",
      "token:  [S2] The the beach? \n",
      "44.09600830078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The the beach? \n",
      "token:  [S1] yeah \n",
      "18.03061294555664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] ok \n",
      "10.792656898498535\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] maybe The pool \n",
      "38.280967712402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] maybe The pool \n",
      "token:  [S2] I would say \n",
      "14.28741455078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I would say \n",
      "token:  [S1] \n",
      "7.478969097137451\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] eh a pool \n",
      "51.85136413574219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh a pool \n",
      "token:  [S1] yeah \n",
      "11.848416328430176\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] ok yes A park? \n",
      "68.05498504638672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok yes A park? \n",
      "token:  [S1] the park maybe \n",
      "22.473237991333008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the park maybe \n",
      "token:  [S2] A port? \n",
      "28.580810546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A port? \n",
      "token:  [MOD] All these are yeah these \n",
      "414.0699462890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] All these are yeah these \n",
      "token:  [S1] the port yeah \n",
      "179.1668243408203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the port yeah \n",
      "token:  [MOD] very good ideas but it's just that they are not among the three most popular answers so keep gue ssing yeah \n",
      "125.65605926513672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very good ideas but it's just that they are not among the three most popular answers so keep gue ssing yeah \n",
      "token:  [S2] An airport? \n",
      "118.48100280761719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] An airport? \n",
      "token:  [MOD] you're very close, not exactly the place \n",
      "93.32748413085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you're very close, not exactly the place \n",
      "token:  [S1] The bus? \n",
      "64.70209503173828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The bus? \n",
      "token:  [MOD] but the but the means of transport? \n",
      "101.40985107421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] but the but the means of transport? \n",
      "token:  [S1] The bus? \n",
      "30.179378509521484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The bus? \n",
      "token:  [MOD] In an airport? \n",
      "48.08498001098633\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] In an airport? \n",
      "token:  [S2] Airplane? \n",
      "22.317607879638672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Airplane? \n",
      "token:  [MOD] Airplane yes air plane is \n",
      "86.9256820678711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Airplane yes air plane is \n",
      "token:  [S1] hmm \n",
      "41.78590774536133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] one of the three \n",
      "59.27437973022461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] one of the three \n",
      "token:  [S1] Really? \n",
      "68.870361328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Really? \n",
      "token:  [MOD] Yes. ok \n",
      "87.30244445800781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes. ok \n",
      "token:  [S1] One of the three we want another two \n",
      "110.20130157470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] One of the three we want another two \n",
      "token:  [MOD] Exactly. \n",
      "99.53337097167969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly. \n",
      "token:  [S2] We can look for \n",
      "67.69488525390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] We can look for \n",
      "token:  [S1] the hospital \n",
      "154.11598205566406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the hospital \n",
      "token:  [MOD] Very good. \n",
      "103.40115356445312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good. \n",
      "token:  [S2] ah \n",
      "204.60145568847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah \n",
      "token:  [MOD] Great, yes. \n",
      "91.3755111694336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Great, yes. \n",
      "token:  [S1] Lot of viruses there. \n",
      "68.13138580322266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Lot of viruses there. \n",
      "token:  [MOD] So two out of three. We need one \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So two out of three. We need one \n",
      "token:  [S1] ok \n",
      "167.9195556640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] more. Ah think about different age grou achool. yes I was about to \n",
      "700.4086303710938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] more. Ah think about different age grou achool. yes I was about to \n",
      "token:  [S1] Sorry? \n",
      "74.30731201171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Sorry? \n",
      "token:  [MOD] tell \n",
      "211.4720001220703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] tell \n",
      "token:  [S2] The school. \n",
      "111.14265441894531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The school. \n",
      "token:  [MOD] school yeah \n",
      "653.990478515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] school yeah \n",
      "token:  [S1] The school yeah . \n",
      "49.04581069946289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The school yeah . \n",
      "token:  [MOD] Excellent, you're great, good job. So, I'd like you to to rank them in terms of popularity, what people think are most popular. So you have \n",
      "36.33596420288086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent, you're great, good job. So, I'd like you to to rank them in terms of popularity, what people think are most popular. So you have \n",
      "token:  [S1] What people think or the the \n",
      "78.84088134765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] What people think or the the \n",
      "token:  [MOD] no not the actual, what people think so \n",
      "141.8204345703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no not the actual, what people think so \n",
      "token:  [S1] actual ok what people think \n",
      "60.24658203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] actual ok what people think \n",
      "token:  [MOD] yeah there's no ground truth so we have hospital, school and airplane ah waht would be the \n",
      "148.9586639404297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah there's no ground truth so we have hospital, school and airplane ah waht would be the \n",
      "token:  [S1] Hospital I think \n",
      "98.05610656738281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hospital I think \n",
      "token:  [S2] Hospital the first yes \n",
      "33.3101692199707\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hospital the first yes \n",
      "token:  [S1] it's scary \n",
      "21.595346450805664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it's scary \n",
      "token:  [S2] Then maybe school? \n",
      "37.23579406738281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Then maybe school? \n",
      "token:  [S1] Maybe sco school yeah. Then the airport. \n",
      "53.0909423828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Maybe sco school yeah. Then the airport. \n",
      "token:  [S2] Then the airplane. \n",
      "6.6126227378845215\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Then the airplane. \n",
      "token:  [MOD] Is this your final decision? \n",
      "37.032466888427734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Is this your final decision? \n",
      "token:  [S1] yeah \n",
      "62.21250915527344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] yes \n",
      "5.454062461853027\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes \n",
      "token:  [MOD] ok \n",
      "75.33858489990234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok \n",
      "token:  [S1] \n",
      "26.07242774963379\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] ok Very good, I'm afraid you just had to swap the two first, so first it's ah it's school, then hospital and the third one \n",
      "99.60016632080078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok Very good, I'm afraid you just had to swap the two first, so first it's ah it's school, then hospital and the third one \n",
      "token:  [S1] ok \n",
      "39.80928421020508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] is aiplane, but very good job, yeah thank you. Are you ready for the the second one? \n",
      "93.57475280761719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] is aiplane, but very good job, yeah thank you. Are you ready for the the second one? \n",
      "token:  [S1] Yeah fine. \n",
      "36.637271881103516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah fine. \n",
      "token:  [MOD] ok \n",
      "128.3344268798828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok \n",
      "token:  [S2] umhm \n",
      "175.58457946777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] umhm \n",
      "token:  [MOD] So Name an instrument that one can find in a symphony orchestra. \n",
      "98.76853942871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So Name an instrument that one can find in a symphony orchestra. \n",
      "token:  [S2] Name \n",
      "70.38043212890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Name \n",
      "token:  [S1] Symphony? \n",
      "33.16209030151367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Symphony? \n",
      "token:  [MOD] An \n",
      "231.9794158935547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] An \n",
      "token:  [S2] and? \n",
      "105.24415588378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and? \n",
      "token:  [MOD] instrument. \n",
      "457.8434753417969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] instrument. \n",
      "token:  [S1] in the symphony or \n",
      "86.81326293945312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] in the symphony or \n",
      "token:  [MOD] A musical instrument. ah \n",
      "466.083740234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] A musical instrument. ah \n",
      "token:  [S1] chestra \n",
      "190.26283264160156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] chestra \n",
      "token:  [MOD] in a s \n",
      "98.76053619384766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] in a s \n",
      "token:  [S2] the name of the in in instrument \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.67433166503906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the name of the in in instrument \n",
      "token:  [MOD] yes \n",
      "159.86334228515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes \n",
      "token:  [S2] ok \n",
      "42.407859802246094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] yeah \n",
      "90.82000732421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] Symphony? \n",
      "154.03060913085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Symphony? \n",
      "token:  [S2] Violin? \n",
      "8.708806991577148\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violin? \n",
      "token:  [S1] Violin? \n",
      "5.558254241943359\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin? \n",
      "token:  [MOD] Great! Excellent. unani mous decision yeah. \n",
      "790.0823974609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Great! Excellent. unani mous decision yeah. \n",
      "token:  [S1] makes sense this popu lar \n",
      "180.52304077148438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] makes sense this popu lar \n",
      "token:  [S2] Violoncello? \n",
      "32.67108154296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violoncello? \n",
      "token:  [MOD] Great, the yeah the the the second part cello, yeah \n",
      "193.42996215820312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Great, the yeah the the the second part cello, yeah \n",
      "token:  [S2] ah we are loo weare looking for the \n",
      "103.14340209960938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah we are loo weare looking for the \n",
      "token:  [MOD] eh but it \n",
      "187.00714111328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] eh but it \n",
      "token:  [S2] ok \n",
      "48.178436279296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] 's the same I mean yeah I'm just quoting the exact word yeah you're very good. very good so you \n",
      "91.95574951171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] 's the same I mean yeah I'm just quoting the exact word yeah you're very good. very good so you \n",
      "token:  [S2] eh \n",
      "105.89473724365234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh \n",
      "token:  [MOD] have two violin and cello \n",
      "328.3805847167969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] have two violin and cello \n",
      "token:  [S2] of the three most \n",
      "91.79720306396484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] of the three most \n",
      "token:  [MOD] and you need one more eh \n",
      "347.946044921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and you need one more eh \n",
      "token:  [S1] eh \n",
      "41.23249053955078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] eh \n",
      "token:  [S2] We are looking for the three most popular? \n",
      "39.615055084228516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] We are looking for the three most popular? \n",
      "token:  [MOD] exactly \n",
      "248.02859497070312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] exactly \n",
      "token:  [S2] ok \n",
      "90.46253204345703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] What peo \n",
      "325.2037658691406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] What peo \n",
      "token:  [S1] The what \n",
      "83.1142807006836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] The what \n",
      "token:  [MOD] ple think. \n",
      "505.2189025878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ple think. \n",
      "token:  [S2] What \n",
      "79.70639038085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] What \n",
      "token:  [MOD] I mean \n",
      "130.0229034423828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I mean \n",
      "token:  [S2] people think \n",
      "58.16281509399414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] people think \n",
      "token:  [MOD] what people have answered as popular. Yeah \n",
      "237.76820373535156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] what people have answered as popular. Yeah \n",
      "token:  [S1] it's ca lled ah I'm not clever in this the one with the big \n",
      "122.22537994384766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it's ca lled ah I'm not clever in this the one with the big \n",
      "token:  [S2] ah the saxophone no \n",
      "65.91524505615234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah the saxophone no \n",
      "token:  [S1] no \n",
      "8.59202766418457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] no \n",
      "token:  [S2] no \n",
      "5.416778087615967\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no \n",
      "token:  [MOD] Trumpet? \n",
      "164.08737182617188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Trumpet? \n",
      "token:  [S1] I think yes, this one. \n",
      "23.910234451293945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think yes, this one. \n",
      "token:  [MOD] But no \n",
      "115.77293395996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] But no \n",
      "token:  [S1] no \n",
      "29.889055252075195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] no \n",
      "token:  [MOD] eh \n",
      "237.5397491455078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] eh \n",
      "token:  [S1] it is not \n",
      "29.256540298461914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it is not \n",
      "token:  [MOD] I mean great idea \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.2630157470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I mean great idea \n",
      "token:  [S2] Piano? \n",
      "116.02693939208984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Piano? \n",
      "token:  [S1] ok \n",
      "19.624021530151367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] No. \n",
      "78.7618637084961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No. \n",
      "token:  [S2] No. \n",
      "25.61289405822754\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] No. \n",
      "token:  [MOD] It's yeah \n",
      "286.049560546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's yeah \n",
      "token:  [S1] orchestra \n",
      "256.9748840332031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] orchestra \n",
      "token:  [MOD] is I mean sh piano should be in the list but it's not. \n",
      "102.27351379394531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] is I mean sh piano should be in the list but it's not. \n",
      "token:  [S2] not \n",
      "81.98006439208984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] not \n",
      "token:  [MOD] Different \n",
      "382.8664245605469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Different \n",
      "token:  [S2] Lyra? I don't know how it's called in English. \n",
      "39.08447265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Lyra? I don't know how it's called in English. \n",
      "token:  [MOD] it is \n",
      "99.99800109863281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it is \n",
      "token:  [S1] Which one? \n",
      "37.6634635925293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Which one? \n",
      "token:  [S2] It is a big havi ng like \n",
      "59.95475769042969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It is a big havi ng like \n",
      "token:  [MOD] like harp \n",
      "275.6460876464844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] like harp \n",
      "token:  [S2] fifty y \n",
      "294.469482421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] fifty y \n",
      "token:  [S1] like the \n",
      "15.54271125793457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like the \n",
      "token:  [S2] chords \n",
      "55.389366149902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] chords \n",
      "token:  [S1] harp \n",
      "5.8861002922058105\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] harp \n",
      "token:  [S2] yes \n",
      "13.139904975891113\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yes \n",
      "token:  [MOD] yeah \n",
      "71.40386199951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] like the harp \n",
      "52.17338180541992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like the harp \n",
      "token:  [MOD] more or less but no \n",
      "72.19035339355469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] more or less but no \n",
      "token:  [S2] no \n",
      "41.86112594604492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no \n",
      "token:  [MOD] Ah something not with strings, something else something that keeps the rhythm \n",
      "334.284423828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ah something not with strings, something else something that keeps the rhythm \n",
      "token:  [S2] something else \n",
      "37.63163375854492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] something else \n",
      "token:  [S1] \n",
      "9.443387985229492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] ah \n",
      "29.559457778930664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah \n",
      "token:  [S1] like the drums? \n",
      "34.012298583984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] like the drums? \n",
      "token:  [S2] eh \n",
      "24.64822769165039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh \n",
      "token:  [MOD] Great. Excellent. \n",
      "100.8824462890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Great. Excellent. \n",
      "token:  [S1] ok \n",
      "61.94092559814453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] drum the symphony drum yeah \n",
      "324.0284729003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] drum the symphony drum yeah \n",
      "token:  [S1] I don't know its name but \n",
      "37.14213562011719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't know its name but \n",
      "token:  [MOD] It's not the normal drum set you can find \n",
      "104.08500671386719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's not the normal drum set you can find \n",
      "token:  [S1] yeas yeah \n",
      "194.27398681640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeas yeah \n",
      "token:  [MOD] in a symphony orchestra but the rather the big one \n",
      "156.7392578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] in a symphony orchestra but the rather the big one \n",
      "token:  [S1] to keep the rhythm \n",
      "51.43464279174805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] to keep the rhythm \n",
      "token:  [MOD] eh yeah ok great. Ah so what do you think would be the correct order in terms of popularity? So you have I will remind you violin, you have cello and you have drum. \n",
      "63.47578811645508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] eh yeah ok great. Ah so what do you think would be the correct order in terms of popularity? So you have I will remind you violin, you have cello and you have drum. \n",
      "token:  [S1] Violin? \n",
      "26.949644088745117\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin? \n",
      "token:  [S2] Violin? you think the first \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.92896842956543\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violin? you think the first \n",
      "token:  [MOD] \n",
      "183.23634338378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [S1] eh and then the drums maybe? \n",
      "279.6881103515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] eh and then the drums maybe? \n",
      "token:  [S2] May be yes. \n",
      "17.696786880493164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] May be yes. \n",
      "token:  [S1] to give the rhythm? and then the \n",
      "109.62776184082031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] to give the rhythm? and then the \n",
      "token:  [S2] and then \n",
      "8.690279006958008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and then \n",
      "token:  [S1] cello \n",
      "46.5588264465332\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cello \n",
      "token:  [S2] cello. umhm \n",
      "40.028926849365234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cello. umhm \n",
      "token:  [MOD] Are you sure? \n",
      "28.042217254638672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Are you sure? \n",
      "token:  [S2] \n",
      "33.653114318847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] no \n",
      "182.12242126464844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no \n",
      "token:  [S1] we think we think we're not sure \n",
      "41.87712478637695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] we think we think we're not sure \n",
      "token:  [S2] cello drums \n",
      "69.72289276123047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cello drums \n",
      "token:  [S1] we think \n",
      "22.638965606689453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] we think \n",
      "token:  [MOD] exactly exactly so actua lly the order that you guessed eh was \n",
      "514.9204711914062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] exactly exactly so actua lly the order that you guessed eh was \n",
      "token:  [S2] umhm \n",
      "125.42015838623047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] umhm \n",
      "token:  [MOD] the actual order that people \n",
      "204.8650665283203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the actual order that people \n",
      "token:  [S1] the right one yeah \n",
      "125.0354232788086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the right one yeah \n",
      "token:  [MOD] answered, but nevermind I mean you were very quick in identifying the three eh answers so let's move on to the third and final question. And this is name something that people cut. \n",
      "84.95275115966797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] answered, but nevermind I mean you were very quick in identifying the three eh answers so let's move on to the third and final question. And this is name something that people cut. \n",
      "token:  [S2] cut \n",
      "98.42857360839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cut \n",
      "token:  [S1] cut? \n",
      "7.58447790145874\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] cut? \n",
      "token:  [S2] knife or something that \n",
      "52.79413604736328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] knife or something that \n",
      "token:  [MOD] not the instrument \n",
      "205.08389282226562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] not the instrument \n",
      "token:  [S2] an object that eh \n",
      "248.5518035888672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] an object that eh \n",
      "token:  [MOD] the the object that is being \n",
      "85.69122314453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the the object that is being \n",
      "token:  [S2] ok \n",
      "124.41007232666016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] cut \n",
      "252.9403076171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] cut \n",
      "token:  [S1] vegetables \n",
      "106.44036865234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] vegetables \n",
      "token:  [S2] eh yes \n",
      "36.283260345458984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] eh yes \n",
      "token:  [MOD] something \n",
      "128.4092254638672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] something \n",
      "token:  [S2] you want the vegetable? \n",
      "133.67889404296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] you want the vegetable? \n",
      "token:  [MOD] no no no something so specific no no I'm not that demanding ah \n",
      "144.6920928955078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no no no something so specific no no I'm not that demanding ah \n",
      "token:  [S2] ok \n",
      "93.73722076416016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] somehting very close it's also food \n",
      "244.6077117919922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] somehting very close it's also food \n",
      "token:  [S1] meat? \n",
      "61.71250534057617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat? \n",
      "token:  [MOD] yes excellent \n",
      "279.7553405761719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes excellent \n",
      "token:  [S1] meat \n",
      "122.8559799194336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat \n",
      "token:  [MOD] great \n",
      "203.6952667236328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] great \n",
      "token:  [S1] ok \n",
      "39.90873336791992\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] Thank you. \n",
      "45.19688034057617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Thank you. \n",
      "token:  [S1] Makes sense. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.012420654296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Makes sense. \n",
      "token:  [S2] hmm \n",
      "19.643739700317383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] and paper \n",
      "60.04542541503906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and paper \n",
      "token:  [MOD] Paper! You have the \n",
      "114.20359802246094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Paper! You have the \n",
      "token:  [S2] paper? \n",
      "48.903839111328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] paper? \n",
      "token:  [MOD] second one. \n",
      "136.3604736328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] second one. \n",
      "token:  [S1] papercut? \n",
      "173.65069580078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] papercut? \n",
      "token:  [MOD] Excellent. Yeah, now it's a very generic question people can cut like lots of things but The answers also may be may vary \n",
      "205.26498413085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent. Yeah, now it's a very generic question people can cut like lots of things but The answers also may be may vary \n",
      "token:  [S1] rece ntly the jeans recently they know this \n",
      "629.9932861328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] rece ntly the jeans recently they know this \n",
      "token:  [MOD] that's true very it'a a very clever \n",
      "151.52304077148438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] that's true very it'a a very clever \n",
      "token:  [S2] so we have one other \n",
      "58.51714324951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so we have one other \n",
      "token:  [MOD] oh yeah yeah you still ah missing one. \n",
      "293.2606506347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] oh yeah yeah you still ah missing one. \n",
      "token:  [S2] Trees? to make the paper \n",
      "247.58477783203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Trees? to make the paper \n",
      "token:  [S1] Right. Perfect. \n",
      "20.648950576782227\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Right. Perfect. \n",
      "token:  [MOD] but \n",
      "324.67681884765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] but \n",
      "token:  [S1] Nice idea. \n",
      "78.17278289794922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Nice idea. \n",
      "token:  [S2] But not nice idea. ok \n",
      "30.052818298339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] But not nice idea. ok \n",
      "token:  [S1] ah paper people cut \n",
      "380.7799377441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah paper people cut \n",
      "token:  [S2] \n",
      "6.733269691467285\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] people cut \n",
      "112.49400329589844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] people cut \n",
      "token:  [MOD] Something that has to do with ah the way we look? and both \n",
      "121.881591796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Something that has to do with ah the way we look? and both \n",
      "token:  [S1] clothes? \n",
      "91.25128173828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] clothes? \n",
      "token:  [MOD] No ahm Something that e everybody, both men and women eh do ah often \n",
      "421.62969970703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No ahm Something that e everybody, both men and women eh do ah often \n",
      "token:  [S1] Hair? \n",
      "111.9144058227539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hair? \n",
      "token:  [S2] Sorry? \n",
      "10.79953670501709\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Sorry? \n",
      "token:  [S1] Hair. \n",
      "39.12444305419922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hair. \n",
      "token:  [MOD] Hair. \n",
      "25.138277053833008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Hair. \n",
      "token:  [S2] \n",
      "32.36760330200195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] \n",
      "4.780122756958008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] Exactly I was about to \n",
      "128.4842529296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly I was about to \n",
      "token:  [S2] Nice. \n",
      "49.91291427612305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Nice. \n",
      "token:  [MOD] to tell you whether men or women do cut their hair more often but then it it that depends. on the style, I guess yeah. \n",
      "104.28873443603516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] to tell you whether men or women do cut their hair more often but then it it that depends. on the style, I guess yeah. \n",
      "token:  [S1] That depends yeah \n",
      "99.67909240722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] That depends yeah \n",
      "token:  [MOD] ok great, so we have \n",
      "79.38819122314453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok great, so we have \n",
      "token:  [S1] to rank them? \n",
      "64.21772003173828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] to rank them? \n",
      "token:  [MOD] meat we have paper, we have hair. What do you think is the right order. \n",
      "92.57197570800781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] meat we have paper, we have hair. What do you think is the right order. \n",
      "token:  [S2] Meat. \n",
      "33.238616943359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Meat. \n",
      "token:  [S1] Meat, not hair? \n",
      "15.256587028503418\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Meat, not hair? \n",
      "token:  [S2] Hair. \n",
      "8.457357406616211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair. \n",
      "token:  [MOD] \n",
      "55.093997955322266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [S1] Meat makes sense. Makes sense. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.4137954711914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Meat makes sense. Makes sense. \n",
      "token:  [S2] \n",
      "7.765684127807617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] No? No? \n",
      "15.625138282775879\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] No? No? \n",
      "token:  [MOD] Ah you you have to tell me the the whole \n",
      "173.27584838867188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ah you you have to tell me the the whole \n",
      "token:  [S1] oh the whole the whole order \n",
      "55.714256286621094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh the whole the whole order \n",
      "token:  [MOD] yeah \n",
      "90.78230285644531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] Then meat ah \n",
      "518.5617065429688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Then meat ah \n",
      "token:  [S2] hair \n",
      "34.96355438232422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair \n",
      "token:  [S1] hair, then \n",
      "23.20722770690918\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hair, then \n",
      "token:  [S2] paper \n",
      "21.996078491210938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] paper \n",
      "token:  [S1] paper no \n",
      "15.13485336303711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] paper no \n",
      "token:  [MOD] I'm so sorry first is hair \n",
      "246.10360717773438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'm so sorry first is hair \n",
      "token:  [S2] first is and hair? \n",
      "49.25571060180664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] first is and hair? \n",
      "token:  [MOD] second is paper \n",
      "126.17879486083984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] second is paper \n",
      "token:  [S1] pa \n",
      "95.49181365966797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] pa \n",
      "token:  [MOD] and third is \n",
      "346.85784912109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and third is \n",
      "token:  [S1] really? \n",
      "54.50075912475586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] really? \n",
      "token:  [MOD] meat. \n",
      "201.94961547851562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] meat. \n",
      "token:  [S2] third? \n",
      "100.26944732666016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] third? \n",
      "token:  [MOD] I un derstand that you said meat because it's it was the first answer and usually what first comes to mind you judge it as \n",
      "108.38492584228516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I un derstand that you said meat because it's it was the first answer and usually what first comes to mind you judge it as \n",
      "token:  [S1] no because it's like you said that \n",
      "37.110862731933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] no because it's like you said that \n",
      "token:  [S2] no yes \n",
      "14.655845642089844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no yes \n",
      "token:  [S1] the you may not cut your hair but you have to cut your meat all the time \n",
      "24.56351089477539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the you may not cut your hair but you have to cut your meat all the time \n",
      "token:  [MOD] yes yeah I I guess it's what comes to the mind of the people that are being \n",
      "56.219329833984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yes yeah I I guess it's what comes to the mind of the people that are being \n",
      "token:  [S1] yeah \n",
      "65.2210693359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] asked it's \n",
      "263.1943359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] asked it's \n",
      "token:  [S1] yeah right \n",
      "135.37899780273438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah right \n",
      "token:  [MOD] it's but thank you you are great thank you good job. \n",
      "59.38644027709961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] it's but thank you you are great thank you good job. \n",
      "token:  [S1] thank you \n",
      "26.58428955078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] thank you \n",
      "token:  [MOD] Ah thank you very much, I hope That's it I hope you had fun. \n",
      "33.98177719116211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ah thank you very much, I hope That's it I hope you had fun. \n",
      "token:  [S1] Thank you. that's it \n",
      "20.841655731201172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Thank you. that's it \n",
      "token:  [MOD] That's it yeah no more questions thank you but it seems you want more Ok now thank you very much \n",
      "45.32457733154297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's it yeah no more questions thank you but it seems you want more Ok now thank you very much \n",
      "token:  [S2] It was funny. \n",
      "30.83719825744629\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It was funny. \n",
      "token:  [MOD] That's it. Thank you. \n",
      "19.842557907104492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's it. Thank you. \n",
      "token:  [S1] Thank you. \n",
      "10.464999198913574\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Thank you. \n",
      "token:  [S2] ok thank\n",
      "39.54094314575195\n",
      "MOD : 188.60537078462798\n",
      "S1 : 81.39169066222672\n",
      "S2 : 65.67612563732058\n",
      "speech transcription_Transcriber/S23.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] So hi guys thanks \n",
      "985.431640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So hi guys thanks \n",
      "token:  [S1] hi \n",
      "36.46311950683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hi \n",
      "token:  [MOD] very much for coming here today. We are going to play a quiz. So I'm going to ask you three questions that were previously posed to a group of hundred people. You have to find the three most famous answers to each question. You have to talk to each other you have to collaborate in order to order these answers then eh in terms of popularity. \n",
      "33.53383255004883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very much for coming here today. We are going to play a quiz. So I'm going to ask you three questions that were previously posed to a group of hundred people. You have to find the three most famous answers to each question. You have to talk to each other you have to collaborate in order to order these answers then eh in terms of popularity. \n",
      "token:  [S1] mhmm \n",
      "37.611148834228516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [S2] ok \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.952502250671387\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] Ready to start? \n",
      "40.74002456665039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ready to start? \n",
      "token:  [S1] mhmm \n",
      "36.388057708740234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] Yeah? So the first question name a public place where you're likely to catch a cold or a flu bug. \n",
      "73.0657958984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah? So the first question name a public place where you're likely to catch a cold or a flu bug. \n",
      "token:  [S2] w w who who was asked this like what's the public where was it? \n",
      "107.41180419921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] w w who who was asked this like what's the public where was it? \n",
      "token:  [MOD] It was just a random sample but I think Maria can give you more information yeah. \n",
      "48.215965270996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It was just a random sample but I think Maria can give you more information yeah. \n",
      "token:  [S2] ok ok \n",
      "56.102516174316406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok ok \n",
      "token:  [S1] So we're just trying to figure out the answers \n",
      "14.87853717803955\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So we're just trying to figure out the answers \n",
      "token:  [MOD] yeah \n",
      "212.70428466796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] they people might have come up with? \n",
      "82.57518768310547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] they people might have come up with? \n",
      "token:  [MOD] Yeah. \n",
      "43.540348052978516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] So what's \n",
      "45.79473876953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So what's \n",
      "token:  [MOD] three \n",
      "742.802490234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] three \n",
      "token:  [S2] the question again? \n",
      "113.14165496826172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the question again? \n",
      "token:  [MOD] name a place where you're more likely to catch a cold or a flu bug. And you need to get three answers \n",
      "44.463130950927734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] name a place where you're more likely to catch a cold or a flu bug. And you need to get three answers \n",
      "token:  [S1] in general \n",
      "71.27066040039062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] in general \n",
      "token:  [MOD] yeah. \n",
      "154.3251953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah. \n",
      "token:  [S1] ehm \n",
      "61.18185043334961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ehm \n",
      "token:  [S2] It's very broad. \n",
      "18.91437339782715\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It's very broad. \n",
      "token:  [S1] I suppose the ob obvious one would be the hospital would it be? \n",
      "58.998992919921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I suppose the ob obvious one would be the hospital would it be? \n",
      "token:  [MOD] Perfect that's one. \n",
      "86.23680877685547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect that's one. \n",
      "token:  [S2] ok \n",
      "87.2430648803711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] yeah \n",
      "9.444658279418945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] That's correct. \n",
      "36.736080169677734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's correct. \n",
      "token:  [S2] ok \n",
      "70.63339233398438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] \n",
      "9.268112182617188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] I would never have thought about it ok. I'd say the beach but I don't think that makes any sense. \n",
      "20.864099502563477\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I would never have thought about it ok. I'd say the beach but I don't think that makes any sense. \n",
      "token:  [S1] Beach probably's least likely cause the salt water and that's kind of an antiseptic. \n",
      "46.22428894042969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Beach probably's least likely cause the salt water and that's kind of an antiseptic. \n",
      "token:  [S2] yeah ok It's windy the coast \n",
      "91.19964599609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah ok It's windy the coast \n",
      "token:  [S1] yeah \n",
      "11.0378999710083\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] I'm from Brazil \n",
      "19.00450325012207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'm from Brazil \n",
      "token:  [MOD] yeah yeah \n",
      "141.04547119140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah yeah \n",
      "token:  [S1] the people get sick on the beach in Brazil a lot oh well then maybe it is then yeah I do I do \n",
      "74.29690551757812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the people get sick on the beach in Brazil a lot oh well then maybe it is then yeah I do I do \n",
      "token:  [S2] ok hospital catch a cold \n",
      "73.6761245727539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok hospital catch a cold \n",
      "token:  [S1] but \n",
      "17.844621658325195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but \n",
      "token:  [S2] \n",
      "7.967920303344727\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] think of different age groups maybe \n",
      "270.40252685546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] think of different age groups maybe \n",
      "token:  [S1] I suppose public toilets be another \n",
      "233.32040405273438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I suppose public toilets be another \n",
      "token:  [S2] hmm \n",
      "13.263545989990234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] hmm \n",
      "16.621774673461914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] ok not really ok \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.19524383544922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok not really ok \n",
      "token:  [MOD] no \n",
      "83.3913803100586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] no \n",
      "token:  [S2] \n",
      "33.213539123535156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] Think about children. \n",
      "110.50988006591797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Think about children. \n",
      "token:  [S1] hmm yeah schools \n",
      "202.63534545898438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm yeah schools \n",
      "token:  [MOD] So where school \n",
      "228.89183044433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So where school \n",
      "token:  [S1] yeah schools \n",
      "114.76111602783203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah schools \n",
      "token:  [MOD] very very good \n",
      "68.19469451904297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very very good \n",
      "token:  [S2] ok ok \n",
      "32.615440368652344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok ok \n",
      "token:  [MOD] So you \n",
      "123.15111541748047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So you \n",
      "token:  [S1] yeah \n",
      "74.90721893310547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] have hospital and school and you need to find the third answer. \n",
      "143.7166290283203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] have hospital and school and you need to find the third answer. \n",
      "token:  [S1] ok ok \n",
      "71.94489288330078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok ok \n",
      "token:  [S2] This is probably a co a crowded place? \n",
      "74.10944366455078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] This is probably a co a crowded place? \n",
      "token:  [MOD] mhmm \n",
      "74.60824584960938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] yeah \n",
      "57.96043395996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] \n",
      "9.712367057800293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] Oh airplane? Yeah that's it \n",
      "83.87958526611328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh airplane? Yeah that's it \n",
      "token:  [MOD] you found \n",
      "182.93385314941406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you found \n",
      "token:  [S1] yeah \n",
      "53.369102478027344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] all three \n",
      "119.7825927734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] all three \n",
      "token:  [S2] wow \n",
      "130.11288452148438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] wow \n",
      "token:  [MOD] well done. \n",
      "75.10762023925781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] well done. \n",
      "token:  [S1] yeah yeah \n",
      "61.851524353027344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah yeah \n",
      "token:  [S2] You don't need me. No we need you. I'll stay anyways \n",
      "26.631290435791016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] You don't need me. No we need you. I'll stay anyways \n",
      "token:  [MOD] so can you rank those answers please you know which one is the most popular you think \n",
      "70.02896118164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] so can you rank those answers please you know which one is the most popular you think \n",
      "token:  [S2] hmm \n",
      "41.5356559753418\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [S1] \n",
      "7.852408409118652\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] Probably the hospital or the school is the first. \n",
      "43.838661193847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Probably the hospital or the school is the first. \n",
      "token:  [S1] Yeah I was th either of those two. \n",
      "29.14938735961914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah I was th either of those two. \n",
      "token:  [S2] yeah \n",
      "14.881332397460938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] But I'd say maybe school actually now \n",
      "93.10755157470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But I'd say maybe school actually now \n",
      "token:  [S2] Is the number one? \n",
      "15.136528015136719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Is the number one? \n",
      "token:  [S1] Yeah cause there we have a lot more antiseptic stuff in hospitals so \n",
      "80.00038146972656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah cause there we have a lot more antiseptic stuff in hospitals so \n",
      "token:  [S2] yeah yeah \n",
      "11.853199005126953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah yeah \n",
      "token:  [S1] I guess they're \n",
      "17.046415328979492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I guess they're \n",
      "token:  [S2] it's probably yeah \n",
      "20.01915168762207\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] it's probably yeah \n",
      "token:  [S1] they're more prepared to train \n",
      "63.939697265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] they're more prepared to train \n",
      "token:  [S2] if the person is a parent \n",
      "22.0130615234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] if the person is a parent \n",
      "token:  [S1] yeah he or she will probably have remembered \n",
      "36.55413818359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah he or she will probably have remembered \n",
      "token:  [S2] their children than a \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.52548217773438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] their children than a \n",
      "token:  [S1] yeah yeah \n",
      "20.436214447021484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah yeah \n",
      "token:  [S2] yeah \n",
      "7.338903903961182\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] whereas schools it's just it's they're not really \n",
      "77.38407897949219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] whereas schools it's just it's they're not really \n",
      "token:  [S2] yeah \n",
      "12.167896270751953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] prepared \n",
      "30.375553131103516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] prepared \n",
      "token:  [S2] you don't go to the hospitals so often as you go to schools \n",
      "28.349550247192383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] you don't go to the hospitals so often as you go to schools \n",
      "token:  [S1] yeah yeah exactly \n",
      "24.076051712036133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah yeah exactly \n",
      "token:  [S2] I guess \n",
      "9.582741737365723\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I guess \n",
      "token:  [S1] yeah yeah so s we do school as one? \n",
      "115.7442855834961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah yeah so s we do school as one? \n",
      "token:  [S2] School yeah maybe hospital and airplane or \n",
      "151.91680908203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] School yeah maybe hospital and airplane or \n",
      "token:  [S1] hospital hospital next and then airplane? \n",
      "30.93297576904297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hospital hospital next and then airplane? \n",
      "token:  [S2] Yeah. \n",
      "11.611520767211914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Yeah. \n",
      "5.5839009284973145\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Perfect. \n",
      "34.70311737060547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Perfect. \n",
      "token:  [S1] done now \n",
      "124.06966400146484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] done now \n",
      "token:  [S2] Yeah? \n",
      "14.61481761932373\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah? \n",
      "token:  [MOD] That's correct. Yeah well done! \n",
      "58.557865142822266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's correct. Yeah well done! \n",
      "token:  [S1] yeah \n",
      "64.95967102050781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] ok \n",
      "8.3804349899292\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] Ready for the second one? \n",
      "41.3142204284668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ready for the second one? \n",
      "token:  [S2] yeah \n",
      "71.26045989990234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] yeah \n",
      "6.762359142303467\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] can you name an instrument that is found in a symphony orchestra. \n",
      "55.08638381958008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] can you name an instrument that is found in a symphony orchestra. \n",
      "token:  [S2] symphony \n",
      "92.31961822509766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] symphony \n",
      "token:  [S1] I can \n",
      "16.20531463623047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I can \n",
      "token:  [MOD] symphonic orchestra In a symphony orchestra. \n",
      "81.5499038696289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] symphonic orchestra In a symphony orchestra. \n",
      "token:  [S1] timpani? \n",
      "49.31758117675781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] timpani? \n",
      "token:  [S2] ok is a cello found in a symphonic orchestra? \n",
      "21.804244995117188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok is a cello found in a symphonic orchestra? \n",
      "token:  [MOD] That's co rrect \n",
      "304.1827087402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's co rrect \n",
      "token:  [S1] yeah \n",
      "63.55583572387695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] cello is one yeah \n",
      "401.0909729003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] cello is one yeah \n",
      "token:  [S2] violin \n",
      "123.36871337890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] violin \n",
      "token:  [MOD] very good. \n",
      "126.7421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very good. \n",
      "token:  [S1] violin \n",
      "196.11837768554688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] violin \n",
      "token:  [MOD] Yeah \n",
      "282.8065185546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah \n",
      "token:  [S1] yeah \n",
      "23.053115844726562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] very good you have two. \n",
      "112.99651336669922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very good you have two. \n",
      "token:  [S2] There will be a lot of \n",
      "22.256267547607422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] There will be a lot of \n",
      "token:  [S1] There'll be brass \n",
      "41.23820495605469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] There'll be brass \n",
      "token:  [S2] the drums \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.655200958251953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] the drums \n",
      "token:  [S1] drums \n",
      "12.26707649230957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] drums \n",
      "token:  [MOD] a drum \n",
      "49.39092254638672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] a drum \n",
      "token:  [S1] yeah \n",
      "56.76496887207031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] actually drum is the third one \n",
      "260.5971984863281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] actually drum is the third one \n",
      "token:  [S2] yeah \n",
      "67.62097930908203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] perfect \n",
      "131.4493408203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] perfect \n",
      "token:  [S1] ok \n",
      "49.9904899597168\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] So it's you have three answers \n",
      "133.7222442626953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So it's you have three answers \n",
      "token:  [S2] umhm \n",
      "205.70033264160156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] umhm \n",
      "token:  [MOD] can you order them now in terms of popularity? \n",
      "66.58842468261719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] can you order them now in terms of popularity? \n",
      "token:  [S2] hm \n",
      "65.66236877441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm \n",
      "token:  [S1] So we've got what violin? \n",
      "62.620880126953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So we've got what violin? \n",
      "token:  [MOD] You have violin you have drum and you have cello. \n",
      "50.79938888549805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have violin you have drum and you have cello. \n",
      "token:  [S1] ok \n",
      "67.37857818603516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] ok \n",
      "4.219604969024658\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] I'd say violin \n",
      "16.81246566772461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'd say violin \n",
      "token:  [S2] ok \n",
      "19.907684326171875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] has to be number one. \n",
      "19.960437774658203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] has to be number one. \n",
      "token:  [S2] Yeah yeah probably drums is the last one. \n",
      "31.70400619506836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah yeah probably drums is the last one. \n",
      "token:  [S1] Yeah. \n",
      "6.095861911773682\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Yeah. \n",
      "3.7858242988586426\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] ok \n",
      "23.433319091796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] So it's violin, cello \n",
      "12.273980140686035\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So it's violin, cello \n",
      "token:  [S1] yeah \n",
      "18.124427795410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] and drums yeah? \n",
      "24.455318450927734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and drums yeah? \n",
      "token:  [MOD] That's correct. \n",
      "30.491910934448242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's correct. \n",
      "token:  [S2] Yeah? \n",
      "30.608755111694336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah? \n",
      "token:  [S1] yeah \n",
      "17.396099090576172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] ok \n",
      "8.381787300109863\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] Well done! Very good. So the last one. Name something that people cut. \n",
      "105.75687408447266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well done! Very good. So the last one. Name something that people cut. \n",
      "token:  [S2] Paper? \n",
      "67.87667083740234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Paper? \n",
      "token:  [MOD] Very good that's one. \n",
      "73.7145004272461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good that's one. \n",
      "token:  [S1] That's what a strange question. \n",
      "39.064849853515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] That's what a strange question. \n",
      "token:  [S2] yeah Wood maybe? \n",
      "120.86029815673828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah Wood maybe? \n",
      "token:  [S1] Wood yeah ah \n",
      "52.22823715209961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Wood yeah ah \n",
      "token:  [S2] ah \n",
      "20.45033836364746\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ah \n",
      "token:  [S1] Material? \n",
      "52.336639404296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Material? \n",
      "token:  [S2] Yeah like ah cloth? No? \n",
      "79.76007843017578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah like ah cloth? No? \n",
      "token:  [MOD] It's not wrong but it's not one of the most popular answers. \n",
      "15.319060325622559\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's not wrong but it's not one of the most popular answers. \n",
      "token:  [S2] ok \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.24162292480469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] Themselves? Not really but that \n",
      "75.0926513671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Themselves? Not really but that \n",
      "token:  [S2] Other people? \n",
      "11.308932304382324\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Other people? \n",
      "token:  [MOD] that's correct as well. Think about food maybe? \n",
      "109.5760269165039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] that's correct as well. Think about food maybe? \n",
      "token:  [S2] ok fruits yeah \n",
      "391.3316345214844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok fruits yeah \n",
      "token:  [S1] fruit yeah ve \n",
      "79.5289077758789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] fruit yeah ve \n",
      "token:  [S2] yeah \n",
      "15.785255432128906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] getables \n",
      "52.73711395263672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] getables \n",
      "token:  [S2] veg yeah \n",
      "44.202720642089844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] veg yeah \n",
      "token:  [MOD] what else \n",
      "112.00100708007812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] what else \n",
      "token:  [S1] meat \n",
      "78.97991180419922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat \n",
      "token:  [MOD] Meat that's good \n",
      "80.7798080444336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Meat that's good \n",
      "token:  [S1] ok \n",
      "50.12453842163086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] so you have \n",
      "78.07183074951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] so you have \n",
      "token:  [S2] Wow! \n",
      "65.66728210449219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Wow! \n",
      "token:  [MOD] two. \n",
      "165.45912170410156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] two. \n",
      "token:  [S1] Alright. \n",
      "35.91389083862305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright. \n",
      "token:  [MOD] One more answer. \n",
      "33.097267150878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] One more answer. \n",
      "token:  [S1] What was first one paper? \n",
      "90.60420989990234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] What was first one paper? \n",
      "token:  [MOD] Yeah. \n",
      "71.38575744628906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] yeah \n",
      "51.18270492553711\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] You have paper and meat so the last one \n",
      "299.3618469238281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have paper and meat so the last one \n",
      "token:  [S2] paper meat \n",
      "84.9211196899414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] paper meat \n",
      "token:  [MOD] What would men and women cut? It has to do with appearance. \n",
      "71.59915924072266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] What would men and women cut? It has to do with appearance. \n",
      "token:  [S2] appearance Wow. Ah! Their hair. \n",
      "183.44888305664062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] appearance Wow. Ah! Their hair. \n",
      "token:  [MOD] yeah \n",
      "219.24183654785156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] yeah \n",
      "token:  [S1] oh yeah \n",
      "21.677133560180664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh yeah \n",
      "token:  [MOD] perfect yeah \n",
      "168.94422912597656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] perfect yeah \n",
      "token:  [S1] of course \n",
      "25.594280242919922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] of course \n",
      "token:  [S2] ok \n",
      "9.44649600982666\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] so you found all three yeah \n",
      "150.62408447265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] so you found all three yeah \n",
      "token:  [S2] Now you can see I don't have this problem right? \n",
      "25.065065383911133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Now you can see I don't have this problem right? \n",
      "token:  [S1] yeah yeah \n",
      "17.813709259033203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah yeah \n",
      "token:  [MOD] And can you order those answers please. \n",
      "150.06324768066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And can you order those answers please. \n",
      "token:  [S2] I don't know maybe I'm biased but I would say that paper comes first becau just because it was the the first thing that \n",
      "52.962242126464844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know maybe I'm biased but I would say that paper comes first becau just because it was the the first thing that \n",
      "token:  [S1] it's \n",
      "21.334854125976562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] it's \n",
      "token:  [S2] hit my head. \n",
      "28.733951568603516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hit my head. \n",
      "token:  [S1] Yeah I think so as well. \n",
      "12.420655250549316\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah I think so as well. \n",
      "token:  [S2] yeah \n",
      "29.084341049194336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] And I'd say probably hair would be the next one don't you think? \n",
      "26.634973526000977\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] And I'd say probably hair would be the next one don't you think? \n",
      "token:  [S2] Yeah \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.937021255493164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [S1] even though it didn't come to my mind \n",
      "17.51299476623535\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] even though it didn't come to my mind \n",
      "token:  [S2] thst's a very good shot I think. \n",
      "33.93686294555664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] thst's a very good shot I think. \n",
      "token:  [S1] at all but \n",
      "44.20742416381836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] at all but \n",
      "token:  [S2] yeah \n",
      "31.5549373626709\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [S1] I think thinking about it now \n",
      "18.757736206054688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think thinking about it now \n",
      "token:  [S2] More than meat. Meat sounds ve \n",
      "191.62847900390625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] More than meat. Meat sounds ve \n",
      "token:  [S1] yeah \n",
      "47.802574157714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] ry random \n",
      "59.80693435668945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ry random \n",
      "token:  [S1] yeah \n",
      "17.481712341308594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] why not \n",
      "8.725725173950195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] why not \n",
      "token:  [S1] I never \n",
      "16.88385009765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I never \n",
      "token:  [S2] veg \n",
      "26.054492950439453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] veg \n",
      "token:  [S1] I'm vegetarian I \n",
      "27.869417190551758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I'm vegetarian I \n",
      "token:  [S2] or anything \n",
      "32.684783935546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] or anything \n",
      "token:  [S1] never cut meat \n",
      "94.03363800048828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] never cut meat \n",
      "token:  [S2] Yeah that's a good one. \n",
      "10.890741348266602\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah that's a good one. \n",
      "token:  [MOD] So what do you think? \n",
      "12.742602348327637\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So what do you think? \n",
      "token:  [S2] So it's paper \n",
      "116.8924560546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So it's paper \n",
      "token:  [S1] Pa \n",
      "51.75016403198242\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Pa \n",
      "token:  [S2] hair \n",
      "66.36886596679688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair \n",
      "token:  [S1] per hair and meat? \n",
      "102.80313110351562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] per hair and meat? \n",
      "token:  [S2] and meat? \n",
      "6.629024505615234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and meat? \n",
      "token:  [MOD] You're almost there guys al most there \n",
      "401.8070983886719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You're almost there guys al most there \n",
      "token:  [S2] ok \n",
      "75.7730484008789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] hair is the first one hair \n",
      "271.6913757324219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hair is the first one hair \n",
      "token:  [S1] alright \n",
      "91.76140594482422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] alright \n",
      "token:  [MOD] paper and then meat. \n",
      "351.9270324707031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] paper and then meat. \n",
      "token:  [S1] ok \n",
      "94.6804428100586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] hm \n",
      "8.952146530151367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hm \n",
      "token:  [MOD] So well done! And thanks for \n",
      "114.88014221191406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So well done! And thanks for \n",
      "token:  [S2] ok \n",
      "211.0800018310547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] coming, I hope you enjoyed it that was it. \n",
      "65.03219604492188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] coming, I hope you enjoyed it that was it. \n",
      "token:  [S1] ok\n",
      "42.61442184448242\n",
      "MOD : 147.00504769545336\n",
      "S1 : 52.20516790740791\n",
      "S2 : 54.22759817367376\n",
      "speech transcription_Transcriber/S09.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Ok \n",
      "493.3454284667969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok \n",
      "token:  [S2] Yeah so \n",
      "77.00619506835938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah so \n",
      "token:  [MOD] So I would like us to pay play a quiz. Right? \n",
      "99.15553283691406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So I would like us to pay play a quiz. Right? \n",
      "token:  [S2] ok. \n",
      "40.368499755859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] So I would like to ask you three questions that were posed to a group of one hundred people. \n",
      "18.972888946533203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So I would like to ask you three questions that were posed to a group of one hundred people. \n",
      "token:  [S2] mhmm \n",
      "87.38719940185547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] And I would like you to guess, talk to each other and guess the three most popular answers to these questions. And then I will ask you to decide on the ranking. Ok do you in terms of popularity. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.641937255859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And I would like you to guess, talk to each other and guess the three most popular answers to these questions. And then I will ask you to decide on the ranking. Ok do you in terms of popularity. \n",
      "token:  [S2] Ok. \n",
      "19.458816528320312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] So for example like if I ask you name what are the main ways in which you can transfer patients in hospital. You would say something like you know a wheelchair, an ambulance, a patient's bed and then I will ask you to talk to each other and decide upon a ranking. O \n",
      "41.115989685058594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So for example like if I ask you name what are the main ways in which you can transfer patients in hospital. You would say something like you know a wheelchair, an ambulance, a patient's bed and then I will ask you to talk to each other and decide upon a ranking. O \n",
      "token:  [S1] Ok. \n",
      "36.49165344238281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] k? Is that clear? Yeah. \n",
      "62.769371032714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] k? Is that clear? Yeah. \n",
      "token:  [S2] Ok. \n",
      "21.046968460083008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] \n",
      "64.58123779296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [Do you have any ques] tions? \n",
      "143.3277130126953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [Do you have any ques] tions? \n",
      "token:  [S2] Yeah. \n",
      "5.858343601226807\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Nope? N ok? \n",
      "227.1375274658203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Nope? N ok? \n",
      "token:  [S2] o. I suppose no it's \n",
      "135.4679718017578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] o. I suppose no it's \n",
      "token:  [MOD] Alright? \n",
      "193.8411102294922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Alright? \n",
      "token:  [S2] ok yeah thanks. \n",
      "67.47677612304688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok yeah thanks. \n",
      "token:  [MOD] So if you're ready for the first question I would like you to name public places where you would be more likely to get the cold or a flu bug. \n",
      "27.377185821533203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So if you're ready for the first question I would like you to name public places where you would be more likely to get the cold or a flu bug. \n",
      "token:  [S2] Ok. \n",
      "27.222673416137695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] Ok. \n",
      "5.393057346343994\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] Right \n",
      "25.89518928527832\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Right \n",
      "token:  [S1] So I imagine I was just thinking \n",
      "33.996524810791016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So I imagine I was just thinking \n",
      "token:  [S2] where we're sitting like in a university or something like The univ \n",
      "56.502079010009766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] where we're sitting like in a university or something like The univ \n",
      "token:  [S1] that. ersity somewhere where it's always like in colder places as well. \n",
      "63.15717697143555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] that. ersity somewhere where it's always like in colder places as well. \n",
      "token:  [S2] Yeah. \n",
      "6.01080846786499\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] But high concentration of pe ople. \n",
      "63.92841720581055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But high concentration of pe ople. \n",
      "token:  [S2] Exactly. \n",
      "7.650209903717041\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Exactly. \n",
      "token:  [S1] Schools. \n",
      "47.52915954589844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Schools. \n",
      "token:  [S2] Schools. Yeah. \n",
      "3.563807964324951\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Schools. Yeah. \n",
      "token:  [MOD] Excellent. \n",
      "68.2806625366211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent. \n",
      "token:  [S2] Airports. \n",
      "66.21833801269531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Airports. \n",
      "token:  [MOD] You got the one. \n",
      "41.852203369140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You got the one. \n",
      "token:  [S2] Airplanes. \n",
      "63.59588623046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Airplanes. \n",
      "token:  [MOD] mhmm \n",
      "113.65479278564453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm \n",
      "token:  [S1] hmm I don't know if you get these much in the west. But indoor sort of ski things. \n",
      "73.01397705078125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm I don't know if you get these much in the west. But indoor sort of ski things. \n",
      "token:  [S2] \n",
      "8.573884963989258\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] Or like indoor sort of kind of like sports venues. \n",
      "122.33453369140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Or like indoor sort of kind of like sports venues. \n",
      "token:  [S2] I know what you mean we don't have a lot of indoor ski \n",
      "18.24154281616211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I know what you mean we don't have a lot of indoor ski \n",
      "token:  [S1] Because they have it like in \n",
      "38.795860290527344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Because they have it like in \n",
      "token:  [S2] in Ireland but \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.46831512451172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] in Ireland but \n",
      "token:  [S1] America and in sort of the Middle East \n",
      "39.20700454711914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] America and in sort of the Middle East \n",
      "token:  [S2] Yeah yeah. \n",
      "11.504698753356934\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah yeah. \n",
      "token:  [S1] but I don't know if \n",
      "19.115339279174805\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but I don't know if \n",
      "token:  [S2] Yeah. \n",
      "13.915897369384766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] that wouldn't be an answer. \n",
      "21.115631103515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] that wouldn't be an answer. \n",
      "token:  [S2] I can imagine. \n",
      "8.95626449584961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I can imagine. \n",
      "token:  [S1] Just because a lot of things could get caught in the snow. Anyway \n",
      "43.48493957519531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Just because a lot of things could get caught in the snow. Anyway \n",
      "token:  [S2] Ye ah . \n",
      "42.81584930419922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ye ah . \n",
      "token:  [S1] I just thought about the concentration of people so. \n",
      "2.3739421367645264\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I just thought about the concentration of people so. \n",
      "token:  [MOD] Keep guess ing. \n",
      "178.64283752441406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Keep guess ing. \n",
      "token:  [S2] Well at school well like maybe doctor's surgeries and hospitals \n",
      "478.41375732421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Well at school well like maybe doctor's surgeries and hospitals \n",
      "token:  [S1] Must \n",
      "66.96580505371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Must \n",
      "token:  [S2] probably. \n",
      "11.21799373626709\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] probably. \n",
      "token:  [S1] be hospitals. \n",
      "6.1163554191589355\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] be hospitals. \n",
      "token:  [MOD] hmm that's the second one. \n",
      "38.72272491455078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm that's the second one. \n",
      "token:  [S2] ok. \n",
      "28.28990936279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] Yes very good hospit \n",
      "496.0013732910156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes very good hospit \n",
      "token:  [S2] And \n",
      "58.19322204589844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] And \n",
      "token:  [MOD] als. \n",
      "154.04345703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] als. \n",
      "token:  [S1] So where is \n",
      "67.9183120727539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So where is \n",
      "token:  [S2] Airports and airplanes really no I always thought air \n",
      "2.399977684020996\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Airports and airplanes really no I always thought air \n",
      "token:  [MOD] Ex \n",
      "602.8092651367188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ex \n",
      "token:  [S2] ports would \n",
      "605.2531127929688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ports would \n",
      "token:  [MOD] cellent. \n",
      "349.2740783691406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] cellent. \n",
      "token:  [S1] Ah. \n",
      "53.37519454956055\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ah. \n",
      "token:  [S2] o \n",
      "7.876623153686523\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] o \n",
      "token:  [MOD] Air \n",
      "491.86444091796875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Air \n",
      "token:  [S2] k. \n",
      "90.6511001586914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] k. \n",
      "token:  [MOD] planes So you've got the three. \n",
      "228.3386993408203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] planes So you've got the three. \n",
      "token:  [S1] Great. \n",
      "36.83350372314453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Great. \n",
      "token:  [MOD] So I would like you now to decide about you know about the ranking what were \n",
      "157.74215698242188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So I would like you now to decide about you know about the ranking what were \n",
      "token:  [S1] What would the hundred people say first? \n",
      "60.11928176879883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] What would the hundred people say first? \n",
      "token:  [MOD] Yeah. Yeah. \n",
      "55.05636978149414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. Yeah. \n",
      "token:  [S2] It's like a game of family fortunes. ok. \n",
      "59.1218376159668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It's like a game of family fortunes. ok. \n",
      "token:  [S1] Yeah . \n",
      "6.657623767852783\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah . \n",
      "token:  [MOD] Which one was \n",
      "92.88932800292969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Which one was \n",
      "token:  [S2] What do you think? \n",
      "26.430709838867188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] What do you think? \n",
      "token:  [MOD] the most popular answer? \n",
      "69.12359619140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the most popular answer? \n",
      "token:  [S1] I might \n",
      "55.0089225769043\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I might \n",
      "token:  [S2] I'd say Go on . \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.54998779296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'd say Go on . \n",
      "token:  [S1] I was only going to say hospital number one purely because it's like highest concentration of \n",
      "67.76222229003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I was only going to say hospital number one purely because it's like highest concentration of \n",
      "token:  [S2] Of really sick people \n",
      "51.99968719482422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Of really sick people \n",
      "token:  [S1] Yeah. \n",
      "11.451578140258789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] maybe yeah yeah. \n",
      "28.679731369018555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] maybe yeah yeah. \n",
      "token:  [S1] But then schools or hospital s? \n",
      "130.52476501464844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But then schools or hospital s? \n",
      "token:  [S2] I'd say schools just because young children just tends to be lots of runny noses and things around and \n",
      "42.894935607910156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'd say schools just because young children just tends to be lots of runny noses and things around and \n",
      "token:  [S1] Less hygie ne. \n",
      "198.80018615722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Less hygie ne. \n",
      "token:  [S2] Yeah. Teachers are sick a lot. And then maybe airports Airplanes \n",
      "173.09449768066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. Teachers are sick a lot. And then maybe airports Airplanes \n",
      "token:  [S1] ports yeah. \n",
      "83.24556732177734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ports yeah. \n",
      "token:  [S2] after the number three? \n",
      "30.76687240600586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] after the number three? \n",
      "token:  [S1] I think that would make sense. \n",
      "8.936843872070312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think that would make sense. \n",
      "token:  [S2] I'm happy with it. \n",
      "7.954601287841797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'm happy with it. \n",
      "token:  [S1] Schools first. \n",
      "74.39435577392578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Schools first. \n",
      "token:  [S2] Or no didn't you say ehm \n",
      "88.04861450195312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Or no didn't you say ehm \n",
      "token:  [S1] say hospitals \n",
      "127.71815490722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] say hospitals \n",
      "token:  [S2] hospitals doctors \n",
      "12.754727363586426\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hospitals doctors \n",
      "token:  [S1] but what do you think? \n",
      "8.483756065368652\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] but what do you think? \n",
      "token:  [S2] Surgeries first schools secon \n",
      "446.56243896484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Surgeries first schools secon \n",
      "token:  [S1] Would you agree with that? \n",
      "11.761751174926758\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Would you agree with that? \n",
      "token:  [S2] d. Yeah. \n",
      "35.38676834106445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] d. Yeah. \n",
      "token:  [S1] Yeah. Hospitals, schools, airplane \n",
      "2.659930467605591\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. Hospitals, schools, airplane \n",
      "token:  [MOD] So is that the fi \n",
      "148.4712677001953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So is that the fi \n",
      "token:  [S1] airports. \n",
      "373.83209228515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] airports. \n",
      "token:  [MOD] nal ranking? \n",
      "315.2621765136719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] nal ranking? \n",
      "token:  [S2] Yeah. \n",
      "56.87800979614258\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Hos pitals, schools, airplanes? \n",
      "683.1860961914062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Hos pitals, schools, airplanes? \n",
      "token:  [S2] Yeah. \n",
      "30.195138931274414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] I am sorry but you didn't get the first two right. \n",
      "19.724472045898438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I am sorry but you didn't get the first two right. \n",
      "token:  [S2] Oh we didn't win the prize. Oh no! \n",
      "31.101850509643555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh we didn't win the prize. Oh no! \n",
      "token:  [S1] Tell the \n",
      "3.805112600326538\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Tell the \n",
      "token:  [MOD] School is number one \n",
      "525.5971069335938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] School is number one \n",
      "token:  [S2] Is it? \n",
      "27.004650115966797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Is it? \n",
      "token:  [S1] Yeah. \n",
      "12.486665725708008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] ok. \n",
      "5.913229942321777\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] \n",
      "72.43285369873047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [Hospital's] number two and then airplane you got that \n",
      "864.8017578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [Hospital's] number two and then airplane you got that \n",
      "token:  [S2] ok. \n",
      "54.25323486328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] right. It's \n",
      "73.30278015136719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] right. It's \n",
      "token:  [S1] Fair enough. \n",
      "57.439109802246094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Fair enough. \n",
      "token:  [MOD] the third one. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.2241439819336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the third one. \n",
      "token:  [S2] Done well. \n",
      "84.26263427734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Done well. \n",
      "token:  [MOD] Alright? Very good. Are you ready for the second question? \n",
      "24.13138198852539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Alright? Very good. Are you ready for the second question? \n",
      "token:  [S2] mhmm \n",
      "34.60340881347656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [S1] Sure. \n",
      "25.151094436645508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Sure. \n",
      "token:  [MOD] I would like you to nu nu now think about musical instruments in a symphony orchestra. \n",
      "107.62544250488281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I would like you to nu nu now think about musical instruments in a symphony orchestra. \n",
      "token:  [S1] Ok. \n",
      "19.83531951904297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] Ok. \n",
      "3.2591793537139893\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] Oh the most popular \n",
      "60.63938903808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh the most popular \n",
      "token:  [MOD] Yeah. \n",
      "114.64193725585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] Most popular \n",
      "178.20962524414062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Most popular \n",
      "token:  [MOD] Answers. \n",
      "316.5505676269531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Answers. \n",
      "token:  [S2] or \n",
      "79.38694763183594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] or \n",
      "token:  [MOD] so \n",
      "183.26422119140625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] so \n",
      "token:  [S2] Most pop \n",
      "357.2206115722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Most pop \n",
      "token:  [MOD] Yes. \n",
      "169.49903869628906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes. \n",
      "token:  [S2] ular okay. I would say probably \n",
      "218.59408569335938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ular okay. I would say probably \n",
      "token:  [S1] Violin. \n",
      "3.636524200439453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin. \n",
      "token:  [S2] violin. Yeah. hmm \n",
      "36.04710388183594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] violin. Yeah. hmm \n",
      "token:  [MOD] Would \n",
      "268.22210693359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Would \n",
      "token:  [S2] be number one. \n",
      "47.95113754272461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] be number one. \n",
      "token:  [MOD] Very good yes. \n",
      "78.24829864501953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good yes. \n",
      "token:  [S1] \n",
      "26.13279914855957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [S2] Cello? \n",
      "62.57649230957031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cello? \n",
      "token:  [MOD] That's correct. Well done. \n",
      "28.328821182250977\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's correct. Well done. \n",
      "token:  [S1] Wow! and \n",
      "64.92715454101562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Wow! and \n",
      "token:  [S2] A nd \n",
      "16.34105682373047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A nd \n",
      "token:  [S1] Drums. \n",
      "5.34011697769165\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Drums. \n",
      "token:  [S2] Flute? \n",
      "17.500226974487305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Flute? \n",
      "token:  [MOD] Ah very good. You're \n",
      "113.81185913085938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ah very good. You're \n",
      "token:  [S2] ok. \n",
      "70.01591491699219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] very \n",
      "244.7122344970703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] very \n",
      "token:  [S2] Very good. \n",
      "40.2586784362793\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Very good. \n",
      "token:  [MOD] good, very fast. \n",
      "53.137935638427734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] good, very fast. \n",
      "token:  [S1] \n",
      "27.86189079284668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] So what would be your ranking then? \n",
      "53.8141975402832\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So what would be your ranking then? \n",
      "token:  [S1] Violin first yeah. \n",
      "164.13307189941406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violin first yeah. \n",
      "token:  [S2] I'd say violin number one. Cello maybe number two? \n",
      "32.08811950683594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'd say violin number one. Cello maybe number two? \n",
      "token:  [S1] Yeah I wouldn't know between cello or drums. That was a shot in the dark from me so I think yeah. \n",
      "28.667980194091797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah I wouldn't know between cello or drums. That was a shot in the dark from me so I think yeah. \n",
      "token:  [S2] Drums. Three. \n",
      "4.19528341293335\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Drums. Three. \n",
      "token:  [S1] Yeah. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.792369842529297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Is \n",
      "174.774658203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Is \n",
      "token:  [S2] Yeah. \n",
      "135.5219268798828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] that your final yeah? \n",
      "334.037109375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] that your final yeah? \n",
      "token:  [S2] mhmm \n",
      "43.54074478149414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] Well done. Yes. \n",
      "66.63380432128906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well done. Yes. \n",
      "token:  [S1] Good stuff. \n",
      "20.97705841064453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Good stuff. \n",
      "token:  [S2] Nice \n",
      "21.207590103149414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Nice \n",
      "token:  [MOD] You're right violin, \n",
      "177.31985473632812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You're right violin, \n",
      "token:  [S2] one yeah. \n",
      "208.47396850585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] one yeah. \n",
      "token:  [MOD] cello and the drum. \n",
      "144.50131225585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] cello and the drum. \n",
      "token:  [S2] ok. \n",
      "54.16801834106445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [S1] Brilliant. \n",
      "25.21376609802246\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Brilliant. \n",
      "token:  [MOD] Very good. Let's see if you can guess n the third one. I would like you to name things that people cut. \n",
      "49.09759521484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good. Let's see if you can guess n the third one. I would like you to name things that people cut. \n",
      "token:  [S2] Things that people cut? \n",
      "12.431536674499512\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Things that people cut? \n",
      "token:  [MOD] Yeah. \n",
      "49.501243591308594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S2] ok. Like with a scissors or a knife or something? \n",
      "42.930809020996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. Like with a scissors or a knife or something? \n",
      "token:  [MOD] Things that \n",
      "207.37969970703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Things that \n",
      "token:  [S2] Ok. \n",
      "65.71805572509766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] people cut. \n",
      "295.16790771484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] people cut. \n",
      "token:  [S2] Ok. \n",
      "37.20188903808594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] Food? Is that an answer that Within \n",
      "168.70230102539062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Food? Is that an answer that Within \n",
      "token:  [MOD] would suffice? that category would you be more specific? \n",
      "167.82589721679688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] would suffice? that category would you be more specific? \n",
      "token:  [S1] oh ok. \n",
      "38.84355926513672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh ok. \n",
      "token:  [S2] \n",
      "7.750581741333008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] Bread. \n",
      "27.816741943359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Bread. \n",
      "token:  [S2] Bread \n",
      "11.575167655944824\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Bread \n",
      "token:  [S1] Bread. \n",
      "7.111280918121338\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Bread. \n",
      "token:  [S2] exactly yeah that's a good one. \n",
      "25.068124771118164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] exactly yeah that's a good one. \n",
      "token:  [S1] But then I don't know or I was just thinking vegetables in my head. \n",
      "27.775230407714844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But then I don't know or I was just thinking vegetables in my head. \n",
      "token:  [S2] Yeah. Would you say cut or slice I mean \n",
      "39.07758712768555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. Would you say cut or slice I mean \n",
      "token:  [S1] hmm \n",
      "6.089458465576172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] is is it specific to the word? Definitely bread or meat would you cut meat? \n",
      "146.2911834716797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] is is it specific to the word? Definitely bread or meat would you cut meat? \n",
      "token:  [MOD] Excell ent that's it. \n",
      "182.99771118164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excell ent that's it. \n",
      "token:  [S2] ok. \n",
      "35.87043380737305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [MOD] Meat. Yep. \n",
      "176.66087341308594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Meat. Yep. \n",
      "token:  [S2] Cut paper? \n",
      "127.31221771240234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cut paper? \n",
      "token:  [MOD] Very good. \n",
      "39.29994583129883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Very good. \n",
      "token:  [S1] Yeah. \n",
      "23.19879722595215\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [MOD] Yes that's another one. \n",
      "33.19758605957031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes that's another one. \n",
      "token:  [S1] That's what I was thinking. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.058094024658203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] That's what I was thinking. \n",
      "token:  [S2] Cut \n",
      "81.6461181640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cut \n",
      "token:  [S1] Hair. \n",
      "7.019855499267578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hair. \n",
      "token:  [S2] hmm \n",
      "25.270599365234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hmm \n",
      "token:  [MOD] Excellent. \n",
      "105.17472076416016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent. \n",
      "token:  [S2] Hair. \n",
      "105.3193588256836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair. \n",
      "token:  [MOD] Well done. You're very fast. So what do you think about the most popular answer which was it? \n",
      "32.17197799682617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well done. You're very fast. So what do you think about the most popular answer which was it? \n",
      "token:  [S1] I straight away thought food but \n",
      "137.0646209716797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I straight away thought food but \n",
      "token:  [S2] ok. \n",
      "12.505569458007812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [S1] that might be because I'm hungry. \n",
      "14.746136665344238\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] that might be because I'm hungry. \n",
      "token:  [S2] \n",
      "9.797158241271973\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] So I don't know because hair seems like the kind of answer Go for it then. that people would give straight away. I don't know. \n",
      "49.62651824951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So I don't know because hair seems like the kind of answer Go for it then. that people would give straight away. I don't know. \n",
      "token:  [S2] Yeah. \n",
      "4.797210216522217\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Or paper is ah \n",
      "272.28302001953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Or paper is ah \n",
      "token:  [MOD] hmm \n",
      "120.02244567871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] pa I I've I've no idea about the ranking. \n",
      "160.8011932373047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] pa I I've I've no idea about the ranking. \n",
      "token:  [S1] If pe \n",
      "105.48113250732422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] If pe \n",
      "token:  [S2] I \n",
      "18.964372634887695\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I \n",
      "token:  [S1] ople asked \n",
      "139.36070251464844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ople asked \n",
      "token:  [S2] If people were asked \n",
      "19.76490592956543\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] If people were asked \n",
      "token:  [S1] I think \n",
      "16.908203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think \n",
      "token:  [S2] I'd say maybe paper. \n",
      "28.527076721191406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'd say maybe paper. \n",
      "token:  [S1] Yeah. \n",
      "6.015420436859131\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Although \n",
      "37.730384826660156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Although \n",
      "token:  [S1] Pape \n",
      "85.23130798339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Pape \n",
      "token:  [S2] Yeah I don't know. ha meat. \n",
      "33.042137145996094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah I don't know. ha meat. \n",
      "token:  [S1] I think meat would \n",
      "35.67250061035156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I think meat would \n",
      "token:  [S2] Meat. \n",
      "7.750670433044434\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Meat. \n",
      "token:  [S1] maybe come last because \n",
      "162.25900268554688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] maybe come last because \n",
      "token:  [S2] Do you think? \n",
      "15.817788124084473\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Do you think? \n",
      "token:  [S1] It's quite specific food \n",
      "102.57050323486328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] It's quite specific food \n",
      "token:  [S2] Yeah. \n",
      "4.587976932525635\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] so people maybe \n",
      "126.05659484863281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so people maybe \n",
      "token:  [S2] I'm surprised \n",
      "13.488097190856934\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I'm surprised \n",
      "token:  [S1] would say food. \n",
      "38.38232421875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] would say food. \n",
      "token:  [S2] bread isn't on it. Ok well then paper, hair, meat? \n",
      "1.8690470457077026\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] bread isn't on it. Ok well then paper, hair, meat? \n",
      "token:  [S1] Yeah. I think that might be it. \n",
      "11.699546813964844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. I think that might be it. \n",
      "token:  [MOD] Yes? \n",
      "26.424705505371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes? \n",
      "token:  [S2] mhmm No we're wrong. Meat \n",
      "214.0740509033203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm No we're wrong. Meat \n",
      "token:  [MOD] It's cu ah hair first. \n",
      "497.9224853515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It's cu ah hair first. \n",
      "token:  [S2] Hair first wow. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.392539978027344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hair first wow. \n",
      "token:  [S1] Hair okay yeah. \n",
      "23.68105125427246\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Hair okay yeah. \n",
      "token:  [MOD] Paper number two. and meat \n",
      "487.3353271484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Paper number two. and meat \n",
      "token:  [S2] ok. \n",
      "76.29716491699219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok. \n",
      "token:  [S1] Awh that's right ok. \n",
      "33.2845573425293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Awh that's right ok. \n",
      "token:  [MOD] you're right number three. Yep. So that is the end of the quiz. \n",
      "33.547332763671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you're right number three. Yep. So that is the end of the quiz. \n",
      "token:  [S2] Ok! \n",
      "49.99214553833008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok! \n",
      "token:  [MOD] I hope you enjoyed it. Thank you ve Learnt ry much. \n",
      "146.38426208496094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I hope you enjoyed it. Thank you ve Learnt ry much. \n",
      "token:  [S2] a lot thank you. \n",
      "23.15398406982422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] a lot thank you. \n",
      "token:  [S1] No worries.\n",
      "10.307855606079102\n",
      "MOD : 99.47216079340262\n",
      "S1 : 92.5205659247064\n",
      "S2 : 93.35962693507855\n",
      "speech transcription_Transcriber/S02.trs\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  \n",
      "token:  [MOD] Ok so thanks for coming today. we're going to play a quiz. I would n \n",
      "84.2066879272461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok so thanks for coming today. we're going to play a quiz. I would n \n",
      "token:  [S1] Ok. \n",
      "58.35975646972656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] I'm going to ask you three questions and I would li \n",
      "48.7896614074707\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'm going to ask you three questions and I would li \n",
      "token:  [S2] mhmm \n",
      "89.95590209960938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] ke you to to that were posed to group of one hundred pend one hundred people and then I would like you to guess the three most popular answers to these questions. \n",
      "107.37913513183594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ke you to to that were posed to group of one hundred pend one hundred people and then I would like you to guess the three most popular answers to these questions. \n",
      "token:  [S2] Ok \n",
      "68.4853744506836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok \n",
      "token:  [MOD] and then we'll ask you to identify the ranking in terms of popularity. For example if I ask you what is normally used to to transport patients in a hospital you could say th things like ambulance, a wheelchair right? A patient's bed so is that is that clear? Do you have any ques \n",
      "53.10919952392578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and then we'll ask you to identify the ranking in terms of popularity. For example if I ask you what is normally used to to transport patients in a hospital you could say th things like ambulance, a wheelchair right? A patient's bed so is that is that clear? Do you have any ques \n",
      "token:  [S1] Ok \n",
      "154.08041381835938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok \n",
      "token:  [MOD] tions? Nope? Ok. Are you ready for the first question? \n",
      "58.12718963623047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] tions? Nope? Ok. Are you ready for the first question? \n",
      "token:  [S2] mhmm \n",
      "52.7253303527832\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] I have yeah I have to point out that you really need to talk to each other before you make your final decisions so you nee \n",
      "41.99323272705078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I have yeah I have to point out that you really need to talk to each other before you make your final decisions so you nee \n",
      "token:  [S1] Ok. \n",
      "50.033626556396484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [MOD] d to have a discussion, ok? \n",
      "63.86766052246094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] d to have a discussion, ok? \n",
      "token:  [S1] Right. \n",
      "25.15387725830078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Right. \n",
      "token:  [MOD] Right. So the first question i s where in which public place would you be more likely to catch a cold or a flu bug. \n",
      "49.31631088256836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Right. So the first question i s where in which public place would you be more likely to catch a cold or a flu bug. \n",
      "token:  [S2] A flu bag? \n",
      "72.11077880859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] A flu bag? \n",
      "token:  [MOD] A flu bug Sorry I'm not pronouncing \n",
      "118.26216888427734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] A flu bug Sorry I'm not pronouncing \n",
      "token:  [S2] Oh bug ok. \n",
      "243.90992736816406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh bug ok. \n",
      "token:  [MOD] Bug \n",
      "185.3141632080078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Bug \n",
      "token:  [S2] Sorry . \n",
      "108.01361083984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Sorry . \n",
      "token:  [MOD] sorry. \n",
      "72.07498931884766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] sorry. \n",
      "token:  [S1] Which pu \n",
      "284.8739318847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Which pu \n",
      "token:  [S2] Hm. \n",
      "28.67241668701172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Hm. \n",
      "token:  [MOD] Ex \n",
      "798.2970581054688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ex \n",
      "token:  [S1] blic place \n",
      "300.1093444824219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] blic place \n",
      "token:  [MOD] Yes. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.24102783203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes. \n",
      "token:  [S2] ok Ok. \n",
      "49.26698684692383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok Ok. \n",
      "token:  [S1] A doct \n",
      "153.27325439453125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] A doct \n",
      "token:  [S2] So \n",
      "18.493436813354492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So \n",
      "token:  [S1] or's waiting room is that public? \n",
      "88.025146484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] or's waiting room is that public? \n",
      "token:  [S2] I guess it is yeah so that makes sense somewhere where there's just a lot of people and possibly outdoors so something like a park. \n",
      "37.624107360839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I guess it is yeah so that makes sense somewhere where there's just a lot of people and possibly outdoors so something like a park. \n",
      "token:  [S1] Yeah. \n",
      "5.488751411437988\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] So \n",
      "22.051132202148438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] So \n",
      "token:  [S1] Or a public school would they count? Are they kind of indoors? \n",
      "118.27057647705078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Or a public school would they count? Are they kind of indoors? \n",
      "token:  [S2] Yeah actually I think a school would be better again it's real yeah close together and stuff. \n",
      "49.72555160522461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah actually I think a school would be better again it's real yeah close together and stuff. \n",
      "token:  [S1] Good. \n",
      "9.480350494384766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Good. \n",
      "token:  [S2] and I'm just thinking I've a friend who got sick lately after working in a restaurant but I don't think people generally get sick in restaurants. \n",
      "27.074119567871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] and I'm just thinking I've a friend who got sick lately after working in a restaurant but I don't think people generally get sick in restaurants. \n",
      "token:  [S1] Well Depends on the kind of restaurant \n",
      "20.785036087036133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Well Depends on the kind of restaurant \n",
      "token:  [S2] Yeah. \n",
      "6.697269439697266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Yeah that's kinda tricky how you should it \n",
      "77.63911437988281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah that's kinda tricky how you should it \n",
      "token:  [S2] Yeah \n",
      "9.724550247192383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [S1] As is is there are there any parameters going from it like does it have to be an open public pla ce or \n",
      "81.54985809326172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] As is is there are there any parameters going from it like does it have to be an open public pla ce or \n",
      "token:  [MOD] Not really. \n",
      "87.72968292236328\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Not really. \n",
      "token:  [S2] Ok. \n",
      "28.411104202270508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] Ok. \n",
      "4.544778823852539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. \n",
      "token:  [S2] what like \n",
      "53.203208923339844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] what like \n",
      "token:  [S1] Maybe \n",
      "19.405561447143555\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Maybe \n",
      "token:  [S2] a swimming pool be a weird answer or would it make sense? \n",
      "78.34283447265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] a swimming pool be a weird answer or would it make sense? \n",
      "token:  [S1] Would that make infections and things like that for the m like \n",
      "112.20765686035156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Would that make infections and things like that for the m like \n",
      "token:  [S2] Yeah \n",
      "21.84961700439453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [S1] funguses and toe things and Awful stuff like that. \n",
      "99.72662353515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] funguses and toe things and Awful stuff like that. \n",
      "token:  [S2] Yeah exactly. \n",
      "10.933134078979492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah exactly. \n",
      "token:  [S1] Yeah that was tricky. I I'd say school because everyone is always getting sick at school. \n",
      "39.76176834106445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah that was tricky. I I'd say school because everyone is always getting sick at school. \n",
      "token:  [S2] Yeah. \n",
      "5.816749572753906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Or anywhere you're working in close proximity to someone. \n",
      "27.85481071472168\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Or anywhere you're working in close proximity to someone. \n",
      "token:  [S2] Yeah. \n",
      "6.64361047744751\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] But \n",
      "19.09248924255371\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] But \n",
      "token:  [S2] Me too though I think the doctor's waiting room is a pretty good one and then a school and then \n",
      "46.25077819824219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Me too though I think the doctor's waiting room is a pretty good one and then a school and then \n",
      "token:  [S1] Ah yeah \n",
      "24.205108642578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ah yeah \n",
      "token:  [S2] like a a bus like public transport. \n",
      "77.37747955322266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] like a a bus like public transport. \n",
      "token:  [S1] Awh yeah Sorry I I just touched a bus on the way here and it was so slimy it was gross yeah \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.333740234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Awh yeah Sorry I I just touched a bus on the way here and it was so slimy it was gross yeah \n",
      "token:  [S2] Gross \n",
      "28.773639678955078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Gross \n",
      "token:  [S1] So a bus would be a good one. \n",
      "23.1760196685791\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So a bus would be a good one. \n",
      "token:  [S2] Yeah. \n",
      "5.92560338973999\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Alright. \n",
      "6.487790584564209\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright. \n",
      "token:  [S2] Ok we say that that's a good three fair enough in that case? \n",
      "64.26762390136719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok we say that that's a good three fair enough in that case? \n",
      "token:  [S1] ok which is the most popular though? \n",
      "24.799625396728516\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok which is the most popular though? \n",
      "token:  [S2] I think \n",
      "10.49185562133789\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think \n",
      "token:  [MOD] Before you can I \n",
      "241.15267944335938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Before you can I \n",
      "token:  [S1] Oh \n",
      "46.67854309082031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh \n",
      "token:  [MOD] give you my feedback? Before \n",
      "251.95611572265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] give you my feedback? Before \n",
      "token:  [S1] Yes \n",
      "66.50157165527344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yes \n",
      "token:  [MOD] you decide \n",
      "136.00473022460938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you decide \n",
      "token:  [S1] absolutely \n",
      "64.54826354980469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] absolutely \n",
      "token:  [MOD] do you know about the ranking very good you have the two right? So it's the school \n",
      "123.8703384399414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] do you know about the ranking very good you have the two right? So it's the school \n",
      "token:  [S1] ok \n",
      "59.92123031616211\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] mhmm \n",
      "10.007641792297363\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] mhmm \n",
      "token:  [MOD] and then it's the next one you mentioned the doctor's waiting room can you mention something similar? \n",
      "106.5153579711914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and then it's the next one you mentioned the doctor's waiting room can you mention something similar? \n",
      "token:  [S1] Like a hospital waiting room \n",
      "28.472261428833008\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Like a hospital waiting room \n",
      "token:  [MOD] Exactly. Great. \n",
      "90.76875305175781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly. Great. \n",
      "token:  [S2] Ok. \n",
      "23.871463775634766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] So a hospital is the second one and \n",
      "186.0286407470703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So a hospital is the second one and \n",
      "token:  [S2] ok \n",
      "215.68539428710938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] the third one again well done it's a means of trans port but it's not the b b the bus it's a different mean \n",
      "148.46243286132812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the third one again well done it's a means of trans port but it's not the b b the bus it's a different mean \n",
      "token:  [S1] hmm \n",
      "35.59797668457031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [MOD] s of transport \n",
      "369.7102966308594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] s of transport \n",
      "token:  [S2] Is it Is it still public transport? \n",
      "82.22423553466797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Is it Is it still public transport? \n",
      "token:  [MOD] We ll it's a means of transportation yes it i righ it is I suppose. \n",
      "102.85834503173828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] We ll it's a means of transportation yes it i righ it is I suppose. \n",
      "token:  [S2] Ok. \n",
      "26.833499908447266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] \n",
      "64.58123779296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] \n",
      "token:  [S2] Are these people asked in Ireland or exactly would it be the luas or would it be New Yorkers saying the subway or something you know \n",
      "158.53973388671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Are these people asked in Ireland or exactly would it be the luas or would it be New Yorkers saying the subway or something you know \n",
      "token:  [MOD] No it's not the subway. \n",
      "27.151121139526367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No it's not the subway. \n",
      "token:  [S2] ok The \n",
      "199.35923767089844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok The \n",
      "token:  [S1] I don't know I think it's like the bus the luas the dart \n",
      "42.03066635131836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't know I think it's like the bus the luas the dart \n",
      "token:  [S2] Yeah the train \n",
      "12.76828670501709\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah the train \n",
      "token:  [MOD] You're ge \n",
      "165.5253143310547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You're ge \n",
      "token:  [S1] the luas \n",
      "126.24554443359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] the luas \n",
      "token:  [MOD] tting there you're very close \n",
      "273.6835021972656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] tting there you're very close \n",
      "token:  [S1] taxis like Dublin bikes cause I don't know \n",
      "209.20440673828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] taxis like Dublin bikes cause I don't know \n",
      "token:  [MOD] Yeah but what is \n",
      "74.72178649902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah but what is \n",
      "token:  [S2] I don't \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.558879852294922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't \n",
      "token:  [MOD] the one thing that Irish people love to do How \n",
      "123.52256774902344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] the one thing that Irish people love to do How \n",
      "token:  [S1] Complain? \n",
      "107.8968505859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Complain? \n",
      "token:  [MOD] do they travel \n",
      "358.1083068847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] do they travel \n",
      "token:  [S1] Oh sorry that was under there \n",
      "138.36807250976562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh sorry that was under there \n",
      "token:  [S2] \n",
      "11.192832946777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] one of our own cars walking not walking \n",
      "99.13038635253906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] one of our own cars walking not walking \n",
      "token:  [S2] it makes sen nse to say in your own car though \n",
      "71.30570220947266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] it makes sen nse to say in your own car though \n",
      "token:  [S1] That's not public \n",
      "26.756736755371094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] That's not public \n",
      "token:  [S2] but it's a public place \n",
      "11.17852783203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] but it's a public place \n",
      "token:  [MOD] When people love to escape for fo from Ireland right they want \n",
      "1136.3858642578125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] When people love to escape for fo from Ireland right they want \n",
      "token:  [S1] Oh pla ane of course the recycled \n",
      "226.88478088378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh pla ane of course the recycled \n",
      "token:  [S2] Oh plane \n",
      "44.29375457763672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh plane \n",
      "token:  [MOD] Excellent \n",
      "186.82095336914062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent \n",
      "token:  [S1] air! and \n",
      "185.85264587402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] air! and \n",
      "token:  [S2] Ye ah \n",
      "50.71736526489258\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ye ah \n",
      "token:  [S1] Jesus \n",
      "22.30882453918457\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Jesus \n",
      "token:  [MOD] Well done \n",
      "108.58258056640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well done \n",
      "token:  [S1] So hard Took us long enough. \n",
      "71.61517333984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] So hard Took us long enough. \n",
      "token:  [MOD] Now that you have the three most pop ular answers would you be able to discuss the ranking then? \n",
      "75.97982025146484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Now that you have the three most pop ular answers would you be able to discuss the ranking then? \n",
      "token:  [S1] Oh god ! \n",
      "58.846763610839844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh god ! \n",
      "token:  [S2] Ok. \n",
      "8.131697654724121\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] I suppose by population the number of people that travel on planes as opposed to the people that go to school or \n",
      "37.30906295776367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I suppose by population the number of people that travel on planes as opposed to the people that go to school or \n",
      "token:  [S2] Yeah exact I think that plane might \n",
      "111.18256378173828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah exact I think that plane might \n",
      "token:  [S1] doctor's waiting room \n",
      "51.18879318237305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] doctor's waiting room \n",
      "token:  [S2] be the third one because it's people who like travel all the time being like oh I hate travelling getting sick on the plane \n",
      "51.74978256225586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] be the third one because it's people who like travel all the time being like oh I hate travelling getting sick on the plane \n",
      "token:  [S1] La di daw \n",
      "104.9529800415039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] La di daw \n",
      "token:  [S2] \n",
      "12.766297340393066\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [S1] What about doctor's waiting room or hospital waiting rooms? because you're already kinda \n",
      "69.01546478271484\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] What about doctor's waiting room or hospital waiting rooms? because you're already kinda \n",
      "token:  [MOD] hmm \n",
      "151.44422912597656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] sick in there. \n",
      "111.943603515625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] sick in there. \n",
      "token:  [S2] Yeah exactly like where does So if this is like understanding what people said \n",
      "139.5143585205078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah exactly like where does So if this is like understanding what people said \n",
      "token:  [S1] hmm \n",
      "8.443097114562988\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] like your mind went to waiting room before it went \n",
      "136.40988159179688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] like your mind went to waiting room before it went \n",
      "token:  [S1] ah well \n",
      "18.11252784729004\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah well \n",
      "token:  [S2] to \n",
      "25.594478607177734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] to \n",
      "token:  [S1] ugh it's just the super bugs and stuff yeah \n",
      "68.29007720947266\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ugh it's just the super bugs and stuff yeah \n",
      "token:  [S2] schools yeah so and ag gain if you seen that this is adults talking more adults have probably been to a hospital or whatever lately than \n",
      "252.55332946777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] schools yeah so and ag gain if you seen that this is adults talking more adults have probably been to a hospital or whatever lately than \n",
      "token:  [S1] I \n",
      "27.04946517944336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I \n",
      "token:  [S2] to a school so \n",
      "83.23735046386719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] to a school so \n",
      "token:  [S1] You did tell us the order there though didn't you? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.041847229003906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] You did tell us the order there though didn't you? \n",
      "token:  [MOD] I will give you the order at the e nd If \n",
      "75.67276763916016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I will give you the order at the e nd If \n",
      "token:  [S1] Yeah \n",
      "138.93115234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah \n",
      "token:  [MOD] you can make your final decision then I can give you mine feedback yeah. \n",
      "104.8311996459961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you can make your final decision then I can give you mine feedback yeah. \n",
      "token:  [S2] Ok. \n",
      "25.870615005493164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] So what do you \n",
      "44.23896789550781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So what do you \n",
      "token:  [S1] I \n",
      "39.93115997314453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I \n",
      "token:  [MOD] think \n",
      "130.5795440673828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] think \n",
      "token:  [S1] I remember you you just said it like five seconds ago and I don't remember it now You did the did you just say \n",
      "35.112884521484375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I remember you you just said it like five seconds ago and I don't remember it now You did the did you just say \n",
      "token:  [S2] I think she was just saying what they were. She didn't give the order \n",
      "26.204599380493164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think she was just saying what they were. She didn't give the order \n",
      "token:  [S1] Oh I thought you said this I thought you said the third one was and the second one was but maybe it wasn't the order ok. \n",
      "22.437137603759766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh I thought you said this I thought you said the third one was and the second one was but maybe it wasn't the order ok. \n",
      "token:  [MOD] No no it wasn't the order \n",
      "17.789262771606445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] No no it wasn't the order \n",
      "token:  [S1] I was like darn I missed the answers \n",
      "72.88127136230469\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I was like darn I missed the answers \n",
      "token:  [S2] She was just saying what they were \n",
      "18.887609481811523\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] She was just saying what they were \n",
      "token:  [S1] ok \n",
      "21.22481918334961\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] Not giving you any hints now \n",
      "77.7520751953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Not giving you any hints now \n",
      "token:  [S1] Ok so would you say hos \n",
      "67.97740936279297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok so would you say hos \n",
      "token:  [S2] I would poss ibly go hospital and then school and then plane. \n",
      "121.46479034423828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I would poss ibly go hospital and then school and then plane. \n",
      "token:  [S1] and then plane. Grand. \n",
      "35.40812301635742\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and then plane. Grand. \n",
      "token:  [S2] Ok. \n",
      "11.380078315734863\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [S1] \n",
      "11.332765579223633\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] Is that your final decision yep? \n",
      "108.0625991821289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Is that your final decision yep? \n",
      "token:  [S2] Yeah. \n",
      "24.791526794433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Final answer. \n",
      "17.644397735595703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Final answer. \n",
      "token:  [MOD] ok now the first option is actually the school \n",
      "228.61117553710938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ok now the first option is actually the school \n",
      "token:  [S2] Ok. \n",
      "40.46621322631836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] You mentioned adults there but don't forget that adults have families and they have kids. \n",
      "57.76688003540039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You mentioned adults there but don't forget that adults have families and they have kids. \n",
      "token:  [S2] They do. \n",
      "18.721885681152344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] They do. \n",
      "token:  [MOD] So s \n",
      "337.3171081542969\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So s \n",
      "token:  [S2] Yeah \n",
      "132.22479248046875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [MOD] The school is number one hospital is number two and the airplane is number three. But \n",
      "52.5115852355957\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] The school is number one hospital is number two and the airplane is number three. But \n",
      "token:  [S2] ok \n",
      "188.0104217529297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] Great, good job, very good. Are you ready for the second question now? \n",
      "23.739757537841797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Great, good job, very good. Are you ready for the second question now? \n",
      "token:  [S2] Yeah \n",
      "54.2671012878418\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [S1] Ok \n",
      "7.966897964477539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok \n",
      "token:  [MOD] Great. So I would like you to think about instruments what are the most popular answers to name the question of naming an instrument in an in a symphony orchestra. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.07333374023438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Great. So I would like you to think about instruments what are the most popular answers to name the question of naming an instrument in an in a symphony orchestra. \n",
      "token:  [S1] Oh ah just name? \n",
      "103.71318054199219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh ah just name? \n",
      "token:  [S2] Just an orchestra. \n",
      "14.30970573425293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Just an orchestra. \n",
      "token:  [MOD] In a symphony orchestra or what are the instruments \n",
      "70.5851821899414\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] In a symphony orchestra or what are the instruments \n",
      "token:  [S1] Violins \n",
      "53.2414665222168\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Violins \n",
      "token:  [S2] so violin yeah most popular one \n",
      "182.22406005859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so violin yeah most popular one \n",
      "token:  [S1] I don't cello based o based all the other strings flutes \n",
      "113.80360412597656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't cello based o based all the other strings flutes \n",
      "token:  [S2] Yeah. \n",
      "13.258692741394043\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] I don't know a symphony orchestra. I'm terrible at those. It's just a mini orchestra \n",
      "14.3790864944458\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't know a symphony orchestra. I'm terrible at those. It's just a mini orchestra \n",
      "token:  [S2] There was a map of all the things in a symphony ochestra in my school and I'm trying to think of it now. \n",
      "22.18385887145996\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] There was a map of all the things in a symphony ochestra in my school and I'm trying to think of it now. \n",
      "token:  [MOD] Well you've already got the two. \n",
      "46.60725021362305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well you've already got the two. \n",
      "token:  [S2] Yeah. \n",
      "24.81778335571289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Oh oh there you go. so what do I say? \n",
      "18.410184860229492\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh oh there you go. so what do I say? \n",
      "token:  [MOD] So \n",
      "117.05086517333984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So \n",
      "token:  [S2] Violins and cellos is it? \n",
      "96.66136169433594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Violins and cellos is it? \n",
      "token:  [MOD] Exactly. \n",
      "63.12797546386719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Exactly. \n",
      "token:  [S1] Ok. as are there symbols and are those things that crash together? \n",
      "176.07513427734375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Ok. as are there symbols and are those things that crash together? \n",
      "token:  [S2] Basically like a symbol or a drum or something \n",
      "38.28867721557617\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Basically like a symbol or a drum or something \n",
      "token:  [S1] Yeah. What are those yolks called \n",
      "35.035888671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. What are those yolks called \n",
      "token:  [MOD] hmm \n",
      "75.0122299194336\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S1] with the monkeys \n",
      "120.82970428466797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] with the monkeys \n",
      "token:  [MOD] You did find the third one \n",
      "120.9787826538086\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You did find the third one \n",
      "token:  [S2] The drum? \n",
      "144.7891845703125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] The drum? \n",
      "token:  [MOD] Yes! Exactly. \n",
      "58.91133499145508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes! Exactly. \n",
      "token:  [S2] Yeah. \n",
      "25.331296920776367\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [MOD] Well done. \n",
      "34.820438385009766\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Well done. \n",
      "token:  [S2] Cool. \n",
      "27.6669979095459\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Cool. \n",
      "token:  [S1] There you go. \n",
      "6.106449604034424\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] There you go. \n",
      "token:  [MOD] You're very good. So What with the right or the ranking in terms of popularity. \n",
      "79.57738494873047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You're very good. So What with the right or the ranking in terms of popularity. \n",
      "token:  [S2] ok I think violin would be number one \n",
      "144.68890380859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok I think violin would be number one \n",
      "token:  [S1] Yeah we both came to it first \n",
      "46.90477752685547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah we both came to it first \n",
      "token:  [S2] in a big way. \n",
      "13.957372665405273\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] in a big way. \n",
      "token:  [S1] to it first. \n",
      "25.284372329711914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] to it first. \n",
      "token:  [S2] Yeah. \n",
      "10.249726295471191\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Then it's cellos? or drums maybe. \n",
      "67.41759490966797\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Then it's cellos? or drums maybe. \n",
      "token:  [S2] I don't know I think that was or I don't know the kinda default thing that you think of with the symphony orchestra is like duh duh duh duh duh you know that starts with like the start of universal \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.215578079223633\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I don't know I think that was or I don't know the kinda default thing that you think of with the symphony orchestra is like duh duh duh duh duh you know that starts with like the start of universal \n",
      "token:  [S1] Yeah \n",
      "13.978425025939941\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah \n",
      "token:  [S2] movies you know the dun dun dun dun dun. \n",
      "34.700496673583984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] movies you know the dun dun dun dun dun. \n",
      "token:  [S1] oh so the drums? \n",
      "36.42822265625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh so the drums? \n",
      "token:  [S2] so people might go to drums \n",
      "36.15163040161133\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so people might go to drums \n",
      "token:  [S1] ok \n",
      "19.588478088378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [S2] then second I don't know it's just a way of thinking of it \n",
      "24.662960052490234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] then second I don't know it's just a way of thinking of it \n",
      "token:  [S1] maybe \n",
      "18.053319931030273\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] maybe \n",
      "token:  [S2] yeah. \n",
      "11.011643409729004\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah. \n",
      "token:  [S1] We go with that then? the violin, drums, cello Ok \n",
      "122.31021118164062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] We go with that then? the violin, drums, cello Ok \n",
      "token:  [S2] Yeah. Think so. \n",
      "15.725488662719727\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. Think so. \n",
      "token:  [MOD] mhmm Ok? \n",
      "78.23528289794922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] mhmm Ok? \n",
      "token:  [S2] Yeah \n",
      "68.92666625976562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [S1] mhmm \n",
      "6.591109752655029\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] mhmm \n",
      "token:  [MOD] you were very fast when you had to find the three answers but I'm afraid you again don't have the right ranking. \n",
      "57.811134338378906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you were very fast when you had to find the three answers but I'm afraid you again don't have the right ranking. \n",
      "token:  [S2] \n",
      "26.984813690185547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] \n",
      "token:  [MOD] It was the violin then the cello. \n",
      "79.07634735107422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] It was the violin then the cello. \n",
      "token:  [S1] oh \n",
      "85.2006607055664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh \n",
      "token:  [MOD] and the drum was the third \n",
      "323.99755859375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and the drum was the third \n",
      "token:  [S2] Ok. \n",
      "84.089111328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] last one but good great work. \n",
      "169.35275268554688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] last one but good great work. \n",
      "token:  [S1] well we're \n",
      "89.50889587402344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] well we're \n",
      "token:  [MOD] good job \n",
      "78.62406921386719\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] good job \n",
      "token:  [S1] getting there \n",
      "51.9743766784668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] getting there \n",
      "token:  [S2] Yeah \n",
      "16.24774742126465\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah \n",
      "token:  [MOD] I think the third question should be very simple. So I would like you to name things that people cut. \n",
      "48.87883377075195\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I think the third question should be very simple. So I would like you to name things that people cut. \n",
      "token:  [S1] Cut? \n",
      "20.37449073791504\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cut? \n",
      "token:  [MOD] Yeah. \n",
      "50.69011688232422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yeah. \n",
      "token:  [S1] My god their hair. \n",
      "75.4771957397461\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] My god their hair. \n",
      "token:  [S2] Yeah. \n",
      "5.372476100921631\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Cucumbers. \n",
      "13.24277400970459\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Cucumbers. \n",
      "token:  [S2] Vege \n",
      "60.560096740722656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Vege \n",
      "token:  [S1] tables \n",
      "82.7135009765625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] tables \n",
      "token:  [MOD] You have the hair. \n",
      "124.49742889404297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You have the hair. \n",
      "token:  [S2] Yeah. \n",
      "26.532419204711914\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Yeah. \n",
      "token:  [S1] Alright. \n",
      "7.104462623596191\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Alright. \n",
      "token:  [S2] Paper? \n",
      "23.1472225189209\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Paper? \n",
      "token:  [MOD] That's one. \n",
      "45.22663879394531\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's one. \n",
      "token:  [S1] Yeah. \n",
      "16.080739974975586\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Yeah. \n",
      "token:  [S2] Wrapping paper or \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.68451690673828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Wrapping paper or \n",
      "token:  [MOD] Excellent. \n",
      "200.3609161376953\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Excellent. \n",
      "token:  [S2] something \n",
      "164.71206665039062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] something \n",
      "token:  [MOD] That's the second one. \n",
      "41.257598876953125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] That's the second one. \n",
      "token:  [S2] calorie \n",
      "435.4995422363281\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] calorie \n",
      "token:  [S1] s nowadays no? carbs \n",
      "188.49102783203125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] s nowadays no? carbs \n",
      "token:  [MOD] hmm \n",
      "60.24555206298828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hmm \n",
      "token:  [S2] interest ing interpretation \n",
      "527.6841430664062\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] interest ing interpretation \n",
      "token:  [S1] hu I know \n",
      "29.963008880615234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hu I know \n",
      "token:  [S2] of the word cut. \n",
      "49.41822814941406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] of the word cut. \n",
      "token:  [S1] what am I saying \n",
      "19.925329208374023\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] what am I saying \n",
      "token:  [S2] about myself Sellotape? \n",
      "63.99542236328125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] about myself Sellotape? \n",
      "token:  [S1] Would you \n",
      "27.61628532409668\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Would you \n",
      "token:  [S2] Is it \n",
      "8.165658950805664\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Is it \n",
      "token:  [S1] or would you break sellotape with those little snazzy some people \n",
      "112.11689758300781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] or would you break sellotape with those little snazzy some people \n",
      "token:  [S2] things they have nowadays \n",
      "42.5990104675293\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] things they have nowadays \n",
      "token:  [S1] some people god \n",
      "42.101715087890625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] some people god \n",
      "token:  [S2] are classic they go with the scissors \n",
      "119.97351837158203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] are classic they go with the scissors \n",
      "token:  [S1] yeah \n",
      "14.589455604553223\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] technologies really \n",
      "775.1267700195312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] technologies really \n",
      "token:  [S1] screwed us \n",
      "109.04222869873047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] screwed us \n",
      "token:  [MOD] You did mention \n",
      "168.64898681640625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] You did mention \n",
      "token:  [S2] cheese \n",
      "330.7539978027344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cheese \n",
      "token:  [MOD] vegetables Would you \n",
      "396.0136413574219\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] vegetables Would you \n",
      "token:  [S1] yeah \n",
      "80.12908172607422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [MOD] not think of a different cate gory of food \n",
      "139.64022827148438\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] not think of a different cate gory of food \n",
      "token:  [S1] fruit \n",
      "81.7891616821289\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] fruit \n",
      "token:  [S2] cheese \n",
      "7.708200931549072\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cheese \n",
      "token:  [S1] so specific \n",
      "47.819034576416016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] so specific \n",
      "token:  [S2] bread \n",
      "20.97129249572754\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] bread \n",
      "token:  [S1] meat, butcher \n",
      "32.09502029418945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] meat, butcher \n",
      "token:  [MOD] Yes excellent meat. \n",
      "339.40826416015625\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Yes excellent meat. \n",
      "token:  [S2] but I'm a vegetarian I'd never have thought of that \n",
      "28.021072387695312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] but I'm a vegetarian I'd never have thought of that \n",
      "token:  [S1] oh well that's not gonna \n",
      "30.72873878479004\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh well that's not gonna \n",
      "token:  [MOD] Alright. \n",
      "77.9945068359375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Alright. \n",
      "token:  [S2] Ok. \n",
      "16.380678176879883\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Ok. \n",
      "token:  [MOD] So what would be the ranking then? \n",
      "40.0822639465332\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] So what would be the ranking then? \n",
      "token:  [S1] Oh what was the third one paper \n",
      "164.69996643066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] Oh what was the third one paper \n",
      "token:  [MOD] hair \n",
      "516.2342529296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] hair \n",
      "token:  [S1] hair oh \n",
      "62.259666442871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hair oh \n",
      "token:  [S2] hair \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.501104354858398\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair \n",
      "token:  [S1] yes hair \n",
      "14.409503936767578\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yes hair \n",
      "token:  [S2] yeah \n",
      "12.728894233703613\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] and meat. \n",
      "270.4305114746094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and meat. \n",
      "token:  [S1] and meat. Ok. \n",
      "17.904130935668945\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] and meat. Ok. \n",
      "token:  [S2] Oh yeah I'd been thinking hair and then you said hair Ok. \n",
      "54.563323974609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Oh yeah I'd been thinking hair and then you said hair Ok. \n",
      "token:  [S1] first \n",
      "47.95430374145508\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] first \n",
      "token:  [S2] so it might make sense to put that number one? \n",
      "32.70197677612305\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] so it might make sense to put that number one? \n",
      "token:  [S1] alright \n",
      "22.809526443481445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] alright \n",
      "token:  [S2] But \n",
      "19.23223114013672\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] But \n",
      "token:  [S1] yep \n",
      "32.56483459472656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yep \n",
      "token:  [S2] again I wouldn't really know where to place meat in that cause I I'd say second \n",
      "62.73938751220703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] again I wouldn't really know where to place meat in that cause I I'd say second \n",
      "token:  [S1] I don't meat is pretty popular I've heard yeah \n",
      "58.43602752685547\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't meat is pretty popular I've heard yeah \n",
      "token:  [S2] I guess would you say hair pa ah hair meat paper \n",
      "221.84364318847656\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I guess would you say hair pa ah hair meat paper \n",
      "token:  [S1] I don't know maybe we could go with cut paper first. I don't know. \n",
      "13.332653045654297\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I don't know maybe we could go with cut paper first. I don't know. \n",
      "token:  [S2] I can't think of the last time \n",
      "11.376410484313965\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I can't think of the last time \n",
      "token:  [S1] I haven't dealt with paper. \n",
      "25.788076400756836\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] I haven't dealt with paper. \n",
      "token:  [S2] I cut pa \n",
      "183.32443237304688\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I cut pa \n",
      "token:  [S1] yeah \n",
      "59.76545715332031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] per yeah \n",
      "53.02919387817383\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] per yeah \n",
      "token:  [S1] neither can I \n",
      "47.0892333984375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] neither can I \n",
      "token:  [S2] definitely got my hair cut more recently like \n",
      "88.14317321777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] definitely got my hair cut more recently like \n",
      "token:  [S1] yeah \n",
      "46.782169342041016\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah \n",
      "token:  [S2] Pe ople who eat meat regularly have probably cut meat more rec ently \n",
      "209.81932067871094\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] Pe ople who eat meat regularly have probably cut meat more rec ently \n",
      "token:  [S1] pro bably \n",
      "20.388412475585938\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] pro bably \n",
      "token:  [S2] It's a classic dinner \n",
      "46.998748779296875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It's a classic dinner \n",
      "token:  [S1] hmm very Iri \n",
      "111.02495574951172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm very Iri \n",
      "token:  [S2] ok so \n",
      "15.535649299621582\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok so \n",
      "token:  [S1] sh \n",
      "38.889190673828125\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] sh \n",
      "token:  [S2] hair meat paper \n",
      "175.73048400878906\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] hair meat paper \n",
      "token:  [S1] ok go \n",
      "40.006324768066406\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok go \n",
      "token:  [S2] or would \n",
      "29.056840896606445\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] or would \n",
      "token:  [S1] with that \n",
      "22.698848724365234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] with that \n",
      "token:  [S2] meat be more popular than hair do you think? \n",
      "40.687801361083984\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] meat be more popular than hair do you think? \n",
      "token:  [S1] nah ah sure I don't know I I thought of hair first too \n",
      "48.07709503173828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] nah ah sure I don't know I I thought of hair first too \n",
      "token:  [S2] ok I think people go to hair first \n",
      "18.189075469970703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok I think people go to hair first \n",
      "token:  [S1] yeah like \n",
      "23.10200309753418\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] yeah like \n",
      "token:  [S2] is all haircut is a word meat cut isn't \n",
      "137.3307647705078\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] is all haircut is a word meat cut isn't \n",
      "token:  [S1] well in the butchers probably alright should we \n",
      "186.0242156982422\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] well in the butchers probably alright should we \n",
      "token:  [S2] It's a noun phra \n",
      "57.45149230957031\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] It's a noun phra \n",
      "token:  [S1] stick with that then \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112.09412384033203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] stick with that then \n",
      "token:  [S2] se at best but yeah \n",
      "110.06318664550781\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] se at best but yeah \n",
      "token:  [S1] hmm \n",
      "11.49522876739502\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] hmm \n",
      "token:  [S2] I think hair meat paper \n",
      "93.8115005493164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] I think hair meat paper \n",
      "token:  [S1] ok \n",
      "24.423702239990234\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ok \n",
      "token:  [MOD] Ok \n",
      "52.49748992919922\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Ok \n",
      "token:  [S1] oh no \n",
      "52.83848571777344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] oh no \n",
      "token:  [MOD] now you ha you got the first one and it's hair. obv \n",
      "162.26580810546875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] now you ha you got the first one and it's hair. obv \n",
      "token:  [S2] yeah \n",
      "75.99278259277344\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] yeah \n",
      "token:  [MOD] viously and then it's the paper \n",
      "256.98724365234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] viously and then it's the paper \n",
      "token:  [S2] ok \n",
      "105.06735229492188\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [S1] ah \n",
      "17.95795440673828\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] ah \n",
      "token:  [MOD] and the thirdy \n",
      "408.64739990234375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] and the thirdy \n",
      "token:  [S1] just missed it \n",
      "115.44900512695312\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] just missed it \n",
      "token:  [MOD] one is the meat t \n",
      "440.4400329589844\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] one is the meat t \n",
      "token:  [S2] ok \n",
      "167.2274169921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] but well done you did great \n",
      "88.34417724609375\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] but well done you did great \n",
      "token:  [S2] cool \n",
      "84.38197326660156\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] cool \n",
      "token:  [MOD] excellent. \n",
      "192.0481719970703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] excellent. \n",
      "token:  [S2] ok \n",
      "75.12456512451172\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] ok \n",
      "token:  [MOD] And I think that is the end of the quiz. well thank \n",
      "62.73788833618164\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] And I think that is the end of the quiz. well thank \n",
      "token:  [S2] woo! \n",
      "85.3388671875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] woo! \n",
      "token:  [MOD] you for your \n",
      "237.00234985351562\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] you for your \n",
      "token:  [S1] great \n",
      "53.868648529052734\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] great \n",
      "token:  [MOD] particip \n",
      "420.43133544921875\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] particip \n",
      "token:  [S2] great \n",
      "117.4915542602539\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] great \n",
      "token:  [MOD] ation and \n",
      "214.15676879882812\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] ation and \n",
      "token:  [S1] That was fast \n",
      "78.1883316040039\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] That was fast \n",
      "token:  [MOD] I hope you enjoyed that. \n",
      "23.669422149658203\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I hope you enjoyed that. \n",
      "token:  [S1] \n",
      "22.33733558654785\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] \n",
      "token:  [MOD] Do you like more questions? \n",
      "69.65869903564453\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] Do you like more questions? \n",
      "token:  [S2] oh it's done? \n",
      "76.84740447998047\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] oh it's done? \n",
      "token:  [MOD] I'm so sorry I don't have any \n",
      "21.30023765563965\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [MOD] I'm so sorry I don't have any \n",
      "token:  [S1] That would be great We'll have a chat \n",
      "34.542503356933594\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S1] That would be great We'll have a chat \n",
      "token:  [S2] no that was fine \n",
      "27.62903594970703\n",
      "prompt:  This is a conversation between users in parethesis ([S1], [S2], [MOD])\n",
      " Predict the next most probable utterance:\n",
      "context:  [S2] no that was fine \n",
      "token:  [MOD] so yeah thanks very much again.\n",
      "111.65972900390625\n",
      "MOD : 160.19832898190148\n",
      "S1 : 61.69273423797944\n",
      "S2 : 69.85870576972393\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "dominance_scores = {}\n",
    "\n",
    "for el,path in zip(multisimo_df[\"text\"], multisimo_df[\"path\"]):\n",
    "    print(path)\n",
    "    dataset = re.sub(r'\\[', r'\\n[', el).split(\"\\n\")[1:]\n",
    "    pattern = r'\\[(S\\d|MOD)\\]'\n",
    "    matches = re.findall(pattern, \"\".join(dataset))\n",
    "    MOD_idxs = np.argwhere(np.asarray(matches) =='MOD').ravel()\n",
    "    mod_idx = []\n",
    "    for idx,(el, nxt_el) in enumerate(zip(MOD_idxs[:-1], MOD_idxs[1:])):\n",
    "        mod_idx +=[el for idx in range(nxt_el - el)]\n",
    "    mod_idx += [MOD_idxs[-1] for _ in range(len(dataset) - MOD_idxs[-1])]\n",
    "    firstliner = \"\"\n",
    "    dataset = [firstliner] + dataset\n",
    "    assert len(mod_idx) == len(dataset[1:])\n",
    "    prmt = \"This is a conversation between users in parethesis ([S1], [S2], [MOD])\\n Predict the next most probable utterance:\"\n",
    "    perpl = compute_perplexity(dataset, prmt, mod_idx=np.asarray(mod_idx))\n",
    "    dominance_scores[path] = {}\n",
    "    for patt in np.unique(matches):\n",
    "        idx = np.asarray([index for index, element in enumerate(matches) if element == patt])\n",
    "        dominance_scores[path][patt] = np.mean(np.asarray(perpl)[idx])\n",
    "        print(f\"{patt} :\", np.mean(np.asarray(perpl)[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech transcription_Transcriber/S05.trs': {'MOD': 150.78121198491849,\n",
       "  'S1': 75.41003963723779,\n",
       "  'S2': 71.14946473163107},\n",
       " 'speech transcription_Transcriber/S17.trs': {'MOD': 158.64770763397217,\n",
       "  'S1': 71.5698383857464,\n",
       "  'S2': 69.63107684275487},\n",
       " 'speech transcription_Transcriber/S10.trs': {'MOD': 140.7730285805392,\n",
       "  'S1': 82.46366771226077,\n",
       "  'S2': 112.94518043055679},\n",
       " 'speech transcription_Transcriber/S21.trs': {'MOD': 155.60970138641724,\n",
       "  'S1': 74.32951695578438,\n",
       "  'S2': 74.87702072806981},\n",
       " 'speech transcription_Transcriber/S18.trs': {'MOD': 211.46182588599194,\n",
       "  'S1': 68.83044043935911,\n",
       "  'S2': 128.40242790108297},\n",
       " 'speech transcription_Transcriber/S14.trs': {'MOD': 167.36222941438916,\n",
       "  'S1': 70.10998123342341,\n",
       "  'S2': 92.11443028883501},\n",
       " 'speech transcription_Transcriber/S19.trs': {'MOD': 179.93626904728436,\n",
       "  'S1': 62.52755670458357,\n",
       "  'S2': 92.15837649988934},\n",
       " 'speech transcription_Transcriber/S22.trs': {'MOD': 192.7635320410671,\n",
       "  'S1': 71.92604222923818,\n",
       "  'S2': 85.64886283874512},\n",
       " 'speech transcription_Transcriber/S11.trs': {'MOD': 155.41077333450318,\n",
       "  'S1': 90.69210723468235,\n",
       "  'S2': 60.58110282380702},\n",
       " 'speech transcription_Transcriber/S20.trs': {'MOD': 155.39662481561493,\n",
       "  'S1': 123.0578809988619,\n",
       "  'S2': 103.50375768873427},\n",
       " 'speech transcription_Transcriber/S13.trs': {'MOD': 122.6839175557389,\n",
       "  'S1': 131.2319638318029,\n",
       "  'S2': 170.7658010579772},\n",
       " 'speech transcription_Transcriber/S04.trs': {'MOD': 162.48758922304427,\n",
       "  'S1': 70.36396294340081,\n",
       "  'S2': 84.60318922996521},\n",
       " 'speech transcription_Transcriber/S07.trs': {'MOD': 250.00223968278115,\n",
       "  'S1': 85.45062513966714,\n",
       "  'S2': 76.78833593091657},\n",
       " 'speech transcription_Transcriber/S08.trs': {'MOD': 238.7351604987835,\n",
       "  'S1': 79.98461752822719,\n",
       "  'S2': 79.034911499467},\n",
       " 'speech transcription_Transcriber/S23.trs': {'MOD': 190.53473569429838,\n",
       "  'S1': 64.25753418056445,\n",
       "  'S2': 75.67804695839105},\n",
       " 'speech transcription_Transcriber/S09.trs': {'MOD': 106.55536075199352,\n",
       "  'S1': 115.64019980987945,\n",
       "  'S2': 108.62873114989354},\n",
       " 'speech transcription_Transcriber/S02.trs': {'MOD': 209.76830851906223,\n",
       "  'S1': 72.50440544240615,\n",
       "  'S2': 89.04108453864482}}"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dominance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOD</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S05</th>\n",
       "      <td>150.781212</td>\n",
       "      <td>75.410040</td>\n",
       "      <td>71.149465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S17</th>\n",
       "      <td>158.647708</td>\n",
       "      <td>71.569838</td>\n",
       "      <td>69.631077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S10</th>\n",
       "      <td>140.773029</td>\n",
       "      <td>82.463668</td>\n",
       "      <td>112.945180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S21</th>\n",
       "      <td>155.609701</td>\n",
       "      <td>74.329517</td>\n",
       "      <td>74.877021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S18</th>\n",
       "      <td>211.461826</td>\n",
       "      <td>68.830440</td>\n",
       "      <td>128.402428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S14</th>\n",
       "      <td>167.362229</td>\n",
       "      <td>70.109981</td>\n",
       "      <td>92.114430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S19</th>\n",
       "      <td>179.936269</td>\n",
       "      <td>62.527557</td>\n",
       "      <td>92.158376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S22</th>\n",
       "      <td>192.763532</td>\n",
       "      <td>71.926042</td>\n",
       "      <td>85.648863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S11</th>\n",
       "      <td>155.410773</td>\n",
       "      <td>90.692107</td>\n",
       "      <td>60.581103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S20</th>\n",
       "      <td>155.396625</td>\n",
       "      <td>123.057881</td>\n",
       "      <td>103.503758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S13</th>\n",
       "      <td>122.683918</td>\n",
       "      <td>131.231964</td>\n",
       "      <td>170.765801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S04</th>\n",
       "      <td>162.487589</td>\n",
       "      <td>70.363963</td>\n",
       "      <td>84.603189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S07</th>\n",
       "      <td>250.002240</td>\n",
       "      <td>85.450625</td>\n",
       "      <td>76.788336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S08</th>\n",
       "      <td>238.735160</td>\n",
       "      <td>79.984618</td>\n",
       "      <td>79.034911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S23</th>\n",
       "      <td>190.534736</td>\n",
       "      <td>64.257534</td>\n",
       "      <td>75.678047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S09</th>\n",
       "      <td>106.555361</td>\n",
       "      <td>115.640200</td>\n",
       "      <td>108.628731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S02</th>\n",
       "      <td>209.768309</td>\n",
       "      <td>72.504405</td>\n",
       "      <td>89.041085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MOD          S1          S2\n",
       "S05  150.781212   75.410040   71.149465\n",
       "S17  158.647708   71.569838   69.631077\n",
       "S10  140.773029   82.463668  112.945180\n",
       "S21  155.609701   74.329517   74.877021\n",
       "S18  211.461826   68.830440  128.402428\n",
       "S14  167.362229   70.109981   92.114430\n",
       "S19  179.936269   62.527557   92.158376\n",
       "S22  192.763532   71.926042   85.648863\n",
       "S11  155.410773   90.692107   60.581103\n",
       "S20  155.396625  123.057881  103.503758\n",
       "S13  122.683918  131.231964  170.765801\n",
       "S04  162.487589   70.363963   84.603189\n",
       "S07  250.002240   85.450625   76.788336\n",
       "S08  238.735160   79.984618   79.034911\n",
       "S23  190.534736   64.257534   75.678047\n",
       "S09  106.555361  115.640200  108.628731\n",
       "S02  209.768309   72.504405   89.041085"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dominance_df = pd.DataFrame(dominance_scores)\n",
    "new_columns = pd.DataFrame(dominance_scores).keys().map(lambda x: x.split(\"/\")[-1].replace(\".trs\",\"\"))\n",
    "dominance_df.rename(columns=dict(zip(dominance_df.columns, new_columns)), inplace=True)\n",
    "\n",
    "dominance_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>MOD</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S05</td>\n",
       "      <td>150.781212</td>\n",
       "      <td>75.410040</td>\n",
       "      <td>71.149465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S17</td>\n",
       "      <td>158.647708</td>\n",
       "      <td>71.569838</td>\n",
       "      <td>69.631077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S10</td>\n",
       "      <td>140.773029</td>\n",
       "      <td>82.463668</td>\n",
       "      <td>112.945180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S21</td>\n",
       "      <td>155.609701</td>\n",
       "      <td>74.329517</td>\n",
       "      <td>74.877021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S18</td>\n",
       "      <td>211.461826</td>\n",
       "      <td>68.830440</td>\n",
       "      <td>128.402428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S14</td>\n",
       "      <td>167.362229</td>\n",
       "      <td>70.109981</td>\n",
       "      <td>92.114430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S19</td>\n",
       "      <td>179.936269</td>\n",
       "      <td>62.527557</td>\n",
       "      <td>92.158376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S22</td>\n",
       "      <td>192.763532</td>\n",
       "      <td>71.926042</td>\n",
       "      <td>85.648863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S11</td>\n",
       "      <td>155.410773</td>\n",
       "      <td>90.692107</td>\n",
       "      <td>60.581103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S20</td>\n",
       "      <td>155.396625</td>\n",
       "      <td>123.057881</td>\n",
       "      <td>103.503758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S13</td>\n",
       "      <td>122.683918</td>\n",
       "      <td>131.231964</td>\n",
       "      <td>170.765801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S04</td>\n",
       "      <td>162.487589</td>\n",
       "      <td>70.363963</td>\n",
       "      <td>84.603189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S07</td>\n",
       "      <td>250.002240</td>\n",
       "      <td>85.450625</td>\n",
       "      <td>76.788336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S08</td>\n",
       "      <td>238.735160</td>\n",
       "      <td>79.984618</td>\n",
       "      <td>79.034911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S23</td>\n",
       "      <td>190.534736</td>\n",
       "      <td>64.257534</td>\n",
       "      <td>75.678047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S09</td>\n",
       "      <td>106.555361</td>\n",
       "      <td>115.640200</td>\n",
       "      <td>108.628731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S02</td>\n",
       "      <td>209.768309</td>\n",
       "      <td>72.504405</td>\n",
       "      <td>89.041085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name         MOD          S1          S2\n",
       "0        S05  150.781212   75.410040   71.149465\n",
       "1        S17  158.647708   71.569838   69.631077\n",
       "2        S10  140.773029   82.463668  112.945180\n",
       "3        S21  155.609701   74.329517   74.877021\n",
       "4        S18  211.461826   68.830440  128.402428\n",
       "5        S14  167.362229   70.109981   92.114430\n",
       "6        S19  179.936269   62.527557   92.158376\n",
       "7        S22  192.763532   71.926042   85.648863\n",
       "8        S11  155.410773   90.692107   60.581103\n",
       "9        S20  155.396625  123.057881  103.503758\n",
       "10       S13  122.683918  131.231964  170.765801\n",
       "11       S04  162.487589   70.363963   84.603189\n",
       "12       S07  250.002240   85.450625   76.788336\n",
       "13       S08  238.735160   79.984618   79.034911\n",
       "14       S23  190.534736   64.257534   75.678047\n",
       "15       S09  106.555361  115.640200  108.628731\n",
       "16       S02  209.768309   72.504405   89.041085"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ = dominance_df.T\n",
    "new_ = new_.reset_index()\n",
    "new_.rename(columns={'index': 'file_name'}, inplace=True)\n",
    "new_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>first_occ_speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S02</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S03</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S04</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S05</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S07</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S08</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S09</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S10</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S11</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S13</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S14</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S17</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S18</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S19</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S20</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S21</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S22</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S23</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   path first_occ_speaker\n",
       "0   S02                P1\n",
       "1   S03                P1\n",
       "2   S04                P1\n",
       "3   S05                P2\n",
       "4   S07                P2\n",
       "5   S08                P2\n",
       "6   S09                P2\n",
       "7   S10                P1\n",
       "8   S11                P1\n",
       "9   S13                P1\n",
       "10  S14                P2\n",
       "11  S17                P1\n",
       "12  S18                P1\n",
       "13  S19                P1\n",
       "14  S20                P1\n",
       "15  S21                P1\n",
       "16  S22                P1\n",
       "17  S23                P2"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels = []\n",
    "for el, name in zip(pd.read_csv(\"../data/processed/transcript_dominance.csv\")[\"file_content\"],pd.read_csv(\"../data/processed/transcript_dominance.csv\")[\"file_name\"]):\n",
    "    pattern = r'\\[(P\\d|MOD)\\]'\n",
    "    matches = re.findall(pattern, el)\n",
    "    real_labels.append([name, matches[0]])\n",
    "\n",
    "real_labels_df = pd.DataFrame(real_labels, columns=[\"path\",\"first_occ_speaker\"])\n",
    "real_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>first_occ_speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S05</td>\n",
       "      <td>[MOD] Ok hi welcome, thank you for coming toda...</td>\n",
       "      <td>S2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S17</td>\n",
       "      <td>[MOD] Hello guys, thanks very much for being h...</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S10</td>\n",
       "      <td>[MOD] Ok. So I would like us to play a quiz. O...</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S21</td>\n",
       "      <td>[MOD] Ok so hello guys. Thanks very [S1] Hi. [...</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S18</td>\n",
       "      <td>[MOD] Ok hi guys Thanks very much for coming [...</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S14</td>\n",
       "      <td>[MOD] Hello guys thanks very much for coming h...</td>\n",
       "      <td>S2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S19</td>\n",
       "      <td>[MOD] Perfect. Well hi guys. Welcome. [S1] Hi....</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S22</td>\n",
       "      <td>[MOD] Ah it's fine. Hello guys. Thanks very mu...</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S11</td>\n",
       "      <td>[MOD] Right. So, I would like us to play a qui...</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S20</td>\n",
       "      <td>[MOD] So hello. Thanks very [S1] Hi. [MOD] muc...</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S13</td>\n",
       "      <td>[MOD]: Well hello, thanks very much for coming...</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S04</td>\n",
       "      <td>[MOD] ok Hello, thank you for coming today, we...</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S07</td>\n",
       "      <td>[MOD] Ok. So welcome, thank you very much for ...</td>\n",
       "      <td>S2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S08</td>\n",
       "      <td>[MOD] So good evening [S2] Good evening. [MOD]...</td>\n",
       "      <td>S2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S23</td>\n",
       "      <td>[MOD] So hi guys thanks [S1] hi [MOD] very muc...</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S09</td>\n",
       "      <td>[MOD] Ok [S2] Yeah so [MOD] So I would like us...</td>\n",
       "      <td>S2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S02</td>\n",
       "      <td>[MOD] Ok so thanks for coming today. we're goi...</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   path                                               text first_occ_speaker\n",
       "0   S05  [MOD] Ok hi welcome, thank you for coming toda...                S2\n",
       "1   S17  [MOD] Hello guys, thanks very much for being h...                S1\n",
       "2   S10  [MOD] Ok. So I would like us to play a quiz. O...                S1\n",
       "3   S21  [MOD] Ok so hello guys. Thanks very [S1] Hi. [...                S1\n",
       "4   S18  [MOD] Ok hi guys Thanks very much for coming [...                S1\n",
       "5   S14  [MOD] Hello guys thanks very much for coming h...                S2\n",
       "6   S19  [MOD] Perfect. Well hi guys. Welcome. [S1] Hi....                S1\n",
       "7   S22  [MOD] Ah it's fine. Hello guys. Thanks very mu...                S1\n",
       "8   S11  [MOD] Right. So, I would like us to play a qui...                S1\n",
       "9   S20  [MOD] So hello. Thanks very [S1] Hi. [MOD] muc...                S1\n",
       "10  S13  [MOD]: Well hello, thanks very much for coming...                S1\n",
       "11  S04  [MOD] ok Hello, thank you for coming today, we...                S1\n",
       "12  S07  [MOD] Ok. So welcome, thank you very much for ...                S2\n",
       "13  S08  [MOD] So good evening [S2] Good evening. [MOD]...                S2\n",
       "14  S23  [MOD] So hi guys thanks [S1] hi [MOD] very muc...                S1\n",
       "15  S09  [MOD] Ok [S2] Yeah so [MOD] So I would like us...                S2\n",
       "16  S02  [MOD] Ok so thanks for coming today. we're goi...                S1"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'\\[(S\\d)\\]'\n",
    "\n",
    "multisimo_df[\"path\"] = multisimo_df[\"path\"].map(lambda x: x.split(\"/\")[-1].replace(\".trs\",\"\"))\n",
    "multisimo_df[\"first_occ_speaker\"] = multisimo_df[\"text\"].map(lambda x: re.findall(pattern, x)[0])\n",
    "multisimo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>first_occ_speaker_y</th>\n",
       "      <th>first_occ_speaker_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S02</td>\n",
       "      <td>S1</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S04</td>\n",
       "      <td>S1</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S05</td>\n",
       "      <td>S2</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S07</td>\n",
       "      <td>S2</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S08</td>\n",
       "      <td>S2</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S09</td>\n",
       "      <td>S2</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S10</td>\n",
       "      <td>S1</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S11</td>\n",
       "      <td>S1</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S13</td>\n",
       "      <td>S1</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S14</td>\n",
       "      <td>S2</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S17</td>\n",
       "      <td>S1</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S18</td>\n",
       "      <td>S1</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S19</td>\n",
       "      <td>S1</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S20</td>\n",
       "      <td>S1</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S21</td>\n",
       "      <td>S1</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S22</td>\n",
       "      <td>S1</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S23</td>\n",
       "      <td>S1</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   path first_occ_speaker_y first_occ_speaker_x\n",
       "0   S02                  S1                  P1\n",
       "1   S04                  S1                  P1\n",
       "2   S05                  S2                  P2\n",
       "3   S07                  S2                  P2\n",
       "4   S08                  S2                  P2\n",
       "5   S09                  S2                  P2\n",
       "6   S10                  S1                  P1\n",
       "7   S11                  S1                  P1\n",
       "8   S13                  S1                  P1\n",
       "9   S14                  S2                  P2\n",
       "10  S17                  S1                  P1\n",
       "11  S18                  S1                  P1\n",
       "12  S19                  S1                  P1\n",
       "13  S20                  S1                  P1\n",
       "14  S21                  S1                  P1\n",
       "15  S22                  S1                  P1\n",
       "16  S23                  S1                  P2"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(real_labels_df,multisimo_df, on=\"path\")[[\"path\",\"first_occ_speaker_y\",\"first_occ_speaker_x\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>speaker_1_1</th>\n",
       "      <th>speaker_1_2</th>\n",
       "      <th>speaker_1_3</th>\n",
       "      <th>speaker_1_4</th>\n",
       "      <th>speaker_1_5</th>\n",
       "      <th>speaker_2_1</th>\n",
       "      <th>speaker_2_2</th>\n",
       "      <th>speaker_2_3</th>\n",
       "      <th>speaker_2_4</th>\n",
       "      <th>speaker_2_5</th>\n",
       "      <th>speaker_1_dom_score</th>\n",
       "      <th>speaker_2_dom_score</th>\n",
       "      <th>MOD</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>209.768309</td>\n",
       "      <td>72.504405</td>\n",
       "      <td>89.041085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>162.487589</td>\n",
       "      <td>70.363963</td>\n",
       "      <td>84.603189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.781212</td>\n",
       "      <td>75.410040</td>\n",
       "      <td>71.149465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>250.002240</td>\n",
       "      <td>85.450625</td>\n",
       "      <td>76.788336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>238.735160</td>\n",
       "      <td>79.984618</td>\n",
       "      <td>79.034911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>106.555361</td>\n",
       "      <td>115.640200</td>\n",
       "      <td>108.628731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>140.773029</td>\n",
       "      <td>82.463668</td>\n",
       "      <td>112.945180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>155.410773</td>\n",
       "      <td>90.692107</td>\n",
       "      <td>60.581103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>122.683918</td>\n",
       "      <td>131.231964</td>\n",
       "      <td>170.765801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>167.362229</td>\n",
       "      <td>70.109981</td>\n",
       "      <td>92.114430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>158.647708</td>\n",
       "      <td>71.569838</td>\n",
       "      <td>69.631077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>211.461826</td>\n",
       "      <td>68.830440</td>\n",
       "      <td>128.402428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>179.936269</td>\n",
       "      <td>62.527557</td>\n",
       "      <td>92.158376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155.396625</td>\n",
       "      <td>123.057881</td>\n",
       "      <td>103.503758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>155.609701</td>\n",
       "      <td>74.329517</td>\n",
       "      <td>74.877021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>192.763532</td>\n",
       "      <td>71.926042</td>\n",
       "      <td>85.648863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>190.534736</td>\n",
       "      <td>64.257534</td>\n",
       "      <td>75.678047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  speaker_1_1  speaker_1_2  speaker_1_3  speaker_1_4  speaker_1_5  \\\n",
       "0        S02          3.0          2.0          2.0          2.0          1.0   \n",
       "1        S04          2.0          1.0          2.0          4.0          1.0   \n",
       "2        S05          4.0          4.0          4.0          4.0          3.0   \n",
       "3        S07          4.0          2.0          3.0          4.0          4.0   \n",
       "4        S08          4.0          2.0          3.0          2.0          1.0   \n",
       "5        S09          4.0          3.0          3.0          5.0          3.0   \n",
       "6        S10          3.0          2.0          3.0          4.0          2.0   \n",
       "7        S11          5.0          2.0          3.0          3.0          5.0   \n",
       "8        S13          3.0          1.0          2.0          4.0          2.0   \n",
       "9        S14          4.0          3.0          3.0          4.0          3.0   \n",
       "10       S17          5.0          2.0          3.0          3.0          2.0   \n",
       "11       S18          5.0          3.0          3.0          3.0          3.0   \n",
       "12       S19          4.0          3.0          3.0          2.0          2.0   \n",
       "13       S20          5.0          4.0          4.0          5.0          3.0   \n",
       "14       S21          3.0          3.0          2.0          3.0          1.0   \n",
       "15       S22          4.0          2.0          3.0          5.0          3.0   \n",
       "16       S23          4.0          4.0          3.0          5.0          2.0   \n",
       "\n",
       "    speaker_2_1  speaker_2_2  speaker_2_3  speaker_2_4  speaker_2_5  \\\n",
       "0           4.0          3.0          3.0          4.0          3.0   \n",
       "1           1.0          1.0          1.0          4.0          1.0   \n",
       "2           3.0          2.0          3.0          1.0          1.0   \n",
       "3           4.0          2.0          3.0          5.0          3.0   \n",
       "4           3.0          3.0          3.0          3.0          2.0   \n",
       "5           4.0          3.0          3.0          5.0          3.0   \n",
       "6           3.0          2.0          2.0          4.0          2.0   \n",
       "7           2.0          1.0          2.0          1.0          1.0   \n",
       "8           2.0          1.0          2.0          1.0          1.0   \n",
       "9           3.0          4.0          4.0          4.0          3.0   \n",
       "10          3.0          2.0          3.0          3.0          1.0   \n",
       "11          2.0          1.0          2.0          1.0          1.0   \n",
       "12          5.0          4.0          4.0          3.0          3.0   \n",
       "13          5.0          4.0          4.0          4.0          3.0   \n",
       "14          4.0          4.0          3.0          4.0          2.0   \n",
       "15          4.0          3.0          4.0          4.0          3.0   \n",
       "16          4.0          3.0          3.0          4.0          3.0   \n",
       "\n",
       "    speaker_1_dom_score  speaker_2_dom_score         MOD          S1  \\\n",
       "0                   2.0                  3.4  209.768309   72.504405   \n",
       "1                   2.0                  1.6  162.487589   70.363963   \n",
       "2                   3.8                  2.0  150.781212   75.410040   \n",
       "3                   3.4                  3.4  250.002240   85.450625   \n",
       "4                   2.4                  2.8  238.735160   79.984618   \n",
       "5                   3.6                  3.6  106.555361  115.640200   \n",
       "6                   2.8                  2.6  140.773029   82.463668   \n",
       "7                   3.6                  1.4  155.410773   90.692107   \n",
       "8                   2.4                  1.4  122.683918  131.231964   \n",
       "9                   3.4                  3.6  167.362229   70.109981   \n",
       "10                  3.0                  2.4  158.647708   71.569838   \n",
       "11                  3.4                  1.4  211.461826   68.830440   \n",
       "12                  2.8                  3.8  179.936269   62.527557   \n",
       "13                  4.2                  4.0  155.396625  123.057881   \n",
       "14                  2.4                  3.4  155.609701   74.329517   \n",
       "15                  3.4                  3.6  192.763532   71.926042   \n",
       "16                  3.6                  3.4  190.534736   64.257534   \n",
       "\n",
       "            S2  \n",
       "0    89.041085  \n",
       "1    84.603189  \n",
       "2    71.149465  \n",
       "3    76.788336  \n",
       "4    79.034911  \n",
       "5   108.628731  \n",
       "6   112.945180  \n",
       "7    60.581103  \n",
       "8   170.765801  \n",
       "9    92.114430  \n",
       "10   69.631077  \n",
       "11  128.402428  \n",
       "12   92.158376  \n",
       "13  103.503758  \n",
       "14   74.877021  \n",
       "15   85.648863  \n",
       "16   75.678047  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.read_csv(\"../data/processed/transcript_dominance.csv\").iloc[:,:13].merge(new_)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import plotly\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "import plotly.express as px\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = 'algae'\n",
    "def correlation_heatmap(y_cols, x_cols, full_data):\n",
    "    '''\n",
    "    Uses scipy.stats.spearmanr function\n",
    "    Params:\n",
    "    y_cols, x_cols: sets of column titles (strings)\n",
    "    full_data: pandas dataframe that includes all columns listed in y_cols, x_cols\n",
    "    Returns:\n",
    "    corr: Spearman correlation coefficient matrix (y_cols = rows, x_cols = cols of matrix)\n",
    "    fig_corr: annotated plotly heatmap of coefficients\n",
    "    p: Spearman p-value matrix\n",
    "    fig_p: annotated plotly heatmap of p-values\n",
    "    '''\n",
    "    cols = y_cols+x_cols\n",
    "    all_correlations = scipy.stats.spearmanr(full_data[cols], nan_policy='omit')\n",
    "    corr = all_correlations.statistic[:len(y_cols), -len(x_cols):]\n",
    "    corr = pd.DataFrame(corr)\n",
    "    corr.columns = x_cols\n",
    "    corr.index = y_cols\n",
    "\n",
    "    p = all_correlations.pvalue[:len(y_cols), -len(x_cols):]\n",
    "    p = pd.DataFrame(p)\n",
    "    p.columns = x_cols\n",
    "    p.index = y_cols\n",
    "    \n",
    "    fig_corr = px.imshow(corr, text_auto=True, aspect='auto', color_continuous_scale='agsunset')\n",
    "    fig_r2 = px.imshow(corr**2, text_auto=True, aspect='auto', color_continuous_scale='agsunset')\n",
    "    fig_p = px.imshow(p, text_auto=True, aspect='auto', color_continuous_scale='gray_r')\n",
    "\n",
    "    return corr, fig_corr, p, fig_p, fig_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df_final):\n",
    "        corr, fig_corr, p, fig_p, fig_r2 = correlation_heatmap(col_1, col_2, df_final)\n",
    "        fig_corr.show()\n",
    "        fig_p.show()\n",
    "        fig_r2.show()\n",
    "        return corr, fig_corr, p, fig_p, fig_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z}",
         "type": "heatmap",
         "x": [
          "S1",
          "S2"
         ],
         "xaxis": "x",
         "y": [
          "speaker_1_dom_score",
          "speaker_2_dom_score"
         ],
         "yaxis": "y",
         "z": [
          [
           0.1799145922883346,
           -0.1402093029557366
          ],
          [
           -0.10657416193771789,
           0.15490430514203182
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(75, 41, 145)"
          ],
          [
           0.16666666666666666,
           "rgb(135, 44, 162)"
          ],
          [
           0.3333333333333333,
           "rgb(192, 54, 157)"
          ],
          [
           0.5,
           "rgb(234, 79, 136)"
          ],
          [
           0.6666666666666666,
           "rgb(250, 120, 118)"
          ],
          [
           0.8333333333333334,
           "rgb(246, 169, 122)"
          ],
          [
           1,
           "rgb(237, 217, 163)"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"882a3706-f3c2-44ab-91be-a175e8a1f539\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"882a3706-f3c2-44ab-91be-a175e8a1f539\")) {                    Plotly.newPlot(                        \"882a3706-f3c2-44ab-91be-a175e8a1f539\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"texttemplate\":\"%{z}\",\"x\":[\"S1\",\"S2\"],\"y\":[\"speaker_1_dom_score\",\"speaker_2_dom_score\"],\"z\":[[0.1799145922883346,-0.1402093029557366],[-0.10657416193771789,0.15490430514203182]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\"},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(75, 41, 145)\"],[0.16666666666666666,\"rgb(135, 44, 162)\"],[0.3333333333333333,\"rgb(192, 54, 157)\"],[0.5,\"rgb(234, 79, 136)\"],[0.6666666666666666,\"rgb(250, 120, 118)\"],[0.8333333333333334,\"rgb(246, 169, 122)\"],[1.0,\"rgb(237, 217, 163)\"]]},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('882a3706-f3c2-44ab-91be-a175e8a1f539');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z}",
         "type": "heatmap",
         "x": [
          "S1",
          "S2"
         ],
         "xaxis": "x",
         "y": [
          "speaker_1_dom_score",
          "speaker_2_dom_score"
         ],
         "yaxis": "y",
         "z": [
          [
           0.48958121227297136,
           0.5914557192196175
          ],
          [
           0.6839278551691783,
           0.5527530525173101
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(254, 254, 253)"
          ],
          [
           0.09090909090909091,
           "rgb(224, 224, 223)"
          ],
          [
           0.18181818181818182,
           "rgb(197, 197, 195)"
          ],
          [
           0.2727272727272727,
           "rgb(171, 171, 170)"
          ],
          [
           0.36363636363636365,
           "rgb(146, 146, 145)"
          ],
          [
           0.45454545454545453,
           "rgb(124, 123, 122)"
          ],
          [
           0.5454545454545454,
           "rgb(102, 101, 101)"
          ],
          [
           0.6363636363636364,
           "rgb(81, 80, 80)"
          ],
          [
           0.7272727272727273,
           "rgb(59, 59, 59)"
          ],
          [
           0.8181818181818182,
           "rgb(38, 38, 38)"
          ],
          [
           0.9090909090909091,
           "rgb(16, 16, 16)"
          ],
          [
           1,
           "rgb(0, 0, 0)"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"04fdcfa0-4aa2-4e32-82df-825038331015\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"04fdcfa0-4aa2-4e32-82df-825038331015\")) {                    Plotly.newPlot(                        \"04fdcfa0-4aa2-4e32-82df-825038331015\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"texttemplate\":\"%{z}\",\"x\":[\"S1\",\"S2\"],\"y\":[\"speaker_1_dom_score\",\"speaker_2_dom_score\"],\"z\":[[0.48958121227297136,0.5914557192196175],[0.6839278551691783,0.5527530525173101]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\"},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(254, 254, 253)\"],[0.09090909090909091,\"rgb(224, 224, 223)\"],[0.18181818181818182,\"rgb(197, 197, 195)\"],[0.2727272727272727,\"rgb(171, 171, 170)\"],[0.36363636363636365,\"rgb(146, 146, 145)\"],[0.45454545454545453,\"rgb(124, 123, 122)\"],[0.5454545454545454,\"rgb(102, 101, 101)\"],[0.6363636363636364,\"rgb(81, 80, 80)\"],[0.7272727272727273,\"rgb(59, 59, 59)\"],[0.8181818181818182,\"rgb(38, 38, 38)\"],[0.9090909090909091,\"rgb(16, 16, 16)\"],[1.0,\"rgb(0, 0, 0)\"]]},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('04fdcfa0-4aa2-4e32-82df-825038331015');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z}",
         "type": "heatmap",
         "x": [
          "S1",
          "S2"
         ],
         "xaxis": "x",
         "y": [
          "speaker_1_dom_score",
          "speaker_2_dom_score"
         ],
         "yaxis": "y",
         "z": [
          [
           0.03236926051827767,
           0.01965864863533353
          ],
          [
           0.011358051992726917,
           0.023995343751535708
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(75, 41, 145)"
          ],
          [
           0.16666666666666666,
           "rgb(135, 44, 162)"
          ],
          [
           0.3333333333333333,
           "rgb(192, 54, 157)"
          ],
          [
           0.5,
           "rgb(234, 79, 136)"
          ],
          [
           0.6666666666666666,
           "rgb(250, 120, 118)"
          ],
          [
           0.8333333333333334,
           "rgb(246, 169, 122)"
          ],
          [
           1,
           "rgb(237, 217, 163)"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"db14cb50-8df9-45c2-8d18-763788a23b29\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"db14cb50-8df9-45c2-8d18-763788a23b29\")) {                    Plotly.newPlot(                        \"db14cb50-8df9-45c2-8d18-763788a23b29\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"texttemplate\":\"%{z}\",\"x\":[\"S1\",\"S2\"],\"y\":[\"speaker_1_dom_score\",\"speaker_2_dom_score\"],\"z\":[[0.03236926051827767,0.01965864863533353],[0.011358051992726917,0.023995343751535708]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\"},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(75, 41, 145)\"],[0.16666666666666666,\"rgb(135, 44, 162)\"],[0.3333333333333333,\"rgb(192, 54, 157)\"],[0.5,\"rgb(234, 79, 136)\"],[0.6666666666666666,\"rgb(250, 120, 118)\"],[0.8333333333333334,\"rgb(246, 169, 122)\"],[1.0,\"rgb(237, 217, 163)\"]]},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('db14cb50-8df9-45c2-8d18-763788a23b29');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_s = final_df.iloc[:,-2:]\n",
    "X = final_df.iloc[:,-5:-3]\n",
    "col_1 = list(X.keys())\n",
    "col_2 = list(y_s.keys())\n",
    "corr, fig_corr, p, fig_p, fig_r2 = correlation(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      89.041085\n",
       "1      84.603189\n",
       "2      71.149465\n",
       "3      76.788336\n",
       "4      79.034911\n",
       "5     108.628731\n",
       "6     112.945180\n",
       "7      60.581103\n",
       "8     170.765801\n",
       "9      92.114430\n",
       "10     69.631077\n",
       "11    128.402428\n",
       "12     92.158376\n",
       "13    103.503758\n",
       "14     74.877021\n",
       "15     85.648863\n",
       "16     75.678047\n",
       "Name: S2, dtype: float64"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[:,-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1      True\n",
       "2      True\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6      True\n",
       "7      True\n",
       "8      True\n",
       "9     False\n",
       "10     True\n",
       "11     True\n",
       "12    False\n",
       "13     True\n",
       "14    False\n",
       "15    False\n",
       "16     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"speaker_1_dom_score\"]>final_df[\"speaker_2_dom_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>speaker_1_1</th>\n",
       "      <th>speaker_1_2</th>\n",
       "      <th>speaker_1_3</th>\n",
       "      <th>speaker_1_4</th>\n",
       "      <th>speaker_1_5</th>\n",
       "      <th>speaker_2_1</th>\n",
       "      <th>speaker_2_2</th>\n",
       "      <th>speaker_2_3</th>\n",
       "      <th>speaker_2_4</th>\n",
       "      <th>speaker_2_5</th>\n",
       "      <th>speaker_1_dom_score</th>\n",
       "      <th>speaker_2_dom_score</th>\n",
       "      <th>MOD</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>s1_gt_s2</th>\n",
       "      <th>s1gt_gt_s2gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>209.768309</td>\n",
       "      <td>72.504405</td>\n",
       "      <td>89.041085</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>162.487589</td>\n",
       "      <td>70.363963</td>\n",
       "      <td>84.603189</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.781212</td>\n",
       "      <td>75.410040</td>\n",
       "      <td>71.149465</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>250.002240</td>\n",
       "      <td>85.450625</td>\n",
       "      <td>76.788336</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>238.735160</td>\n",
       "      <td>79.984618</td>\n",
       "      <td>79.034911</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>106.555361</td>\n",
       "      <td>115.640200</td>\n",
       "      <td>108.628731</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>140.773029</td>\n",
       "      <td>82.463668</td>\n",
       "      <td>112.945180</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>155.410773</td>\n",
       "      <td>90.692107</td>\n",
       "      <td>60.581103</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>122.683918</td>\n",
       "      <td>131.231964</td>\n",
       "      <td>170.765801</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>167.362229</td>\n",
       "      <td>70.109981</td>\n",
       "      <td>92.114430</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>158.647708</td>\n",
       "      <td>71.569838</td>\n",
       "      <td>69.631077</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>211.461826</td>\n",
       "      <td>68.830440</td>\n",
       "      <td>128.402428</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>179.936269</td>\n",
       "      <td>62.527557</td>\n",
       "      <td>92.158376</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155.396625</td>\n",
       "      <td>123.057881</td>\n",
       "      <td>103.503758</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>155.609701</td>\n",
       "      <td>74.329517</td>\n",
       "      <td>74.877021</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>192.763532</td>\n",
       "      <td>71.926042</td>\n",
       "      <td>85.648863</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>190.534736</td>\n",
       "      <td>64.257534</td>\n",
       "      <td>75.678047</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  speaker_1_1  speaker_1_2  speaker_1_3  speaker_1_4  speaker_1_5  \\\n",
       "0        S02          3.0          2.0          2.0          2.0          1.0   \n",
       "1        S04          2.0          1.0          2.0          4.0          1.0   \n",
       "2        S05          4.0          4.0          4.0          4.0          3.0   \n",
       "3        S07          4.0          2.0          3.0          4.0          4.0   \n",
       "4        S08          4.0          2.0          3.0          2.0          1.0   \n",
       "5        S09          4.0          3.0          3.0          5.0          3.0   \n",
       "6        S10          3.0          2.0          3.0          4.0          2.0   \n",
       "7        S11          5.0          2.0          3.0          3.0          5.0   \n",
       "8        S13          3.0          1.0          2.0          4.0          2.0   \n",
       "9        S14          4.0          3.0          3.0          4.0          3.0   \n",
       "10       S17          5.0          2.0          3.0          3.0          2.0   \n",
       "11       S18          5.0          3.0          3.0          3.0          3.0   \n",
       "12       S19          4.0          3.0          3.0          2.0          2.0   \n",
       "13       S20          5.0          4.0          4.0          5.0          3.0   \n",
       "14       S21          3.0          3.0          2.0          3.0          1.0   \n",
       "15       S22          4.0          2.0          3.0          5.0          3.0   \n",
       "16       S23          4.0          4.0          3.0          5.0          2.0   \n",
       "\n",
       "    speaker_2_1  speaker_2_2  speaker_2_3  speaker_2_4  speaker_2_5  \\\n",
       "0           4.0          3.0          3.0          4.0          3.0   \n",
       "1           1.0          1.0          1.0          4.0          1.0   \n",
       "2           3.0          2.0          3.0          1.0          1.0   \n",
       "3           4.0          2.0          3.0          5.0          3.0   \n",
       "4           3.0          3.0          3.0          3.0          2.0   \n",
       "5           4.0          3.0          3.0          5.0          3.0   \n",
       "6           3.0          2.0          2.0          4.0          2.0   \n",
       "7           2.0          1.0          2.0          1.0          1.0   \n",
       "8           2.0          1.0          2.0          1.0          1.0   \n",
       "9           3.0          4.0          4.0          4.0          3.0   \n",
       "10          3.0          2.0          3.0          3.0          1.0   \n",
       "11          2.0          1.0          2.0          1.0          1.0   \n",
       "12          5.0          4.0          4.0          3.0          3.0   \n",
       "13          5.0          4.0          4.0          4.0          3.0   \n",
       "14          4.0          4.0          3.0          4.0          2.0   \n",
       "15          4.0          3.0          4.0          4.0          3.0   \n",
       "16          4.0          3.0          3.0          4.0          3.0   \n",
       "\n",
       "    speaker_1_dom_score  speaker_2_dom_score         MOD          S1  \\\n",
       "0                   2.0                  3.4  209.768309   72.504405   \n",
       "1                   2.0                  1.6  162.487589   70.363963   \n",
       "2                   3.8                  2.0  150.781212   75.410040   \n",
       "3                   3.4                  3.4  250.002240   85.450625   \n",
       "4                   2.4                  2.8  238.735160   79.984618   \n",
       "5                   3.6                  3.6  106.555361  115.640200   \n",
       "6                   2.8                  2.6  140.773029   82.463668   \n",
       "7                   3.6                  1.4  155.410773   90.692107   \n",
       "8                   2.4                  1.4  122.683918  131.231964   \n",
       "9                   3.4                  3.6  167.362229   70.109981   \n",
       "10                  3.0                  2.4  158.647708   71.569838   \n",
       "11                  3.4                  1.4  211.461826   68.830440   \n",
       "12                  2.8                  3.8  179.936269   62.527557   \n",
       "13                  4.2                  4.0  155.396625  123.057881   \n",
       "14                  2.4                  3.4  155.609701   74.329517   \n",
       "15                  3.4                  3.6  192.763532   71.926042   \n",
       "16                  3.6                  3.4  190.534736   64.257534   \n",
       "\n",
       "            S2  s1_gt_s2  s1gt_gt_s2gt  \n",
       "0    89.041085     False         False  \n",
       "1    84.603189      True         False  \n",
       "2    71.149465      True          True  \n",
       "3    76.788336     False          True  \n",
       "4    79.034911     False         False  \n",
       "5   108.628731     False          True  \n",
       "6   112.945180      True         False  \n",
       "7    60.581103      True          True  \n",
       "8   170.765801      True         False  \n",
       "9    92.114430     False         False  \n",
       "10   69.631077      True          True  \n",
       "11  128.402428      True         False  \n",
       "12   92.158376     False         False  \n",
       "13  103.503758      True          True  \n",
       "14   74.877021     False         False  \n",
       "15   85.648863     False         False  \n",
       "16   75.678047      True         False  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['s1_gt_s2'] = final_df[\"speaker_1_dom_score\"] > final_df[\"speaker_2_dom_score\"]\n",
    "final_df['s1gt_gt_s2gt'] = final_df[\"S1\"].astype(int) > final_df[\"S2\"].astype(int)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5882352941176471"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(final_df[\"s1_gt_s2\"] == final_df[\"s1gt_gt_s2gt\"])/len(final_df[\"s1_gt_s2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>speaker_1_1</th>\n",
       "      <th>speaker_1_2</th>\n",
       "      <th>speaker_1_3</th>\n",
       "      <th>speaker_1_4</th>\n",
       "      <th>speaker_1_5</th>\n",
       "      <th>speaker_2_1</th>\n",
       "      <th>speaker_2_2</th>\n",
       "      <th>speaker_2_3</th>\n",
       "      <th>speaker_2_4</th>\n",
       "      <th>speaker_2_5</th>\n",
       "      <th>speaker_1_dom_score</th>\n",
       "      <th>speaker_2_dom_score</th>\n",
       "      <th>MOD</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>s1_gt_s2</th>\n",
       "      <th>s1gt_gt_s2gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>209.768309</td>\n",
       "      <td>72.504405</td>\n",
       "      <td>89.041085</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>162.487589</td>\n",
       "      <td>70.363963</td>\n",
       "      <td>84.603189</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.781212</td>\n",
       "      <td>75.410040</td>\n",
       "      <td>71.149465</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>250.002240</td>\n",
       "      <td>85.450625</td>\n",
       "      <td>76.788336</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>238.735160</td>\n",
       "      <td>79.984618</td>\n",
       "      <td>79.034911</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>106.555361</td>\n",
       "      <td>115.640200</td>\n",
       "      <td>108.628731</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>140.773029</td>\n",
       "      <td>82.463668</td>\n",
       "      <td>112.945180</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>155.410773</td>\n",
       "      <td>90.692107</td>\n",
       "      <td>60.581103</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>122.683918</td>\n",
       "      <td>131.231964</td>\n",
       "      <td>170.765801</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>167.362229</td>\n",
       "      <td>70.109981</td>\n",
       "      <td>92.114430</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>158.647708</td>\n",
       "      <td>71.569838</td>\n",
       "      <td>69.631077</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>211.461826</td>\n",
       "      <td>68.830440</td>\n",
       "      <td>128.402428</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>179.936269</td>\n",
       "      <td>62.527557</td>\n",
       "      <td>92.158376</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155.396625</td>\n",
       "      <td>123.057881</td>\n",
       "      <td>103.503758</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>155.609701</td>\n",
       "      <td>74.329517</td>\n",
       "      <td>74.877021</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>192.763532</td>\n",
       "      <td>71.926042</td>\n",
       "      <td>85.648863</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>190.534736</td>\n",
       "      <td>64.257534</td>\n",
       "      <td>75.678047</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  speaker_1_1  speaker_1_2  speaker_1_3  speaker_1_4  speaker_1_5  \\\n",
       "0        S02          3.0          2.0          2.0          2.0          1.0   \n",
       "1        S04          2.0          1.0          2.0          4.0          1.0   \n",
       "2        S05          4.0          4.0          4.0          4.0          3.0   \n",
       "3        S07          4.0          2.0          3.0          4.0          4.0   \n",
       "4        S08          4.0          2.0          3.0          2.0          1.0   \n",
       "5        S09          4.0          3.0          3.0          5.0          3.0   \n",
       "6        S10          3.0          2.0          3.0          4.0          2.0   \n",
       "7        S11          5.0          2.0          3.0          3.0          5.0   \n",
       "8        S13          3.0          1.0          2.0          4.0          2.0   \n",
       "9        S14          4.0          3.0          3.0          4.0          3.0   \n",
       "10       S17          5.0          2.0          3.0          3.0          2.0   \n",
       "11       S18          5.0          3.0          3.0          3.0          3.0   \n",
       "12       S19          4.0          3.0          3.0          2.0          2.0   \n",
       "13       S20          5.0          4.0          4.0          5.0          3.0   \n",
       "14       S21          3.0          3.0          2.0          3.0          1.0   \n",
       "15       S22          4.0          2.0          3.0          5.0          3.0   \n",
       "16       S23          4.0          4.0          3.0          5.0          2.0   \n",
       "\n",
       "    speaker_2_1  speaker_2_2  speaker_2_3  speaker_2_4  speaker_2_5  \\\n",
       "0           4.0          3.0          3.0          4.0          3.0   \n",
       "1           1.0          1.0          1.0          4.0          1.0   \n",
       "2           3.0          2.0          3.0          1.0          1.0   \n",
       "3           4.0          2.0          3.0          5.0          3.0   \n",
       "4           3.0          3.0          3.0          3.0          2.0   \n",
       "5           4.0          3.0          3.0          5.0          3.0   \n",
       "6           3.0          2.0          2.0          4.0          2.0   \n",
       "7           2.0          1.0          2.0          1.0          1.0   \n",
       "8           2.0          1.0          2.0          1.0          1.0   \n",
       "9           3.0          4.0          4.0          4.0          3.0   \n",
       "10          3.0          2.0          3.0          3.0          1.0   \n",
       "11          2.0          1.0          2.0          1.0          1.0   \n",
       "12          5.0          4.0          4.0          3.0          3.0   \n",
       "13          5.0          4.0          4.0          4.0          3.0   \n",
       "14          4.0          4.0          3.0          4.0          2.0   \n",
       "15          4.0          3.0          4.0          4.0          3.0   \n",
       "16          4.0          3.0          3.0          4.0          3.0   \n",
       "\n",
       "    speaker_1_dom_score  speaker_2_dom_score         MOD          S1  \\\n",
       "0                   2.0                  3.4  209.768309   72.504405   \n",
       "1                   2.0                  1.6  162.487589   70.363963   \n",
       "2                   3.8                  2.0  150.781212   75.410040   \n",
       "3                   3.4                  3.4  250.002240   85.450625   \n",
       "4                   2.4                  2.8  238.735160   79.984618   \n",
       "5                   3.6                  3.6  106.555361  115.640200   \n",
       "6                   2.8                  2.6  140.773029   82.463668   \n",
       "7                   3.6                  1.4  155.410773   90.692107   \n",
       "8                   2.4                  1.4  122.683918  131.231964   \n",
       "9                   3.4                  3.6  167.362229   70.109981   \n",
       "10                  3.0                  2.4  158.647708   71.569838   \n",
       "11                  3.4                  1.4  211.461826   68.830440   \n",
       "12                  2.8                  3.8  179.936269   62.527557   \n",
       "13                  4.2                  4.0  155.396625  123.057881   \n",
       "14                  2.4                  3.4  155.609701   74.329517   \n",
       "15                  3.4                  3.6  192.763532   71.926042   \n",
       "16                  3.6                  3.4  190.534736   64.257534   \n",
       "\n",
       "            S2  s1_gt_s2  s1gt_gt_s2gt  \n",
       "0    89.041085     False         False  \n",
       "1    84.603189      True         False  \n",
       "2    71.149465      True          True  \n",
       "3    76.788336     False          True  \n",
       "4    79.034911     False          True  \n",
       "5   108.628731     False          True  \n",
       "6   112.945180      True         False  \n",
       "7    60.581103      True          True  \n",
       "8   170.765801      True         False  \n",
       "9    92.114430     False         False  \n",
       "10   69.631077      True          True  \n",
       "11  128.402428      True         False  \n",
       "12   92.158376     False         False  \n",
       "13  103.503758      True          True  \n",
       "14   74.877021     False         False  \n",
       "15   85.648863     False         False  \n",
       "16   75.678047      True         False  "
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
